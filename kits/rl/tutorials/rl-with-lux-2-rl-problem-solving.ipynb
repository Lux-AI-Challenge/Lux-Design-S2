{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/stonet2000/rl-with-lux-2-rl-problem-solving?scriptVersionId=117904280\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"## Setup Code\n\nBefore we start lets install some dependencies. This will also run some extra code that your local notebook may not need to due to how Kaggle Notebooks are setup.","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade luxai_s2\n!pip install pettingzoo==1.12.0 gym==0.21.0 stable-baselines3\n!pip install --upgrade \"importlib_metadata<5.0\"","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-02-01T04:21:29.615147Z","iopub.execute_input":"2023-02-01T04:21:29.616142Z","iopub.status.idle":"2023-02-01T04:22:54.922196Z","shell.execute_reply.started":"2023-02-01T04:21:29.615792Z","shell.execute_reply":"2023-02-01T04:22:54.92029Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting luxai_s2\n  Downloading luxai_s2-2.1.1-py3-none-any.whl (63 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m234.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from luxai_s2) (1.21.6)\nCollecting importlib-metadata<5.0\n  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from luxai_s2) (1.7.3)\nCollecting vec-noise\n  Downloading vec_noise-1.1.4.zip (134 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m134.1/134.1 kB\u001b[0m \u001b[31m582.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pettingzoo\n  Downloading PettingZoo-1.22.3-py3-none-any.whl (816 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m816.1/816.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from luxai_s2) (1.1.0)\nCollecting pygame\n  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from luxai_s2) (3.5.2)\nCollecting gym==0.21.0\n  Downloading gym-0.21.0.tar.gz (1.5 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting omegaconf\n  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym==0.21.0->luxai_s2) (2.1.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0->luxai_s2) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0->luxai_s2) (3.8.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->luxai_s2) (4.33.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->luxai_s2) (1.4.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->luxai_s2) (2.8.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->luxai_s2) (23.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->luxai_s2) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->luxai_s2) (3.0.9)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->luxai_s2) (9.1.1)\nCollecting antlr4-python3-runtime==4.9.*\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.7/site-packages (from omegaconf->luxai_s2) (6.0)\nCollecting gymnasium>=0.26.0\n  Downloading gymnasium-0.27.1-py3-none-any.whl (883 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting gymnasium-notices>=0.0.1\n  Downloading gymnasium_notices-0.0.1-py3-none-any.whl (2.8 kB)\nCollecting jax-jumpy>=0.2.0\n  Downloading jax_jumpy-0.2.0-py3-none-any.whl (11 kB)\nCollecting typing-extensions>=3.6.4\n  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->luxai_s2) (1.15.0)\nBuilding wheels for collected packages: gym, antlr4-python3-runtime, vec-noise\n  Building wheel for gym (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616824 sha256=d8c5b618843dacabb8ecd25b1e58be526c37d7cd768d9355e68f109e405a1870\n  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=9ab290b640a1487182b494b1caf6b85528c72b83181874fa7172c2ac393d1575\n  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n  Building wheel for vec-noise (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for vec-noise: filename=vec_noise-1.1.4-cp37-cp37m-linux_x86_64.whl size=85824 sha256=ebb80a7ced4c42233134fe136c6d689475f9580c5b19fac3901fe93732b1ee58\n  Stored in directory: /root/.cache/pip/wheels/fc/0c/19/5932b4834cf3204ed2ae845e788f07c79b3279c302d55d6fa8\nSuccessfully built gym antlr4-python3-runtime vec-noise\nInstalling collected packages: gymnasium-notices, antlr4-python3-runtime, vec-noise, typing-extensions, pygame, omegaconf, jax-jumpy, importlib-metadata, gymnasium, gym, pettingzoo, luxai_s2\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.1.1\n    Uninstalling typing_extensions-4.1.1:\n      Successfully uninstalled typing_extensions-4.1.1\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 6.0.0\n    Uninstalling importlib-metadata-6.0.0:\n      Successfully uninstalled importlib-metadata-6.0.0\n  Attempting uninstall: gym\n    Found existing installation: gym 0.26.2\n    Uninstalling gym-0.26.2:\n      Successfully uninstalled gym-0.26.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nthinc 8.0.17 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\ntensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible.\ntensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.4.0 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\nspacy 3.3.2 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.2 which is incompatible.\nflake8 5.0.4 requires importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\ncmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 4.13.0 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\naiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.54 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 gym-0.21.0 gymnasium-0.27.1 gymnasium-notices-0.0.1 importlib-metadata-4.13.0 jax-jumpy-0.2.0 luxai_s2-2.1.1 omegaconf-2.3.0 pettingzoo-1.22.3 pygame-2.1.2 typing-extensions-4.4.0 vec-noise-1.1.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pettingzoo==1.12.0\n  Downloading PettingZoo-1.12.0.tar.gz (756 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m756.1/756.1 kB\u001b[0m \u001b[31m990.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: gym==0.21.0 in /opt/conda/lib/python3.7/site-packages (0.21.0)\nCollecting stable-baselines3\n  Downloading stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m171.8/171.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.7/site-packages (from pettingzoo==1.12.0) (1.21.6)\nRequirement already satisfied: importlib-metadata>=4.8.1 in /opt/conda/lib/python3.7/site-packages (from gym==0.21.0) (4.13.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from gym==0.21.0) (2.1.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from stable-baselines3) (3.5.2)\nRequirement already satisfied: typing-extensions<5,>=4.0 in /opt/conda/lib/python3.7/site-packages (from stable-baselines3) (4.4.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from stable-baselines3) (1.3.5)\nRequirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.7/site-packages (from stable-baselines3) (1.11.0+cpu)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.8.1->gym==0.21.0) (3.8.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3) (9.1.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3) (1.4.3)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3) (23.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3) (4.33.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->stable-baselines3) (0.11.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->stable-baselines3) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.15.0)\nBuilding wheels for collected packages: pettingzoo\n  Building wheel for pettingzoo (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pettingzoo: filename=PettingZoo-1.12.0-py3-none-any.whl size=873583 sha256=d39e40e98294745d02210909cf7e4eb7db138316da0569a2809ea4086ef69583\n  Stored in directory: /root/.cache/pip/wheels/50/1d/da/6a09fdb8c06333aa981d1239e40cc8aa5cbac80b30498b1e85\nSuccessfully built pettingzoo\nInstalling collected packages: stable-baselines3, pettingzoo\n  Attempting uninstall: pettingzoo\n    Found existing installation: PettingZoo 1.22.3\n    Uninstalling PettingZoo-1.22.3:\n      Successfully uninstalled PettingZoo-1.22.3\nSuccessfully installed pettingzoo-1.12.0 stable-baselines3-1.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: importlib_metadata<5.0 in /opt/conda/lib/python3.7/site-packages (4.13.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib_metadata<5.0) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib_metadata<5.0) (4.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile /opt/conda/lib/python3.7/site-packages/luxai_s2/version.py\n__version__ = \"\"\n# this code above is used for Kaggle Notebooks\n# You might not need to run this but if you get an attribute error about the gym package, run it","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-02-01T04:22:54.926526Z","iopub.execute_input":"2023-02-01T04:22:54.927102Z","iopub.status.idle":"2023-02-01T04:22:54.937617Z","shell.execute_reply.started":"2023-02-01T04:22:54.927055Z","shell.execute_reply":"2023-02-01T04:22:54.935941Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Overwriting /opt/conda/lib/python3.7/site-packages/luxai_s2/version.py\n","output_type":"stream"}]},{"cell_type":"code","source":"import importlib\nimport importlib_metadata\n# kaggle has 6.0.0 installed but we need version <5.0\nimportlib.reload(importlib_metadata)\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-02-01T04:22:54.940164Z","iopub.execute_input":"2023-02-01T04:22:54.941173Z","iopub.status.idle":"2023-02-01T04:22:55.267001Z","shell.execute_reply.started":"2023-02-01T04:22:54.941101Z","shell.execute_reply":"2023-02-01T04:22:55.265127Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<module 'importlib_metadata' from '/opt/conda/lib/python3.7/site-packages/importlib_metadata/__init__.py'>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Reinforcement Learning for Lux AI Season 2 洟暴n\nPart 2 of the RL series will now dig into building a working RL agent for the Lux AI Challenge, Season 2!\n\nLux AI is designed to be intuitive to understand, but heavily layered in complexity and interactions of game mechanics in an multi-agent cooperative and competitive environment. \n\nLux AI Season 2's rules can be found here: https://www.lux-ai.org/specs-s2. Make sure to read them to learn how to the game works, and the rest of this tutorial will be much easier to understand.\n\nPart 1 of the series covered the single-agent RL setup, but Lux AI Season 2 is multi-agent! Moreover, the environment has different phases and a complex action space which makes it difficult to learn or use of the box. \n\nThis tutorial will cover simple tools and tricks on how to reduce a complex problem into a easier one! We will primarily focus on three things: \n\n1. Simplifying the action space with controllers/action wrappers\n2. Simplifying observations\n3. Transforming the three phase Lux AI game into a single phase game\n\nThis starter kit is also implemented in https://github.com/Lux-AI-Challenge/Lux-Design-S2/tree/main/kits/rl/sb3\n\nWe highly **recommend running this code on a GPU** as RL training can be fairly slow and needs good tuning.\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Simplifying the Action Space\n\nThe action space is quite complicated in Lux S2 as each robot can move, dig, transfer/pickup, all in addition to being able to combine any sequence of these primitives into an action queue of up to length 20. For machine learning, such a massive action space leads to the [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality), making any ML algorithm have a much harder time to learn something useful, especially in RL.\n\nTo handle this, we can program a custom Controller that translates actions from one action space to the original action space and adds a few tricks and heuristics to be integrated with RL training. Since the original lux action space is large, this controller can be a little complicated. For those who want to dive straight into training you can use the controller as is. \n\nFor a high-level overview this controller will\n- Define a massively simplified action space\n- Translate actions from the discrete action space into the Lux S2 action space `action_to_lux_action`\n- Add a heuristic factory action to build one Heavy robot\n- Generate action masks where False = an action is invalid\n\nOverall, the action space of the controller is a discrete action space with just 12 dimensions to control just one heavy robot. It allows for a robot's 4 directional movement, transferring ice in 4 directions in addition to center, picking up power, digging, and a no-op action. This doesn't include factory actions, self destruct, recharging, transferring other types of resources, or longer planned action queues in the action space, which are all open problems for you to potentially tackle!\n\nThe controller also includes a trick to allow agents to reduce power costs incurred by action queue updates. The controller skips updating action queues if the existing action queue is the same as the new one the agent wants to use for the robot.\n\nWhile this simplification doesn't include adding in more complex things like more heavy robots or planting lichen, it will train out a succesful policy that with simple modifications, will beat the majority of bots using the rule-based starter kits.\n\nMore advanced usages can consider how to model the actions of different types of units on a game board (e.g. heavy, light, or factory) by using a MultiDiscrete action space. A more practical and likely winning solution can be to use a image-like controller by generating actions for each tile on the board and only using the actions with friendly units on that tile. See [Season 1's solution by ToadBrigade](https://www.kaggle.com/competitions/lux-ai-2021/discussion/294993) and our previous [research paper: Emergent Collective Intelligence from Massive-Agent Cooperation and Competition](https://arxiv.org/abs/2301.01609) for how a image-like controller can work.\n","metadata":{"tags":[]}},{"cell_type":"code","source":"import sys\nfrom typing import Any, Dict\n\nimport numpy as np\nimport numpy.typing as npt\nfrom gym import spaces\n\n\n# Controller class copied here since you won't have access to the luxai_s2 package directly on the competition server\nclass Controller:\n    def __init__(self, action_space: spaces.Space) -> None:\n        self.action_space = action_space\n\n    def action_to_lux_action(\n        self, agent: str, obs: Dict[str, Any], action: npt.NDArray\n    ):\n        \"\"\"\n        Takes as input the current \"raw observation\" and the parameterized action and returns\n        an action formatted for the Lux env\n        \"\"\"\n        raise NotImplementedError()\n\n    def action_masks(self, agent: str, obs: Dict[str, Any]):\n        \"\"\"\n        Generates a boolean action mask indicating in each discrete dimension whether it would be valid or not\n        \"\"\"\n        raise NotImplementedError()\n\n\nclass SimpleUnitDiscreteController(Controller):\n    def __init__(self, env_cfg) -> None:\n        \"\"\"\n        A simple controller that controls only the robot that will get spawned.\n        Moreover, it will always try to spawn one heavy robot if there are none regardless of action given\n\n        For the robot unit\n        - 4 cardinal direction movement (4 dims)\n        - a move center no-op action (1 dim)\n        - transfer action just for transferring ice in 4 cardinal directions or center (5)\n        - pickup action for power (1 dims)\n        - dig action (1 dim)\n        - no op action (1 dim) - equivalent to not submitting an action queue which costs power\n\n        It does not include\n        - self destruct action\n        - recharge action\n        - planning (via actions executing multiple times or repeating actions)\n        - factory actions\n        - transferring power or resources other than ice\n\n        To help understand how to this controller works to map one action space to the original lux action space,\n        see how the lux action space is defined in luxai_s2/spaces/action.py\n\n        \"\"\"\n        self.env_cfg = env_cfg\n        self.move_act_dims = 4\n        self.transfer_act_dims = 5\n        self.pickup_act_dims = 1\n        self.dig_act_dims = 1\n        self.no_op_dims = 1\n\n        self.move_dim_high = self.move_act_dims\n        self.transfer_dim_high = self.move_dim_high + self.transfer_act_dims\n        self.pickup_dim_high = self.transfer_dim_high + self.pickup_act_dims\n        self.dig_dim_high = self.pickup_dim_high + self.dig_act_dims\n        self.no_op_dim_high = self.dig_dim_high + self.no_op_dims\n\n        self.total_act_dims = self.no_op_dim_high\n        action_space = spaces.Discrete(self.total_act_dims)\n        super().__init__(action_space)\n\n    def _is_move_action(self, id):\n        return id < self.move_dim_high\n\n    def _get_move_action(self, id):\n        # move direction is id + 1 since we don't allow move center here\n        return np.array([0, id + 1, 0, 0, 0, 1])\n\n    def _is_transfer_action(self, id):\n        return id < self.transfer_dim_high\n\n    def _get_transfer_action(self, id):\n        id = id - self.move_dim_high\n        transfer_dir = id % 5\n        return np.array([1, transfer_dir, 0, self.env_cfg.max_transfer_amount, 0, 1])\n\n    def _is_pickup_action(self, id):\n        return id < self.pickup_dim_high\n\n    def _get_pickup_action(self, id):\n        return np.array([2, 0, 4, self.env_cfg.max_transfer_amount, 0, 1])\n\n    def _is_dig_action(self, id):\n        return id < self.dig_dim_high\n\n    def _get_dig_action(self, id):\n        return np.array([3, 0, 0, 0, 0, 1])\n\n    def action_to_lux_action(\n        self, agent: str, obs: Dict[str, Any], action: npt.NDArray\n    ):\n        shared_obs = obs[\"player_0\"]\n        lux_action = dict()\n        units = shared_obs[\"units\"][agent]\n        for unit_id in units.keys():\n            unit = units[unit_id]\n            choice = action\n            action_queue = []\n            no_op = False\n            if self._is_move_action(choice):\n                action_queue = [self._get_move_action(choice)]\n            elif self._is_transfer_action(choice):\n                action_queue = [self._get_transfer_action(choice)]\n            elif self._is_pickup_action(choice):\n                action_queue = [self._get_pickup_action(choice)]\n            elif self._is_dig_action(choice):\n                action_queue = [self._get_dig_action(choice)]\n            else:\n                # action is a no_op, so we don't update the action queue\n                no_op = True\n\n            # simple trick to help agents conserve power is to avoid updating the action queue\n            # if the agent was previously trying to do that particular action already\n            if len(unit[\"action_queue\"]) > 0 and len(action_queue) > 0:\n                same_actions = (unit[\"action_queue\"][0] == action_queue[0]).all()\n                if same_actions:\n                    no_op = True\n            if not no_op:\n                lux_action[unit_id] = action_queue\n\n            break\n\n        factories = shared_obs[\"factories\"][agent]\n        if len(units) == 0:\n            for unit_id in factories.keys():\n                lux_action[unit_id] = 1  # build a single heavy\n\n        return lux_action\n\n    def action_masks(self, agent: str, obs: Dict[str, Any]):\n        \"\"\"\n        Defines a simplified action mask for this controller's action space\n\n        Doesn't account for whether robot has enough power\n        \"\"\"\n\n        # compute a factory occupancy map that will be useful for checking if a board tile\n        # has a factory and which team's factory it is.\n        shared_obs = obs[agent]\n        factory_occupancy_map = (\n            np.ones_like(shared_obs[\"board\"][\"rubble\"], dtype=int) * -1\n        )\n        factories = dict()\n        for player in shared_obs[\"factories\"]:\n            factories[player] = dict()\n            for unit_id in shared_obs[\"factories\"][player]:\n                f_data = shared_obs[\"factories\"][player][unit_id]\n                f_pos = f_data[\"pos\"]\n                # store in a 3x3 space around the factory position it's strain id.\n                factory_occupancy_map[\n                    f_pos[0] - 1 : f_pos[0] + 2, f_pos[1] - 1 : f_pos[1] + 2\n                ] = f_data[\"strain_id\"]\n\n        units = shared_obs[\"units\"][agent]\n        action_mask = np.zeros((self.total_act_dims), dtype=bool)\n        for unit_id in units.keys():\n            action_mask = np.zeros(self.total_act_dims)\n            # movement is always valid\n            action_mask[:4] = True\n\n            # transferring is valid only if the target exists\n            unit = units[unit_id]\n            pos = np.array(unit[\"pos\"])\n            # a[1] = direction (0 = center, 1 = up, 2 = right, 3 = down, 4 = left)\n            move_deltas = np.array([[0, 0], [0, -1], [1, 0], [0, 1], [-1, 0]])\n            for i, move_delta in enumerate(move_deltas):\n                transfer_pos = np.array(\n                    [pos[0] + move_delta[0], pos[1] + move_delta[1]]\n                )\n                # check if theres a factory tile there\n                if (\n                    transfer_pos[0] < 0\n                    or transfer_pos[1] < 0\n                    or transfer_pos[0] >= len(factory_occupancy_map)\n                    or transfer_pos[1] >= len(factory_occupancy_map[0])\n                ):\n                    continue\n                factory_there = factory_occupancy_map[transfer_pos[0], transfer_pos[1]]\n                if factory_there in shared_obs[\"teams\"][agent][\"factory_strains\"]:\n                    action_mask[\n                        self.transfer_dim_high - self.transfer_act_dims + i\n                    ] = True\n\n            factory_there = factory_occupancy_map[pos[0], pos[1]]\n            on_top_of_factory = (\n                factory_there in shared_obs[\"teams\"][agent][\"factory_strains\"]\n            )\n\n            # dig is valid only if on top of tile with rubble or resources or lichen\n            board_sum = (\n                shared_obs[\"board\"][\"ice\"][pos[0], pos[1]]\n                + shared_obs[\"board\"][\"ore\"][pos[0], pos[1]]\n                + shared_obs[\"board\"][\"rubble\"][pos[0], pos[1]]\n                + shared_obs[\"board\"][\"lichen\"][pos[0], pos[1]]\n            )\n            if board_sum > 0 and not on_top_of_factory:\n                action_mask[\n                    self.dig_dim_high - self.dig_act_dims : self.dig_dim_high\n                ] = True\n\n            # pickup is valid only if on top of factory tile\n            if on_top_of_factory:\n                action_mask[\n                    self.pickup_dim_high - self.pickup_act_dims : self.pickup_dim_high\n                ] = True\n                action_mask[\n                    self.dig_dim_high - self.dig_act_dims : self.dig_dim_high\n                ] = False\n\n            # no-op is always valid\n            action_mask[-1] = True\n            break\n        return action_mask\n","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:22:55.271032Z","iopub.execute_input":"2023-02-01T04:22:55.271927Z","iopub.status.idle":"2023-02-01T04:22:55.632256Z","shell.execute_reply.started":"2023-02-01T04:22:55.271856Z","shell.execute_reply":"2023-02-01T04:22:55.630975Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 2. Simplifying the Observation Space\n\nLux S2 is fully observable which means you can see everything on the map, the opponents units etc. However, this is very high dimensional and not necessarily easy to learn from due to the curse of dimensionality (again!). We want to simplify this observation space in a way that contains sufficient information to learn a good policy but is also easy to learn from.\n\nFor this tutorial, we will create a state-based observation space (no image like features e.g. the rubble, ice, ore maps) with some feature engineering that includes useful information such as the distance to the closest factory and ice tile. The wrapper we provide below will use the `gym.ObservationWrapper` interface. Note that since we are focusing on just controlling one heavy robot, the observation wrapper is written to only support one heavy robot (and returns 0 if there are none).\n\n\nMore advanced solutions can look into using the full set of observations and designing the appropriate neural net architecture to process them. One idea would be to use convolutional neural networks to process board features like images. See [Season 1's solution by ToadBrigade](https://www.kaggle.com/competitions/lux-ai-2021/discussion/294993) and our previous [research paper: Emergent Collective Intelligence from Massive-Agent Cooperation and Competition](https://arxiv.org/abs/2301.01609) for example architectures and feature engineering choices.\n","metadata":{"tags":[]}},{"cell_type":"code","source":"from typing import Any, Dict\n\nimport gym\nimport numpy as np\nimport numpy.typing as npt\nfrom gym import spaces\n\n\nclass SimpleUnitObservationWrapper(gym.ObservationWrapper):\n    \"\"\"\n    A simple state based observation to work with in pair with the SimpleUnitDiscreteController\n\n    It contains info only on the first robot, the first factory you own, and some useful features. If there are no owned robots the observation is just zero.\n    No information about the opponent is included. This will generate observations for all teams.\n\n    Included features:\n    - First robot's stats\n    - distance vector to closest ice tile\n    - distance vector to first factory\n\n    \"\"\"\n\n    def __init__(self, env: gym.Env) -> None:\n        super().__init__(env)\n        self.observation_space = spaces.Box(-999, 999, shape=(13,))\n\n    def observation(self, obs):\n        return SimpleUnitObservationWrapper.convert_obs(obs, self.env.state.env_cfg)\n\n    # we make this method static so the submission/evaluation code can use this as well\n    @staticmethod\n    def convert_obs(obs: Dict[str, Any], env_cfg: Any) -> Dict[str, npt.NDArray]:\n        observation = dict()\n        shared_obs = obs[\"player_0\"]\n        ice_map = shared_obs[\"board\"][\"ice\"]\n        ice_tile_locations = np.argwhere(ice_map == 1)\n\n        for agent in obs.keys():\n            obs_vec = np.zeros(\n                13,\n            )\n\n            factories = shared_obs[\"factories\"][agent]\n            factory_vec = np.zeros(2)\n            for k in factories.keys():\n                # here we track a normalized position of the first friendly factory\n                factory = factories[k]\n                factory_vec = np.array(factory[\"pos\"]) / env_cfg.map_size\n                break\n            units = shared_obs[\"units\"][agent]\n            for k in units.keys():\n                unit = units[k]\n\n                # store cargo+power values scaled to [0, 1]\n                cargo_space = env_cfg.ROBOTS[unit[\"unit_type\"]].CARGO_SPACE\n                battery_cap = env_cfg.ROBOTS[unit[\"unit_type\"]].BATTERY_CAPACITY\n                cargo_vec = np.array(\n                    [\n                        unit[\"power\"] / battery_cap,\n                        unit[\"cargo\"][\"ice\"] / cargo_space,\n                        unit[\"cargo\"][\"ore\"] / cargo_space,\n                        unit[\"cargo\"][\"water\"] / cargo_space,\n                        unit[\"cargo\"][\"metal\"] / cargo_space,\n                    ]\n                )\n                unit_type = (\n                    0 if unit[\"unit_type\"] == \"LIGHT\" else 1\n                )  # note that build actions use 0 to encode Light\n                # normalize the unit position\n                pos = np.array(unit[\"pos\"]) / env_cfg.map_size\n                unit_vec = np.concatenate(\n                    [pos, [unit_type], cargo_vec, [unit[\"team_id\"]]], axis=-1\n                )\n\n                # we add some engineered features down here\n                # compute closest ice tile\n                ice_tile_distances = np.mean(\n                    (ice_tile_locations - np.array(unit[\"pos\"])) ** 2, 1\n                )\n                # normalize the ice tile location\n                closest_ice_tile = (\n                    ice_tile_locations[np.argmin(ice_tile_distances)] / env_cfg.map_size\n                )\n                obs_vec = np.concatenate(\n                    [unit_vec, factory_vec - pos, closest_ice_tile - pos], axis=-1\n                )\n                break\n            observation[agent] = obs_vec\n\n        return observation","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:22:55.634276Z","iopub.execute_input":"2023-02-01T04:22:55.634671Z","iopub.status.idle":"2023-02-01T04:22:55.653172Z","shell.execute_reply.started":"2023-02-01T04:22:55.634634Z","shell.execute_reply":"2023-02-01T04:22:55.651209Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## 3. Transforming Lux S2 into a Single Phase\n\nNormally RL frameworks like Stable Baselines 3, RLlib, Tianshou etc. expect the action space and observation space to be consistent throughout an episode. Lux S2 does not conform to this as we add some additional complexity like bidding and factory placement phases. A simple way to get around this is to **upgrade the reset function.**\n\nPreviously we saw that `env.reset()` resets an environment to a clean slate. We will upgrade this function by building a environment wrapper that not only resets to the clean slate, but also handles the bidding and factory placement phases so effectively agents that are learning start from game states with factories already placed.\n\nBelow will build a wrapper that works with the SB3 package. To do this, we want to provide the wrapper a bidding policy and factory placement policy which will be used by all teams to handle the first two phases in the reset function. The code below does just that by overriding the environment's reset function in the wrapper. \n\nFurthermore, we want to use the Controller we defined earlier, so that is also an argument to the SB3Wrapper and we use it to transform actions inside the `env.step` function","metadata":{"tags":[]}},{"cell_type":"code","source":"from typing import Callable, Dict\n\nimport gym\nimport numpy as np\nimport numpy.typing as npt\nfrom gym import spaces\n\nimport luxai_s2.env\nfrom luxai_s2.env import LuxAI_S2\nfrom luxai_s2.state import ObservationStateDict\nfrom luxai_s2.unit import ActionType, BidActionType, FactoryPlacementActionType\nfrom luxai_s2.utils import my_turn_to_place_factory\nfrom luxai_s2.wrappers.controllers import (\n    Controller,\n)\n\n\nclass SB3Wrapper(gym.Wrapper):\n    def __init__(\n        self,\n        env: LuxAI_S2,\n        bid_policy: Callable[\n            [str, ObservationStateDict], Dict[str, BidActionType]\n        ] = None,\n        factory_placement_policy: Callable[\n            [str, ObservationStateDict], Dict[str, FactoryPlacementActionType]\n        ] = None,\n        controller: Controller = None,\n    ) -> None:\n        \"\"\"\n        A environment wrapper for Stable Baselines 3. It reduces the LuxAI_S2 env\n        into a single phase game and places the first two phases (bidding and factory placement) into the env.reset function so that\n        interacting agents directly start generating actions to play the third phase of the game.\n\n        It also accepts a Controller that translates action's in one action space to a Lux S2 compatible action\n\n        Parameters\n        ----------\n        bid_policy: Function\n            A function accepting player: str and obs: ObservationStateDict as input that returns a bid action\n            such as dict(bid=10, faction=\"AlphaStrike\"). By default will bid 0\n        factory_placement_policy: Function\n            A function accepting player: str and obs: ObservationStateDict as input that returns a factory placement action\n            such as dict(spawn=np.array([2, 4]), metal=150, water=150). By default will spawn in a random valid location with metal=150, water=150\n        controller : Controller\n            A controller that parameterizes the action space into something more usable and converts parameterized actions to lux actions.\n            See luxai_s2/wrappers/controllers.py for available controllers and how to make your own\n        \"\"\"\n        gym.Wrapper.__init__(self, env)\n        self.env = env\n        \n        assert controller is not None\n        \n        # set our controller and replace the action space\n        self.controller = controller\n        self.action_space = controller.action_space\n\n        # The simplified wrapper removes the first two phases of the game by using predefined policies (trained or heuristic)\n        # to handle those two phases during each reset\n        if factory_placement_policy is None:\n            def factory_placement_policy(player, obs: ObservationStateDict):\n                potential_spawns = np.array(\n                    list(zip(*np.where(obs[\"board\"][\"valid_spawns_mask\"] == 1)))\n                )\n                spawn_loc = potential_spawns[\n                    np.random.randint(0, len(potential_spawns))\n                ]\n                return dict(spawn=spawn_loc, metal=150, water=150)\n\n        self.factory_placement_policy = factory_placement_policy\n        if bid_policy is None:\n            def bid_policy(player, obs: ObservationStateDict):\n                faction = \"AlphaStrike\"\n                if player == \"player_1\":\n                    faction = \"MotherMars\"\n                return dict(bid=0, faction=faction)\n\n        self.bid_policy = bid_policy\n\n        self.prev_obs = None\n\n    def step(self, action: Dict[str, npt.NDArray]):\n        \n        # here, for each agent in the game we translate their action into a Lux S2 action\n        lux_action = dict()\n        for agent in self.env.agents:\n            if agent in action:\n                lux_action[agent] = self.controller.action_to_lux_action(\n                    agent=agent, obs=self.prev_obs, action=action[agent]\n                )\n            else:\n                lux_action[agent] = dict()\n        \n        # lux_action is now a dict mapping agent name to an action\n        obs, reward, done, info = self.env.step(lux_action)\n        self.prev_obs = obs\n        return obs, reward, done, info\n\n    def reset(self, **kwargs):\n        # we upgrade the reset function here\n        \n        # we call the original reset function first\n        obs = self.env.reset(**kwargs)\n        \n        # then use the bid policy to go through the bidding phase\n        action = dict()\n        for agent in self.env.agents:\n            action[agent] = self.bid_policy(agent, obs[agent])\n        obs, _, _, _ = self.env.step(action)\n        \n        # while real_env_steps < 0, we are in the factory placement phase\n        # so we use the factory placement policy to step through this\n        while self.env.state.real_env_steps < 0:\n            action = dict()\n            for agent in self.env.agents:\n                if my_turn_to_place_factory(\n                    obs[\"player_0\"][\"teams\"][agent][\"place_first\"],\n                    self.env.state.env_steps,\n                ):\n                    action[agent] = self.factory_placement_policy(agent, obs[agent])\n                else:\n                    action[agent] = dict()\n            obs, _, _, _ = self.env.step(action)\n        self.prev_obs = obs\n        \n        return obs\n","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:22:55.655298Z","iopub.execute_input":"2023-02-01T04:22:55.655836Z","iopub.status.idle":"2023-02-01T04:22:56.066925Z","shell.execute_reply.started":"2023-02-01T04:22:55.655762Z","shell.execute_reply":"2023-02-01T04:22:56.065634Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"pygame 2.1.2 (SDL 2.0.16, Python 3.7.12)\nHello from the pygame community. https://www.pygame.org/contribute.html\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Defining a Bid and Factory Placement policy\n\nTo test the code above, we can program some heuristic bid and factory placement policies","metadata":{}},{"cell_type":"code","source":"def zero_bid(player, obs):\n    # a policy that always bids 0\n    faction = \"AlphaStrike\"\n    if player == \"player_1\":\n        faction = \"MotherMars\"\n    return dict(bid=0, faction=faction)\n\ndef place_near_random_ice(player, obs):\n    \"\"\"\n    This policy will place a single factory with all the starting resources\n    near a random ice tile\n    \"\"\"\n    if obs[\"teams\"][player][\"metal\"] == 0:\n        return dict()\n    potential_spawns = list(zip(*np.where(obs[\"board\"][\"valid_spawns_mask\"] == 1)))\n    potential_spawns_set = set(potential_spawns)\n    done_search = False\n    \n    # simple numpy trick to find locations adjacent to ice tiles.\n    ice_diff = np.diff(obs[\"board\"][\"ice\"])\n    pot_ice_spots = np.argwhere(ice_diff == 1)\n    if len(pot_ice_spots) == 0:\n        pot_ice_spots = potential_spawns\n    \n    # pick a random ice spot and search around it for spawnable locations.\n    trials = 5\n    while trials > 0:\n        pos_idx = np.random.randint(0, len(pot_ice_spots))\n        pos = pot_ice_spots[pos_idx]\n        area = 3\n        for x in range(area):\n            for y in range(area):\n                check_pos = [pos[0] + x - area // 2, pos[1] + y - area // 2]\n                if tuple(check_pos) in potential_spawns_set:\n                    done_search = True\n                    pos = check_pos\n                    break\n            if done_search:\n                break\n        if done_search:\n            break\n        trials -= 1\n    \n    if not done_search:\n        spawn_loc = potential_spawns[np.random.randint(0, len(potential_spawns))]\n        pos = spawn_loc\n    \n    # this will spawn a factory at pos and with all the starting metal and water\n    metal = obs[\"teams\"][player][\"metal\"]\n    return dict(spawn=pos, metal=metal, water=metal)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:22:56.068839Z","iopub.execute_input":"2023-02-01T04:22:56.069505Z","iopub.status.idle":"2023-02-01T04:22:56.083026Z","shell.execute_reply.started":"2023-02-01T04:22:56.069467Z","shell.execute_reply":"2023-02-01T04:22:56.081767Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"So **without the wrapper**, when we reset the environment it looks like this:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nenv = gym.make(\"LuxAI_S2-v0\")\nenv.reset(seed=0)\nimg = env.render(\"rgb_array\")\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:22:56.08455Z","iopub.execute_input":"2023-02-01T04:22:56.085367Z","iopub.status.idle":"2023-02-01T04:22:56.439449Z","shell.execute_reply.started":"2023-02-01T04:22:56.085321Z","shell.execute_reply":"2023-02-01T04:22:56.438006Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f24177200d0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"**With the wrapper**, when we reset the environment it looks like this:","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nenv = gym.make(\"LuxAI_S2-v0\")\nenv = SB3Wrapper(env, zero_bid, place_near_random_ice, controller=SimpleUnitDiscreteController(env.env_cfg))\nenv.reset(seed=0)\nimg = env.render(\"rgb_array\")\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:22:56.440958Z","iopub.execute_input":"2023-02-01T04:22:56.441342Z","iopub.status.idle":"2023-02-01T04:22:57.807643Z","shell.execute_reply.started":"2023-02-01T04:22:56.441305Z","shell.execute_reply":"2023-02-01T04:22:57.805392Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f2417a46350>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8v0lEQVR4nO19abAk11XmdzJrfVv361UttaSWZEm2ZOQ2ksFgsA0GW9jjkYkJCBEBVgyOgZjBAUTwAwMRAxMOxwCD4cfE4MAePGhmvODAeCwmBFhW2DjskbXYkuzWvrXVm3p9r99Sa+Y98yOzKvMuVZmVlfVqu5/itSpv3S23U/d89yzEzLCwsJhfOOOegIWFxXhhhYCFxZzDCgELizmHFQIWFnMOKwQsLOYcVghYWMw5RiYEiOhOInqOiF4koo+MahwLC4vhQKOwEyAiF8DzAH4WwEkAjwL4JWZ+OvfBLCwshsKoVgI/AuBFZn6ZmVsAPg/grhGNZWFhMQQKI+r3KgAnYscnAfxor8qrlSJfuVwZ0VSGBzPgCSGX5dg/5dhX33EIcB1HGs8XDG01mHpC1OcoHRwi0JAXgMN/1HuSqtuduvgTMPzTF7YuMPN+tXxUQsB0btI9IqJfA/BrAHBoqYzPfuD2EU1leHi+wPmtmlSWpxpFGd4CArSXhwyXPV6n4DjYtVCBEyvcbDTR9HxtPmpPpimqtfT56OemtqmWCnCd4RakzAyfGUK5JwT9QdTmk/LSm65tHshy77Pi6H//lx+YykelDpwEcHXs+DCA0/EKzPxJZr6Dme9YrRRHNA0LC4skjEoIPArgRiK6johKAO4GcN+IxrKwsBgCI1EHmNkjog8D+GcALoBPM/NToxhrpzBKb0tT33ktE+NdC2bUW23pe5XrMKHoOtqSPYu6IJjhC/lcPSG0ZbwK13EkFSYtxqzuTw1GxQmAme8HcP+o+rcYHL5g1BQhACQLnILjoFIc/lHxhIAvZP7B84WBN5DhEKVX3hVk41tGM9akuu2PTAhYTCaYs71PO0lgWewsrNmwhcWcw64EUkLVSZk5V1uBSYKjbvXltAogw0I7bde6LcOoNu3mD1YIpIDrEPYuVaWyrUYL9bY3sjHVh159ERky6QcADhkIxgFfFYcIS+WSNF4WUs4E1yFUSvIj1/J8iRgkBOcWH7/tC+ksHIdQcJzMPMGokHTP0rQxgUAjZTmtEEgBIkLRdaWyvF6MSQMR4JIDR10O5NI3wY1dN9MLwNCfd1aIjAnl16YWlhOwsJhzWCFgYTHnmBl1gJnRVPRLE8oFd2hbdaCjk+/MupSIEscKdGl9v51Jt6ePL7hVQ6BgT364+eaB+KyHmU4WPT0v5PV8sMk7KgXSnuvsCAEAW80W2n5/C7g9i1W4U7b+YeZkQ5Qe5UmPQaVYQKU4m74bJn7BQseUvQ4WFhZ5wwoBC4s5x8yoAx3E9TCjX3xO45h81U1797mMRT30S4p/1HmDoB3J1SnfgCg7BgNJMCpOxtTrNKoVaa/PTAkB9ZyLjoOValkqK+RECCxWSqiWIl3aFwJr2w2Mwo7Q+P53rGo6daDzBtxDKTbYFE084tdVCEbLcJ3zI/1mRQykw0wJARUOBez3KBjhguNIypTn76wZaxpHIFUGMEIBECucBsMb03mo7+lO225RgtHTNMFyAhYWcw4rBCws5hwzow4QOoZA0TKttMMGAQz05wRyXDUGpF+/At3IKDAekut5vkAz5ggV+EmMRoUywXVI4iiYgwhEUOadZr2vnisQnm+sTCaOO8MkBUydXT4AmCEhAADLldLYxubuf/3q5AdVtwczHMN+haS7Qteva6225A1ZcAi7Fyo7JgRUxyxfMJre4N6ZKkeSxniqIw9SnWq/OomxtXcAQ9yuoYQAER0HsAnAB+Ax8x1EtAfA3wI4AuA4gF9k5rVhxkk5l1EPMVHIyxrOSLrtEMz3LL8Z5Gkx2G81YPpup6NNDLNayWO9/FPMfJSZ7wiPPwLgQWa+EcCD4bGFhcWEYhRK810A7g0/3wvgAyMYw8LCIicMywkwgK8QEQP4K2b+JICDzHwGAJj5DBEdGHaS0wLVYjDt/nGWpWNAcinGQcqK0GECxVk3CqS+xifGjn3BuFxvSv1US8Vcog1nhfHqGK9ttuxCSV2PU9NM+2wMow4Me2ffxsynwxf9ASJ6Nm1DNQ3ZvCKr7phO31Utg3TLQhMnoHpillLkJrDIhkkwOhpKHWDm0+H/zwH4EoJsxGeJ6BAAhP8/16OtTUNmYTEByCwEiGiRiJY7nwG8G8AxBOnG7gmr3QPgy8NO0sLCYnQYRh04COBL4XKmAOCzzPxPRPQogC8Q0YcAvArgF4af5pSA9SWdtNzvsdrLxglQYjvVMKgTpls2qjH0Q/KBLxiteOZiCpyzRrUta9LJVe9QLQR8z74MxlLxvqHfM1Nk5yxOFsn3VTfwMtYZ8XZjZiHAzC8DeJOh/CKAdw0zqWmFetP1Y0ObHhF3k0CGWmqAYMHKA82s5weEXuZIEcYYjXYbLU+2KlxdrO6YHZ1qCEQASgXZyMjzBXxVACvtBMw8StJ5mHJM5CP/DP2CpM5pB+IjzZTF4CwgrczP+mhkTUMmzWvMXnOd6XcEXBCSHFMaKEGHvlYZLawDkYXFnMOuBDJC0/3Dw6QfI7NKkFRH0Vm7pbFloyFiEGltU/6qpFlmsFnnHQVP0KvH/KL5Jo81y7BCICO2m23U21Gab8GBoY3+YEbHzPqLGhgYyaXarrzhYdc93QBXqSagL/VUg6KgQBFoJomiYKvZkuZQKrgoKc5AWeA4hHJR7scUxq2l2DIw69deC69GPQSHejGN19sQtSmhm2mBFQIZ0Wz72G5GQsBEHuk7BdCO1XZp+gHCGIeKlY9qQUjESi6CTt9ymUoMmsKSqQZFTc/T8hXmIgSI4CT04wuBtu9r5ZqwUD0LDXzI6Gm3yYflBCws5hxWCFhYzDmsOpAZJv0/QQUwLPWNbQyko9rS0fbE9JDjrNSRttRiZYo9EYJzg1wn3g9IS+U2jngO/QyByFSHTCqTQd1KYVCkwtR3FvTiLUZ5fa0QyAiGQcdPwQEIlbxTCC1mhq9UEsxajkXXka3miACQrkvHow119tM1ByJFbwapHIDKGzB2Vyvj9a4zXGuVt0jiCIz99ihPNijKhxg05dJUrSPzhhUCOSHLdtVU27bQeH79B4El/dLBcgIWFnMOKwQsLOYcVh1IAU8IrG83pOV7o91O5ACeP/AmPHfwaPe40q7hR1/8Ryw0N6I2LKsSjGAfPN6XJ4Kw4FF0XEK1VJDIOYcA19HnI5VQ8E+c5GODFyFpRk1k6Gfn0PJ8SVfm0OpKokUNhBp1vohBV9sMJKDBQlP1PlSRhjzMgp1QuawQSAEhGBsNOeRWkgAAgFO7r8ejR36me7zcWMNtx7+GakcIsNlYSChlni/QaEfGMQRTejWZ5QcCY0B5dwJgkkk+hmpQ1INUSzrZEcLzfc1DkGL/AkM4RqkGRdDPvZf3oYqRvK55MY59YIXAKEHU9wZONTFoMTOwnICFxZzDrgQGQJIhkFpWaW1hdfts93ixcRmu0G3eNSh2QETyXnHgN5B9iagaB2nGQjF9uzOMamC009CiIYVGTVGZ7iyktpO+QORlqV+PFP3Eu+zMccK3THvBCoGUSGMIpOLoD/4Frz/1SPeYWER8QB845EjkVMl14VbkRVvACcTbJHZrhMnJJm5AFJy2GqGYzcrziCAgX9+O8VK/4U1OUFCK0hgU9Xr306Q8mxZYITBClL0GSl6je2zyEOwF1arPURW3jMY6O8AzjQDJVy2rhWBemGbDpEROgIg+TUTniOhYrGwPET1ARC+E/1+Nffd7RPQiET1HRO8Z1cQtLCzyQRpi8G8A3KmUGfMNEtEtAO4GcGvY5i+JDAbtFhYWE4NEdYCZv0FER5TiuwC8M/x8L4CvA/jdsPzzzNwE8AoRvYggIclDOc13bEhyFqoXF/H4NW9Hs1Dtll174Rlce+Hp/h1rJCDBIVaqkBYRyCWZExgm55Z2btq6WvFG3OmFL5t0c5NBD/SypMhCpuuW2WNwNOyAL4Q0T8cQcn0YZOUEeuUbvArAt2P1ToZlGmYtDVm9uIiHbngvNqp7umXvePaLkhDQHpHw3VJTUWk3mLr/REVEGieQF2uvP8q6gdFOotdo/W3/DJ6FBo4g0TDK0HcvrmEUOQwZCAyl4rsjjpMr2ZG3nUBq8WjTkFlYTAayCoFe+QZPArg6Vu8wgNPZp2dhYTFqZFUHOvkG/xhyvsH7AHyWiP4cwJUAbgTwiLGHaURsSdYoLqDlRmpMrbyMheaGtOwpteuJXSqUQK45NPLU3CWDmsx96MFRdDVHN4ZyiCAUniQpVVnQM4Fj7UhtRwRSOBGiNIyHKf+TeYtyGpAoBIjocwhIwH1EdBLAHyJ4+bV8g8z8FBF9AcDTADwAv8HMKUzkJh/qA/bQDT+HJw+/rXu83FjD+578NBZam92ySmurb5+9Xvg0ur3KG2g0AumFo+MM0qHl+9hutpRSeU4l18FiuSSVVUtF6YXyhUCt1ZbqmI2DVC5D/bprF9ktKjiEYiFNtGM55Hka4W3yapwEpNkd+KUeXxnzDTLzxwB8bJhJTQO2S8tYWzgg3dSV+iWsNNa6x2kJNIl0SvVLFLZLEASmOuN8CE2h01RrxJ7htWLTFgZmPi9jHVOyU2kcVn0u048/qQZF1oHIwmLOYc2GB0CPbY6dnsZcII3DkrqYV7mVXmWjQtKW5aTCCoGUYMjv+7UXnpVu+kJzA0W/OfQeek+eQD1O8YSlfQjVcOKBZ52qRuRjLKSnCpNDpfvMaLTl7EYl14UjeUhxeD8UtlJ7CymFkCbp3NLcP21sc6+aVyGlaJcGef/sWCGQEuq9u/XUt3HrqcguKuvLr+e4M+ucpl9D3aYog0MRVM861npSz0xkPFdTLkawzAl4vsC2aEmz2lUtw4GrtZPmp3r/oXMtZWJQv4x6GrY8kNYIKXPnOcJyAhYWcw4rBCws5hxzrw6k0dE6S31pyd+j2bhoQgbApKQG00KIQnMYIoNfQhAzhKU6pmg7meYpOUt1ymQSsBPIZBCo+nZnia+fh9wGCieRdljzc5PgrJQBNtrwDqDR9vDaxjYEi771VJ1/0vYETq/egP9z+3/oHhMLvO/7/xM3XHhq6L41hxmTbp+mH8jtOv3Kzjk9UqXHUHAcrFQja00GUG+20YqlK2fF/qBbUeENSLEySnNe6nkABv0/5QVKescJQLngShXzFgtzLwQEA23fNxqpjANZJX/bLeHi0qGoH/bRKlS0ehNnsGKYkJ77UAYRwVU8L81efWpYtGRPw6wY5XU1eYzmCcsJWFjMOawQsLCYc8y0OtD2fdRb7b56XjNMcSVrA+lUg7w0iDyWekuNy7jtxDejPpmxUruokGXdAaW2ms2NFtlIrsNdy5zB5l1wHFSL0SPHAFqeJ6liFP4b52Bangc/xtm4RCi6rnTdCq5sR8AcOCzJpKPB+1AZKxWZZ/CGVPtRQQBcx0l0/NLaWWJwODTaHs5clj35tFRdMBxPBj0gIelZ2Lt1Bu9//FNSWUFx4DTqxAYjm1HpzUXXwa44ocfAxW1fcioKDHrkEbcVj8FSwcWuqivNqVxwAwIthM+MZk05f+5xbgOenGo9GpSZeYl4m0rBQUELGz1+zLQQAHq85DMIAqMgPKUMo2OrMkCzjuy3zxoXTIbdiX79Ah3Wf7JAGC3BlxWTJ5YsLCx2FBOxEmAOI6qG6ER36Sc1zVFq9Dqd/jtwCpB/HQUg/J1bIajjswjmME1gBByKiC3jO7cqj1+6XmqLPD5Ll830vHRSqkGppxZkmbHJToCV477jThAmQgi0fR+n1qP0XCuViqQ7mlBrtXFxuyYXKkYsvmDpQQWAQ7c5qO6ObkltjXH6ewIsr6SVfpPdg0j+x4hCGbj6dgfFalRn/STj/HO6FNAdiwxjZnyy1IdVJ8MMHcc97Rg4v7Ut7eUvlotYUiICpZ5PgmehOruWJ7Bea3TnSRSMXy5Ej7NDhJVKOVm6K6eaJpR3EPzXIF1iRa7joFIsSN27WXPFjRgTIQQEM2qt6C2sFpMjknlCSG0AA1ljeHOqq4Tlg4qFWMK9SWtFlnSLyQEW9xHKy9SdXz05NWGuUOeZlfRrtD1JCJQTQnL1nI/h4ibNSTCjpYT3qhTlR5nCHYSdgspbEBEKjjORHICKrGnI/oiIThHRE+Hfe2Pf2TRkFhZThKxpyADgL5j5aPh3PwCbhszCYgqRNQ1ZL9yFDGnI1H3Xtq9Hk1XR9HxtuW/a41fr1NZYGqy+BrBQjYUMc0ydmqp3PSEI2xcYrVpUp7mh8w0mPT3NstLIXCgRglTvtsA4SHZO0ceWvQijdr319vRgJUKQHgZch3ydd3rB7YRLfWlGyiTcKVADOhiGE/gwEX0QwGMAfoeZ15AxDdm+qpyB6HK9icv1Zt/BjQIgoQ4AnHjMVyvptgQZPMB6ub9KUXMajJe/5Se+0Hk6tZgK+xkHpTEoMtfLJgYEK5sjoRdh8hUaduRsICKUCi5KGTmQSURWO4FPALgBwFEAZwB8PCw33TvzsxhLQ7ZcGt8FnTyTEguLnUUmIcDMZ5nZZ2YB4FMIlvyATUNmYTF1yKQOENGhTlZiAD8PoLNzMEQashQbuuqSlHsdqPWSf+9VB6KkJr3TU6t14gY10dagVE9rp+vfWt/9p9eFyYBFGt6R4w+R0ipqoxsGGbf3snAZWkQgNsVEksbXIhQxp7rPagbopDrzgKxpyN5JREcRPC3HAfw6gOxpyLjvOwy3BBz6IUJpMbo5m2cFzj03OC/AKTmA5JDSOgmoPTuKEYIp+EWQLy9+DFyxawkF15HKBmcJGBe362i0vViJ3s8j170bx/fd0j3eVb+An37271HxarE2Ss8GR5ztZhstL9LuHSKsLlZRdBO0e4MHJ5tM/WJQ/ItADGw22qi3+ll8AYvlEsrFyPtQMGOz0ZIsT6vFAqql+cqSnTUN2V/3qZ97GjJygOUrSLL089vyg5KWGDQJAL0szcrBEL4Kg5NsahQdhm79lgXMnEiuAsCpXdfhmUN3dI8PbJzA291/CER4v/4hn1vL86X8fC4Rdi/okY2SEPCr5mvba2wG0PI9tP3+AqdcLKAcC13OHBg9xYVA0Z0/d5r5O2MLCwsJVghYWMw5JsJ3AOhPC7IA6msMP7ZEbW6Z9H29p6Q6HUMlRS1NmJHu5AIKdFOZiCPJoCYi2WJEnGa8Q2i0PEP2XkhtSq4LN0WACi1qEGSFfk/tHK669KJ07Aivr0rUPY8+RkZMhKYSNUifG8NXCb3Qg7SvSmakDPrzCEDgbxKPSCwEB8v/tgcK+YwieXB78C8Mgii58IG+9wcAHCcIhjoNJOPECIF+8FrA8YeVKDGK453Js8tkd6Y+lMyGMpPRj/JgEBS9lQEfsq5KxHAUfT8NR3BybcPgFhsdO0Q4vLqMxQG99kzj//jz9+GtL9wfjQOBot8yuOn270e9Yp4QOL+xnYLP1Ld8TK9XcshzPUKxeg0v15vYiPEkBdfBleRiYb0Bpysc6r1NlQjwqmVc2l3FumLRqo5VKRYSPWEnBVMhBABAJBBV2ZHOXMhE4AFZOPvkNoL1DbKkl67XWEnjF0QblMQCpujHBAHJA7lnT6P6tTSRt9J0PIHKZh0FT93A6jFpBgrbDRQcBlfkHYReRPE0wHICFnMLEgLkDx7RxWkn73pPE6wQsLCYc0yMOjBo3jazDYCu76v1hMICCrBG8gjBWl8BCReVORTo5rLxHck56VXnGARSVw3prXr6HdqtGgvpnoBp7Aj2LFSxEuMNWr6Pi9t1Y6RctX/5e31ZT6C+96xRXMC3bnw/Nqp7umXXXHoedxx/UBmrfz/BWP2NyaJ6urViv76FgX84K1w8JcoACLe7dewifaXAkMPhAeG9j43V9Dysx7xFiQiL5eKOBjpJi4kRAsPCfLOTrQNVQdEhCnVWW0g6X5eLTkhzpc8ouc5KpYxycbhb03nogEh3rbfauLRdz+Q0pV1HAxEXR9sp4rkr3oxzK1dL5aoQSKNLG4nCNHNMMjoy7AKd4CKeEWXc7LT6tDM9V/JYni+kHxdCYI2IyZMBVh0YBlleJovJBgNYYxeX2BmY9J1WzMxKwMIiD1TA+Em3hre5tUn80R4JJlMIpOQHegWpjH9O9CkIjVXi9XwhtNRYruNqxjCSUQuF/2jubf3naKoRpEaTK+Xxq9Ty/fCaKLqzOr/Ejfpk0xyHfezZek0qW65f1Ps2Kvz5/AarhliblVXUS0vd46rXxvW1U4hbod3ktOADKCRMQbNJIdJvrPIseELAUbcjE8YhEFxntEZHEykEUu2Ba+QWoBpxmb0DhfzCM8MTsTIOdOe4ZZlDhGVHNfxwQmUq9PFjgB3V8scwAYJGBKr398Sly7K+bRICKQSDKWy5PyAB2x3LcL373alycwv/6vFPQTjR72nBb0GobTTCMUcoff+/Iz+LJ655e/f44PZ53Pq1P0Wlvt4tKycbNoTPmmpgpsxdeRTAjPVa0+A2rhfEi4qug9XF6khVk4kUAqNE0p4Cg7UEpYwehiexG5321TKF6lIREEr9GfugLJmGzOUXJA2bqYDAqLa2MuX5G9UD3yxUsVXe1b2YS+0GmHKixVJMXLAwWJ6q/cj3LCnBTh6wxKDF/IIoWSIbwCNcmo8Dk7MSmCCqPe0tNj4LSQp/nki6Zr0U90HnlfE80jbTnZxGhXCFFQ7ILqG9XAXX+g8aN+IWpQLayxWwF/kORI5hcbuATpck14n1a6JDesVTGSRq0qA2NxMjBJITfeUD1YCEKPD24qgAxUIB5MhRclSPvSBfom5VkxBxrMf+dlpjGdVOob9CTUzmOrGiXdWylr1HG39ktv3Aeq2OtlDdlUbzLNx45rtYrF/qHi96dVykBloLJTixCEzxs20WF/Dda38qIBSJ0F4oYd/Gy7jmxMPReUBfUgfaQXQuQR353BiGHxIlbL3nC2w25OAw6nPnOISFUlEL8tLUfCLMmBghsJNQjX6c2AvOzCgVXBRYeekN7YK+ojqj0mdN/ab5gTd6Q7LMKC5VSlhdqA45w2zwhcBWoylFJBrlj8H1Z5/E9WeflMq2AGwHvtndsvg93ags4L6b34O1pYPhBBlv+cGDuPrVh6V+hMq/hIZI8RdWq2OEfLd9wdist/SwdLGCguMEhkixsqbnY6vZ2+ApjjRpyK4moq8R0TNE9BQR/VZYvoeIHiCiF8L/r8ba2FRkFhZTgjTEoIcgucgbALwVwG+E6cY+AuBBZr4RwIPhsU1FZmExZUgTaPQMggQjYOZNInoGQVahuwC8M6x2L4CvA/hdZExFNi4k7ttCVwX61U0DNSKRiUgwOfH005WNNjfdb+JDsdQNC7MzzE74xhMIjkNSOnCGnk5+pHPQOCKFqGRG2auh0trulhW9ljG0uhaWPc7JGCImqWMBwTUxOXTJdke6Y5RggEScb0gXgh0YkBMIcxK+GcDDAA52cg8w8xkiOhBWS5WKLJ6GbG9l56gJ1duLiOA6iF1lArn6RVZfCjWPfSAoBp8PGxT+LK9fr9tNah2l4qn1DZxej2pVigUc2bcLhR3wdiMCDq+uSGWbjRZOXLo8cF9pnvc0EaM68+qgXLuEX/7GR6VtwSJ7mtGVZkfCgadpfILBjiTFi7TxhWZlBEOIdZlraHk+zm1sKfPRTqsnUr99RLQE4IsAfpuZN/r8UiRtnAUFzJ8E8EkAuH5XdWSi30SoqQkoCOhe+ODGmC169HMmA2HTfz6jNIbJgsCzOrr8gjWbvpGhszOjlu0kku4HMaPcrsmkcEqJn+Ve9yKBE+nEIW5aKmMhIioiEACfYea/D4vPEtGh8PtDAM6F5TYVmYXFFCHN7gAhSDbyDDP/eeyr+wDcE36+B8CXY+V3E1GZiK7DQKnILCwsdhpp1IG3AfgVAN8noifCst8H8McAvkBEHwLwKoBfAJA9FVkOUM1MzMSLopsQSc4xHUsvdXVlzA+Y08pV5x+ApDyHqfsecHG/g5xcTxjDwic2MvWjO/kkNSQKbSniNZxALYjqELRo78rD5pgpvp6ziPdtJh3VWSf7lqRFmt2Bb6L34/6uHm1yT0WWBkbrKwPLLhUZPHpMwkMdYJSaqzBTEjuC8csAPbRbGsGUNeekCqM7gZDLCLqgEKrjT8dmUCEHE1ngHhGSNYI3R8ycxWCWi6Vtx7FO+KVpZzGrmDQ6N19YL0ILiznHzK0E4kjWwCwmFf2W7r2+Mqeci+AWASf2xLMA2k05doTq5ANAixpkMszqtSrs9/z1WltofFSwb9239TDP+cwIAZPRB5Mhk49sMGe+EYbCXjd9VItEKZTZiMZIGnccYA6cZpJmkYYDUC0PD7+hiAPXR498fUvg+1+ro1WP6rmOYrtAhEA0xO6HyYbEcSQuo0sc9xEwDMNSvAebbSK4JQxx2yZGCKgGPLn1m1BmvKHKMYfWXnrF2dMTx71ySrMTkOb5MAmFYpWwsBoziXYZTHJ4eWLFGjSMQamGltfnrYdg1znnZG4hKYLVKGA5AQuLOYcVAhYWc46JUQd2CqbwTUmLy7wJxr59GZa6OzY2gkg2l7brcDsBOAlYKBWxUCr2b5gjTEt5Ux2tjdJIKN6Ra+c8oBCVNWuMet1Dqx01LLkOSHkrXEde6BP0AKBakGLSCURWnddgNkpLMh4L2iWRBOkxkULA5ERiujByhXQvi0OyAREb2mk6J+m046h056z9ZvWiU9H0PPzg4mWp7PDqys4JATalgFOr6JaAqhBgQz8nnmniB09HZb4Q2Gy0pHbVUkGLIFVwHWnJHKRcl/t2DFMWkAlrNbKQkSEwcAJaFUPZMJSBVQcsLOYcVghYWMw5JlMdgK4SJC5ke9j7J+qWxPD17NM7hl7bXXJxOiUhnUqQvj8guA+CWYs+lAZJEYpMS/bOceI2oKLGMevnn8pXwODmkwbmbcJ4vzCu9+UIQQZOwFQnYXq96qTdVpxIIbBroYI9C5WBFZ0s5gX1lofTlzdlw5IUF36U0D3G0jXSjGXSNEw8UcbZy1u4tFXvW0t92Quug+v27e4bzlww4/iFddRaUbhvT8gpvXvNyfTCS1fAwPUQ5EfKdRwslotSX0XXkewEjPyUcUYyOcgwvOTKfr+Rj4LcUWAjoFOIml+SgkE8USdSCBQcB9VScUeizHQiC8neXip5qF/lNDPLIkeyCh+d3MzWzoRmyhj28ftVdJ1UsQJrrTa2mu3EenGYhKQqAo2/7irBy6zlk3AMyT9TPYWmX/20bRPamAyIEvsZwMDIcgIWFnMOKwQsLOYcE6EOuA5hpVLqHielxUqLtu+j3mprelkcnhBYrpSlJX+t1UYrxhamIWfSgAGzMZBhgmqRaXmbVCcVUZoT+bGw28XiqhNlZmIHW60m6u3eS33BjLYvBvYV6X0dB+snSCXX3/5kkFW4fP3lEOMUdqZGujbGHjKkrteMjBImFh87CRMhBIoFF1fv2ZV7v/WWh1cvXtZY5DiWykVcs3c33DA+NDNwcu0yLm035IoGkicPpHlRdX1X95AzklUGq7pRYd+1Dm54S7krBFp1xuP3r2NrbWe2XpLciIGYZ18MarRjh0gKFZ5WFzc6EMWG6wguLdK10r/Qp6gTiqY6epPUGCYN2R8R0SkieiL8e2+szUBpyDpbgurfsGCk2CJEJ6RUOGbHRZiivw6vHP9vVBjjpsTQIALIIZBDutCcBJD5Oev3Nw9IsxLopCH7LhEtA/gOET0QfvcXzPxn8cpKGrIrAXyViG7aqWCjFhYWgyFxJcDMZ5j5u+HnTQCdNGS9cBfCNGTM/AqAThoyCwuLCcQwacjeBuDDRPRBAI8hWC2sIWUasjiano9XLqx3j3dXy9i9UOkux3wh8NrlLYmsM1qDKPBSWLk12h5eOb8eixREWK6WsWcxStfd8oXmVJMJBqs2TePngDCTy0yGQLoOrEcjMvAG2h578nU0QtlzP/V8C5dei4x+hA9sXRYpbAV2bsmtGguVFx3c/OMVFCtR6dkX2jjzvBdrlM5ugKFY+jHDdZRLa3SM0+fIBpfEeL1v3vSv8dKBH+oer9bO4z3HPoNqextZMEwask8A+CiC8/wogI8D+FX0vkZqf91chPsqRdRaEYuseqwxA/W2JxmspI0uo48rH/uCpbEJwOpiBUuVcres0fagQo/+kk0DNpGARiuyPsdRy15HYZmJhMyquCvWKPUtRn1L1vhMRJyho5FyLDKo6+ILAG4B2H3QRWUpWhBvvCZApGuu0v3u8TLrUasHjwiUhvQ7v3Qlju97Q7dmbeMEPCc7x585DRkzn2Vmn5kFgE8hWvKnSkPGzJ9k5juY+Y7lks1cbmExLmROQ9bJQxji5wEcCz/bNGQWFlOEYdKQ/RIRHUWwgjkO4NcBIEsaMrcILB+MFkGOENIS3RfJgSZyg2Et5hBhuVySFthNz0M7yf0wMUIO9zYEip1vqUpY2OV058bM2Ljoo93sbwdg6ldT0Q1zTLWCNUTJ0eugL99A4XUtxOz3W77AdrOVZgbm8bSi3mcjPODyWR+1y9F9rG/ma9fQvUSkG/Bol6dbh+Q6Ckewf/MUjpx/pnu82NzA6d3Xo+Q3E2ZzzFhK4w4xDQBvvG6Bv/CHr+sen3uW8dpTMmE1aLSZtPXUVg6Aq1ZXsBojBk0ur6fWNnFxuy7VMY1leOdiY7P2EjIYKp954PoCbvrxMpxQa/JajCcfrGHtjMyR6J516QhFFamyLxleLrO1Xe/OXIdw2+GDWInxLxe2anj69HlD38kWcmmEgBRYioBCUWkkCFAs9hySxyciOSIxIlsX9Thei0g/D7WfTv9q5/ESzynBj3EAF5cO4Yt3fBi18rLWVxyP//sf+w4z36GWT4TFIAhwS7HTdDiVB1pOQyfXIdIsy/KyIzFsFujjO0ChBDgudaskjW8kGHMU+CYLuSxwiVBwo5WA62TrMw2hZmrkteXzIAIyTmHHUBAtFEW0Ui74LbQKZTSLC5n6sw5EFhZzjslYCTAgfGmdPLXgHp/TtulVQfhRTfbZvOefwqnGXCf6nNZZikCSrqrpst1+YnVITvSaFHlImmMf5oKiSqaJDg1tWT98l7mCwHCFB9cfLC5DBxMhBFrbjFcfjpEz69MpBZL9FHTDIEB/6dR+1s/6ePobje4LJARj+5LsfcfQ9X3V6Ig5mVsBGx5yo66dcNzpJ/bFarWMw6u7ojpk9hgd1ICplyqgeumRYaZJKk3BcXB4zzKKbrSNvdlo4dJ2/0hLaZGJlIUsFJcba3jPsc+g7Zb6tAC+36N8IoSA1wQuvSJfjqSLoV28FGHKTfXGSYyqVmYwHANAbUNg63KMBITOmegvPPcoS56XdiXZcN0g53lUX8TOcfwlKxcLOLR7qe/YpliB3Q7jc1QNc8y9peItVEIvDocIqwvVrrDqXNe8hEAeqLS3ccvp7LvwlhOwsJhzWCFgYTHnmAh1QIVLJAWAZDA8X0wzX9gXkkpCQGWJEI9/2WoCjW1htAPoe6yUeW4J2wv7pKg0ldolFFq1+PAaeqfGik/bECVHbTeInt9PTTOwl4FRjb6sV0nPON3Qqc5KJVmtYTQ9T5o8M6NckE3dEw3HYm2jocyqivo8EENRvkzqUPa3YyKFwO7FCg4sL3aPPSHw6sXLqSLeThcYpjfj6J1VLKxEd/n0C20c+3q9+0AzB5xAvKVghs/yg+r5suC4uOdafOP9/xleMTKE+uGv/hdc89xXpfHViLsE7mHUIp+LWkeNkpPG6pPBySHHmeGoFjSkcxIBlyE1kyoxAw76R/Jt+wLPnbko9bN/eRG3XrlfGuvZMxcSn0/VociYhhyKIOZ0diHDYCKFQEcWdy6Q0TpNOTbuDqUkCycNnQg9UUFuPYPJATuxX7Ecn668DIhGhe4KYOB2+v4DadJlemE5AQuLOYcVAhYWc46JVAdUOETYt7TQX1d0GO7hJqgiGx1deFFus3dpASVXjV8g10mThnt1oYJKMarn+QJnN7f6z5GTHZjAwEvfaaIQ86XYWvODPX+FY4uzAgzZyYlBePmW92Ftz5FuWWNhFb5iUPLq638WawdvjpXIyjUBOHT82zj46mNSOydg4qR6WghvUnRgMF4hB/9QKGG7hxpSWyngwrXBHFeZcZfXQuP8JcmrtHP+qhWfaY8fGhEXXbVShXDktjKKsWt96aSPiyci3b7gOrhy9zKKMf+GquH5YLBOMDJLvkgmYyWNcA3bav1L5yFbZ/ZCWk1vMoSA8rCod5MIWKmW0Q9UAEpHPNBKdLHWTwIXXpKtz1YqpVQveRIWyyUsxqbU9Hyc39qGPwBLa7SJYcZrL8gPvBCKAGADoagY2QginL7mLTh15MfkesqTcf7wm3H+8Jv7zrK8dQH7jz8qlyr3jKC/iOozeBIOPl5awDGnTxCZagmoRqTwuvDwvvUNQHEvppA1j4+lLmu5UzFWEucsCiXClTcVUV6MyrwmS0LAQfADpO4GaFBvJjOYRsOQZIlY1A+TIQQA9KNr0tmXs6Gu+YXMI5T01ISjTppnojtifqTX9x0XTznuQE/wt50C3kgOrs1pDiYTY+r3C2SsM1uwnIDFjsEjSsyco0IQQUzwjsMsYIJWAkOCAW46EPXol8tpE0quajAyHw8UgVGpXcLi5Si8o++W0FjcEwQoGACt8gq2VqJocsQCi9vnAY6nagv0b44KAvOhfguJlBFNNH0bkKPyUGisZDDE0cpi2qEQjPqWkIK4aNGawMb9f3W9mecuYVanIq2flHOaHSEggPbzC9LapuQDR/bKV0JNRT2zYMYtD/0P3Oj8727R+v7X4dE7/wB+zFgoGYTjt74XJ296Z7ek2NzGT/7db6LYikJcC2Y4ceHCDHaC9vE6KvafaaNaF2hWCOevKEEYVG9fBIZP3RkRwPH7GK7x1b17UqKDsJDlX2Ob8b2v1KWyIFZHjCPwBV46d0mJLKS/mIkGTinRyyNylEgUAkRUAfANAOWw/t8x8x8S0R4AfwvgCIIYg78Y5h0AEf0egA8B8AH8JjP/80hmL88UaJNaguK8BjJmRqmxgULsxasv7Rv8J4sIXnkRXjki6/xCxbisV42FNAJLI8+AUkvAKxCaZQeip3xWzaN1azvTy2O0yIvNiQXQrAlD6DB55LbvG0OHxWEqmxak+VlsAvhpZn4TgKMA7iSitwL4CIAHmflGAA+Gx2oasjsB/CURzeuraJEABlBbdNBYcEZrG2vRE2nSkDEzb4WHxfCPEaQbuzcsvxfAB8LPd8GmIbNIAwK2VgrY3F1AY8H+TowLqTiB8Jf8OwBeB+C/MfPDRHSQmc8AADOfIaIDYfWB05DNAgqOg4Mri5JuuNloYrORMXz2kAiWp7LfxcL2Bdz02Ocg3Oi2n7nhJ7Cx74aB+vYLJbxw+91wvejc9p7+PvaffEIyFnJk+s64YbuxmvzyH7/53djmiMdY2DiLa178OtxYsE0oXE/H6KZfJqZehjkm9PM0TAvu/iN1lQm6V2f2VVQqIRDmDThKRLsBfImI3tinumk22p2Q0pBVhzfeGTcKroODK3LUnNPr2FEhoKrfqn5brV3ETd/5rNRme9eVAwsBUSjhxdvvlspufPRz2HtCFgKqhZzmvJXywX3l9e/GuaUj3eP9J5/EoZe/CcSEEEGAJPdzE0ch25KkZUdM3MIsYSCqnJnXAXwdga5/tpOFKPz/ubCaTUM28yDD306OaZEn0qQh2x+uAEBEVQA/A+BZBOnG7gmr3QPgy+Fnm4bMwogrWGCFB8jww4x9LLB7yl11Jx1p1IFDAO4NeQEHwBeY+f8S0UMAvkBEHwLwKoBfAJApDdm8QtaYc+gsfkgEItlYJ9NvKDOc5jbcWPQhEKG9tFfadPdKC2jEtiCJBarNTTgiyuh8q9fGL9e28PlCGb2CY/tuGa3KMkBAhYEPtht4Dg5ekeoUUV/YC6+bbINRbdfgiLh60PkmxSnGPu/0OiONhmSMlZGqVjokCgFm/h4AzcOEmS8CeFePNh8D8LHMs5phqCG3UgmC0DilS2gRhSGn4v2Q9gA5ilcfE0EIRxox+aFn7H/8y9j/2N91S/zyEp774CcgKhEHcvLmd+HstW/p9ldqbOD2B/4Ey+snu3UurW/h8LHncQ85aHZ7l8/+/NW348l3/FswEaoAvssCa6XdUp31/a/Dt97/MVB4QRy/jTc9+je4+vhDsVmHvEjc8cpg5KOSdYHTUf8rki/ysQ8cZrE0OxaD04DwjTeZtKZprMbEk0gvJUwWM+vsN3NifkATCvXLqKyd6h57lWWQsqxvV5bRrkS58LxaFcKRHy9PCPjNNhYBLMJ8/g0PKJZWAceFj4hoikMUyqjFzJgdvxVbFcSQwvwub4+8acSc2NBaWFj0gl0J5IQ0KcAmFikceRLPJO9z1cIEj3CsOYcVAjnBZ8blWkNyklGj4ejQ6StyCFdcV5AjC637uHjKi3EC0MiEoEh2cuE4kRDWIiXX/YGTj6PQirLptCrLeO26H4NfrHTbbF31Rpy//d9064hiBaIgRyjadf4FrJ59tjtesVVDqbnZ/+xJf58XN17Ddcf+QQqx/dr1bwtIxxDV7Yu44sSjID8gHR3hS9xDMOt0y3zVGSgvzaCjiWjEbIoBdHsK+d7mjYkQAuoNm0YVzfMFTq9vSvHn064ESDn5G+4oY2FXpKmder6FS2e8IIY3Qj02rBuHozrvqDG3wVqK9Wuf/QqueeYr3ePLe47gwlVvioQAES7f/HZcvvntfc/hwKuP4Q0PfVqzGNQcbSTnHP3R3nXhZdz2L/9VKtvae0QSAkuXT+K2b/0VirEdC5dI8xpUxzM9V5qwyPHhy0L5jcMwyXICFhZzDisELCzmHBOhDkwjRkn6MQMcD1KxgzwYITD0ITGgfdcoyTplPpR5LF09SdtulmGFQEac3djGei0i1ARDin6TGQw8+U9ytJt2k7t8ABAzDDKEuI4OCeyQRFQSkSZPCnAkgbZr8zTe8aXfgaC4M44pvJf8YpSbmygoRIUx8IZ6vmoBEdS8e2998M/gF6LQzq7fRMVvShyA6zhSq8B5SuUjevMT/TDrdgRWCGSEJ3wp9hzzMCkhIzAz6gqpLkTANXf3EgJzQT2clmIsBEAr018E2aLG9T0pLmFHAJhILkkQhAyb/CJ2vpCrJUGts7B9Xq/jmEhHEzGoSZlML7UaWWiWYDkBC4s5hxUCFhZzDqsOZMRCqQh/IVok+4KxUW/2Tb+tOgt1VsuqcZzWhckwSK2npdwKl+uqsRAMur20vpU18k6LpD1vMkTbUfteLBWxZyGKEMRgXNisoTUgl0IUphiLde4QaTYBJg5AVQW044FmMj7E74dLhMVyUeJAGm0vMVV6B1YIZMTqQhW7Yw900/Ox3WxB+PLbKpnqsPyiRLp9vFAfixDk/uOooW4s1HUO6h5qL6FunxhE5RKKECLWBUzSbohZH4d0cnsXqzh6zRXdY08wHnnlFNa2G9octX6UsShWuyMUZCFA3bpS56rMUzkCMp/LoOiKqB2QKgXXwRUrS3Bj+RLPb2yj6dX7tIq1H9XEZh3qL5/5XptK9ZcpQQZo9Qb0PYz1zQbBBE14qC9GWis2oyBQvo/nfeDQE9HUtWmloRSYVx6ZMCKTwdx76zNObDdkUKtDywlYWMw57EogJ3SWpOretPSrHaro0co6WHurkWxVUoARqg4xtFv97XMotBuYRn87/Rc+uY6xnx1U8NXMVhFvESszzNqk6uh1+p+IOs6gsEIgJxQdF9fu3a3pzoOGtwJ0a0R3Txvu1Y3uk+97jOcfaWDjgpyaS5EToUFR/Jj0wUiJ7kMUCCppQiqlmTbkVfL3jhIROain7/+rbbUXzNFaGdUFlfTMy1nn6j0rKLmxgLka9xAWJiHDdBwiuAbnqbQYJg3ZHwH4dwA6lhy/z8z3h23GkIZsvHAcwlKllFwxA9xdDgpXel0rwnaLUSyrerv8ixEIkmTdntTwO+GhzFPIdXoF7El8DHvo/mYugfrWMZGeqY2F+tTJ+iotlkuoFKfzNzXNrDtpyLaIqAjgm0T0j+F3f8HMfxavrKQhuxLAV4noJhts1MJiMjFMGrJeuAs2DZmFxdRgmDRkPwfgw0T0QQCPAfidMCvxXKYhGyVadYGtM35X6fc9KflOCFlvpzDSMCucgL7fr+v7/Xs2t0izjG55Pi5uRYFAfGZ4QjcUMnEC2lhp1Gt9V3Hg5b5DwFK5BMfpr54MS86NE8OkIfsEgI8ieB4+CuDjAH4VKTfHZy0N2Shx8aSPFx+vSy+07wvlZZE3/Dv7/yon4CRo84F1oEICZnh5op6jlpe2G3jkldPK94BL+oJUt+RTXjpTFCHT+BpvoFsFkFI/3nXRdXHDgT0oK/r+9L7yOjKnIWPms8zsc2Dx8SlES/6B05Ct2DRkyYiHF5jGfb8pByl/s4TMacg6eQhD/DyAY+Fnm4bMwmKKMEwasv9FREcR/EYdB/DrACY+DdkkhgGf5Yy3WZDf5ci0Uz93GCYN2a/0aTOxacjOb9Y07ypNLBgNfrhfFQAwehAmGQLtqpaxf3mx53x7QTUE6lgjqt+bvBbjcKCkRaOOH2FUxpzTq2PgFrRde1OdNH4LUIVHf3sAaPVnCyvVcmq7hYmxbhhlXPU4aq22lA/AtC7QrP6MiUX0NirPbbIeVMskK7OU6Lyiqveh7gikGP0YLO/MziYxc6BelkEZYXYWMhn5qMeGHQKlfpLRUaciKcezBiJCpVhILQSsA5GFxZzDCgELiznHxKgDw4KZ0fL8vpF9ALPePk60fR9bDdnyZ6FU1I1TMGgcgQCJRj5k5jfijUh1KMoRSXv7veqk6SmTf4OBo5h1zJAQAM5ubqPe9pQv5EPfYKGWF1JZSSlYqzWwXmtGfRBwy5X7UXH0W9N9sSnQdWVCz/A2a16DajDvsFfS63CS9MiANOp3t04CBxAvMe3dd8tiX3QNpUipo/QVH3sOZMAMCQEEv/LxF2NHf/QNrDZ3/+mNwG03bgk0wJBqOHHJ8o/DOvJYeieGebPJQzH9vPphIEEwYB0jwZimjmJCOA8vfhyWE7CwmHNYIWBhMeeYWnWg1mpjvRZFqWUw2ilDLMdRWQEOvN6BE27XMwMXXhTYOi/r25NoaahCdYQRqrGQiTZAsgaSSB6mnV/GdbbJJiAJpSrh5reWpcavveBj7fTEGK9ODKZWCLR9HxuNZnLFBBSrhD3XEtxS8LQIn7F5lrB9IaqTpwCQ9XggT95d0/8V/VbV9YMymSxk9KiTGyeQjesf1NqvUCIcurEo5SvcPN/AuubKZmHVAQuLOYcVAhYWc46JVAd8wWh6ft8lXy5pwCcUjbYnGTW1/Gx6rMHHKFn/T1Fn1MjCAWjbnIKxtSaktu0GNKh9F11H8ucouu4suhdImEghsNFoYqupxc+SMGmWf3nipXOXpAfPF6y9zKYnkzULH9WBqIexULwOWAtdPuq3QOvdlF1IM+QzGBPFiprbjMfvl9Nw+W1oUNvtW1rAlbuWpQoFZ7YXzBMpBJiD+HN964z992o0YGZ4yrnPssDLE4rhI5o1YSAUTfkIIriOg2JhviJdzbaIs7CwSMRMC4FBVrHd9GCGABpZHVgsxoxU5sf2vk2kOpAFBGBXtYKCq8g1w0o6rkqUieD/gMBu8DAwA8ueQGE5OZJQvMgXAhe3aiNZuk8CWTeNMPEG8ZKC4+CKXUtSHsHlEWWRmmTMjhCgIFRXtTR4+HJxElJUoCUAS8u9apvR9Dys1+oQ/iheV7MBz07B6BiVU1+jRr9fetd1cHDXIsqFmXkNMmGm1QELC4tkWCFgYTHnsELAwmLOQZPgHUdE5wFsA7iQVHcKsQ/2vKYNs3pu1zLzfrVwIoQAABDRY8x8x7jnkTfseU0fZvncTLDqgIXFnMMKAQuLOcckCYFPjnsCI4I9r+nDLJ+bhonhBCwsLMaDSVoJWFhYjAFjFwJEdCcRPUdELxLRR8Y9n0FBRJ8monNEdCxWtoeIHiCiF8L/r8a++73wXJ8joveMZ9bJIKKriehrRPQMET1FRL8Vlk/1uRFRhYgeIaInw/P6T2H5VJ/XUOAwYcc4/gC4AF4CcD2AEoAnAdwyzjllOIe3A/hhAMdiZX8K4CPh548A+JPw8y3hOZYBXBeeuzvuc+hxXocA/HD4eRnA8+H8p/rcELgvLIWfiwAeBvDWaT+vYf7GvRL4EQAvMvPLzNwC8HkAd415TgOBmb8B4JJSfBeAe8PP9wL4QKz888zcZOZXALyI4BpMHJj5DDN/N/y8CeAZAFdhys+NA2yFh8XwjzHl5zUMxi0ErgJwInZ8Miybdhxk5jNA8DIBOBCWT+X5EtERAG9G8Ks59edGRC4RPQHgHIAHmHkmzisrxi0ETH6es7xdMXXnS0RLAL4I4LeZeaNfVUPZRJ4bM/vMfBTAYQA/QkRv7FN9as4rK8YtBE4CuDp2fBjALKSHOEtEhwAg/P+5sHyqzpeIiggEwGeY+e/D4pk4NwBg5nUAXwdwJ2bovAbFuIXAowBuJKLriKgE4G4A9415TnngPgD3hJ/vAfDlWPndRFQmousA3AjgkTHMLxEUROP4awDPMPOfx76a6nMjov1EtDv8XAXwMwCexZSf11AYNzMJ4L0ImOeXAPzBuOeTYf6fA3AGQBvBr8aHAOwF8CCAF8L/74nV/4PwXJ8D8HPjnn+f8/oJBMve7wF4Ivx777SfG4DbADwentcxAP8xLJ/q8xrmz1oMWljMOcatDlhYWIwZVghYWMw5rBCwsJhzWCFgYTHnsELAwmLOYYWAhcWcwwoBC4s5hxUCFhZzjv8P4e9+XlkMg0EAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"Success! Our upgraded reset function makes the environment now start from the start of the normal game phase, meaning the action space can be consistently the same throughout the game.","metadata":{}},{"cell_type":"markdown","source":"## 4. Training with RL\n\nIn the previous tutorial, we saw how to train an agent with SB3 in single-agent environments. Handling true multi-agent via training separate or shared policies to control all agents requires a few extra things so instead, for the purpose of a tutorial we will treat Lux S2 like a single agent environment by training a policy for one team and letting the other team simply do nothing.\n\nMoreover, we want to define our own reward function to encourage our robots to seek ice, dig it, and return to a factory so it can generate water and survive longer. To do this all, we will just create a custom environment wrapper.\n\n\n","metadata":{}},{"cell_type":"code","source":"import copy\nclass CustomEnvWrapper(gym.Wrapper):\n    def __init__(self, env: gym.Env) -> None:\n        \"\"\"\n        Adds a custom reward and turns the LuxAI_S2 environment into a single-agent environment for easy training\n        \"\"\"\n        super().__init__(env)\n        self.prev_step_metrics = None\n\n    def step(self, action):\n        agent = \"player_0\"\n        opp_agent = \"player_1\"\n\n        opp_factories = self.env.state.factories[opp_agent]\n        for k in opp_factories.keys():\n            factory = opp_factories[k]\n             # set enemy factories to have 1000 water to keep them alive the whole around and treat the game as single-agent\n            factory.cargo.water = 1000\n\n        # submit actions for just one agent to make it single-agent\n        # and save single-agent versions of the data below\n        action = {agent: action}\n        obs, _, done, info = self.env.step(action)\n        obs = obs[agent]\n        done = done[agent]\n        \n        # we collect stats on teams here. These are useful stats that can be used to help generate reward functions\n        stats: StatsStateDict = self.env.state.stats[agent]\n\n        info = dict()\n        metrics = dict()\n        metrics[\"ice_dug\"] = (\n            stats[\"generation\"][\"ice\"][\"HEAVY\"] + stats[\"generation\"][\"ice\"][\"LIGHT\"]\n        )\n        metrics[\"water_produced\"] = stats[\"generation\"][\"water\"]\n\n        # we save these two to see often the agent updates robot action queues and how often enough\n        # power to do so and succeed (less frequent updates = more power is saved)\n        metrics[\"action_queue_updates_success\"] = stats[\"action_queue_updates_success\"]\n        metrics[\"action_queue_updates_total\"] = stats[\"action_queue_updates_total\"]\n\n        # we can save the metrics to info so we can use tensorboard to log them to get a glimpse into how our agent is behaving\n        info[\"metrics\"] = metrics\n\n        reward = 0\n        if self.prev_step_metrics is not None:\n            # we check how much ice and water is produced and reward the agent for generating both\n            ice_dug_this_step = metrics[\"ice_dug\"] - self.prev_step_metrics[\"ice_dug\"]\n            water_produced_this_step = (\n                metrics[\"water_produced\"] - self.prev_step_metrics[\"water_produced\"]\n            )\n            # we reward water production more as it is the most important resource for survival\n            reward = ice_dug_this_step / 100 + water_produced_this_step\n\n        self.prev_step_metrics = copy.deepcopy(metrics)\n        return obs, reward, done, info\n\n    def reset(self, **kwargs):\n        obs = self.env.reset(**kwargs)[\"player_0\"]\n        self.prev_step_metrics = None\n        return obs","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:22:57.813091Z","iopub.execute_input":"2023-02-01T04:22:57.813559Z","iopub.status.idle":"2023-02-01T04:22:57.831275Z","shell.execute_reply.started":"2023-02-01T04:22:57.81352Z","shell.execute_reply":"2023-02-01T04:22:57.829636Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### 3.1 Defining the Environment and using Wrappers","metadata":{}},{"cell_type":"markdown","source":"Next, we will define a `make_env` function and use it with SB3 to create multiple environments in parallel that scale with the number of CPU cores you have. A future tutorial will show a variant that creates a single jax-powered environment to achieve the same functionality but scaling with GPU.\n\nWe will use the SB3Wrapper, the controller and observation wrapper we defined, and the custom env wrapper as well. These put together will give us an environment that resets to the start of the normal game phase, has a consistent and simplified observation and action space, and contains our reward function.","metadata":{}},{"cell_type":"code","source":"from stable_baselines3.common.vec_env import SubprocVecEnv\nfrom stable_baselines3.common.monitor import Monitor\nfrom gym.wrappers import TimeLimit\ndef make_env(env_id: str, rank: int, seed: int = 0, max_episode_steps=200):\n    def _init() -> gym.Env:\n        # verbose = 0\n        # collect_stats=True lets us track stats like total ice dug during an episode to help create reward functions\n        # max factories set to 2 for simplification and keeping returns consistent as we survive longer \n        # if there are more initial resources\n        env = gym.make(env_id, verbose=0, collect_stats=True, MAX_FACTORIES=2)\n\n        # Add a SB3 wrapper to make it work with SB3 and simplify the action space with the controller\n        # this will remove the bidding phase and factory placement phase. For factory placement we use\n        # the provided place_near_random_ice function which will randomly select an ice tile and place a factory near it.\n        env = SB3Wrapper(\n            env,\n            factory_placement_policy=place_near_random_ice,\n            controller=SimpleUnitDiscreteController(env.env_cfg),\n        )\n        \n        # changes observation to include a few simple features\n        env = SimpleUnitObservationWrapper(\n            env\n        )\n        \n        # convert to single agent, adds our reward\n        env = CustomEnvWrapper(env)  \n        \n        # Add a timelimit to the environment, which can truncate episodes, speed up training\n        env = TimeLimit(\n            env, max_episode_steps=max_episode_steps\n        )\n        env = Monitor(env) # for SB3 to allow it to record metrics\n        env.reset(seed=seed + rank)\n        set_random_seed(seed)\n        return env\n\n    return _init","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:22:57.833143Z","iopub.execute_input":"2023-02-01T04:22:57.833655Z","iopub.status.idle":"2023-02-01T04:23:00.257303Z","shell.execute_reply.started":"2023-02-01T04:22:57.833612Z","shell.execute_reply":"2023-02-01T04:23:00.255777Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Next we will define a useful callback function to log some of the custom metrics we defined earlier in the CustomEnvWrapper","metadata":{}},{"cell_type":"code","source":"from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\nclass TensorboardCallback(BaseCallback):\n    def __init__(self, tag: str, verbose=0):\n        super().__init__(verbose)\n        self.tag = tag\n\n    def _on_step(self) -> bool:\n        c = 0\n\n        for i, done in enumerate(self.locals[\"dones\"]):\n            if done:\n                info = self.locals[\"infos\"][i]\n                c += 1\n                for k in info[\"metrics\"]:\n                    stat = info[\"metrics\"][k]\n                    self.logger.record_mean(f\"{self.tag}/{k}\", stat)\n        return True","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:23:00.259116Z","iopub.execute_input":"2023-02-01T04:23:00.260056Z","iopub.status.idle":"2023-02-01T04:23:00.273055Z","shell.execute_reply.started":"2023-02-01T04:23:00.260003Z","shell.execute_reply":"2023-02-01T04:23:00.270232Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Training Setup\n\nNow we can prepare for training by creating training and evaluation environments, as well as defining our algorithm and model.","metadata":{}},{"cell_type":"code","source":"import os.path as osp\nfrom stable_baselines3.common.utils import set_random_seed\nfrom stable_baselines3.ppo import PPO\n\nset_random_seed(42)\nlog_path = \"logs/exp_1\"\nnum_envs = 4\n\n# set max episode steps to 200 for training environments to train faster\nenv = SubprocVecEnv([make_env(\"LuxAI_S2-v0\", i, max_episode_steps=200) for i in range(num_envs)])\nenv.reset()\n# set max episode steps to 1000 to match original environment\neval_env = SubprocVecEnv([make_env(\"LuxAI_S2-v0\", i, max_episode_steps=1000) for i in range(4)])\neval_env.reset()\nrollout_steps = 4000\npolicy_kwargs = dict(net_arch=(128, 128))\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    n_steps=rollout_steps // num_envs,\n    batch_size=800,\n    learning_rate=3e-4,\n    policy_kwargs=policy_kwargs,\n    verbose=1,\n    n_epochs=2,\n    target_kl=0.05,\n    gamma=0.99,\n    tensorboard_log=osp.join(log_path),\n)\n\neval_callback = EvalCallback(\n    eval_env,\n    best_model_save_path=osp.join(log_path, \"models\"),\n    log_path=osp.join(log_path, \"eval_logs\"),\n    eval_freq=24_000,\n    deterministic=False,\n    render=False,\n    n_eval_episodes=5,\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T04:23:00.275059Z","iopub.execute_input":"2023-02-01T04:23:00.275512Z","iopub.status.idle":"2023-02-01T04:23:10.001359Z","shell.execute_reply.started":"2023-02-01T04:23:00.275472Z","shell.execute_reply":"2023-02-01T04:23:09.999882Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Using cpu device\n","output_type":"stream"}]},{"cell_type":"markdown","source":"With our callback functions and model defined, we can now begin training using `model.learn`. On CPU this training can take around 3-4 hours to train, on GPU it can take 30min to an hour to train. The hyperparameters and reward function can be improved to make it train much faster. A simple way to also increase training speed is to train on a machine with more CPU cores and increasing `num_envs` above. Kaggle notebooks by default only have 4, but with e.g. 10 you can easily train a policy in around 30 minutes.\n\nIf you want to skip this training you can also just use the pretrained model that's in the downloaded dataset for the RL kit called `best_model.dontunzipme`. (kaggle auto unzips files but we need to keep it as a zip so the file extention is called .dontunzipme but for submission just change it to a .zip)\n\nTo track the progress we recommend using tensorboard which you can run with\n```\ntensorboard --logdir logs\n```","metadata":{}},{"cell_type":"code","source":"total_timesteps = 10_000_000\nmodel.learn(\n    total_timesteps,\n    callback=[TensorboardCallback(tag=\"train_metrics\"), eval_callback],\n)\nmodel.save(osp.join(log_path, \"models/latest_model\"))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-02-01T04:23:10.003419Z","iopub.execute_input":"2023-02-01T04:23:10.003819Z","iopub.status.idle":"2023-02-01T07:40:23.552054Z","shell.execute_reply.started":"2023-02-01T04:23:10.003782Z","shell.execute_reply":"2023-02-01T07:40:23.550364Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Logging to logs/exp_1/PPO_1\n----------------------------------------------\n| rollout/                        |          |\n|    ep_len_mean                  | 200      |\n|    ep_rew_mean                  | 0        |\n| time/                           |          |\n|    fps                          | 407      |\n|    iterations                   | 1        |\n|    time_elapsed                 | 9        |\n|    total_timesteps              | 4000     |\n| train_metrics/                  |          |\n|    action_queue_updates_success | 145      |\n|    action_queue_updates_total   | 177      |\n|    ice_dug                      | 0        |\n|    water_produced               | 0        |\n----------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 0.02          |\n| time/                           |               |\n|    fps                          | 548           |\n|    iterations                   | 2             |\n|    time_elapsed                 | 14            |\n|    total_timesteps              | 8000          |\n| train/                          |               |\n|    approx_kl                    | 0.00025716395 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.48         |\n|    explained_variance           | 0.843         |\n|    learning_rate                | 0.0003        |\n|    loss                         | -0.000655     |\n|    n_updates                    | 2             |\n|    policy_gradient_loss         | -0.000534     |\n|    value_loss                   | 0.000729      |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 176           |\n|    ice_dug                      | 4             |\n|    water_produced               | 0             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 0.0133        |\n| time/                           |               |\n|    fps                          | 620           |\n|    iterations                   | 3             |\n|    time_elapsed                 | 19            |\n|    total_timesteps              | 12000         |\n| train/                          |               |\n|    approx_kl                    | 9.9918936e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.48         |\n|    explained_variance           | 0.363         |\n|    learning_rate                | 0.0003        |\n|    loss                         | -0.00112      |\n|    n_updates                    | 4             |\n|    policy_gradient_loss         | -0.000431     |\n|    value_loss                   | 0.000874      |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 177           |\n|    ice_dug                      | 0             |\n|    water_produced               | 0             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.075        |\n| time/                           |              |\n|    fps                          | 654          |\n|    iterations                   | 4            |\n|    time_elapsed                 | 24           |\n|    total_timesteps              | 16000        |\n| train/                          |              |\n|    approx_kl                    | 0.0001520467 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.48        |\n|    explained_variance           | 0.945        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.00105     |\n|    n_updates                    | 6            |\n|    policy_gradient_loss         | -0.000384    |\n|    value_loss                   | 2.93e-05     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1            |\n|    water_produced               | 0.25         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 0.06          |\n| time/                           |               |\n|    fps                          | 683           |\n|    iterations                   | 5             |\n|    time_elapsed                 | 29            |\n|    total_timesteps              | 20000         |\n| train/                          |               |\n|    approx_kl                    | 0.00014432374 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.48         |\n|    explained_variance           | 0.000437      |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.0395        |\n|    n_updates                    | 8             |\n|    policy_gradient_loss         | -0.00028      |\n|    value_loss                   | 0.0566        |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 177           |\n|    ice_dug                      | 0             |\n|    water_produced               | 0             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.06         |\n| time/                           |              |\n|    fps                          | 704          |\n|    iterations                   | 6            |\n|    time_elapsed                 | 34           |\n|    total_timesteps              | 24000        |\n| train/                          |              |\n|    approx_kl                    | 7.736915e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.48        |\n|    explained_variance           | 0.926        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.00122     |\n|    n_updates                    | 10           |\n|    policy_gradient_loss         | -0.000353    |\n|    value_loss                   | 0.000268     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 0            |\n|    water_produced               | 0            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 0.052         |\n| time/                           |               |\n|    fps                          | 718           |\n|    iterations                   | 7             |\n|    time_elapsed                 | 38            |\n|    total_timesteps              | 28000         |\n| train/                          |               |\n|    approx_kl                    | 0.00023715764 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.48         |\n|    explained_variance           | 0.824         |\n|    learning_rate                | 0.0003        |\n|    loss                         | -0.00399      |\n|    n_updates                    | 12            |\n|    policy_gradient_loss         | -0.00151      |\n|    value_loss                   | 5.99e-05      |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 177           |\n|    ice_dug                      | 0             |\n|    water_produced               | 0             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.056        |\n| time/                           |              |\n|    fps                          | 729          |\n|    iterations                   | 8            |\n|    time_elapsed                 | 43           |\n|    total_timesteps              | 32000        |\n| train/                          |              |\n|    approx_kl                    | 0.0005054677 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.48        |\n|    explained_variance           | 0.924        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.00543     |\n|    n_updates                    | 14           |\n|    policy_gradient_loss         | -0.00253     |\n|    value_loss                   | 1.45e-05     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 2            |\n|    water_produced               | 0            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 0.008         |\n| time/                           |               |\n|    fps                          | 741           |\n|    iterations                   | 9             |\n|    time_elapsed                 | 48            |\n|    total_timesteps              | 36000         |\n| train/                          |               |\n|    approx_kl                    | 0.00033363188 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.48         |\n|    explained_variance           | 0.33          |\n|    learning_rate                | 0.0003        |\n|    loss                         | -0.00186      |\n|    n_updates                    | 16            |\n|    policy_gradient_loss         | -0.000427     |\n|    value_loss                   | 0.000187      |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 175           |\n|    ice_dug                      | 2             |\n|    water_produced               | 0             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 0.008         |\n| time/                           |               |\n|    fps                          | 748           |\n|    iterations                   | 10            |\n|    time_elapsed                 | 53            |\n|    total_timesteps              | 40000         |\n| train/                          |               |\n|    approx_kl                    | 0.00030649855 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.48         |\n|    explained_variance           | 0.2           |\n|    learning_rate                | 0.0003        |\n|    loss                         | -0.0022       |\n|    n_updates                    | 18            |\n|    policy_gradient_loss         | -0.000971     |\n|    value_loss                   | 0.000312      |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 175           |\n|    ice_dug                      | 0             |\n|    water_produced               | 0             |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 0.01        |\n| time/                           |             |\n|    fps                          | 752         |\n|    iterations                   | 11          |\n|    time_elapsed                 | 58          |\n|    total_timesteps              | 44000       |\n| train/                          |             |\n|    approx_kl                    | 0.000877353 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -2.47       |\n|    explained_variance           | 0.931       |\n|    learning_rate                | 0.0003      |\n|    loss                         | -0.00712    |\n|    n_updates                    | 20          |\n|    policy_gradient_loss         | -0.00295    |\n|    value_loss                   | 6.81e-06    |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 132         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1           |\n|    water_produced               | 0           |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.01         |\n| time/                           |              |\n|    fps                          | 758          |\n|    iterations                   | 12           |\n|    time_elapsed                 | 63           |\n|    total_timesteps              | 48000        |\n| train/                          |              |\n|    approx_kl                    | 0.0011578674 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.46        |\n|    explained_variance           | 0.371        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.00181     |\n|    n_updates                    | 22           |\n|    policy_gradient_loss         | -0.000925    |\n|    value_loss                   | 7.56e-05     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 0            |\n|    water_produced               | 0            |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 0.006       |\n| time/                           |             |\n|    fps                          | 762         |\n|    iterations                   | 13          |\n|    time_elapsed                 | 68          |\n|    total_timesteps              | 52000       |\n| train/                          |             |\n|    approx_kl                    | 0.002232566 |\n|    clip_fraction                | 0.003       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -2.44       |\n|    explained_variance           | 0.898       |\n|    learning_rate                | 0.0003      |\n|    loss                         | -0.0102     |\n|    n_updates                    | 24          |\n|    policy_gradient_loss         | -0.00382    |\n|    value_loss                   | 5.88e-06    |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 132         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 0           |\n|    water_produced               | 0           |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 0.002      |\n| time/                           |            |\n|    fps                          | 766        |\n|    iterations                   | 14         |\n|    time_elapsed                 | 73         |\n|    total_timesteps              | 56000      |\n| train/                          |            |\n|    approx_kl                    | 0.00616081 |\n|    clip_fraction                | 0.0591     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -2.4       |\n|    explained_variance           | 0.908      |\n|    learning_rate                | 0.0003     |\n|    loss                         | -0.00325   |\n|    n_updates                    | 26         |\n|    policy_gradient_loss         | -0.00513   |\n|    value_loss                   | 3.88e-06   |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 121        |\n|    action_queue_updates_total   | 171        |\n|    ice_dug                      | 0          |\n|    water_produced               | 0          |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.004        |\n| time/                           |              |\n|    fps                          | 772          |\n|    iterations                   | 15           |\n|    time_elapsed                 | 77           |\n|    total_timesteps              | 60000        |\n| train/                          |              |\n|    approx_kl                    | 0.0025576144 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.36        |\n|    explained_variance           | 0.844        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.00746     |\n|    n_updates                    | 28           |\n|    policy_gradient_loss         | -0.00235     |\n|    value_loss                   | 4e-06        |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 118          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1            |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.056        |\n| time/                           |              |\n|    fps                          | 776          |\n|    iterations                   | 16           |\n|    time_elapsed                 | 82           |\n|    total_timesteps              | 64000        |\n| train/                          |              |\n|    approx_kl                    | 0.0026448176 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.29        |\n|    explained_variance           | 0.163        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.00305      |\n|    n_updates                    | 30           |\n|    policy_gradient_loss         | 0.000345     |\n|    value_loss                   | 8.15e-05     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 120          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 2            |\n|    water_produced               | 0.25         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 0.056         |\n| time/                           |               |\n|    fps                          | 775           |\n|    iterations                   | 17            |\n|    time_elapsed                 | 87            |\n|    total_timesteps              | 68000         |\n| train/                          |               |\n|    approx_kl                    | 0.00060837384 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.29         |\n|    explained_variance           | 0.000745      |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.0319        |\n|    n_updates                    | 32            |\n|    policy_gradient_loss         | -0.00047      |\n|    value_loss                   | 0.0473        |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 118           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 0             |\n|    water_produced               | 0             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.056        |\n| time/                           |              |\n|    fps                          | 778          |\n|    iterations                   | 18           |\n|    time_elapsed                 | 92           |\n|    total_timesteps              | 72000        |\n| train/                          |              |\n|    approx_kl                    | 0.0003276844 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.24        |\n|    explained_variance           | 0.891        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.000166    |\n|    n_updates                    | 34           |\n|    policy_gradient_loss         | -3.8e-05     |\n|    value_loss                   | 0.000133     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 117          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 0            |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.056        |\n| time/                           |              |\n|    fps                          | 781          |\n|    iterations                   | 19           |\n|    time_elapsed                 | 97           |\n|    total_timesteps              | 76000        |\n| train/                          |              |\n|    approx_kl                    | 0.0017416099 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.31        |\n|    explained_variance           | 0.722        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.00485     |\n|    n_updates                    | 36           |\n|    policy_gradient_loss         | -0.00195     |\n|    value_loss                   | 6.42e-05     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 127          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 0            |\n|    water_produced               | 0            |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 0.054       |\n| time/                           |             |\n|    fps                          | 783         |\n|    iterations                   | 20          |\n|    time_elapsed                 | 102         |\n|    total_timesteps              | 80000       |\n| train/                          |             |\n|    approx_kl                    | 0.003034997 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -2.32       |\n|    explained_variance           | 0.86        |\n|    learning_rate                | 0.0003      |\n|    loss                         | -0.00174    |\n|    n_updates                    | 38          |\n|    policy_gradient_loss         | -0.00257    |\n|    value_loss                   | 2.84e-05    |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 125         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 0           |\n|    water_produced               | 0           |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.002        |\n| time/                           |              |\n|    fps                          | 784          |\n|    iterations                   | 21           |\n|    time_elapsed                 | 107          |\n|    total_timesteps              | 84000        |\n| train/                          |              |\n|    approx_kl                    | 0.0010488753 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.37        |\n|    explained_variance           | 0.903        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.0017       |\n|    n_updates                    | 40           |\n|    policy_gradient_loss         | 0.00017      |\n|    value_loss                   | 1.63e-05     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1            |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.002        |\n| time/                           |              |\n|    fps                          | 784          |\n|    iterations                   | 22           |\n|    time_elapsed                 | 112          |\n|    total_timesteps              | 88000        |\n| train/                          |              |\n|    approx_kl                    | 0.0002110318 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.37        |\n|    explained_variance           | 0.491        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.000476    |\n|    n_updates                    | 42           |\n|    policy_gradient_loss         | -0.000178    |\n|    value_loss                   | 8.75e-05     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 0            |\n|    water_produced               | 0            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 0.006         |\n| time/                           |               |\n|    fps                          | 785           |\n|    iterations                   | 23            |\n|    time_elapsed                 | 117           |\n|    total_timesteps              | 92000         |\n| train/                          |               |\n|    approx_kl                    | 0.00034651073 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.37         |\n|    explained_variance           | 0.894         |\n|    learning_rate                | 0.0003        |\n|    loss                         | -0.00256      |\n|    n_updates                    | 44            |\n|    policy_gradient_loss         | -0.00077      |\n|    value_loss                   | 8.5e-06       |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 2             |\n|    water_produced               | 0             |\n---------------------------------------------------\nEval num_timesteps=96000, episode_reward=0.04 +/- 0.08\nEpisode length: 301.00 +/- 0.00\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 301           |\n|    mean_reward                  | 0.04          |\n| time/                           |               |\n|    total_timesteps              | 96000         |\n| train/                          |               |\n|    approx_kl                    | 0.00035094516 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.35         |\n|    explained_variance           | 0.468         |\n|    learning_rate                | 0.0003        |\n|    loss                         | -0.00106      |\n|    n_updates                    | 46            |\n|    policy_gradient_loss         | -0.000159     |\n|    value_loss                   | 0.000198      |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 127           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 1             |\n|    water_produced               | 0             |\n---------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 0.008    |\n| time/              |          |\n|    fps             | 763      |\n|    iterations      | 24       |\n|    time_elapsed    | 125      |\n|    total_timesteps | 96000    |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.028        |\n| time/                           |              |\n|    fps                          | 762          |\n|    iterations                   | 25           |\n|    time_elapsed                 | 131          |\n|    total_timesteps              | 100000       |\n| train/                          |              |\n|    approx_kl                    | 0.0008710647 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.37        |\n|    explained_variance           | 0.245        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.00485     |\n|    n_updates                    | 48           |\n|    policy_gradient_loss         | -0.00137     |\n|    value_loss                   | 8.9e-05      |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 129          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 10           |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.034        |\n| time/                           |              |\n|    fps                          | 763          |\n|    iterations                   | 26           |\n|    time_elapsed                 | 136          |\n|    total_timesteps              | 104000       |\n| train/                          |              |\n|    approx_kl                    | 0.0008234091 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.38        |\n|    explained_variance           | 0.131        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.00152      |\n|    n_updates                    | 50           |\n|    policy_gradient_loss         | -0.000816    |\n|    value_loss                   | 0.00182      |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 129          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 4            |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.046        |\n| time/                           |              |\n|    fps                          | 762          |\n|    iterations                   | 27           |\n|    time_elapsed                 | 141          |\n|    total_timesteps              | 108000       |\n| train/                          |              |\n|    approx_kl                    | 0.0008310125 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.37        |\n|    explained_variance           | 0.237        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.00501     |\n|    n_updates                    | 52           |\n|    policy_gradient_loss         | -0.00122     |\n|    value_loss                   | 0.000898     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 6            |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.05         |\n| time/                           |              |\n|    fps                          | 762          |\n|    iterations                   | 28           |\n|    time_elapsed                 | 146          |\n|    total_timesteps              | 112000       |\n| train/                          |              |\n|    approx_kl                    | 0.0013095809 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.35        |\n|    explained_variance           | 0.289        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.000849     |\n|    n_updates                    | 54           |\n|    policy_gradient_loss         | -0.00138     |\n|    value_loss                   | 0.000843     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 122          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 4            |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.07         |\n| time/                           |              |\n|    fps                          | 759          |\n|    iterations                   | 29           |\n|    time_elapsed                 | 152          |\n|    total_timesteps              | 116000       |\n| train/                          |              |\n|    approx_kl                    | 0.0017493216 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.32        |\n|    explained_variance           | 0.195        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.000718     |\n|    n_updates                    | 56           |\n|    policy_gradient_loss         | -0.000558    |\n|    value_loss                   | 0.000536     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 129          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 11           |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.052        |\n| time/                           |              |\n|    fps                          | 759          |\n|    iterations                   | 30           |\n|    time_elapsed                 | 157          |\n|    total_timesteps              | 120000       |\n| train/                          |              |\n|    approx_kl                    | 0.0013841867 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.28        |\n|    explained_variance           | 0.134        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.00214      |\n|    n_updates                    | 58           |\n|    policy_gradient_loss         | -0.000754    |\n|    value_loss                   | 0.00445      |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1            |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.104        |\n| time/                           |              |\n|    fps                          | 761          |\n|    iterations                   | 31           |\n|    time_elapsed                 | 162          |\n|    total_timesteps              | 124000       |\n| train/                          |              |\n|    approx_kl                    | 0.0016302329 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.27        |\n|    explained_variance           | 0.772        |\n|    learning_rate                | 0.0003       |\n|    loss                         | -0.00248     |\n|    n_updates                    | 60           |\n|    policy_gradient_loss         | -0.00223     |\n|    value_loss                   | 0.000326     |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 5            |\n|    water_produced               | 0.25         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 0.18        |\n| time/                           |             |\n|    fps                          | 761         |\n|    iterations                   | 32          |\n|    time_elapsed                 | 168         |\n|    total_timesteps              | 128000      |\n| train/                          |             |\n|    approx_kl                    | 0.000806186 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -2.23       |\n|    explained_variance           | 0.0181      |\n|    learning_rate                | 0.0003      |\n|    loss                         | 0.0375      |\n|    n_updates                    | 62          |\n|    policy_gradient_loss         | 0.000137    |\n|    value_loss                   | 0.0598      |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 140         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 19          |\n|    water_produced               | 0.25        |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 0.318       |\n| time/                           |             |\n|    fps                          | 762         |\n|    iterations                   | 33          |\n|    time_elapsed                 | 173         |\n|    total_timesteps              | 132000      |\n| train/                          |             |\n|    approx_kl                    | 0.001065569 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -2.22       |\n|    explained_variance           | 0.0271      |\n|    learning_rate                | 0.0003      |\n|    loss                         | 0.0328      |\n|    n_updates                    | 64          |\n|    policy_gradient_loss         | -0.00134    |\n|    value_loss                   | 0.0623      |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 135         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 48          |\n|    water_produced               | 0.25        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.36         |\n| time/                           |              |\n|    fps                          | 763          |\n|    iterations                   | 34           |\n|    time_elapsed                 | 178          |\n|    total_timesteps              | 136000       |\n| train/                          |              |\n|    approx_kl                    | 0.0014423163 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.21        |\n|    explained_variance           | -0.0109      |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.0462       |\n|    n_updates                    | 66           |\n|    policy_gradient_loss         | -7.75e-05    |\n|    value_loss                   | 0.0869       |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 32           |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.602        |\n| time/                           |              |\n|    fps                          | 763          |\n|    iterations                   | 35           |\n|    time_elapsed                 | 183          |\n|    total_timesteps              | 140000       |\n| train/                          |              |\n|    approx_kl                    | 0.0017468471 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.16        |\n|    explained_variance           | 0.202        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.00301      |\n|    n_updates                    | 68           |\n|    policy_gradient_loss         | -0.00102     |\n|    value_loss                   | 0.00888      |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 22           |\n|    water_produced               | 1            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.682        |\n| time/                           |              |\n|    fps                          | 764          |\n|    iterations                   | 36           |\n|    time_elapsed                 | 188          |\n|    total_timesteps              | 144000       |\n| train/                          |              |\n|    approx_kl                    | 0.0016584389 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.09        |\n|    explained_variance           | 0.0387       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.208        |\n|    n_updates                    | 70           |\n|    policy_gradient_loss         | -0.000939    |\n|    value_loss                   | 0.343        |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 20           |\n|    water_produced               | 0.5          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.742        |\n| time/                           |              |\n|    fps                          | 765          |\n|    iterations                   | 37           |\n|    time_elapsed                 | 193          |\n|    total_timesteps              | 148000       |\n| train/                          |              |\n|    approx_kl                    | 0.0010056595 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.05        |\n|    explained_variance           | 0.201        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.0601       |\n|    n_updates                    | 72           |\n|    policy_gradient_loss         | -0.000795    |\n|    value_loss                   | 0.128        |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 24           |\n|    water_produced               | 0.5          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 0.848        |\n| time/                           |              |\n|    fps                          | 767          |\n|    iterations                   | 38           |\n|    time_elapsed                 | 198          |\n|    total_timesteps              | 152000       |\n| train/                          |              |\n|    approx_kl                    | 0.0016303925 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.06        |\n|    explained_variance           | 0.0882       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.15         |\n|    n_updates                    | 74           |\n|    policy_gradient_loss         | -0.000931    |\n|    value_loss                   | 0.203        |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 26           |\n|    water_produced               | 1            |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 0.898      |\n| time/                           |            |\n|    fps                          | 769        |\n|    iterations                   | 39         |\n|    time_elapsed                 | 202        |\n|    total_timesteps              | 156000     |\n| train/                          |            |\n|    approx_kl                    | 0.00164708 |\n|    clip_fraction                | 0          |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -2.03      |\n|    explained_variance           | 0.02       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 0.107      |\n|    n_updates                    | 76         |\n|    policy_gradient_loss         | -0.00143   |\n|    value_loss                   | 0.235      |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 138        |\n|    action_queue_updates_total   | 157        |\n|    ice_dug                      | 7          |\n|    water_produced               | 0.5        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 1.8         |\n| time/                           |             |\n|    fps                          | 770         |\n|    iterations                   | 40          |\n|    time_elapsed                 | 207         |\n|    total_timesteps              | 160000      |\n| train/                          |             |\n|    approx_kl                    | 0.003974599 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.92       |\n|    explained_variance           | 0.0994      |\n|    learning_rate                | 0.0003      |\n|    loss                         | 0.103       |\n|    n_updates                    | 78          |\n|    policy_gradient_loss         | -0.00125    |\n|    value_loss                   | 0.23        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 134         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 75          |\n|    water_produced               | 5           |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 3.27         |\n| time/                           |              |\n|    fps                          | 771          |\n|    iterations                   | 41           |\n|    time_elapsed                 | 212          |\n|    total_timesteps              | 164000       |\n| train/                          |              |\n|    approx_kl                    | 0.0026435042 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.88        |\n|    explained_variance           | 0.0301       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 2.19         |\n|    n_updates                    | 80           |\n|    policy_gradient_loss         | -0.00119     |\n|    value_loss                   | 5.14         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 151          |\n|    water_produced               | 6.5          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 4.82         |\n| time/                           |              |\n|    fps                          | 771          |\n|    iterations                   | 42           |\n|    time_elapsed                 | 217          |\n|    total_timesteps              | 168000       |\n| train/                          |              |\n|    approx_kl                    | 0.0008459856 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.76        |\n|    explained_variance           | 0.0403       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 3.78         |\n|    n_updates                    | 82           |\n|    policy_gradient_loss         | -0.000208    |\n|    value_loss                   | 8.27         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 123          |\n|    action_queue_updates_total   | 138          |\n|    ice_dug                      | 101          |\n|    water_produced               | 7.5          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 5.5        |\n| time/                           |            |\n|    fps                          | 772        |\n|    iterations                   | 43         |\n|    time_elapsed                 | 222        |\n|    total_timesteps              | 172000     |\n| train/                          |            |\n|    approx_kl                    | 0.00048582 |\n|    clip_fraction                | 0          |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.73      |\n|    explained_variance           | 0.0321     |\n|    learning_rate                | 0.0003     |\n|    loss                         | 5.85       |\n|    n_updates                    | 84         |\n|    policy_gradient_loss         | -0.000748  |\n|    value_loss                   | 12.4       |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 120        |\n|    action_queue_updates_total   | 144        |\n|    ice_dug                      | 64         |\n|    water_produced               | 4          |\n------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 5.76          |\n| time/                           |               |\n|    fps                          | 774           |\n|    iterations                   | 44            |\n|    time_elapsed                 | 227           |\n|    total_timesteps              | 176000        |\n| train/                          |               |\n|    approx_kl                    | 0.00069236057 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.8          |\n|    explained_variance           | 0.106         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 2.9           |\n|    n_updates                    | 86            |\n|    policy_gradient_loss         | -0.000522     |\n|    value_loss                   | 4.81          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 40            |\n|    water_produced               | 1.5           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 8.15         |\n| time/                           |              |\n|    fps                          | 775          |\n|    iterations                   | 45           |\n|    time_elapsed                 | 232          |\n|    total_timesteps              | 180000       |\n| train/                          |              |\n|    approx_kl                    | 0.0015396948 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.82        |\n|    explained_variance           | 0.17         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 1.29         |\n|    n_updates                    | 88           |\n|    policy_gradient_loss         | -0.000787    |\n|    value_loss                   | 2.14         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 145          |\n|    water_produced               | 16.2         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 7.65        |\n| time/                           |             |\n|    fps                          | 776         |\n|    iterations                   | 46          |\n|    time_elapsed                 | 237         |\n|    total_timesteps              | 184000      |\n| train/                          |             |\n|    approx_kl                    | 0.000665737 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.86       |\n|    explained_variance           | 0.0594      |\n|    learning_rate                | 0.0003      |\n|    loss                         | 23.4        |\n|    n_updates                    | 90          |\n|    policy_gradient_loss         | -0.000483   |\n|    value_loss                   | 38.3        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 140         |\n|    action_queue_updates_total   | 154         |\n|    ice_dug                      | 75          |\n|    water_produced               | 4.75        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 6.28          |\n| time/                           |               |\n|    fps                          | 777           |\n|    iterations                   | 47            |\n|    time_elapsed                 | 241           |\n|    total_timesteps              | 188000        |\n| train/                          |               |\n|    approx_kl                    | 0.00020301346 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.86         |\n|    explained_variance           | 0.0657        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 3.67          |\n|    n_updates                    | 92            |\n|    policy_gradient_loss         | -0.00022      |\n|    value_loss                   | 7.82          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 141           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 64            |\n|    water_produced               | 1             |\n---------------------------------------------------\nEval num_timesteps=192000, episode_reward=13.16 +/- 20.69\nEpisode length: 313.00 +/- 19.39\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 313           |\n|    mean_reward                  | 13.2          |\n| time/                           |               |\n|    total_timesteps              | 192000        |\n| train/                          |               |\n|    approx_kl                    | 0.00025811998 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.88         |\n|    explained_variance           | 0.466         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.14          |\n|    n_updates                    | 94            |\n|    policy_gradient_loss         | -0.00049      |\n|    value_loss                   | 0.755         |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 64            |\n|    water_produced               | 8             |\n---------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 7.08     |\n| time/              |          |\n|    fps             | 768      |\n|    iterations      | 48       |\n|    time_elapsed    | 249      |\n|    total_timesteps | 192000   |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 7.95         |\n| time/                           |              |\n|    fps                          | 769          |\n|    iterations                   | 49           |\n|    time_elapsed                 | 254          |\n|    total_timesteps              | 196000       |\n| train/                          |              |\n|    approx_kl                    | 8.083284e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.88        |\n|    explained_variance           | 0.0969       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 5.68         |\n|    n_updates                    | 96           |\n|    policy_gradient_loss         | 8.58e-05     |\n|    value_loss                   | 12.5         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 75           |\n|    water_produced               | 5.5          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 4.44          |\n| time/                           |               |\n|    fps                          | 771           |\n|    iterations                   | 50            |\n|    time_elapsed                 | 259           |\n|    total_timesteps              | 200000        |\n| train/                          |               |\n|    approx_kl                    | 0.00021829375 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.86         |\n|    explained_variance           | 0.121         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 3.2           |\n|    n_updates                    | 98            |\n|    policy_gradient_loss         | -0.000146     |\n|    value_loss                   | 8.82          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 17            |\n|    water_produced               | 0             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 6.32          |\n| time/                           |               |\n|    fps                          | 773           |\n|    iterations                   | 51            |\n|    time_elapsed                 | 263           |\n|    total_timesteps              | 204000        |\n| train/                          |               |\n|    approx_kl                    | 0.00073647796 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.8          |\n|    explained_variance           | 0.835         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.109         |\n|    n_updates                    | 100           |\n|    policy_gradient_loss         | 0.000133      |\n|    value_loss                   | 0.237         |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 139           |\n|    water_produced               | 13.5          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 7.09        |\n| time/                           |             |\n|    fps                          | 774         |\n|    iterations                   | 52          |\n|    time_elapsed                 | 268         |\n|    total_timesteps              | 208000      |\n| train/                          |             |\n|    approx_kl                    | 0.000326183 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.84       |\n|    explained_variance           | 0.0994      |\n|    learning_rate                | 0.0003      |\n|    loss                         | 9.65        |\n|    n_updates                    | 102         |\n|    policy_gradient_loss         | -0.000251   |\n|    value_loss                   | 26.3        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 136         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 75          |\n|    water_produced               | 4.75        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 6.27         |\n| time/                           |              |\n|    fps                          | 775          |\n|    iterations                   | 53           |\n|    time_elapsed                 | 273          |\n|    total_timesteps              | 212000       |\n| train/                          |              |\n|    approx_kl                    | 0.0004068938 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.78        |\n|    explained_variance           | 0.176        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 2.15         |\n|    n_updates                    | 104          |\n|    policy_gradient_loss         | -0.000438    |\n|    value_loss                   | 4.45         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 77           |\n|    water_produced               | 3.75         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 5.03         |\n| time/                           |              |\n|    fps                          | 775          |\n|    iterations                   | 54           |\n|    time_elapsed                 | 278          |\n|    total_timesteps              | 216000       |\n| train/                          |              |\n|    approx_kl                    | 0.0001394609 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.81        |\n|    explained_variance           | 0.213        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 2.19         |\n|    n_updates                    | 106          |\n|    policy_gradient_loss         | -0.000283    |\n|    value_loss                   | 4.37         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 6            |\n|    water_produced               | 0            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 5.75          |\n| time/                           |               |\n|    fps                          | 775           |\n|    iterations                   | 55            |\n|    time_elapsed                 | 283           |\n|    total_timesteps              | 220000        |\n| train/                          |               |\n|    approx_kl                    | 0.00019217537 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.78         |\n|    explained_variance           | 0.826         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.0725        |\n|    n_updates                    | 108           |\n|    policy_gradient_loss         | -0.000117     |\n|    value_loss                   | 0.261         |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 134           |\n|    action_queue_updates_total   | 146           |\n|    ice_dug                      | 54            |\n|    water_produced               | 3.25          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 3.51          |\n| time/                           |               |\n|    fps                          | 777           |\n|    iterations                   | 56            |\n|    time_elapsed                 | 288           |\n|    total_timesteps              | 224000        |\n| train/                          |               |\n|    approx_kl                    | 0.00031904533 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.77         |\n|    explained_variance           | 0.264         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 1.16          |\n|    n_updates                    | 110           |\n|    policy_gradient_loss         | -0.0005       |\n|    value_loss                   | 2.38          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 41            |\n|    water_produced               | 3.25          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 3.84        |\n| time/                           |             |\n|    fps                          | 777         |\n|    iterations                   | 57          |\n|    time_elapsed                 | 293         |\n|    total_timesteps              | 228000      |\n| train/                          |             |\n|    approx_kl                    | 0.001044607 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.74       |\n|    explained_variance           | 0.113       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 2.15        |\n|    n_updates                    | 112         |\n|    policy_gradient_loss         | -0.000722   |\n|    value_loss                   | 3.46        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 137         |\n|    action_queue_updates_total   | 148         |\n|    ice_dug                      | 69          |\n|    water_produced               | 6.5         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 8.89          |\n| time/                           |               |\n|    fps                          | 778           |\n|    iterations                   | 58            |\n|    time_elapsed                 | 297           |\n|    total_timesteps              | 232000        |\n| train/                          |               |\n|    approx_kl                    | 0.00084565266 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.78         |\n|    explained_variance           | 0.104         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 3.46          |\n|    n_updates                    | 114           |\n|    policy_gradient_loss         | -0.00025      |\n|    value_loss                   | 10.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 173           |\n|    water_produced               | 28            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 8.9           |\n| time/                           |               |\n|    fps                          | 779           |\n|    iterations                   | 59            |\n|    time_elapsed                 | 302           |\n|    total_timesteps              | 236000        |\n| train/                          |               |\n|    approx_kl                    | 0.00020317236 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.73         |\n|    explained_variance           | 0.0496        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 32.1          |\n|    n_updates                    | 116           |\n|    policy_gradient_loss         | -0.000433     |\n|    value_loss                   | 50.3          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 11            |\n|    water_produced               | 0             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11.6          |\n| time/                           |               |\n|    fps                          | 780           |\n|    iterations                   | 60            |\n|    time_elapsed                 | 307           |\n|    total_timesteps              | 240000        |\n| train/                          |               |\n|    approx_kl                    | 3.3405795e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.71         |\n|    explained_variance           | 0.72          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.211         |\n|    n_updates                    | 118           |\n|    policy_gradient_loss         | 4.94e-05      |\n|    value_loss                   | 0.487         |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 177           |\n|    water_produced               | 15.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11.3          |\n| time/                           |               |\n|    fps                          | 780           |\n|    iterations                   | 61            |\n|    time_elapsed                 | 312           |\n|    total_timesteps              | 244000        |\n| train/                          |               |\n|    approx_kl                    | 1.6553016e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.75         |\n|    explained_variance           | 0.00712       |\n|    learning_rate                | 0.0003        |\n|    loss                         | 8.46          |\n|    n_updates                    | 120           |\n|    policy_gradient_loss         | 2.28e-05      |\n|    value_loss                   | 22.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 68            |\n|    water_produced               | 1.5           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11.4          |\n| time/                           |               |\n|    fps                          | 780           |\n|    iterations                   | 62            |\n|    time_elapsed                 | 317           |\n|    total_timesteps              | 248000        |\n| train/                          |               |\n|    approx_kl                    | 1.1464402e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.79         |\n|    explained_variance           | 0.361         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.467         |\n|    n_updates                    | 122           |\n|    policy_gradient_loss         | -5.63e-05     |\n|    value_loss                   | 1.36          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 58            |\n|    water_produced               | 7             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 6.77         |\n| time/                           |              |\n|    fps                          | 780          |\n|    iterations                   | 63           |\n|    time_elapsed                 | 322          |\n|    total_timesteps              | 252000       |\n| train/                          |              |\n|    approx_kl                    | 7.817574e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.75        |\n|    explained_variance           | 0.12         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 3.75         |\n|    n_updates                    | 124          |\n|    policy_gradient_loss         | 3.66e-05     |\n|    value_loss                   | 7.74         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 48           |\n|    water_produced               | 6            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 9.99          |\n| time/                           |               |\n|    fps                          | 781           |\n|    iterations                   | 64            |\n|    time_elapsed                 | 327           |\n|    total_timesteps              | 256000        |\n| train/                          |               |\n|    approx_kl                    | 0.00025784745 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.77         |\n|    explained_variance           | 0.0496        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 1.8           |\n|    n_updates                    | 126           |\n|    policy_gradient_loss         | 1.64e-05      |\n|    value_loss                   | 7.35          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 96            |\n|    water_produced               | 15.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 9.29          |\n| time/                           |               |\n|    fps                          | 782           |\n|    iterations                   | 65            |\n|    time_elapsed                 | 332           |\n|    total_timesteps              | 260000        |\n| train/                          |               |\n|    approx_kl                    | 0.00026554256 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.72         |\n|    explained_variance           | 0.0365        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 11.8          |\n|    n_updates                    | 128           |\n|    policy_gradient_loss         | -0.000323     |\n|    value_loss                   | 29.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 77            |\n|    water_produced               | 13.3          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 9.34         |\n| time/                           |              |\n|    fps                          | 783          |\n|    iterations                   | 66           |\n|    time_elapsed                 | 336          |\n|    total_timesteps              | 264000       |\n| train/                          |              |\n|    approx_kl                    | 0.0001891165 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.79        |\n|    explained_variance           | 0.0612       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 13.8         |\n|    n_updates                    | 130          |\n|    policy_gradient_loss         | -0.000197    |\n|    value_loss                   | 22.1         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 16           |\n|    water_produced               | 2.25         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 9.57         |\n| time/                           |              |\n|    fps                          | 784          |\n|    iterations                   | 67           |\n|    time_elapsed                 | 341          |\n|    total_timesteps              | 268000       |\n| train/                          |              |\n|    approx_kl                    | 0.0006065965 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.79        |\n|    explained_variance           | 0.0635       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.844        |\n|    n_updates                    | 132          |\n|    policy_gradient_loss         | -0.00108     |\n|    value_loss                   | 2.49         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 75           |\n|    water_produced               | 8            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11.1          |\n| time/                           |               |\n|    fps                          | 785           |\n|    iterations                   | 68            |\n|    time_elapsed                 | 346           |\n|    total_timesteps              | 272000        |\n| train/                          |               |\n|    approx_kl                    | 0.00037927998 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.79         |\n|    explained_variance           | 0.0888        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.53          |\n|    n_updates                    | 134           |\n|    policy_gradient_loss         | -0.00023      |\n|    value_loss                   | 11.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 69            |\n|    water_produced               | 13.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 10.1          |\n| time/                           |               |\n|    fps                          | 785           |\n|    iterations                   | 69            |\n|    time_elapsed                 | 351           |\n|    total_timesteps              | 276000        |\n| train/                          |               |\n|    approx_kl                    | 0.00044146608 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.76         |\n|    explained_variance           | 0.0432        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.2           |\n|    n_updates                    | 136           |\n|    policy_gradient_loss         | -0.000636     |\n|    value_loss                   | 23.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 76            |\n|    water_produced               | 10.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 9.51          |\n| time/                           |               |\n|    fps                          | 786           |\n|    iterations                   | 70            |\n|    time_elapsed                 | 356           |\n|    total_timesteps              | 280000        |\n| train/                          |               |\n|    approx_kl                    | 0.00086314604 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.79         |\n|    explained_variance           | 0.0969        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 5.88          |\n|    n_updates                    | 138           |\n|    policy_gradient_loss         | -0.00128      |\n|    value_loss                   | 15.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 69            |\n|    water_produced               | 10.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 13.6         |\n| time/                           |              |\n|    fps                          | 786          |\n|    iterations                   | 71           |\n|    time_elapsed                 | 360          |\n|    total_timesteps              | 284000       |\n| train/                          |              |\n|    approx_kl                    | 0.0010566121 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.73        |\n|    explained_variance           | 0.0822       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 10.9         |\n|    n_updates                    | 140          |\n|    policy_gradient_loss         | -0.000962    |\n|    value_loss                   | 19.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 154          |\n|    water_produced               | 21.2         |\n--------------------------------------------------\nEval num_timesteps=288000, episode_reward=0.36 +/- 0.72\nEpisode length: 301.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 301          |\n|    mean_reward                  | 0.36         |\n| time/                           |              |\n|    total_timesteps              | 288000       |\n| train/                          |              |\n|    approx_kl                    | 0.0009082459 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.69        |\n|    explained_variance           | 0.0683       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 21.2         |\n|    n_updates                    | 142          |\n|    policy_gradient_loss         | 0.000231     |\n|    value_loss                   | 42           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 48           |\n|    water_produced               | 4            |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 12.7     |\n| time/              |          |\n|    fps             | 781      |\n|    iterations      | 72       |\n|    time_elapsed    | 368      |\n|    total_timesteps | 288000   |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.3          |\n| time/                           |               |\n|    fps                          | 781           |\n|    iterations                   | 73            |\n|    time_elapsed                 | 373           |\n|    total_timesteps              | 292000        |\n| train/                          |               |\n|    approx_kl                    | 0.00011291199 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.71         |\n|    explained_variance           | 0.149         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 3.1           |\n|    n_updates                    | 144           |\n|    policy_gradient_loss         | -9.41e-06     |\n|    value_loss                   | 7.26          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 118           |\n|    water_produced               | 15.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.2          |\n| time/                           |               |\n|    fps                          | 782           |\n|    iterations                   | 74            |\n|    time_elapsed                 | 378           |\n|    total_timesteps              | 296000        |\n| train/                          |               |\n|    approx_kl                    | 1.2346834e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.67         |\n|    explained_variance           | 0.138         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 15.3          |\n|    n_updates                    | 146           |\n|    policy_gradient_loss         | 5.54e-05      |\n|    value_loss                   | 23.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 75            |\n|    water_produced               | 10            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11.9          |\n| time/                           |               |\n|    fps                          | 783           |\n|    iterations                   | 75            |\n|    time_elapsed                 | 383           |\n|    total_timesteps              | 300000        |\n| train/                          |               |\n|    approx_kl                    | 6.1173334e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.72         |\n|    explained_variance           | 0.127         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 11.3          |\n|    n_updates                    | 148           |\n|    policy_gradient_loss         | -0.000117     |\n|    value_loss                   | 18.3          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 68            |\n|    water_produced               | 4             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 8.81          |\n| time/                           |               |\n|    fps                          | 783           |\n|    iterations                   | 76            |\n|    time_elapsed                 | 387           |\n|    total_timesteps              | 304000        |\n| train/                          |               |\n|    approx_kl                    | 0.00012447716 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.67         |\n|    explained_variance           | 0.194         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 4.16          |\n|    n_updates                    | 150           |\n|    policy_gradient_loss         | 1.04e-05      |\n|    value_loss                   | 6.78          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 48            |\n|    water_produced               | 6.75          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 9.66         |\n| time/                           |              |\n|    fps                          | 784          |\n|    iterations                   | 77           |\n|    time_elapsed                 | 392          |\n|    total_timesteps              | 308000       |\n| train/                          |              |\n|    approx_kl                    | 0.0003696676 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.72        |\n|    explained_variance           | 0.197        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 7.28         |\n|    n_updates                    | 152          |\n|    policy_gradient_loss         | -0.000495    |\n|    value_loss                   | 11.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 96           |\n|    water_produced               | 7.75         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 10.2         |\n| time/                           |              |\n|    fps                          | 784          |\n|    iterations                   | 78           |\n|    time_elapsed                 | 397          |\n|    total_timesteps              | 312000       |\n| train/                          |              |\n|    approx_kl                    | 0.0006211189 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.71        |\n|    explained_variance           | 0.158        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 7.65         |\n|    n_updates                    | 154          |\n|    policy_gradient_loss         | 2.98e-05     |\n|    value_loss                   | 12.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 114          |\n|    water_produced               | 18.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.2          |\n| time/                           |               |\n|    fps                          | 785           |\n|    iterations                   | 79            |\n|    time_elapsed                 | 402           |\n|    total_timesteps              | 316000        |\n| train/                          |               |\n|    approx_kl                    | 0.00042644804 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.72         |\n|    explained_variance           | 0.0973        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 18.7          |\n|    n_updates                    | 156           |\n|    policy_gradient_loss         | -0.000432     |\n|    value_loss                   | 31.2          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 148           |\n|    water_produced               | 24.5          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 16.9        |\n| time/                           |             |\n|    fps                          | 785         |\n|    iterations                   | 80          |\n|    time_elapsed                 | 407         |\n|    total_timesteps              | 320000      |\n| train/                          |             |\n|    approx_kl                    | 0.000703286 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.75       |\n|    explained_variance           | 0.0567      |\n|    learning_rate                | 0.0003      |\n|    loss                         | 18.5        |\n|    n_updates                    | 158         |\n|    policy_gradient_loss         | 0.000147    |\n|    value_loss                   | 50.4        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 224         |\n|    water_produced               | 20.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.7         |\n| time/                           |              |\n|    fps                          | 785          |\n|    iterations                   | 81           |\n|    time_elapsed                 | 412          |\n|    total_timesteps              | 324000       |\n| train/                          |              |\n|    approx_kl                    | 0.0004339232 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.74        |\n|    explained_variance           | 0.159        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 14.8         |\n|    n_updates                    | 160          |\n|    policy_gradient_loss         | 4.66e-05     |\n|    value_loss                   | 28.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 137          |\n|    water_produced               | 20.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 23.4          |\n| time/                           |               |\n|    fps                          | 785           |\n|    iterations                   | 82            |\n|    time_elapsed                 | 417           |\n|    total_timesteps              | 328000        |\n| train/                          |               |\n|    approx_kl                    | 0.00022797105 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.72         |\n|    explained_variance           | 0.0665        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 19.8          |\n|    n_updates                    | 162           |\n|    policy_gradient_loss         | 8.45e-05      |\n|    value_loss                   | 40.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 181           |\n|    water_produced               | 25.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 21.2          |\n| time/                           |               |\n|    fps                          | 785           |\n|    iterations                   | 83            |\n|    time_elapsed                 | 422           |\n|    total_timesteps              | 332000        |\n| train/                          |               |\n|    approx_kl                    | 0.00024342074 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.71         |\n|    explained_variance           | 0.0773        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 26.9          |\n|    n_updates                    | 164           |\n|    policy_gradient_loss         | 0.000389      |\n|    value_loss                   | 53.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 44            |\n|    water_produced               | 8.25          |\n---------------------------------------------------\n----------------------------------------------------\n| rollout/                        |                |\n|    ep_len_mean                  | 200            |\n|    ep_rew_mean                  | 16.9           |\n| time/                           |                |\n|    fps                          | 786            |\n|    iterations                   | 84             |\n|    time_elapsed                 | 427            |\n|    total_timesteps              | 336000         |\n| train/                          |                |\n|    approx_kl                    | 0.000119701355 |\n|    clip_fraction                | 0              |\n|    clip_range                   | 0.2            |\n|    entropy_loss                 | -1.72          |\n|    explained_variance           | 0.187          |\n|    learning_rate                | 0.0003         |\n|    loss                         | 4.48           |\n|    n_updates                    | 166            |\n|    policy_gradient_loss         | -9.64e-05      |\n|    value_loss                   | 14.4           |\n| train_metrics/                  |                |\n|    action_queue_updates_success | 151            |\n|    action_queue_updates_total   | 167            |\n|    ice_dug                      | 76             |\n|    water_produced               | 3.75           |\n----------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 16.1          |\n| time/                           |               |\n|    fps                          | 786           |\n|    iterations                   | 85            |\n|    time_elapsed                 | 432           |\n|    total_timesteps              | 340000        |\n| train/                          |               |\n|    approx_kl                    | 0.00040250184 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.74         |\n|    explained_variance           | 0.377         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 1.91          |\n|    n_updates                    | 168           |\n|    policy_gradient_loss         | -0.000171     |\n|    value_loss                   | 3.99          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 143           |\n|    water_produced               | 17.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.8          |\n| time/                           |               |\n|    fps                          | 787           |\n|    iterations                   | 86            |\n|    time_elapsed                 | 437           |\n|    total_timesteps              | 344000        |\n| train/                          |               |\n|    approx_kl                    | 0.00015786414 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.73         |\n|    explained_variance           | 0.157         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 13.6          |\n|    n_updates                    | 170           |\n|    policy_gradient_loss         | -1.67e-05     |\n|    value_loss                   | 30.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 69            |\n|    water_produced               | 9.5           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11.1          |\n| time/                           |               |\n|    fps                          | 787           |\n|    iterations                   | 87            |\n|    time_elapsed                 | 441           |\n|    total_timesteps              | 348000        |\n| train/                          |               |\n|    approx_kl                    | 0.00017424766 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.75         |\n|    explained_variance           | 0.159         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.59          |\n|    n_updates                    | 172           |\n|    policy_gradient_loss         | -0.000115     |\n|    value_loss                   | 20.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 117           |\n|    water_produced               | 12.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 12.4         |\n| time/                           |              |\n|    fps                          | 788          |\n|    iterations                   | 88           |\n|    time_elapsed                 | 446          |\n|    total_timesteps              | 352000       |\n| train/                          |              |\n|    approx_kl                    | 0.0005022868 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.75        |\n|    explained_variance           | 0.233        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 8.07         |\n|    n_updates                    | 174          |\n|    policy_gradient_loss         | -0.000248    |\n|    value_loss                   | 15.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 114          |\n|    water_produced               | 13.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 12.3          |\n| time/                           |               |\n|    fps                          | 789           |\n|    iterations                   | 89            |\n|    time_elapsed                 | 451           |\n|    total_timesteps              | 356000        |\n| train/                          |               |\n|    approx_kl                    | 0.00014429663 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.77         |\n|    explained_variance           | 0.313         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.87          |\n|    n_updates                    | 176           |\n|    policy_gradient_loss         | -1.52e-06     |\n|    value_loss                   | 15.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 21            |\n|    water_produced               | 4             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 12.3          |\n| time/                           |               |\n|    fps                          | 789           |\n|    iterations                   | 90            |\n|    time_elapsed                 | 456           |\n|    total_timesteps              | 360000        |\n| train/                          |               |\n|    approx_kl                    | 0.00085658545 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.76         |\n|    explained_variance           | 0.47          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 1.69          |\n|    n_updates                    | 178           |\n|    policy_gradient_loss         | -0.000119     |\n|    value_loss                   | 5.06          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 127           |\n|    water_produced               | 17.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 10.8          |\n| time/                           |               |\n|    fps                          | 789           |\n|    iterations                   | 91            |\n|    time_elapsed                 | 461           |\n|    total_timesteps              | 364000        |\n| train/                          |               |\n|    approx_kl                    | 0.00020486079 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.77         |\n|    explained_variance           | 0.227         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 15.9          |\n|    n_updates                    | 180           |\n|    policy_gradient_loss         | 0.000172      |\n|    value_loss                   | 32.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 72            |\n|    water_produced               | 1.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 10.7          |\n| time/                           |               |\n|    fps                          | 790           |\n|    iterations                   | 92            |\n|    time_elapsed                 | 465           |\n|    total_timesteps              | 368000        |\n| train/                          |               |\n|    approx_kl                    | 0.00015487775 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.78         |\n|    explained_variance           | 0.734         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 1.16          |\n|    n_updates                    | 182           |\n|    policy_gradient_loss         | -9.3e-06      |\n|    value_loss                   | 2.33          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 113           |\n|    water_produced               | 12.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 10.6         |\n| time/                           |              |\n|    fps                          | 790          |\n|    iterations                   | 93           |\n|    time_elapsed                 | 470          |\n|    total_timesteps              | 372000       |\n| train/                          |              |\n|    approx_kl                    | 0.0016817044 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.76        |\n|    explained_variance           | 0.266        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 9.1          |\n|    n_updates                    | 184          |\n|    policy_gradient_loss         | -0.0011      |\n|    value_loss                   | 17           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 122          |\n|    water_produced               | 13           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 11.7         |\n| time/                           |              |\n|    fps                          | 790          |\n|    iterations                   | 94           |\n|    time_elapsed                 | 475          |\n|    total_timesteps              | 376000       |\n| train/                          |              |\n|    approx_kl                    | 0.0006763857 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.64        |\n|    explained_variance           | 0.15         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 17.4         |\n|    n_updates                    | 186          |\n|    policy_gradient_loss         | -7.96e-05    |\n|    value_loss                   | 22.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 79           |\n|    water_produced               | 9            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11            |\n| time/                           |               |\n|    fps                          | 791           |\n|    iterations                   | 95            |\n|    time_elapsed                 | 480           |\n|    total_timesteps              | 380000        |\n| train/                          |               |\n|    approx_kl                    | 0.00032742237 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.77         |\n|    explained_variance           | 0.224         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 10.9          |\n|    n_updates                    | 188           |\n|    policy_gradient_loss         | -2.02e-05     |\n|    value_loss                   | 20.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 135           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 79            |\n|    water_produced               | 14.2          |\n---------------------------------------------------\nEval num_timesteps=384000, episode_reward=36.56 +/- 73.02\nEpisode length: 336.00 +/- 70.00\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 336           |\n|    mean_reward                  | 36.6          |\n| time/                           |               |\n|    total_timesteps              | 384000        |\n| train/                          |               |\n|    approx_kl                    | 0.00034279362 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.75         |\n|    explained_variance           | 0.197         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 20.8          |\n|    n_updates                    | 190           |\n|    policy_gradient_loss         | -0.000371     |\n|    value_loss                   | 32.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 135           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 153           |\n|    water_produced               | 27.8          |\n---------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 16.3     |\n| time/              |          |\n|    fps             | 786      |\n|    iterations      | 96       |\n|    time_elapsed    | 488      |\n|    total_timesteps | 384000   |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 16.9         |\n| time/                           |              |\n|    fps                          | 786          |\n|    iterations                   | 97           |\n|    time_elapsed                 | 493          |\n|    total_timesteps              | 388000       |\n| train/                          |              |\n|    approx_kl                    | 0.0005015042 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.63        |\n|    explained_variance           | 0.144        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 30.4         |\n|    n_updates                    | 192          |\n|    policy_gradient_loss         | -0.000358    |\n|    value_loss                   | 57.6         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 144          |\n|    ice_dug                      | 84           |\n|    water_produced               | 15.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 16.7          |\n| time/                           |               |\n|    fps                          | 787           |\n|    iterations                   | 98            |\n|    time_elapsed                 | 497           |\n|    total_timesteps              | 392000        |\n| train/                          |               |\n|    approx_kl                    | 0.00044463776 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.57         |\n|    explained_variance           | 0.182         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 14.2          |\n|    n_updates                    | 194           |\n|    policy_gradient_loss         | 1.12e-05      |\n|    value_loss                   | 28            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 141           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 78            |\n|    water_produced               | 12.3          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 17.4          |\n| time/                           |               |\n|    fps                          | 787           |\n|    iterations                   | 99            |\n|    time_elapsed                 | 502           |\n|    total_timesteps              | 396000        |\n| train/                          |               |\n|    approx_kl                    | 0.00016963489 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.58         |\n|    explained_variance           | 0.151         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 13.3          |\n|    n_updates                    | 196           |\n|    policy_gradient_loss         | 6.89e-06      |\n|    value_loss                   | 28.2          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 106           |\n|    water_produced               | 12.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 17.8         |\n| time/                           |              |\n|    fps                          | 787          |\n|    iterations                   | 100          |\n|    time_elapsed                 | 507          |\n|    total_timesteps              | 400000       |\n| train/                          |              |\n|    approx_kl                    | 0.0009872374 |\n|    clip_fraction                | 0.00188      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.69        |\n|    explained_variance           | 0.244        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 8            |\n|    n_updates                    | 198          |\n|    policy_gradient_loss         | -0.00119     |\n|    value_loss                   | 17.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 95           |\n|    water_produced               | 15.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 13.6         |\n| time/                           |              |\n|    fps                          | 788          |\n|    iterations                   | 101          |\n|    time_elapsed                 | 512          |\n|    total_timesteps              | 404000       |\n| train/                          |              |\n|    approx_kl                    | 0.0030415982 |\n|    clip_fraction                | 0.00388      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.65        |\n|    explained_variance           | 0.167        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 15.4         |\n|    n_updates                    | 200          |\n|    policy_gradient_loss         | -0.0019      |\n|    value_loss                   | 28.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 124          |\n|    action_queue_updates_total   | 135          |\n|    ice_dug                      | 38           |\n|    water_produced               | 8            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 14.5         |\n| time/                           |              |\n|    fps                          | 789          |\n|    iterations                   | 102          |\n|    time_elapsed                 | 516          |\n|    total_timesteps              | 408000       |\n| train/                          |              |\n|    approx_kl                    | 0.0013733355 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.53        |\n|    explained_variance           | 0.136        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 12.2         |\n|    n_updates                    | 202          |\n|    policy_gradient_loss         | 0.000127     |\n|    value_loss                   | 28.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 119          |\n|    action_queue_updates_total   | 132          |\n|    ice_dug                      | 148          |\n|    water_produced               | 19.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 12.6          |\n| time/                           |               |\n|    fps                          | 789           |\n|    iterations                   | 103           |\n|    time_elapsed                 | 521           |\n|    total_timesteps              | 412000        |\n| train/                          |               |\n|    approx_kl                    | 0.00025131094 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.56         |\n|    explained_variance           | 0.153         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 23.7          |\n|    n_updates                    | 204           |\n|    policy_gradient_loss         | -0.00014      |\n|    value_loss                   | 42.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 127           |\n|    action_queue_updates_total   | 141           |\n|    ice_dug                      | 47            |\n|    water_produced               | 3             |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 12.7        |\n| time/                           |             |\n|    fps                          | 790         |\n|    iterations                   | 104         |\n|    time_elapsed                 | 526         |\n|    total_timesteps              | 416000      |\n| train/                          |             |\n|    approx_kl                    | 3.66032e-05 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.6        |\n|    explained_variance           | 0.49        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 2.54        |\n|    n_updates                    | 206         |\n|    policy_gradient_loss         | 2.05e-05    |\n|    value_loss                   | 4.84        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 120         |\n|    action_queue_updates_total   | 131         |\n|    ice_dug                      | 84          |\n|    water_produced               | 13.2        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 18.7         |\n| time/                           |              |\n|    fps                          | 789          |\n|    iterations                   | 105          |\n|    time_elapsed                 | 531          |\n|    total_timesteps              | 420000       |\n| train/                          |              |\n|    approx_kl                    | 0.0001189569 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.58        |\n|    explained_variance           | 0.101        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 14.7         |\n|    n_updates                    | 208          |\n|    policy_gradient_loss         | -0.000202    |\n|    value_loss                   | 34.6         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 128          |\n|    action_queue_updates_total   | 135          |\n|    ice_dug                      | 276          |\n|    water_produced               | 44           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 21.6          |\n| time/                           |               |\n|    fps                          | 790           |\n|    iterations                   | 106           |\n|    time_elapsed                 | 536           |\n|    total_timesteps              | 424000        |\n| train/                          |               |\n|    approx_kl                    | 0.00049734936 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.5          |\n|    explained_variance           | 0.0782        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 57.7          |\n|    n_updates                    | 210           |\n|    policy_gradient_loss         | -0.000153     |\n|    value_loss                   | 114           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 118           |\n|    action_queue_updates_total   | 132           |\n|    ice_dug                      | 145           |\n|    water_produced               | 21.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.6         |\n| time/                           |              |\n|    fps                          | 790          |\n|    iterations                   | 107          |\n|    time_elapsed                 | 541          |\n|    total_timesteps              | 428000       |\n| train/                          |              |\n|    approx_kl                    | 0.0004019789 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.51        |\n|    explained_variance           | 0.0964       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 36.6         |\n|    n_updates                    | 212          |\n|    policy_gradient_loss         | -0.000363    |\n|    value_loss                   | 66           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 124          |\n|    action_queue_updates_total   | 133          |\n|    ice_dug                      | 78           |\n|    water_produced               | 9.75         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 26.4          |\n| time/                           |               |\n|    fps                          | 791           |\n|    iterations                   | 108           |\n|    time_elapsed                 | 546           |\n|    total_timesteps              | 432000        |\n| train/                          |               |\n|    approx_kl                    | 3.4632547e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.44         |\n|    explained_variance           | 0.12          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.6           |\n|    n_updates                    | 214           |\n|    policy_gradient_loss         | 0.000113      |\n|    value_loss                   | 19.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 117           |\n|    action_queue_updates_total   | 127           |\n|    ice_dug                      | 179           |\n|    water_produced               | 35.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 26.5          |\n| time/                           |               |\n|    fps                          | 791           |\n|    iterations                   | 109           |\n|    time_elapsed                 | 550           |\n|    total_timesteps              | 436000        |\n| train/                          |               |\n|    approx_kl                    | 4.0246592e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.51         |\n|    explained_variance           | 0.127         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 26.6          |\n|    n_updates                    | 216           |\n|    policy_gradient_loss         | -0.000128     |\n|    value_loss                   | 84.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 116           |\n|    action_queue_updates_total   | 121           |\n|    ice_dug                      | 97            |\n|    water_produced               | 13.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 20.7          |\n| time/                           |               |\n|    fps                          | 791           |\n|    iterations                   | 110           |\n|    time_elapsed                 | 555           |\n|    total_timesteps              | 440000        |\n| train/                          |               |\n|    approx_kl                    | 0.00016541663 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.43         |\n|    explained_variance           | 0.0892        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 13.6          |\n|    n_updates                    | 218           |\n|    policy_gradient_loss         | -0.000184     |\n|    value_loss                   | 25.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 125           |\n|    action_queue_updates_total   | 136           |\n|    ice_dug                      | 116           |\n|    water_produced               | 16.7          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.2          |\n| time/                           |               |\n|    fps                          | 792           |\n|    iterations                   | 111           |\n|    time_elapsed                 | 560           |\n|    total_timesteps              | 444000        |\n| train/                          |               |\n|    approx_kl                    | 0.00048110232 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.47         |\n|    explained_variance           | 0.119         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 16.8          |\n|    n_updates                    | 220           |\n|    policy_gradient_loss         | 7.64e-05      |\n|    value_loss                   | 32.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 124           |\n|    action_queue_updates_total   | 135           |\n|    ice_dug                      | 61            |\n|    water_produced               | 9.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 17.1          |\n| time/                           |               |\n|    fps                          | 792           |\n|    iterations                   | 112           |\n|    time_elapsed                 | 565           |\n|    total_timesteps              | 448000        |\n| train/                          |               |\n|    approx_kl                    | 0.00021812467 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.53         |\n|    explained_variance           | 0.129         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.3           |\n|    n_updates                    | 222           |\n|    policy_gradient_loss         | -0.00015      |\n|    value_loss                   | 20.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 127           |\n|    action_queue_updates_total   | 136           |\n|    ice_dug                      | 26            |\n|    water_produced               | 4.5           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.4          |\n| time/                           |               |\n|    fps                          | 791           |\n|    iterations                   | 113           |\n|    time_elapsed                 | 570           |\n|    total_timesteps              | 452000        |\n| train/                          |               |\n|    approx_kl                    | 0.00019556319 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.49         |\n|    explained_variance           | 0.199         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 5.6           |\n|    n_updates                    | 224           |\n|    policy_gradient_loss         | -8.39e-05     |\n|    value_loss                   | 10.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 120           |\n|    action_queue_updates_total   | 132           |\n|    ice_dug                      | 107           |\n|    water_produced               | 18            |\n---------------------------------------------------\n----------------------------------------------------\n| rollout/                        |                |\n|    ep_len_mean                  | 200            |\n|    ep_rew_mean                  | 13.9           |\n| time/                           |                |\n|    fps                          | 792            |\n|    iterations                   | 114            |\n|    time_elapsed                 | 575            |\n|    total_timesteps              | 456000         |\n| train/                          |                |\n|    approx_kl                    | 0.000107978274 |\n|    clip_fraction                | 0              |\n|    clip_range                   | 0.2            |\n|    entropy_loss                 | -1.49          |\n|    explained_variance           | 0.158          |\n|    learning_rate                | 0.0003         |\n|    loss                         | 18             |\n|    n_updates                    | 226            |\n|    policy_gradient_loss         | -5.5e-05       |\n|    value_loss                   | 40.1           |\n| train_metrics/                  |                |\n|    action_queue_updates_success | 121            |\n|    action_queue_updates_total   | 127            |\n|    ice_dug                      | 89             |\n|    water_produced               | 16.5           |\n----------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.8          |\n| time/                           |               |\n|    fps                          | 792           |\n|    iterations                   | 115           |\n|    time_elapsed                 | 580           |\n|    total_timesteps              | 460000        |\n| train/                          |               |\n|    approx_kl                    | 0.00019832849 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.44         |\n|    explained_variance           | 0.0649        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 18            |\n|    n_updates                    | 228           |\n|    policy_gradient_loss         | -0.000104     |\n|    value_loss                   | 43            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 120           |\n|    action_queue_updates_total   | 133           |\n|    ice_dug                      | 107           |\n|    water_produced               | 16.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 21.8         |\n| time/                           |              |\n|    fps                          | 792          |\n|    iterations                   | 116          |\n|    time_elapsed                 | 585          |\n|    total_timesteps              | 464000       |\n| train/                          |              |\n|    approx_kl                    | 7.485457e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.46        |\n|    explained_variance           | 0.131        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 19.3         |\n|    n_updates                    | 230          |\n|    policy_gradient_loss         | -6.18e-05    |\n|    value_loss                   | 32.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 129          |\n|    action_queue_updates_total   | 139          |\n|    ice_dug                      | 242          |\n|    water_produced               | 48           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 23            |\n| time/                           |               |\n|    fps                          | 793           |\n|    iterations                   | 117           |\n|    time_elapsed                 | 589           |\n|    total_timesteps              | 468000        |\n| train/                          |               |\n|    approx_kl                    | 0.00026079142 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.47         |\n|    explained_variance           | 0.0796        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 52.5          |\n|    n_updates                    | 232           |\n|    policy_gradient_loss         | -0.000543     |\n|    value_loss                   | 120           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 140           |\n|    ice_dug                      | 53            |\n|    water_produced               | 10            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 24.8         |\n| time/                           |              |\n|    fps                          | 793          |\n|    iterations                   | 118          |\n|    time_elapsed                 | 594          |\n|    total_timesteps              | 472000       |\n| train/                          |              |\n|    approx_kl                    | 2.621132e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.46        |\n|    explained_variance           | 0.116        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 14.3         |\n|    n_updates                    | 234          |\n|    policy_gradient_loss         | 2.88e-05     |\n|    value_loss                   | 22           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 142          |\n|    ice_dug                      | 165          |\n|    water_produced               | 26.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 24.6          |\n| time/                           |               |\n|    fps                          | 793           |\n|    iterations                   | 119           |\n|    time_elapsed                 | 599           |\n|    total_timesteps              | 476000        |\n| train/                          |               |\n|    approx_kl                    | 4.6345533e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.48         |\n|    explained_variance           | 0.0935        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 25.1          |\n|    n_updates                    | 236           |\n|    policy_gradient_loss         | -0.000165     |\n|    value_loss                   | 53.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 144           |\n|    ice_dug                      | 119           |\n|    water_produced               | 15.2          |\n---------------------------------------------------\nEval num_timesteps=480000, episode_reward=13.28 +/- 19.98\nEpisode length: 312.00 +/- 19.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 312          |\n|    mean_reward                  | 13.3         |\n| time/                           |              |\n|    total_timesteps              | 480000       |\n| train/                          |              |\n|    approx_kl                    | 0.0002150936 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.56        |\n|    explained_variance           | 0.152        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 12.7         |\n|    n_updates                    | 238          |\n|    policy_gradient_loss         | -0.000182    |\n|    value_loss                   | 26.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 36           |\n|    water_produced               | 5.25         |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 22.2     |\n| time/              |          |\n|    fps             | 790      |\n|    iterations      | 120      |\n|    time_elapsed    | 607      |\n|    total_timesteps | 480000   |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.8          |\n| time/                           |               |\n|    fps                          | 791           |\n|    iterations                   | 121           |\n|    time_elapsed                 | 611           |\n|    total_timesteps              | 484000        |\n| train/                          |               |\n|    approx_kl                    | 0.00047319802 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.53         |\n|    explained_variance           | 0.14          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.24          |\n|    n_updates                    | 240           |\n|    policy_gradient_loss         | 0.000175      |\n|    value_loss                   | 9.69          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 125           |\n|    action_queue_updates_total   | 137           |\n|    ice_dug                      | 43            |\n|    water_produced               | 7.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 16            |\n| time/                           |               |\n|    fps                          | 791           |\n|    iterations                   | 122           |\n|    time_elapsed                 | 616           |\n|    total_timesteps              | 488000        |\n| train/                          |               |\n|    approx_kl                    | 0.00042868807 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.55         |\n|    explained_variance           | 0.233         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.49          |\n|    n_updates                    | 242           |\n|    policy_gradient_loss         | -0.000221     |\n|    value_loss                   | 12.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 129           |\n|    action_queue_updates_total   | 139           |\n|    ice_dug                      | 151           |\n|    water_produced               | 20            |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 14.5        |\n| time/                           |             |\n|    fps                          | 792         |\n|    iterations                   | 123         |\n|    time_elapsed                 | 620         |\n|    total_timesteps              | 492000      |\n| train/                          |             |\n|    approx_kl                    | 3.25426e-05 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.52       |\n|    explained_variance           | 0.155       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 25.2        |\n|    n_updates                    | 244         |\n|    policy_gradient_loss         | -3.36e-05   |\n|    value_loss                   | 47.6        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 127         |\n|    action_queue_updates_total   | 138         |\n|    ice_dug                      | 92          |\n|    water_produced               | 19.8        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 20.8          |\n| time/                           |               |\n|    fps                          | 792           |\n|    iterations                   | 124           |\n|    time_elapsed                 | 625           |\n|    total_timesteps              | 496000        |\n| train/                          |               |\n|    approx_kl                    | 0.00014352065 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.53         |\n|    explained_variance           | 0.0731        |\n|    learning_rate                | 0.0003        |\n|    loss                         | 19.1          |\n|    n_updates                    | 246           |\n|    policy_gradient_loss         | -0.000165     |\n|    value_loss                   | 46.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 146           |\n|    ice_dug                      | 212           |\n|    water_produced               | 46            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 21.4         |\n| time/                           |              |\n|    fps                          | 792          |\n|    iterations                   | 125          |\n|    time_elapsed                 | 630          |\n|    total_timesteps              | 500000       |\n| train/                          |              |\n|    approx_kl                    | 0.0002800067 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.54        |\n|    explained_variance           | 0.0908       |\n|    learning_rate                | 0.0003       |\n|    loss                         | 61.6         |\n|    n_updates                    | 248          |\n|    policy_gradient_loss         | -0.000172    |\n|    value_loss                   | 114          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 62           |\n|    water_produced               | 8            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 22.6         |\n| time/                           |              |\n|    fps                          | 793          |\n|    iterations                   | 126          |\n|    time_elapsed                 | 634          |\n|    total_timesteps              | 504000       |\n| train/                          |              |\n|    approx_kl                    | 7.029156e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.59        |\n|    explained_variance           | 0.223        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 9.77         |\n|    n_updates                    | 250          |\n|    policy_gradient_loss         | -0.000259    |\n|    value_loss                   | 15.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 93           |\n|    water_produced               | 13           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.9          |\n| time/                           |               |\n|    fps                          | 794           |\n|    iterations                   | 127           |\n|    time_elapsed                 | 639           |\n|    total_timesteps              | 508000        |\n| train/                          |               |\n|    approx_kl                    | 0.00052950566 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.58         |\n|    explained_variance           | 0.168         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 18.8          |\n|    n_updates                    | 252           |\n|    policy_gradient_loss         | 4.88e-05      |\n|    value_loss                   | 24.3          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 144           |\n|    ice_dug                      | 40            |\n|    water_produced               | 2.75          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 20.1         |\n| time/                           |              |\n|    fps                          | 794          |\n|    iterations                   | 128          |\n|    time_elapsed                 | 644          |\n|    total_timesteps              | 512000       |\n| train/                          |              |\n|    approx_kl                    | 0.0003762257 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.57        |\n|    explained_variance           | 0.44         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 1.53         |\n|    n_updates                    | 254          |\n|    policy_gradient_loss         | 0.000105     |\n|    value_loss                   | 3.49         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 141          |\n|    ice_dug                      | 127          |\n|    water_produced               | 25.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 14            |\n| time/                           |               |\n|    fps                          | 794           |\n|    iterations                   | 129           |\n|    time_elapsed                 | 649           |\n|    total_timesteps              | 516000        |\n| train/                          |               |\n|    approx_kl                    | 5.9887097e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.61         |\n|    explained_variance           | 0.102         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 23.8          |\n|    n_updates                    | 256           |\n|    policy_gradient_loss         | 0.000126      |\n|    value_loss                   | 57.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 144           |\n|    ice_dug                      | 140           |\n|    water_produced               | 16.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 20.2          |\n| time/                           |               |\n|    fps                          | 795           |\n|    iterations                   | 130           |\n|    time_elapsed                 | 653           |\n|    total_timesteps              | 520000        |\n| train/                          |               |\n|    approx_kl                    | 0.00017327846 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.58         |\n|    explained_variance           | 0.131         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 20.6          |\n|    n_updates                    | 258           |\n|    policy_gradient_loss         | -0.000129     |\n|    value_loss                   | 34.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 219           |\n|    water_produced               | 37.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 20.2          |\n| time/                           |               |\n|    fps                          | 794           |\n|    iterations                   | 131           |\n|    time_elapsed                 | 659           |\n|    total_timesteps              | 524000        |\n| train/                          |               |\n|    approx_kl                    | 0.00021337035 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.62         |\n|    explained_variance           | 0.118         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 35.5          |\n|    n_updates                    | 260           |\n|    policy_gradient_loss         | -7.44e-05     |\n|    value_loss                   | 66.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 144           |\n|    ice_dug                      | 85            |\n|    water_produced               | 13            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 26.6         |\n| time/                           |              |\n|    fps                          | 795          |\n|    iterations                   | 132          |\n|    time_elapsed                 | 664          |\n|    total_timesteps              | 528000       |\n| train/                          |              |\n|    approx_kl                    | 2.789703e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.61        |\n|    explained_variance           | 0.151        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 14.3         |\n|    n_updates                    | 262          |\n|    policy_gradient_loss         | -1.9e-05     |\n|    value_loss                   | 30.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 154          |\n|    water_produced               | 33.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 22.8          |\n| time/                           |               |\n|    fps                          | 795           |\n|    iterations                   | 133           |\n|    time_elapsed                 | 668           |\n|    total_timesteps              | 532000        |\n| train/                          |               |\n|    approx_kl                    | 4.4058357e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.57         |\n|    explained_variance           | 0.109         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 38.5          |\n|    n_updates                    | 264           |\n|    policy_gradient_loss         | -4e-05        |\n|    value_loss                   | 76            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 135           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 71            |\n|    water_produced               | 6.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 28.2          |\n| time/                           |               |\n|    fps                          | 795           |\n|    iterations                   | 134           |\n|    time_elapsed                 | 673           |\n|    total_timesteps              | 536000        |\n| train/                          |               |\n|    approx_kl                    | 0.00013034629 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.68         |\n|    explained_variance           | 0.242         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.84          |\n|    n_updates                    | 266           |\n|    policy_gradient_loss         | -2.43e-05     |\n|    value_loss                   | 12.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 134           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 223           |\n|    water_produced               | 42.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 21.5          |\n| time/                           |               |\n|    fps                          | 796           |\n|    iterations                   | 135           |\n|    time_elapsed                 | 678           |\n|    total_timesteps              | 540000        |\n| train/                          |               |\n|    approx_kl                    | 0.00014052202 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.72         |\n|    explained_variance           | 0.17          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 49.4          |\n|    n_updates                    | 268           |\n|    policy_gradient_loss         | 0.000323      |\n|    value_loss                   | 97.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 132           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 27            |\n|    water_produced               | 6.5           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 21.5         |\n| time/                           |              |\n|    fps                          | 796          |\n|    iterations                   | 136          |\n|    time_elapsed                 | 682          |\n|    total_timesteps              | 544000       |\n| train/                          |              |\n|    approx_kl                    | 9.267153e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.67        |\n|    explained_variance           | 0.224        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 6.89         |\n|    n_updates                    | 270          |\n|    policy_gradient_loss         | 6.66e-05     |\n|    value_loss                   | 17.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 98           |\n|    water_produced               | 13           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.8          |\n| time/                           |               |\n|    fps                          | 797           |\n|    iterations                   | 137           |\n|    time_elapsed                 | 687           |\n|    total_timesteps              | 548000        |\n| train/                          |               |\n|    approx_kl                    | 0.00077834737 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.66         |\n|    explained_variance           | 0.203         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 14.7          |\n|    n_updates                    | 272           |\n|    policy_gradient_loss         | -0.000113     |\n|    value_loss                   | 30.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 31            |\n|    water_produced               | 5.75          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 15.7         |\n| time/                           |              |\n|    fps                          | 797          |\n|    iterations                   | 138          |\n|    time_elapsed                 | 692          |\n|    total_timesteps              | 552000       |\n| train/                          |              |\n|    approx_kl                    | 0.0006762225 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.68        |\n|    explained_variance           | 0.311        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 6.78         |\n|    n_updates                    | 274          |\n|    policy_gradient_loss         | -6.98e-05    |\n|    value_loss                   | 11.1         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 57           |\n|    water_produced               | 6.75         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 10.1         |\n| time/                           |              |\n|    fps                          | 797          |\n|    iterations                   | 139          |\n|    time_elapsed                 | 696          |\n|    total_timesteps              | 556000       |\n| train/                          |              |\n|    approx_kl                    | 0.0012264508 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.88        |\n|    explained_variance           | 0.308        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 8.9          |\n|    n_updates                    | 276          |\n|    policy_gradient_loss         | -0.000155    |\n|    value_loss                   | 13.1         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 91           |\n|    water_produced               | 15.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 14           |\n| time/                           |              |\n|    fps                          | 797          |\n|    iterations                   | 140          |\n|    time_elapsed                 | 701          |\n|    total_timesteps              | 560000       |\n| train/                          |              |\n|    approx_kl                    | 7.645832e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.85        |\n|    explained_variance           | 0.319        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 12.5         |\n|    n_updates                    | 278          |\n|    policy_gradient_loss         | 4.77e-05     |\n|    value_loss                   | 28.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 151          |\n|    water_produced               | 24.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.3          |\n| time/                           |               |\n|    fps                          | 797           |\n|    iterations                   | 141           |\n|    time_elapsed                 | 706           |\n|    total_timesteps              | 564000        |\n| train/                          |               |\n|    approx_kl                    | 0.00021975087 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.73         |\n|    explained_variance           | 0.214         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 15.2          |\n|    n_updates                    | 280           |\n|    policy_gradient_loss         | -0.000121     |\n|    value_loss                   | 39.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 104           |\n|    water_produced               | 19.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 17.6          |\n| time/                           |               |\n|    fps                          | 798           |\n|    iterations                   | 142           |\n|    time_elapsed                 | 711           |\n|    total_timesteps              | 568000        |\n| train/                          |               |\n|    approx_kl                    | 0.00017151487 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.72         |\n|    explained_variance           | 0.261         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 26.1          |\n|    n_updates                    | 282           |\n|    policy_gradient_loss         | -0.000131     |\n|    value_loss                   | 42.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 116           |\n|    water_produced               | 16.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 19.1          |\n| time/                           |               |\n|    fps                          | 798           |\n|    iterations                   | 143           |\n|    time_elapsed                 | 716           |\n|    total_timesteps              | 572000        |\n| train/                          |               |\n|    approx_kl                    | 0.00019878987 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.78         |\n|    explained_variance           | 0.23          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 19.2          |\n|    n_updates                    | 284           |\n|    policy_gradient_loss         | -0.000131     |\n|    value_loss                   | 35.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 135           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 104           |\n|    water_produced               | 14            |\n---------------------------------------------------\nEval num_timesteps=576000, episode_reward=0.00 +/- 0.00\nEpisode length: 301.00 +/- 0.00\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 301           |\n|    mean_reward                  | 0             |\n| time/                           |               |\n|    total_timesteps              | 576000        |\n| train/                          |               |\n|    approx_kl                    | 0.00042357476 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.77         |\n|    explained_variance           | 0.296         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 13.4          |\n|    n_updates                    | 286           |\n|    policy_gradient_loss         | -0.000252     |\n|    value_loss                   | 31.2          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 128           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 94            |\n|    water_produced               | 8.5           |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 17.7     |\n| time/              |          |\n|    fps             | 795      |\n|    iterations      | 144      |\n|    time_elapsed    | 724      |\n|    total_timesteps | 576000   |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 15.6         |\n| time/                           |              |\n|    fps                          | 795          |\n|    iterations                   | 145          |\n|    time_elapsed                 | 729          |\n|    total_timesteps              | 580000       |\n| train/                          |              |\n|    approx_kl                    | 0.0014275485 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.85        |\n|    explained_variance           | 0.499        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 6.3          |\n|    n_updates                    | 288          |\n|    policy_gradient_loss         | -0.000848    |\n|    value_loss                   | 10.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 91           |\n|    water_produced               | 14.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 16           |\n| time/                           |              |\n|    fps                          | 795          |\n|    iterations                   | 146          |\n|    time_elapsed                 | 734          |\n|    total_timesteps              | 584000       |\n| train/                          |              |\n|    approx_kl                    | 0.0005172007 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.65        |\n|    explained_variance           | 0.301        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 18.3         |\n|    n_updates                    | 290          |\n|    policy_gradient_loss         | -0.000417    |\n|    value_loss                   | 28.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 188          |\n|    water_produced               | 21           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 18.6         |\n| time/                           |              |\n|    fps                          | 795          |\n|    iterations                   | 147          |\n|    time_elapsed                 | 739          |\n|    total_timesteps              | 588000       |\n| train/                          |              |\n|    approx_kl                    | 0.0008119313 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.71        |\n|    explained_variance           | 0.279        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 24.7         |\n|    n_updates                    | 292          |\n|    policy_gradient_loss         | -0.000112    |\n|    value_loss                   | 44.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 130          |\n|    water_produced               | 28.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 17.2         |\n| time/                           |              |\n|    fps                          | 795          |\n|    iterations                   | 148          |\n|    time_elapsed                 | 743          |\n|    total_timesteps              | 592000       |\n| train/                          |              |\n|    approx_kl                    | 0.0005473661 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.74        |\n|    explained_variance           | 0.247        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 31.2         |\n|    n_updates                    | 294          |\n|    policy_gradient_loss         | -0.000323    |\n|    value_loss                   | 56.6         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 40           |\n|    water_produced               | 7.75         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 19.7          |\n| time/                           |               |\n|    fps                          | 796           |\n|    iterations                   | 149           |\n|    time_elapsed                 | 748           |\n|    total_timesteps              | 596000        |\n| train/                          |               |\n|    approx_kl                    | 0.00036622933 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.72         |\n|    explained_variance           | 0.402         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.83          |\n|    n_updates                    | 296           |\n|    policy_gradient_loss         | 0.000144      |\n|    value_loss                   | 20            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 136           |\n|    water_produced               | 20.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 21           |\n| time/                           |              |\n|    fps                          | 795          |\n|    iterations                   | 150          |\n|    time_elapsed                 | 753          |\n|    total_timesteps              | 600000       |\n| train/                          |              |\n|    approx_kl                    | 0.0002547471 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.77        |\n|    explained_variance           | 0.301        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 20.6         |\n|    n_updates                    | 298          |\n|    policy_gradient_loss         | 0.000133     |\n|    value_loss                   | 50.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 116          |\n|    water_produced               | 21           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 21.7          |\n| time/                           |               |\n|    fps                          | 796           |\n|    iterations                   | 151           |\n|    time_elapsed                 | 758           |\n|    total_timesteps              | 604000        |\n| train/                          |               |\n|    approx_kl                    | 0.00018713754 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.78         |\n|    explained_variance           | 0.31          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 15.9          |\n|    n_updates                    | 300           |\n|    policy_gradient_loss         | -5.62e-05     |\n|    value_loss                   | 49.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 128           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 121           |\n|    water_produced               | 25            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 20.2          |\n| time/                           |               |\n|    fps                          | 796           |\n|    iterations                   | 152           |\n|    time_elapsed                 | 763           |\n|    total_timesteps              | 608000        |\n| train/                          |               |\n|    approx_kl                    | 0.00012084496 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.71         |\n|    explained_variance           | 0.288         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 44.4          |\n|    n_updates                    | 302           |\n|    policy_gradient_loss         | -9.99e-05     |\n|    value_loss                   | 68.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 129           |\n|    action_queue_updates_total   | 145           |\n|    ice_dug                      | 186           |\n|    water_produced               | 20.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 21.9          |\n| time/                           |               |\n|    fps                          | 796           |\n|    iterations                   | 153           |\n|    time_elapsed                 | 768           |\n|    total_timesteps              | 612000        |\n| train/                          |               |\n|    approx_kl                    | 0.00012577753 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.65         |\n|    explained_variance           | 0.36          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 20.3          |\n|    n_updates                    | 304           |\n|    policy_gradient_loss         | 1.96e-05      |\n|    value_loss                   | 39.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 134           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 146           |\n|    water_produced               | 15.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 21.8          |\n| time/                           |               |\n|    fps                          | 796           |\n|    iterations                   | 154           |\n|    time_elapsed                 | 773           |\n|    total_timesteps              | 616000        |\n| train/                          |               |\n|    approx_kl                    | 0.00021348354 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.78         |\n|    explained_variance           | 0.4           |\n|    learning_rate                | 0.0003        |\n|    loss                         | 14.2          |\n|    n_updates                    | 306           |\n|    policy_gradient_loss         | 0.000114      |\n|    value_loss                   | 29.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 140           |\n|    water_produced               | 19.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 20.4         |\n| time/                           |              |\n|    fps                          | 796          |\n|    iterations                   | 155          |\n|    time_elapsed                 | 778          |\n|    total_timesteps              | 620000       |\n| train/                          |              |\n|    approx_kl                    | 0.0011422962 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.71        |\n|    explained_variance           | 0.439        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 13.3         |\n|    n_updates                    | 308          |\n|    policy_gradient_loss         | -0.000333    |\n|    value_loss                   | 30.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 86           |\n|    water_produced               | 14.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 17.4         |\n| time/                           |              |\n|    fps                          | 796          |\n|    iterations                   | 156          |\n|    time_elapsed                 | 783          |\n|    total_timesteps              | 624000       |\n| train/                          |              |\n|    approx_kl                    | 0.0018914065 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.86        |\n|    explained_variance           | 0.511        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 14.6         |\n|    n_updates                    | 310          |\n|    policy_gradient_loss         | 1.37e-05     |\n|    value_loss                   | 25.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 51           |\n|    water_produced               | 10.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 17.9          |\n| time/                           |               |\n|    fps                          | 796           |\n|    iterations                   | 157           |\n|    time_elapsed                 | 788           |\n|    total_timesteps              | 628000        |\n| train/                          |               |\n|    approx_kl                    | 0.00040925355 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.92         |\n|    explained_variance           | 0.603         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.77          |\n|    n_updates                    | 312           |\n|    policy_gradient_loss         | -0.000366     |\n|    value_loss                   | 15.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 132           |\n|    water_produced               | 23.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 18.6         |\n| time/                           |              |\n|    fps                          | 797          |\n|    iterations                   | 158          |\n|    time_elapsed                 | 792          |\n|    total_timesteps              | 632000       |\n| train/                          |              |\n|    approx_kl                    | 0.0014935824 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.73        |\n|    explained_variance           | 0.427        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 21.4         |\n|    n_updates                    | 314          |\n|    policy_gradient_loss         | -0.000123    |\n|    value_loss                   | 50           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 114          |\n|    water_produced               | 19           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.2          |\n| time/                           |               |\n|    fps                          | 797           |\n|    iterations                   | 159           |\n|    time_elapsed                 | 797           |\n|    total_timesteps              | 636000        |\n| train/                          |               |\n|    approx_kl                    | 5.0288927e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.64         |\n|    explained_variance           | 0.321         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 20.3          |\n|    n_updates                    | 316           |\n|    policy_gradient_loss         | 1.61e-05      |\n|    value_loss                   | 37.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 128           |\n|    action_queue_updates_total   | 140           |\n|    ice_dug                      | 23            |\n|    water_produced               | 4             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.5          |\n| time/                           |               |\n|    fps                          | 798           |\n|    iterations                   | 160           |\n|    time_elapsed                 | 801           |\n|    total_timesteps              | 640000        |\n| train/                          |               |\n|    approx_kl                    | 0.00052962865 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.59         |\n|    explained_variance           | 0.564         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 2.88          |\n|    n_updates                    | 318           |\n|    policy_gradient_loss         | -0.00019      |\n|    value_loss                   | 10.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 147           |\n|    ice_dug                      | 88            |\n|    water_produced               | 15.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.9          |\n| time/                           |               |\n|    fps                          | 798           |\n|    iterations                   | 161           |\n|    time_elapsed                 | 806           |\n|    total_timesteps              | 644000        |\n| train/                          |               |\n|    approx_kl                    | 0.00015061807 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.69         |\n|    explained_variance           | 0.367         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 20.5          |\n|    n_updates                    | 320           |\n|    policy_gradient_loss         | -0.000371     |\n|    value_loss                   | 36.3          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 143           |\n|    ice_dug                      | 76            |\n|    water_produced               | 12.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 14.2          |\n| time/                           |               |\n|    fps                          | 799           |\n|    iterations                   | 162           |\n|    time_elapsed                 | 810           |\n|    total_timesteps              | 648000        |\n| train/                          |               |\n|    approx_kl                    | 0.00020718158 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.58         |\n|    explained_variance           | 0.339         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 12.1          |\n|    n_updates                    | 322           |\n|    policy_gradient_loss         | -0.000387     |\n|    value_loss                   | 31            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 123           |\n|    action_queue_updates_total   | 144           |\n|    ice_dug                      | 75            |\n|    water_produced               | 15.7          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11.7          |\n| time/                           |               |\n|    fps                          | 799           |\n|    iterations                   | 163           |\n|    time_elapsed                 | 815           |\n|    total_timesteps              | 652000        |\n| train/                          |               |\n|    approx_kl                    | 0.00020122866 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.69         |\n|    explained_variance           | 0.43          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 17.4          |\n|    n_updates                    | 324           |\n|    policy_gradient_loss         | -0.000158     |\n|    value_loss                   | 31            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 123           |\n|    action_queue_updates_total   | 139           |\n|    ice_dug                      | 55            |\n|    water_produced               | 7.25          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.7          |\n| time/                           |               |\n|    fps                          | 799           |\n|    iterations                   | 164           |\n|    time_elapsed                 | 820           |\n|    total_timesteps              | 656000        |\n| train/                          |               |\n|    approx_kl                    | 0.00018896077 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.63         |\n|    explained_variance           | 0.513         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 5.26          |\n|    n_updates                    | 326           |\n|    policy_gradient_loss         | 2.01e-05      |\n|    value_loss                   | 10.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 146           |\n|    ice_dug                      | 159           |\n|    water_produced               | 22.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 16.6          |\n| time/                           |               |\n|    fps                          | 800           |\n|    iterations                   | 165           |\n|    time_elapsed                 | 824           |\n|    total_timesteps              | 660000        |\n| train/                          |               |\n|    approx_kl                    | 0.00017486085 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.67         |\n|    explained_variance           | 0.266         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 34.5          |\n|    n_updates                    | 328           |\n|    policy_gradient_loss         | -0.000219     |\n|    value_loss                   | 62.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 125           |\n|    action_queue_updates_total   | 141           |\n|    ice_dug                      | 85            |\n|    water_produced               | 20.2          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 17          |\n| time/                           |             |\n|    fps                          | 800         |\n|    iterations                   | 166         |\n|    time_elapsed                 | 829         |\n|    total_timesteps              | 664000      |\n| train/                          |             |\n|    approx_kl                    | 0.001538135 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.6        |\n|    explained_variance           | 0.223       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 33.3        |\n|    n_updates                    | 330         |\n|    policy_gradient_loss         | -0.000144   |\n|    value_loss                   | 55.4        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 130         |\n|    action_queue_updates_total   | 141         |\n|    ice_dug                      | 81          |\n|    water_produced               | 14.8        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.1          |\n| time/                           |               |\n|    fps                          | 800           |\n|    iterations                   | 167           |\n|    time_elapsed                 | 834           |\n|    total_timesteps              | 668000        |\n| train/                          |               |\n|    approx_kl                    | 0.00019238265 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.55         |\n|    explained_variance           | 0.306         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 20.8          |\n|    n_updates                    | 332           |\n|    policy_gradient_loss         | -0.000152     |\n|    value_loss                   | 33.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 127           |\n|    action_queue_updates_total   | 142           |\n|    ice_dug                      | 118           |\n|    water_produced               | 21            |\n---------------------------------------------------\nEval num_timesteps=672000, episode_reward=5.24 +/- 8.85\nEpisode length: 305.00 +/- 8.00\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 305           |\n|    mean_reward                  | 5.24          |\n| time/                           |               |\n|    total_timesteps              | 672000        |\n| train/                          |               |\n|    approx_kl                    | 0.00022197426 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.64         |\n|    explained_variance           | 0.314         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 21.6          |\n|    n_updates                    | 334           |\n|    policy_gradient_loss         | -0.000167     |\n|    value_loss                   | 38            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 121           |\n|    action_queue_updates_total   | 135           |\n|    ice_dug                      | 82            |\n|    water_produced               | 13.5          |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 19.5     |\n| time/              |          |\n|    fps             | 798      |\n|    iterations      | 168      |\n|    time_elapsed    | 841      |\n|    total_timesteps | 672000   |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.8         |\n| time/                           |              |\n|    fps                          | 799          |\n|    iterations                   | 169          |\n|    time_elapsed                 | 845          |\n|    total_timesteps              | 676000       |\n| train/                          |              |\n|    approx_kl                    | 0.0006194165 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.58        |\n|    explained_variance           | 0.306        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 15.8         |\n|    n_updates                    | 336          |\n|    policy_gradient_loss         | -2.08e-05    |\n|    value_loss                   | 30.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 122          |\n|    water_produced               | 24.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 19.6          |\n| time/                           |               |\n|    fps                          | 799           |\n|    iterations                   | 170           |\n|    time_elapsed                 | 850           |\n|    total_timesteps              | 680000        |\n| train/                          |               |\n|    approx_kl                    | 0.00012223788 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.6          |\n|    explained_variance           | 0.286         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 26.5          |\n|    n_updates                    | 338           |\n|    policy_gradient_loss         | -0.000216     |\n|    value_loss                   | 45.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 141           |\n|    ice_dug                      | 108           |\n|    water_produced               | 19.3          |\n---------------------------------------------------\n----------------------------------------------------\n| rollout/                        |                |\n|    ep_len_mean                  | 200            |\n|    ep_rew_mean                  | 25.4           |\n| time/                           |                |\n|    fps                          | 800            |\n|    iterations                   | 171            |\n|    time_elapsed                 | 854            |\n|    total_timesteps              | 684000         |\n| train/                          |                |\n|    approx_kl                    | 0.000103289916 |\n|    clip_fraction                | 0              |\n|    clip_range                   | 0.2            |\n|    entropy_loss                 | -1.56          |\n|    explained_variance           | 0.256          |\n|    learning_rate                | 0.0003         |\n|    loss                         | 18.5           |\n|    n_updates                    | 340            |\n|    policy_gradient_loss         | -0.000325      |\n|    value_loss                   | 36.8           |\n| train_metrics/                  |                |\n|    action_queue_updates_success | 136            |\n|    action_queue_updates_total   | 147            |\n|    ice_dug                      | 207            |\n|    water_produced               | 42.2           |\n----------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 23.6          |\n| time/                           |               |\n|    fps                          | 801           |\n|    iterations                   | 172           |\n|    time_elapsed                 | 858           |\n|    total_timesteps              | 688000        |\n| train/                          |               |\n|    approx_kl                    | 0.00017056346 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.59         |\n|    explained_variance           | 0.269         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 41.8          |\n|    n_updates                    | 342           |\n|    policy_gradient_loss         | 7.64e-05      |\n|    value_loss                   | 81.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 138           |\n|    ice_dug                      | 62            |\n|    water_produced               | 12.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 21.5          |\n| time/                           |               |\n|    fps                          | 801           |\n|    iterations                   | 173           |\n|    time_elapsed                 | 862           |\n|    total_timesteps              | 692000        |\n| train/                          |               |\n|    approx_kl                    | 2.4299025e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.48         |\n|    explained_variance           | 0.315         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 15.8          |\n|    n_updates                    | 344           |\n|    policy_gradient_loss         | 3.53e-05      |\n|    value_loss                   | 27            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 135           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 25            |\n|    water_produced               | 3.75          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 23.4         |\n| time/                           |              |\n|    fps                          | 802          |\n|    iterations                   | 174          |\n|    time_elapsed                 | 867          |\n|    total_timesteps              | 696000       |\n| train/                          |              |\n|    approx_kl                    | 0.0011129864 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.7         |\n|    explained_variance           | 0.577        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 2.59         |\n|    n_updates                    | 346          |\n|    policy_gradient_loss         | -0.000458    |\n|    value_loss                   | 6.08         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 192          |\n|    water_produced               | 33.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 22           |\n| time/                           |              |\n|    fps                          | 803          |\n|    iterations                   | 175          |\n|    time_elapsed                 | 871          |\n|    total_timesteps              | 700000       |\n| train/                          |              |\n|    approx_kl                    | 0.0003357281 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.7         |\n|    explained_variance           | 0.276        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 22.8         |\n|    n_updates                    | 348          |\n|    policy_gradient_loss         | -0.000153    |\n|    value_loss                   | 72           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 109          |\n|    water_produced               | 12           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.2          |\n| time/                           |               |\n|    fps                          | 803           |\n|    iterations                   | 176           |\n|    time_elapsed                 | 875           |\n|    total_timesteps              | 704000        |\n| train/                          |               |\n|    approx_kl                    | 0.00026154923 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.8          |\n|    explained_variance           | 0.318         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 11.9          |\n|    n_updates                    | 350           |\n|    policy_gradient_loss         | -0.000216     |\n|    value_loss                   | 28.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 49            |\n|    water_produced               | 9.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15            |\n| time/                           |               |\n|    fps                          | 803           |\n|    iterations                   | 177           |\n|    time_elapsed                 | 880           |\n|    total_timesteps              | 708000        |\n| train/                          |               |\n|    approx_kl                    | 0.00026825207 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.74         |\n|    explained_variance           | 0.428         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.13          |\n|    n_updates                    | 352           |\n|    policy_gradient_loss         | 0.00012       |\n|    value_loss                   | 12.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 70            |\n|    water_produced               | 12            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.8          |\n| time/                           |               |\n|    fps                          | 804           |\n|    iterations                   | 178           |\n|    time_elapsed                 | 885           |\n|    total_timesteps              | 712000        |\n| train/                          |               |\n|    approx_kl                    | 0.00066508556 |\n|    clip_fraction                | 0.00137       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.76         |\n|    explained_variance           | 0.359         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 14.6          |\n|    n_updates                    | 354           |\n|    policy_gradient_loss         | 0.000122      |\n|    value_loss                   | 22.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 135           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 117           |\n|    water_produced               | 21.7          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 16.3          |\n| time/                           |               |\n|    fps                          | 804           |\n|    iterations                   | 179           |\n|    time_elapsed                 | 889           |\n|    total_timesteps              | 716000        |\n| train/                          |               |\n|    approx_kl                    | 0.00093234255 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.88         |\n|    explained_variance           | 0.368         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 20.5          |\n|    n_updates                    | 356           |\n|    policy_gradient_loss         | 0.000118      |\n|    value_loss                   | 42.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 109           |\n|    water_produced               | 21.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 14.7         |\n| time/                           |              |\n|    fps                          | 805          |\n|    iterations                   | 180          |\n|    time_elapsed                 | 893          |\n|    total_timesteps              | 720000       |\n| train/                          |              |\n|    approx_kl                    | 0.0011250575 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.79        |\n|    explained_variance           | 0.31         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 22           |\n|    n_updates                    | 358          |\n|    policy_gradient_loss         | -0.000466    |\n|    value_loss                   | 54.6         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 28           |\n|    water_produced               | 5            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.4         |\n| time/                           |              |\n|    fps                          | 805          |\n|    iterations                   | 181          |\n|    time_elapsed                 | 898          |\n|    total_timesteps              | 724000       |\n| train/                          |              |\n|    approx_kl                    | 0.0038592597 |\n|    clip_fraction                | 0.0161       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.93        |\n|    explained_variance           | 0.741        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 2.37         |\n|    n_updates                    | 360          |\n|    policy_gradient_loss         | -0.000127    |\n|    value_loss                   | 5.41         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 152          |\n|    water_produced               | 31.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 20.3          |\n| time/                           |               |\n|    fps                          | 806           |\n|    iterations                   | 182           |\n|    time_elapsed                 | 902           |\n|    total_timesteps              | 728000        |\n| train/                          |               |\n|    approx_kl                    | 0.00011359898 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.68         |\n|    explained_variance           | 0.308         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 37.3          |\n|    n_updates                    | 362           |\n|    policy_gradient_loss         | -4.03e-05     |\n|    value_loss                   | 59.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 128           |\n|    water_produced               | 16.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.1          |\n| time/                           |               |\n|    fps                          | 806           |\n|    iterations                   | 183           |\n|    time_elapsed                 | 907           |\n|    total_timesteps              | 732000        |\n| train/                          |               |\n|    approx_kl                    | 6.9310365e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.83         |\n|    explained_variance           | 0.397         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 16.5          |\n|    n_updates                    | 364           |\n|    policy_gradient_loss         | 7.25e-06      |\n|    value_loss                   | 33.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 70            |\n|    water_produced               | 11            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 21.9         |\n| time/                           |              |\n|    fps                          | 807          |\n|    iterations                   | 184          |\n|    time_elapsed                 | 911          |\n|    total_timesteps              | 736000       |\n| train/                          |              |\n|    approx_kl                    | 0.0009790689 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.8         |\n|    explained_variance           | 0.48         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 10.1         |\n|    n_updates                    | 366          |\n|    policy_gradient_loss         | 0.000889     |\n|    value_loss                   | 18.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 238          |\n|    water_produced               | 39.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 23.2         |\n| time/                           |              |\n|    fps                          | 807          |\n|    iterations                   | 185          |\n|    time_elapsed                 | 916          |\n|    total_timesteps              | 740000       |\n| train/                          |              |\n|    approx_kl                    | 0.0015198134 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.88        |\n|    explained_variance           | 0.389        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 43.4         |\n|    n_updates                    | 368          |\n|    policy_gradient_loss         | -0.000326    |\n|    value_loss                   | 72.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 138          |\n|    water_produced               | 10.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 19            |\n| time/                           |               |\n|    fps                          | 808           |\n|    iterations                   | 186           |\n|    time_elapsed                 | 920           |\n|    total_timesteps              | 744000        |\n| train/                          |               |\n|    approx_kl                    | 0.00016919918 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.91         |\n|    explained_variance           | 0.623         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.58          |\n|    n_updates                    | 370           |\n|    policy_gradient_loss         | -0.000173     |\n|    value_loss                   | 15.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 68            |\n|    water_produced               | 11.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.8         |\n| time/                           |              |\n|    fps                          | 808          |\n|    iterations                   | 187          |\n|    time_elapsed                 | 925          |\n|    total_timesteps              | 748000       |\n| train/                          |              |\n|    approx_kl                    | 0.0016052086 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.98        |\n|    explained_variance           | 0.625        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 10.4         |\n|    n_updates                    | 372          |\n|    policy_gradient_loss         | -3.54e-05    |\n|    value_loss                   | 18.5         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 102          |\n|    water_produced               | 20.5         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 19.8        |\n| time/                           |             |\n|    fps                          | 808         |\n|    iterations                   | 188         |\n|    time_elapsed                 | 929         |\n|    total_timesteps              | 752000      |\n| train/                          |             |\n|    approx_kl                    | 0.000202163 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.83       |\n|    explained_variance           | 0.482       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 15.2        |\n|    n_updates                    | 374         |\n|    policy_gradient_loss         | 0.000234    |\n|    value_loss                   | 35.6        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 138         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 79          |\n|    water_produced               | 10.8        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 13.8         |\n| time/                           |              |\n|    fps                          | 808          |\n|    iterations                   | 189          |\n|    time_elapsed                 | 934          |\n|    total_timesteps              | 756000       |\n| train/                          |              |\n|    approx_kl                    | 0.0021645874 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.96        |\n|    explained_variance           | 0.524        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 7.79         |\n|    n_updates                    | 376          |\n|    policy_gradient_loss         | 3.79e-05     |\n|    value_loss                   | 23.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 66           |\n|    water_produced               | 11.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.4          |\n| time/                           |               |\n|    fps                          | 808           |\n|    iterations                   | 190           |\n|    time_elapsed                 | 939           |\n|    total_timesteps              | 760000        |\n| train/                          |               |\n|    approx_kl                    | 0.00049861905 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.86         |\n|    explained_variance           | 0.602         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 11.7          |\n|    n_updates                    | 378           |\n|    policy_gradient_loss         | -4.28e-05     |\n|    value_loss                   | 21.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 40            |\n|    water_produced               | 9             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 17.1          |\n| time/                           |               |\n|    fps                          | 808           |\n|    iterations                   | 191           |\n|    time_elapsed                 | 944           |\n|    total_timesteps              | 764000        |\n| train/                          |               |\n|    approx_kl                    | 0.00056018506 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.83         |\n|    explained_variance           | 0.633         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 11            |\n|    n_updates                    | 380           |\n|    policy_gradient_loss         | -0.000282     |\n|    value_loss                   | 17.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 139           |\n|    water_produced               | 29.2          |\n---------------------------------------------------\nEval num_timesteps=768000, episode_reward=0.00 +/- 0.00\nEpisode length: 301.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 301          |\n|    mean_reward                  | 0            |\n| time/                           |              |\n|    total_timesteps              | 768000       |\n| train/                          |              |\n|    approx_kl                    | 0.0015369231 |\n|    clip_fraction                | 0.00262      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.87        |\n|    explained_variance           | 0.458        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 32           |\n|    n_updates                    | 382          |\n|    policy_gradient_loss         | -0.000529    |\n|    value_loss                   | 57.6         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 158          |\n|    water_produced               | 29.2         |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 18.9     |\n| time/              |          |\n|    fps             | 806      |\n|    iterations      | 192      |\n|    time_elapsed    | 952      |\n|    total_timesteps | 768000   |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 18.3         |\n| time/                           |              |\n|    fps                          | 806          |\n|    iterations                   | 193          |\n|    time_elapsed                 | 957          |\n|    total_timesteps              | 772000       |\n| train/                          |              |\n|    approx_kl                    | 0.0011260008 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.7         |\n|    explained_variance           | 0.402        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 34.6         |\n|    n_updates                    | 384          |\n|    policy_gradient_loss         | -2.04e-05    |\n|    value_loss                   | 61.8         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 42           |\n|    water_produced               | 8            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 21.5          |\n| time/                           |               |\n|    fps                          | 806           |\n|    iterations                   | 194           |\n|    time_elapsed                 | 962           |\n|    total_timesteps              | 776000        |\n| train/                          |               |\n|    approx_kl                    | 0.00096253026 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.79         |\n|    explained_variance           | 0.604         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.78          |\n|    n_updates                    | 386           |\n|    policy_gradient_loss         | 0.000483      |\n|    value_loss                   | 14.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 133           |\n|    water_produced               | 26.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 25.5          |\n| time/                           |               |\n|    fps                          | 806           |\n|    iterations                   | 195           |\n|    time_elapsed                 | 967           |\n|    total_timesteps              | 780000        |\n| train/                          |               |\n|    approx_kl                    | 0.00034384383 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.8          |\n|    explained_variance           | 0.485         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 21.4          |\n|    n_updates                    | 388           |\n|    policy_gradient_loss         | -6.56e-05     |\n|    value_loss                   | 43.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 137           |\n|    water_produced               | 28.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 21.5         |\n| time/                           |              |\n|    fps                          | 806          |\n|    iterations                   | 196          |\n|    time_elapsed                 | 972          |\n|    total_timesteps              | 784000       |\n| train/                          |              |\n|    approx_kl                    | 0.0021298998 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.76        |\n|    explained_variance           | 0.362        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 34.3         |\n|    n_updates                    | 390          |\n|    policy_gradient_loss         | -0.000806    |\n|    value_loss                   | 57           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 58           |\n|    water_produced               | 10           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 19.2          |\n| time/                           |               |\n|    fps                          | 806           |\n|    iterations                   | 197           |\n|    time_elapsed                 | 977           |\n|    total_timesteps              | 788000        |\n| train/                          |               |\n|    approx_kl                    | 0.00014952707 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.81         |\n|    explained_variance           | 0.471         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 9             |\n|    n_updates                    | 392           |\n|    policy_gradient_loss         | -0.000124     |\n|    value_loss                   | 24.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 135           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 108           |\n|    water_produced               | 18            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 20.7          |\n| time/                           |               |\n|    fps                          | 806           |\n|    iterations                   | 198           |\n|    time_elapsed                 | 982           |\n|    total_timesteps              | 792000        |\n| train/                          |               |\n|    approx_kl                    | 0.00022887201 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.69         |\n|    explained_variance           | 0.469         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 11.4          |\n|    n_updates                    | 394           |\n|    policy_gradient_loss         | -4.75e-05     |\n|    value_loss                   | 28.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 126           |\n|    water_produced               | 14.7          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 20.9         |\n| time/                           |              |\n|    fps                          | 806          |\n|    iterations                   | 199          |\n|    time_elapsed                 | 986          |\n|    total_timesteps              | 796000       |\n| train/                          |              |\n|    approx_kl                    | 0.0001751883 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.67        |\n|    explained_variance           | 0.319        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 18.6         |\n|    n_updates                    | 396          |\n|    policy_gradient_loss         | -0.000129    |\n|    value_loss                   | 41.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 121          |\n|    water_produced               | 27.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.1         |\n| time/                           |              |\n|    fps                          | 806          |\n|    iterations                   | 200          |\n|    time_elapsed                 | 991          |\n|    total_timesteps              | 800000       |\n| train/                          |              |\n|    approx_kl                    | 0.0015025137 |\n|    clip_fraction                | 0.000875     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.75        |\n|    explained_variance           | 0.349        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 30.4         |\n|    n_updates                    | 398          |\n|    policy_gradient_loss         | -0.000833    |\n|    value_loss                   | 62.1         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 111          |\n|    water_produced               | 20           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 17.6         |\n| time/                           |              |\n|    fps                          | 807          |\n|    iterations                   | 201          |\n|    time_elapsed                 | 996          |\n|    total_timesteps              | 804000       |\n| train/                          |              |\n|    approx_kl                    | 0.0001693565 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.64        |\n|    explained_variance           | 0.396        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 22.1         |\n|    n_updates                    | 400          |\n|    policy_gradient_loss         | 9.85e-05     |\n|    value_loss                   | 35.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 39           |\n|    water_produced               | 2.25         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 20.2         |\n| time/                           |              |\n|    fps                          | 807          |\n|    iterations                   | 202          |\n|    time_elapsed                 | 1000         |\n|    total_timesteps              | 808000       |\n| train/                          |              |\n|    approx_kl                    | 0.0015583395 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.68        |\n|    explained_variance           | 0.712        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 2.72         |\n|    n_updates                    | 402          |\n|    policy_gradient_loss         | -1.11e-05    |\n|    value_loss                   | 6.37         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 144          |\n|    ice_dug                      | 173          |\n|    water_produced               | 30.7         |\n--------------------------------------------------\n----------------------------------------------------\n| rollout/                        |                |\n|    ep_len_mean                  | 200            |\n|    ep_rew_mean                  | 22.8           |\n| time/                           |                |\n|    fps                          | 807            |\n|    iterations                   | 203            |\n|    time_elapsed                 | 1005           |\n|    total_timesteps              | 812000         |\n| train/                          |                |\n|    approx_kl                    | 0.000101483776 |\n|    clip_fraction                | 0              |\n|    clip_range                   | 0.2            |\n|    entropy_loss                 | -1.65          |\n|    explained_variance           | 0.353          |\n|    learning_rate                | 0.0003         |\n|    loss                         | 36.9           |\n|    n_updates                    | 404            |\n|    policy_gradient_loss         | -7.24e-05      |\n|    value_loss                   | 64             |\n| train_metrics/                  |                |\n|    action_queue_updates_success | 130            |\n|    action_queue_updates_total   | 144            |\n|    ice_dug                      | 128            |\n|    water_produced               | 27.7           |\n----------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 22.9         |\n| time/                           |              |\n|    fps                          | 807          |\n|    iterations                   | 204          |\n|    time_elapsed                 | 1010         |\n|    total_timesteps              | 816000       |\n| train/                          |              |\n|    approx_kl                    | 0.0007318262 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.63        |\n|    explained_variance           | 0.333        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 31.7         |\n|    n_updates                    | 406          |\n|    policy_gradient_loss         | -0.000503    |\n|    value_loss                   | 65.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 145          |\n|    water_produced               | 27.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 26.9          |\n| time/                           |               |\n|    fps                          | 807           |\n|    iterations                   | 205           |\n|    time_elapsed                 | 1015          |\n|    total_timesteps              | 820000        |\n| train/                          |               |\n|    approx_kl                    | 0.00013486322 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.68         |\n|    explained_variance           | 0.363         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 33.7          |\n|    n_updates                    | 408           |\n|    policy_gradient_loss         | -0.000349     |\n|    value_loss                   | 70.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 134           |\n|    action_queue_updates_total   | 144           |\n|    ice_dug                      | 212           |\n|    water_produced               | 39.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 28.9          |\n| time/                           |               |\n|    fps                          | 807           |\n|    iterations                   | 206           |\n|    time_elapsed                 | 1020          |\n|    total_timesteps              | 824000        |\n| train/                          |               |\n|    approx_kl                    | 0.00041726144 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.55         |\n|    explained_variance           | 0.317         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 42.5          |\n|    n_updates                    | 410           |\n|    policy_gradient_loss         | -0.000502     |\n|    value_loss                   | 92.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 146           |\n|    ice_dug                      | 58            |\n|    water_produced               | 12            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 26.3          |\n| time/                           |               |\n|    fps                          | 807           |\n|    iterations                   | 207           |\n|    time_elapsed                 | 1025          |\n|    total_timesteps              | 828000        |\n| train/                          |               |\n|    approx_kl                    | 0.00026639557 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.64         |\n|    explained_variance           | 0.41          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 14.5          |\n|    n_updates                    | 412           |\n|    policy_gradient_loss         | -2.44e-05     |\n|    value_loss                   | 31.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 126           |\n|    action_queue_updates_total   | 140           |\n|    ice_dug                      | 99            |\n|    water_produced               | 18.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 26.5          |\n| time/                           |               |\n|    fps                          | 807           |\n|    iterations                   | 208           |\n|    time_elapsed                 | 1030          |\n|    total_timesteps              | 832000        |\n| train/                          |               |\n|    approx_kl                    | 0.00089280866 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.59         |\n|    explained_variance           | 0.315         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 27            |\n|    n_updates                    | 414           |\n|    policy_gradient_loss         | -8.18e-05     |\n|    value_loss                   | 51.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 143           |\n|    ice_dug                      | 177           |\n|    water_produced               | 28.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 25.5          |\n| time/                           |               |\n|    fps                          | 807           |\n|    iterations                   | 209           |\n|    time_elapsed                 | 1034          |\n|    total_timesteps              | 836000        |\n| train/                          |               |\n|    approx_kl                    | 0.00011344401 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.61         |\n|    explained_variance           | 0.33          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 36            |\n|    n_updates                    | 416           |\n|    policy_gradient_loss         | -0.000251     |\n|    value_loss                   | 86.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 145           |\n|    ice_dug                      | 131           |\n|    water_produced               | 22.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.9          |\n| time/                           |               |\n|    fps                          | 807           |\n|    iterations                   | 210           |\n|    time_elapsed                 | 1039          |\n|    total_timesteps              | 840000        |\n| train/                          |               |\n|    approx_kl                    | 0.00014708556 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.58         |\n|    explained_variance           | 0.368         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 29.8          |\n|    n_updates                    | 418           |\n|    policy_gradient_loss         | -0.000244     |\n|    value_loss                   | 50.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 120           |\n|    action_queue_updates_total   | 133           |\n|    ice_dug                      | 82            |\n|    water_produced               | 7.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.3          |\n| time/                           |               |\n|    fps                          | 807           |\n|    iterations                   | 211           |\n|    time_elapsed                 | 1044          |\n|    total_timesteps              | 844000        |\n| train/                          |               |\n|    approx_kl                    | 0.00051919126 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.54         |\n|    explained_variance           | 0.522         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 8.22          |\n|    n_updates                    | 420           |\n|    policy_gradient_loss         | 0.000174      |\n|    value_loss                   | 19.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 145           |\n|    ice_dug                      | 74            |\n|    water_produced               | 8.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 16.6          |\n| time/                           |               |\n|    fps                          | 808           |\n|    iterations                   | 212           |\n|    time_elapsed                 | 1049          |\n|    total_timesteps              | 848000        |\n| train/                          |               |\n|    approx_kl                    | 0.00045394036 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.65         |\n|    explained_variance           | 0.478         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 11.6          |\n|    n_updates                    | 422           |\n|    policy_gradient_loss         | 0.000123      |\n|    value_loss                   | 22.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 125           |\n|    action_queue_updates_total   | 137           |\n|    ice_dug                      | 117           |\n|    water_produced               | 9.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 14.7          |\n| time/                           |               |\n|    fps                          | 808           |\n|    iterations                   | 213           |\n|    time_elapsed                 | 1053          |\n|    total_timesteps              | 852000        |\n| train/                          |               |\n|    approx_kl                    | 0.00015867902 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.63         |\n|    explained_variance           | 0.435         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 10.1          |\n|    n_updates                    | 424           |\n|    policy_gradient_loss         | -0.000133     |\n|    value_loss                   | 24.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 132           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 96            |\n|    water_produced               | 19.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 12.1         |\n| time/                           |              |\n|    fps                          | 808          |\n|    iterations                   | 214          |\n|    time_elapsed                 | 1058         |\n|    total_timesteps              | 856000       |\n| train/                          |              |\n|    approx_kl                    | 0.0003449091 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.72        |\n|    explained_variance           | 0.364        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 27.4         |\n|    n_updates                    | 426          |\n|    policy_gradient_loss         | -0.000261    |\n|    value_loss                   | 47.8         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 122          |\n|    action_queue_updates_total   | 137          |\n|    ice_dug                      | 48           |\n|    water_produced               | 10.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.1          |\n| time/                           |               |\n|    fps                          | 809           |\n|    iterations                   | 215           |\n|    time_elapsed                 | 1063          |\n|    total_timesteps              | 860000        |\n| train/                          |               |\n|    approx_kl                    | 0.00028756118 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.61         |\n|    explained_variance           | 0.424         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 10.6          |\n|    n_updates                    | 428           |\n|    policy_gradient_loss         | -6.61e-05     |\n|    value_loss                   | 22.2          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 132           |\n|    action_queue_updates_total   | 143           |\n|    ice_dug                      | 179           |\n|    water_produced               | 21.5          |\n---------------------------------------------------\nEval num_timesteps=864000, episode_reward=92.56 +/- 51.51\nEpisode length: 389.00 +/- 49.05\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 389          |\n|    mean_reward                  | 92.6         |\n| time/                           |              |\n|    total_timesteps              | 864000       |\n| train/                          |              |\n|    approx_kl                    | 0.0003211095 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.61        |\n|    explained_variance           | 0.336        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 23.3         |\n|    n_updates                    | 430          |\n|    policy_gradient_loss         | 6.88e-05     |\n|    value_loss                   | 50.1         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 128          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 156          |\n|    water_produced               | 27           |\n--------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 18.9     |\n| time/              |          |\n|    fps             | 806      |\n|    iterations      | 216      |\n|    time_elapsed    | 1070     |\n|    total_timesteps | 864000   |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.2         |\n| time/                           |              |\n|    fps                          | 807          |\n|    iterations                   | 217          |\n|    time_elapsed                 | 1075         |\n|    total_timesteps              | 868000       |\n| train/                          |              |\n|    approx_kl                    | 0.0003713021 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.7         |\n|    explained_variance           | 0.35         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 37           |\n|    n_updates                    | 432          |\n|    policy_gradient_loss         | 6.79e-05     |\n|    value_loss                   | 79.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 128          |\n|    action_queue_updates_total   | 139          |\n|    ice_dug                      | 59           |\n|    water_produced               | 11.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.7         |\n| time/                           |              |\n|    fps                          | 807          |\n|    iterations                   | 218          |\n|    time_elapsed                 | 1079         |\n|    total_timesteps              | 872000       |\n| train/                          |              |\n|    approx_kl                    | 0.0007994392 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.59        |\n|    explained_variance           | 0.432        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 12.1         |\n|    n_updates                    | 434          |\n|    policy_gradient_loss         | -0.000415    |\n|    value_loss                   | 25.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 130          |\n|    water_produced               | 22           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 19.7          |\n| time/                           |               |\n|    fps                          | 807           |\n|    iterations                   | 219           |\n|    time_elapsed                 | 1084          |\n|    total_timesteps              | 876000        |\n| train/                          |               |\n|    approx_kl                    | 4.7599304e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.72         |\n|    explained_variance           | 0.395         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 23.5          |\n|    n_updates                    | 436           |\n|    policy_gradient_loss         | 8.82e-05      |\n|    value_loss                   | 71            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 123           |\n|    action_queue_updates_total   | 147           |\n|    ice_dug                      | 48            |\n|    water_produced               | 10.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 20           |\n| time/                           |              |\n|    fps                          | 808          |\n|    iterations                   | 220          |\n|    time_elapsed                 | 1089         |\n|    total_timesteps              | 880000       |\n| train/                          |              |\n|    approx_kl                    | 9.761705e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.85        |\n|    explained_variance           | 0.455        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 15.2         |\n|    n_updates                    | 438          |\n|    policy_gradient_loss         | 1.25e-07     |\n|    value_loss                   | 28.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 119          |\n|    action_queue_updates_total   | 131          |\n|    ice_dug                      | 132          |\n|    water_produced               | 23.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 16.3         |\n| time/                           |              |\n|    fps                          | 808          |\n|    iterations                   | 221          |\n|    time_elapsed                 | 1093         |\n|    total_timesteps              | 884000       |\n| train/                          |              |\n|    approx_kl                    | 0.0008234276 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.57        |\n|    explained_variance           | 0.366        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 24.9         |\n|    n_updates                    | 440          |\n|    policy_gradient_loss         | -0.000351    |\n|    value_loss                   | 52.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 124          |\n|    action_queue_updates_total   | 137          |\n|    ice_dug                      | 56           |\n|    water_produced               | 9.5          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 17.7          |\n| time/                           |               |\n|    fps                          | 808           |\n|    iterations                   | 222           |\n|    time_elapsed                 | 1097          |\n|    total_timesteps              | 888000        |\n| train/                          |               |\n|    approx_kl                    | 0.00032900774 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.63         |\n|    explained_variance           | 0.36          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 14.9          |\n|    n_updates                    | 442           |\n|    policy_gradient_loss         | -0.000486     |\n|    value_loss                   | 23.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 128           |\n|    action_queue_updates_total   | 142           |\n|    ice_dug                      | 116           |\n|    water_produced               | 18.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.4          |\n| time/                           |               |\n|    fps                          | 808           |\n|    iterations                   | 223           |\n|    time_elapsed                 | 1102          |\n|    total_timesteps              | 892000        |\n| train/                          |               |\n|    approx_kl                    | 0.00010123962 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.65         |\n|    explained_variance           | 0.413         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 20.8          |\n|    n_updates                    | 444           |\n|    policy_gradient_loss         | -0.000133     |\n|    value_loss                   | 36.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 127           |\n|    action_queue_updates_total   | 141           |\n|    ice_dug                      | 127           |\n|    water_produced               | 25.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 24.1          |\n| time/                           |               |\n|    fps                          | 809           |\n|    iterations                   | 224           |\n|    time_elapsed                 | 1107          |\n|    total_timesteps              | 896000        |\n| train/                          |               |\n|    approx_kl                    | 0.00043650725 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.66         |\n|    explained_variance           | 0.384         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 27.5          |\n|    n_updates                    | 446           |\n|    policy_gradient_loss         | 5.24e-05      |\n|    value_loss                   | 59.3          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 134           |\n|    action_queue_updates_total   | 141           |\n|    ice_dug                      | 221           |\n|    water_produced               | 37.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 28.7         |\n| time/                           |              |\n|    fps                          | 809          |\n|    iterations                   | 225          |\n|    time_elapsed                 | 1111         |\n|    total_timesteps              | 900000       |\n| train/                          |              |\n|    approx_kl                    | 0.0003205806 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.54        |\n|    explained_variance           | 0.304        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 47.2         |\n|    n_updates                    | 448          |\n|    policy_gradient_loss         | -0.000135    |\n|    value_loss                   | 107          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 125          |\n|    action_queue_updates_total   | 139          |\n|    ice_dug                      | 226          |\n|    water_produced               | 45.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 32.9         |\n| time/                           |              |\n|    fps                          | 809          |\n|    iterations                   | 226          |\n|    time_elapsed                 | 1116         |\n|    total_timesteps              | 904000       |\n| train/                          |              |\n|    approx_kl                    | 0.0010600372 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.58        |\n|    explained_variance           | 0.397        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 46.3         |\n|    n_updates                    | 450          |\n|    policy_gradient_loss         | 4.57e-06     |\n|    value_loss                   | 97           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 127          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 132          |\n|    water_produced               | 29.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 38.3          |\n| time/                           |               |\n|    fps                          | 810           |\n|    iterations                   | 227           |\n|    time_elapsed                 | 1120          |\n|    total_timesteps              | 908000        |\n| train/                          |               |\n|    approx_kl                    | 0.00043743983 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.7          |\n|    explained_variance           | 0.382         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 35.5          |\n|    n_updates                    | 452           |\n|    policy_gradient_loss         | 5.05e-05      |\n|    value_loss                   | 76.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 128           |\n|    action_queue_updates_total   | 140           |\n|    ice_dug                      | 209           |\n|    water_produced               | 44            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 36.1          |\n| time/                           |               |\n|    fps                          | 810           |\n|    iterations                   | 228           |\n|    time_elapsed                 | 1125          |\n|    total_timesteps              | 912000        |\n| train/                          |               |\n|    approx_kl                    | 0.00015562904 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.56         |\n|    explained_variance           | 0.33          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 50.8          |\n|    n_updates                    | 454           |\n|    policy_gradient_loss         | -0.000223     |\n|    value_loss                   | 108           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 124           |\n|    action_queue_updates_total   | 127           |\n|    ice_dug                      | 90            |\n|    water_produced               | 14.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 33.2          |\n| time/                           |               |\n|    fps                          | 810           |\n|    iterations                   | 229           |\n|    time_elapsed                 | 1129          |\n|    total_timesteps              | 916000        |\n| train/                          |               |\n|    approx_kl                    | 6.7222936e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.34         |\n|    explained_variance           | 0.315         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 15.5          |\n|    n_updates                    | 456           |\n|    policy_gradient_loss         | -0.000196     |\n|    value_loss                   | 33.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 112           |\n|    action_queue_updates_total   | 118           |\n|    ice_dug                      | 111           |\n|    water_produced               | 24.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 23.9          |\n| time/                           |               |\n|    fps                          | 811           |\n|    iterations                   | 230           |\n|    time_elapsed                 | 1134          |\n|    total_timesteps              | 920000        |\n| train/                          |               |\n|    approx_kl                    | 0.00039507946 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.38         |\n|    explained_variance           | 0.311         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 29.9          |\n|    n_updates                    | 458           |\n|    policy_gradient_loss         | -0.000379     |\n|    value_loss                   | 62            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 127           |\n|    action_queue_updates_total   | 141           |\n|    ice_dug                      | 34            |\n|    water_produced               | 1             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 22.5         |\n| time/                           |              |\n|    fps                          | 811          |\n|    iterations                   | 231          |\n|    time_elapsed                 | 1138         |\n|    total_timesteps              | 924000       |\n| train/                          |              |\n|    approx_kl                    | 0.0003045352 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.59        |\n|    explained_variance           | 0.743        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 2.34         |\n|    n_updates                    | 460          |\n|    policy_gradient_loss         | -7.69e-05    |\n|    value_loss                   | 7.32         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 181          |\n|    water_produced               | 22.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 15.5         |\n| time/                           |              |\n|    fps                          | 811          |\n|    iterations                   | 232          |\n|    time_elapsed                 | 1143         |\n|    total_timesteps              | 928000       |\n| train/                          |              |\n|    approx_kl                    | 0.0005018158 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.87        |\n|    explained_variance           | 0.431        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 21           |\n|    n_updates                    | 462          |\n|    policy_gradient_loss         | -5.04e-05    |\n|    value_loss                   | 43.8         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 109          |\n|    water_produced               | 10           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 18.5         |\n| time/                           |              |\n|    fps                          | 812          |\n|    iterations                   | 233          |\n|    time_elapsed                 | 1147         |\n|    total_timesteps              | 932000       |\n| train/                          |              |\n|    approx_kl                    | 0.0007851451 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.7         |\n|    explained_variance           | 0.507        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 13.6         |\n|    n_updates                    | 464          |\n|    policy_gradient_loss         | 1.68e-05     |\n|    value_loss                   | 23.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 122          |\n|    action_queue_updates_total   | 137          |\n|    ice_dug                      | 149          |\n|    water_produced               | 29           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 21.1         |\n| time/                           |              |\n|    fps                          | 812          |\n|    iterations                   | 234          |\n|    time_elapsed                 | 1152         |\n|    total_timesteps              | 936000       |\n| train/                          |              |\n|    approx_kl                    | 8.262141e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.64        |\n|    explained_variance           | 0.413        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 35.8         |\n|    n_updates                    | 466          |\n|    policy_gradient_loss         | -6.09e-05    |\n|    value_loss                   | 55.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 126          |\n|    action_queue_updates_total   | 142          |\n|    ice_dug                      | 169          |\n|    water_produced               | 36.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 24.4         |\n| time/                           |              |\n|    fps                          | 812          |\n|    iterations                   | 235          |\n|    time_elapsed                 | 1156         |\n|    total_timesteps              | 940000       |\n| train/                          |              |\n|    approx_kl                    | 0.0005505717 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.65        |\n|    explained_variance           | 0.395        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 44.4         |\n|    n_updates                    | 468          |\n|    policy_gradient_loss         | -0.000464    |\n|    value_loss                   | 90.1         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 158          |\n|    water_produced               | 16.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 23.8         |\n| time/                           |              |\n|    fps                          | 812          |\n|    iterations                   | 236          |\n|    time_elapsed                 | 1161         |\n|    total_timesteps              | 944000       |\n| train/                          |              |\n|    approx_kl                    | 0.0020641664 |\n|    clip_fraction                | 0.00663      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.61        |\n|    explained_variance           | 0.407        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 18.1         |\n|    n_updates                    | 470          |\n|    policy_gradient_loss         | 0.000386     |\n|    value_loss                   | 36.5         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 142          |\n|    ice_dug                      | 111          |\n|    water_produced               | 20           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 31.7          |\n| time/                           |               |\n|    fps                          | 812           |\n|    iterations                   | 237           |\n|    time_elapsed                 | 1166          |\n|    total_timesteps              | 948000        |\n| train/                          |               |\n|    approx_kl                    | 0.00040785372 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.6          |\n|    explained_variance           | 0.391         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 15.2          |\n|    n_updates                    | 472           |\n|    policy_gradient_loss         | -3.13e-05     |\n|    value_loss                   | 41.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 255           |\n|    water_produced               | 48            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 36.1         |\n| time/                           |              |\n|    fps                          | 812          |\n|    iterations                   | 238          |\n|    time_elapsed                 | 1171         |\n|    total_timesteps              | 952000       |\n| train/                          |              |\n|    approx_kl                    | 0.0017728902 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.61        |\n|    explained_variance           | 0.393        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 46.6         |\n|    n_updates                    | 474          |\n|    policy_gradient_loss         | 2.96e-05     |\n|    value_loss                   | 98.6         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 220          |\n|    water_produced               | 50           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 29.2         |\n| time/                           |              |\n|    fps                          | 813          |\n|    iterations                   | 239          |\n|    time_elapsed                 | 1175         |\n|    total_timesteps              | 956000       |\n| train/                          |              |\n|    approx_kl                    | 0.0019152559 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.59        |\n|    explained_variance           | 0.367        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 53.5         |\n|    n_updates                    | 476          |\n|    policy_gradient_loss         | -0.000712    |\n|    value_loss                   | 122          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 122          |\n|    action_queue_updates_total   | 139          |\n|    ice_dug                      | 18           |\n|    water_produced               | 3.75         |\n--------------------------------------------------\nEval num_timesteps=960000, episode_reward=37.60 +/- 75.00\nEpisode length: 337.00 +/- 72.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 337          |\n|    mean_reward                  | 37.6         |\n| time/                           |              |\n|    total_timesteps              | 960000       |\n| train/                          |              |\n|    approx_kl                    | 0.0005348517 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.62        |\n|    explained_variance           | 0.668        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 4.98         |\n|    n_updates                    | 478          |\n|    policy_gradient_loss         | 0.000477     |\n|    value_loss                   | 10.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 309          |\n|    water_produced               | 56.5         |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 37.5     |\n| time/              |          |\n|    fps             | 811      |\n|    iterations      | 240      |\n|    time_elapsed    | 1183     |\n|    total_timesteps | 960000   |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 40.6        |\n| time/                           |             |\n|    fps                          | 811         |\n|    iterations                   | 241         |\n|    time_elapsed                 | 1188        |\n|    total_timesteps              | 964000      |\n| train/                          |             |\n|    approx_kl                    | 3.21278e-05 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.53       |\n|    explained_variance           | 0.356       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 68.6        |\n|    n_updates                    | 480         |\n|    policy_gradient_loss         | -5.95e-05   |\n|    value_loss                   | 138         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 126         |\n|    action_queue_updates_total   | 134         |\n|    ice_dug                      | 180         |\n|    water_produced               | 35          |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 32.1          |\n| time/                           |               |\n|    fps                          | 811           |\n|    iterations                   | 242           |\n|    time_elapsed                 | 1192          |\n|    total_timesteps              | 968000        |\n| train/                          |               |\n|    approx_kl                    | 0.00023631603 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.45         |\n|    explained_variance           | 0.362         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 41.5          |\n|    n_updates                    | 482           |\n|    policy_gradient_loss         | 3.24e-05      |\n|    value_loss                   | 91.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 125           |\n|    action_queue_updates_total   | 140           |\n|    ice_dug                      | 85            |\n|    water_produced               | 7.25          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 23           |\n| time/                           |              |\n|    fps                          | 811          |\n|    iterations                   | 243          |\n|    time_elapsed                 | 1197         |\n|    total_timesteps              | 972000       |\n| train/                          |              |\n|    approx_kl                    | 0.0011677453 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.64        |\n|    explained_variance           | 0.6          |\n|    learning_rate                | 0.0003       |\n|    loss                         | 8.09         |\n|    n_updates                    | 484          |\n|    policy_gradient_loss         | 0.000343     |\n|    value_loss                   | 18.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 128          |\n|    action_queue_updates_total   | 141          |\n|    ice_dug                      | 44           |\n|    water_produced               | 6            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 28.7         |\n| time/                           |              |\n|    fps                          | 811          |\n|    iterations                   | 244          |\n|    time_elapsed                 | 1202         |\n|    total_timesteps              | 976000       |\n| train/                          |              |\n|    approx_kl                    | 0.0010476264 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.64        |\n|    explained_variance           | 0.626        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 5.5          |\n|    n_updates                    | 486          |\n|    policy_gradient_loss         | 0.000564     |\n|    value_loss                   | 11.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 128          |\n|    action_queue_updates_total   | 140          |\n|    ice_dug                      | 154          |\n|    water_produced               | 31.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 20.7          |\n| time/                           |               |\n|    fps                          | 812           |\n|    iterations                   | 245           |\n|    time_elapsed                 | 1206          |\n|    total_timesteps              | 980000        |\n| train/                          |               |\n|    approx_kl                    | 0.00020335914 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.6          |\n|    explained_variance           | 0.431         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 35.5          |\n|    n_updates                    | 488           |\n|    policy_gradient_loss         | -0.000159     |\n|    value_loss                   | 61.2          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 78            |\n|    water_produced               | 18.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.7         |\n| time/                           |              |\n|    fps                          | 812          |\n|    iterations                   | 246          |\n|    time_elapsed                 | 1211         |\n|    total_timesteps              | 984000       |\n| train/                          |              |\n|    approx_kl                    | 0.0029804884 |\n|    clip_fraction                | 0.013        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.79        |\n|    explained_variance           | 0.443        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 23.8         |\n|    n_updates                    | 490          |\n|    policy_gradient_loss         | -0.000349    |\n|    value_loss                   | 56.1         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 129          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 150          |\n|    water_produced               | 30.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 20.4          |\n| time/                           |               |\n|    fps                          | 812           |\n|    iterations                   | 247           |\n|    time_elapsed                 | 1215          |\n|    total_timesteps              | 988000        |\n| train/                          |               |\n|    approx_kl                    | 0.00021298481 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.79         |\n|    explained_variance           | 0.441         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 48.7          |\n|    n_updates                    | 492           |\n|    policy_gradient_loss         | -0.000215     |\n|    value_loss                   | 88            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 129           |\n|    action_queue_updates_total   | 147           |\n|    ice_dug                      | 60            |\n|    water_produced               | 10.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 23.9         |\n| time/                           |              |\n|    fps                          | 812          |\n|    iterations                   | 248          |\n|    time_elapsed                 | 1220         |\n|    total_timesteps              | 992000       |\n| train/                          |              |\n|    approx_kl                    | 0.0011334476 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.76        |\n|    explained_variance           | 0.543        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 11           |\n|    n_updates                    | 494          |\n|    policy_gradient_loss         | 0.000349     |\n|    value_loss                   | 22.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 128          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 113          |\n|    water_produced               | 23           |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 20.1        |\n| time/                           |             |\n|    fps                          | 813         |\n|    iterations                   | 249         |\n|    time_elapsed                 | 1224        |\n|    total_timesteps              | 996000      |\n| train/                          |             |\n|    approx_kl                    | 0.000395175 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.76       |\n|    explained_variance           | 0.536       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 23          |\n|    n_updates                    | 496         |\n|    policy_gradient_loss         | -0.000337   |\n|    value_loss                   | 51.6        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 123         |\n|    action_queue_updates_total   | 136         |\n|    ice_dug                      | 72          |\n|    water_produced               | 13          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 17.6         |\n| time/                           |              |\n|    fps                          | 813          |\n|    iterations                   | 250          |\n|    time_elapsed                 | 1229         |\n|    total_timesteps              | 1000000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004987839 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.58        |\n|    explained_variance           | 0.515        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 13.6         |\n|    n_updates                    | 498          |\n|    policy_gradient_loss         | -1.82e-05    |\n|    value_loss                   | 28.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 61           |\n|    water_produced               | 6.25         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 15.5         |\n| time/                           |              |\n|    fps                          | 813          |\n|    iterations                   | 251          |\n|    time_elapsed                 | 1234         |\n|    total_timesteps              | 1004000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014642596 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2           |\n|    explained_variance           | 0.636        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 10.1         |\n|    n_updates                    | 500          |\n|    policy_gradient_loss         | 0.000265     |\n|    value_loss                   | 17.8         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 98           |\n|    water_produced               | 20.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 19.8         |\n| time/                           |              |\n|    fps                          | 813          |\n|    iterations                   | 252          |\n|    time_elapsed                 | 1238         |\n|    total_timesteps              | 1008000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010990673 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.92        |\n|    explained_variance           | 0.509        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 30.2         |\n|    n_updates                    | 502          |\n|    policy_gradient_loss         | -0.000299    |\n|    value_loss                   | 47.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 171          |\n|    water_produced               | 31.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 23.9          |\n| time/                           |               |\n|    fps                          | 814           |\n|    iterations                   | 253           |\n|    time_elapsed                 | 1243          |\n|    total_timesteps              | 1012000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031601347 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.73         |\n|    explained_variance           | 0.458         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 32.6          |\n|    n_updates                    | 504           |\n|    policy_gradient_loss         | 0.000166      |\n|    value_loss                   | 72.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 198           |\n|    water_produced               | 42.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 24.9         |\n| time/                           |              |\n|    fps                          | 814          |\n|    iterations                   | 254          |\n|    time_elapsed                 | 1247         |\n|    total_timesteps              | 1016000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003452353 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.7         |\n|    explained_variance           | 0.436        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 48.7         |\n|    n_updates                    | 506          |\n|    policy_gradient_loss         | -9.78e-05    |\n|    value_loss                   | 107          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 128          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 79           |\n|    water_produced               | 18           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 25.9         |\n| time/                           |              |\n|    fps                          | 814          |\n|    iterations                   | 255          |\n|    time_elapsed                 | 1252         |\n|    total_timesteps              | 1020000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005792126 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.84        |\n|    explained_variance           | 0.505        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 21           |\n|    n_updates                    | 508          |\n|    policy_gradient_loss         | 0.000189     |\n|    value_loss                   | 50.8         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 142          |\n|    ice_dug                      | 55           |\n|    water_produced               | 11.3         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 26.5         |\n| time/                           |              |\n|    fps                          | 814          |\n|    iterations                   | 256          |\n|    time_elapsed                 | 1256         |\n|    total_timesteps              | 1024000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009578364 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.67        |\n|    explained_variance           | 0.54         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 14.6         |\n|    n_updates                    | 510          |\n|    policy_gradient_loss         | -0.00029     |\n|    value_loss                   | 30.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 148          |\n|    water_produced               | 22.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 27.2         |\n| time/                           |              |\n|    fps                          | 814          |\n|    iterations                   | 257          |\n|    time_elapsed                 | 1261         |\n|    total_timesteps              | 1028000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005047376 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.79        |\n|    explained_variance           | 0.472        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 23.2         |\n|    n_updates                    | 512          |\n|    policy_gradient_loss         | -1.06e-05    |\n|    value_loss                   | 66.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 210          |\n|    water_produced               | 34.5         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 24.9        |\n| time/                           |             |\n|    fps                          | 815         |\n|    iterations                   | 258         |\n|    time_elapsed                 | 1266        |\n|    total_timesteps              | 1032000     |\n| train/                          |             |\n|    approx_kl                    | 0.000624693 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.76       |\n|    explained_variance           | 0.459       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 30.3        |\n|    n_updates                    | 514         |\n|    policy_gradient_loss         | -4.47e-05   |\n|    value_loss                   | 90.4        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 132         |\n|    action_queue_updates_total   | 142         |\n|    ice_dug                      | 199         |\n|    water_produced               | 31.2        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 22.5         |\n| time/                           |              |\n|    fps                          | 815          |\n|    iterations                   | 259          |\n|    time_elapsed                 | 1270         |\n|    total_timesteps              | 1036000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010614784 |\n|    clip_fraction                | 0.00125      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.63        |\n|    explained_variance           | 0.463        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 39.1         |\n|    n_updates                    | 516          |\n|    policy_gradient_loss         | 0.000329     |\n|    value_loss                   | 72.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 34           |\n|    water_produced               | 6.5          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 25.7         |\n| time/                           |              |\n|    fps                          | 815          |\n|    iterations                   | 260          |\n|    time_elapsed                 | 1275         |\n|    total_timesteps              | 1040000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020411522 |\n|    clip_fraction                | 0.00288      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.77        |\n|    explained_variance           | 0.592        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 9.72         |\n|    n_updates                    | 518          |\n|    policy_gradient_loss         | 0.000491     |\n|    value_loss                   | 21.8         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 126          |\n|    water_produced               | 26.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 27.3          |\n| time/                           |               |\n|    fps                          | 815           |\n|    iterations                   | 261           |\n|    time_elapsed                 | 1279          |\n|    total_timesteps              | 1044000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035780176 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.81         |\n|    explained_variance           | 0.577         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 26.8          |\n|    n_updates                    | 520           |\n|    policy_gradient_loss         | -0.000354     |\n|    value_loss                   | 56.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 128           |\n|    action_queue_updates_total   | 146           |\n|    ice_dug                      | 132           |\n|    water_produced               | 30.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 22.8          |\n| time/                           |               |\n|    fps                          | 816           |\n|    iterations                   | 262           |\n|    time_elapsed                 | 1284          |\n|    total_timesteps              | 1048000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031716534 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.8          |\n|    explained_variance           | 0.505         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 51.5          |\n|    n_updates                    | 522           |\n|    policy_gradient_loss         | 5.17e-05      |\n|    value_loss                   | 90.3          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 71            |\n|    water_produced               | 13.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 22.5         |\n| time/                           |              |\n|    fps                          | 816          |\n|    iterations                   | 263          |\n|    time_elapsed                 | 1288         |\n|    total_timesteps              | 1052000      |\n| train/                          |              |\n|    approx_kl                    | 7.243102e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.81        |\n|    explained_variance           | 0.559        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 20           |\n|    n_updates                    | 524          |\n|    policy_gradient_loss         | 3e-05        |\n|    value_loss                   | 39.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 142          |\n|    water_produced               | 30.2         |\n--------------------------------------------------\nEval num_timesteps=1056000, episode_reward=26.40 +/- 52.80\nEpisode length: 326.00 +/- 50.00\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 326           |\n|    mean_reward                  | 26.4          |\n| time/                           |               |\n|    total_timesteps              | 1056000       |\n| train/                          |               |\n|    approx_kl                    | 0.00055517023 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.89         |\n|    explained_variance           | 0.57          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 31.5          |\n|    n_updates                    | 526           |\n|    policy_gradient_loss         | -0.00036      |\n|    value_loss                   | 70.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 130           |\n|    action_queue_updates_total   | 142           |\n|    ice_dug                      | 136           |\n|    water_produced               | 29.8          |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 27.4     |\n| time/              |          |\n|    fps             | 814      |\n|    iterations      | 264      |\n|    time_elapsed    | 1296     |\n|    total_timesteps | 1056000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 26.8          |\n| time/                           |               |\n|    fps                          | 814           |\n|    iterations                   | 265           |\n|    time_elapsed                 | 1301          |\n|    total_timesteps              | 1060000       |\n| train/                          |               |\n|    approx_kl                    | 0.00027754993 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.64         |\n|    explained_variance           | 0.526         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 34            |\n|    n_updates                    | 528           |\n|    policy_gradient_loss         | -7.44e-05     |\n|    value_loss                   | 70.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 129           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 120           |\n|    water_produced               | 23.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 22.1         |\n| time/                           |              |\n|    fps                          | 814          |\n|    iterations                   | 266          |\n|    time_elapsed                 | 1305         |\n|    total_timesteps              | 1064000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002875963 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.93        |\n|    explained_variance           | 0.551        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 27.7         |\n|    n_updates                    | 530          |\n|    policy_gradient_loss         | -6.99e-05    |\n|    value_loss                   | 55.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 124          |\n|    action_queue_updates_total   | 143          |\n|    ice_dug                      | 54           |\n|    water_produced               | 8.25         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 21.1         |\n| time/                           |              |\n|    fps                          | 815          |\n|    iterations                   | 267          |\n|    time_elapsed                 | 1310         |\n|    total_timesteps              | 1068000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004328352 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.75        |\n|    explained_variance           | 0.701        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 12.6         |\n|    n_updates                    | 532          |\n|    policy_gradient_loss         | -0.000385    |\n|    value_loss                   | 19.8         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 71           |\n|    water_produced               | 8.5          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 20.3         |\n| time/                           |              |\n|    fps                          | 815          |\n|    iterations                   | 268          |\n|    time_elapsed                 | 1314         |\n|    total_timesteps              | 1072000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006023676 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.87        |\n|    explained_variance           | 0.629        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 22.1         |\n|    n_updates                    | 534          |\n|    policy_gradient_loss         | -0.000301    |\n|    value_loss                   | 27.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 144          |\n|    water_produced               | 26.3         |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 18.2       |\n| time/                           |            |\n|    fps                          | 815        |\n|    iterations                   | 269        |\n|    time_elapsed                 | 1319       |\n|    total_timesteps              | 1076000    |\n| train/                          |            |\n|    approx_kl                    | 0.00113333 |\n|    clip_fraction                | 0.000625   |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.81      |\n|    explained_variance           | 0.532      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 26.5       |\n|    n_updates                    | 536        |\n|    policy_gradient_loss         | -0.000391  |\n|    value_loss                   | 51.8       |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 143        |\n|    action_queue_updates_total   | 159        |\n|    ice_dug                      | 121        |\n|    water_produced               | 19.5       |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 16.5         |\n| time/                           |              |\n|    fps                          | 815          |\n|    iterations                   | 270          |\n|    time_elapsed                 | 1324         |\n|    total_timesteps              | 1080000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020851283 |\n|    clip_fraction                | 0.0035       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.9         |\n|    explained_variance           | 0.473        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 21.1         |\n|    n_updates                    | 538          |\n|    policy_gradient_loss         | 0.000479     |\n|    value_loss                   | 49.6         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 68           |\n|    water_produced               | 15.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 16.7          |\n| time/                           |               |\n|    fps                          | 815           |\n|    iterations                   | 271           |\n|    time_elapsed                 | 1328          |\n|    total_timesteps              | 1084000       |\n| train/                          |               |\n|    approx_kl                    | 0.00051485084 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.92         |\n|    explained_variance           | 0.591         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 10.2          |\n|    n_updates                    | 540           |\n|    policy_gradient_loss         | 0.000279      |\n|    value_loss                   | 32.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 49            |\n|    water_produced               | 9.25          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 18.8         |\n| time/                           |              |\n|    fps                          | 815          |\n|    iterations                   | 272          |\n|    time_elapsed                 | 1333         |\n|    total_timesteps              | 1088000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016538281 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.01        |\n|    explained_variance           | 0.593        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 9.26         |\n|    n_updates                    | 542          |\n|    policy_gradient_loss         | 0.000684     |\n|    value_loss                   | 21.6         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 103          |\n|    water_produced               | 18.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.2          |\n| time/                           |               |\n|    fps                          | 816           |\n|    iterations                   | 273           |\n|    time_elapsed                 | 1337          |\n|    total_timesteps              | 1092000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017962238 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.02         |\n|    explained_variance           | 0.566         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 23.8          |\n|    n_updates                    | 544           |\n|    policy_gradient_loss         | 0.000107      |\n|    value_loss                   | 47.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 131           |\n|    water_produced               | 23.8          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 16.4        |\n| time/                           |             |\n|    fps                          | 816         |\n|    iterations                   | 274         |\n|    time_elapsed                 | 1342        |\n|    total_timesteps              | 1096000     |\n| train/                          |             |\n|    approx_kl                    | 0.000459477 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.85       |\n|    explained_variance           | 0.541       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 22.6        |\n|    n_updates                    | 546         |\n|    policy_gradient_loss         | 0.00017     |\n|    value_loss                   | 48.3        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 134         |\n|    action_queue_updates_total   | 153         |\n|    ice_dug                      | 51          |\n|    water_produced               | 10.8        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 16.5         |\n| time/                           |              |\n|    fps                          | 816          |\n|    iterations                   | 275          |\n|    time_elapsed                 | 1346         |\n|    total_timesteps              | 1100000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014787544 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.86        |\n|    explained_variance           | 0.71         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 7.43         |\n|    n_updates                    | 548          |\n|    policy_gradient_loss         | 0.000458     |\n|    value_loss                   | 15.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 129          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 85           |\n|    water_produced               | 16.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 16.3          |\n| time/                           |               |\n|    fps                          | 816           |\n|    iterations                   | 276           |\n|    time_elapsed                 | 1351          |\n|    total_timesteps              | 1104000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017726843 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.96         |\n|    explained_variance           | 0.631         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 15.3          |\n|    n_updates                    | 550           |\n|    policy_gradient_loss         | 0.000169      |\n|    value_loss                   | 33.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 53            |\n|    water_produced               | 8             |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 14.7        |\n| time/                           |             |\n|    fps                          | 816         |\n|    iterations                   | 277         |\n|    time_elapsed                 | 1356        |\n|    total_timesteps              | 1108000     |\n| train/                          |             |\n|    approx_kl                    | 0.002192241 |\n|    clip_fraction                | 0.000875    |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.99       |\n|    explained_variance           | 0.706       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 12          |\n|    n_updates                    | 552         |\n|    policy_gradient_loss         | 0.000555    |\n|    value_loss                   | 18.7        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 134         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 77          |\n|    water_produced               | 10.7        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.4          |\n| time/                           |               |\n|    fps                          | 817           |\n|    iterations                   | 278           |\n|    time_elapsed                 | 1360          |\n|    total_timesteps              | 1112000       |\n| train/                          |               |\n|    approx_kl                    | 0.00027118268 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.15         |\n|    explained_variance           | 0.655         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 9.21          |\n|    n_updates                    | 554           |\n|    policy_gradient_loss         | 0.000142      |\n|    value_loss                   | 21.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 134           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 125           |\n|    water_produced               | 27.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 15.2         |\n| time/                           |              |\n|    fps                          | 817          |\n|    iterations                   | 279          |\n|    time_elapsed                 | 1365         |\n|    total_timesteps              | 1116000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005089751 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.96        |\n|    explained_variance           | 0.581        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 28.1         |\n|    n_updates                    | 556          |\n|    policy_gradient_loss         | 0.000359     |\n|    value_loss                   | 57.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 52           |\n|    water_produced               | 9.5          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 14.2         |\n| time/                           |              |\n|    fps                          | 817          |\n|    iterations                   | 280          |\n|    time_elapsed                 | 1369         |\n|    total_timesteps              | 1120000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006080299 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.05        |\n|    explained_variance           | 0.68         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 14.4         |\n|    n_updates                    | 558          |\n|    policy_gradient_loss         | 0.00016      |\n|    value_loss                   | 26.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 128          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 62           |\n|    water_produced               | 11.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 15.7          |\n| time/                           |               |\n|    fps                          | 817           |\n|    iterations                   | 281           |\n|    time_elapsed                 | 1374          |\n|    total_timesteps              | 1124000       |\n| train/                          |               |\n|    approx_kl                    | 0.00016689653 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.06         |\n|    explained_variance           | 0.726         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 10.3          |\n|    n_updates                    | 560           |\n|    policy_gradient_loss         | -6.36e-05     |\n|    value_loss                   | 20.4          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 80            |\n|    water_produced               | 15.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 14.2         |\n| time/                           |              |\n|    fps                          | 818          |\n|    iterations                   | 282          |\n|    time_elapsed                 | 1378         |\n|    total_timesteps              | 1128000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007549894 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.02        |\n|    explained_variance           | 0.705        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 15           |\n|    n_updates                    | 562          |\n|    policy_gradient_loss         | -0.000409    |\n|    value_loss                   | 27           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 124          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 17           |\n|    water_produced               | 3.75         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 10.9        |\n| time/                           |             |\n|    fps                          | 818         |\n|    iterations                   | 283         |\n|    time_elapsed                 | 1383        |\n|    total_timesteps              | 1132000     |\n| train/                          |             |\n|    approx_kl                    | 0.000624061 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -2.17       |\n|    explained_variance           | 0.792       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 4.12        |\n|    n_updates                    | 564         |\n|    policy_gradient_loss         | -0.000774   |\n|    value_loss                   | 8.38        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 130         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 60          |\n|    water_produced               | 12          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 10.5         |\n| time/                           |              |\n|    fps                          | 818          |\n|    iterations                   | 284          |\n|    time_elapsed                 | 1388         |\n|    total_timesteps              | 1136000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003749789 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.16        |\n|    explained_variance           | 0.693        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 14.8         |\n|    n_updates                    | 566          |\n|    policy_gradient_loss         | -0.000243    |\n|    value_loss                   | 31.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 42           |\n|    water_produced               | 7.5          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 9.92         |\n| time/                           |              |\n|    fps                          | 818          |\n|    iterations                   | 285          |\n|    time_elapsed                 | 1393         |\n|    total_timesteps              | 1140000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017598458 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.16        |\n|    explained_variance           | 0.721        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 6.79         |\n|    n_updates                    | 568          |\n|    policy_gradient_loss         | 0.000238     |\n|    value_loss                   | 15.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 59           |\n|    water_produced               | 8.5          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 6.71          |\n| time/                           |               |\n|    fps                          | 818           |\n|    iterations                   | 286           |\n|    time_elapsed                 | 1397          |\n|    total_timesteps              | 1144000       |\n| train/                          |               |\n|    approx_kl                    | 0.00020297637 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.1          |\n|    explained_variance           | 0.754         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.99          |\n|    n_updates                    | 570           |\n|    policy_gradient_loss         | 0.000163      |\n|    value_loss                   | 15.3          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 135           |\n|    action_queue_updates_total   | 169           |\n|    ice_dug                      | 2             |\n|    water_produced               | 0             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 7.02         |\n| time/                           |              |\n|    fps                          | 818          |\n|    iterations                   | 287          |\n|    time_elapsed                 | 1402         |\n|    total_timesteps              | 1148000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020938807 |\n|    clip_fraction                | 0.00413      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.2         |\n|    explained_variance           | 0.822        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 1.5          |\n|    n_updates                    | 572          |\n|    policy_gradient_loss         | 0.000942     |\n|    value_loss                   | 3.31         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 46           |\n|    water_produced               | 5            |\n--------------------------------------------------\nEval num_timesteps=1152000, episode_reward=1.08 +/- 2.16\nEpisode length: 302.00 +/- 2.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 302          |\n|    mean_reward                  | 1.08         |\n| time/                           |              |\n|    total_timesteps              | 1152000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008510974 |\n|    clip_fraction                | 0.000875     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.22        |\n|    explained_variance           | 0.682        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 6.03         |\n|    n_updates                    | 574          |\n|    policy_gradient_loss         | 0.000453     |\n|    value_loss                   | 12           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 77           |\n|    water_produced               | 12.2         |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 7.1      |\n| time/              |          |\n|    fps             | 817      |\n|    iterations      | 288      |\n|    time_elapsed    | 1410     |\n|    total_timesteps | 1152000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 8.72         |\n| time/                           |              |\n|    fps                          | 817          |\n|    iterations                   | 289          |\n|    time_elapsed                 | 1414         |\n|    total_timesteps              | 1156000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005210367 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.22        |\n|    explained_variance           | 0.715        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 12.5         |\n|    n_updates                    | 576          |\n|    policy_gradient_loss         | 2.57e-05     |\n|    value_loss                   | 21           |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 77           |\n|    water_produced               | 15.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 8.8           |\n| time/                           |               |\n|    fps                          | 817           |\n|    iterations                   | 290           |\n|    time_elapsed                 | 1419          |\n|    total_timesteps              | 1160000       |\n| train/                          |               |\n|    approx_kl                    | 0.00044472553 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.22         |\n|    explained_variance           | 0.69          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 13.5          |\n|    n_updates                    | 578           |\n|    policy_gradient_loss         | 0.000183      |\n|    value_loss                   | 25.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 49            |\n|    water_produced               | 9             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11.5          |\n| time/                           |               |\n|    fps                          | 817           |\n|    iterations                   | 291           |\n|    time_elapsed                 | 1424          |\n|    total_timesteps              | 1164000       |\n| train/                          |               |\n|    approx_kl                    | 0.00062468735 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.01         |\n|    explained_variance           | 0.74          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 9.14          |\n|    n_updates                    | 580           |\n|    policy_gradient_loss         | 0.000129      |\n|    value_loss                   | 16.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 75            |\n|    water_produced               | 12.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11.4          |\n| time/                           |               |\n|    fps                          | 817           |\n|    iterations                   | 292           |\n|    time_elapsed                 | 1429          |\n|    total_timesteps              | 1168000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031951623 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.02         |\n|    explained_variance           | 0.632         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 14.1          |\n|    n_updates                    | 582           |\n|    policy_gradient_loss         | -0.000335     |\n|    value_loss                   | 23.7          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 125           |\n|    action_queue_updates_total   | 170           |\n|    ice_dug                      | 20            |\n|    water_produced               | 4.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 11            |\n| time/                           |               |\n|    fps                          | 817           |\n|    iterations                   | 293           |\n|    time_elapsed                 | 1433          |\n|    total_timesteps              | 1172000       |\n| train/                          |               |\n|    approx_kl                    | 0.00011024615 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.25         |\n|    explained_variance           | 0.78          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.8           |\n|    n_updates                    | 584           |\n|    policy_gradient_loss         | -0.000296     |\n|    value_loss                   | 8.43          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 43            |\n|    water_produced               | 10.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.2          |\n| time/                           |               |\n|    fps                          | 817           |\n|    iterations                   | 294           |\n|    time_elapsed                 | 1438          |\n|    total_timesteps              | 1176000       |\n| train/                          |               |\n|    approx_kl                    | 0.00043498678 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.22         |\n|    explained_variance           | 0.67          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 7.84          |\n|    n_updates                    | 586           |\n|    policy_gradient_loss         | 0.000312      |\n|    value_loss                   | 17.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 159           |\n|    water_produced               | 25.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 15.9         |\n| time/                           |              |\n|    fps                          | 817          |\n|    iterations                   | 295          |\n|    time_elapsed                 | 1443         |\n|    total_timesteps              | 1180000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010667145 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.08        |\n|    explained_variance           | 0.683        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 25.5         |\n|    n_updates                    | 588          |\n|    policy_gradient_loss         | 0.000221     |\n|    value_loss                   | 55.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 103          |\n|    water_produced               | 22.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 15.6         |\n| time/                           |              |\n|    fps                          | 817          |\n|    iterations                   | 296          |\n|    time_elapsed                 | 1447         |\n|    total_timesteps              | 1184000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008863056 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.12        |\n|    explained_variance           | 0.693        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 15.3         |\n|    n_updates                    | 590          |\n|    policy_gradient_loss         | -9.44e-05    |\n|    value_loss                   | 41.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 129          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 79           |\n|    water_produced               | 11           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 19.3          |\n| time/                           |               |\n|    fps                          | 818           |\n|    iterations                   | 297           |\n|    time_elapsed                 | 1452          |\n|    total_timesteps              | 1188000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032515073 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.01         |\n|    explained_variance           | 0.795         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 10.3          |\n|    n_updates                    | 592           |\n|    policy_gradient_loss         | -0.000181     |\n|    value_loss                   | 20.2          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 128           |\n|    action_queue_updates_total   | 171           |\n|    ice_dug                      | 104           |\n|    water_produced               | 22.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 18.7         |\n| time/                           |              |\n|    fps                          | 818          |\n|    iterations                   | 298          |\n|    time_elapsed                 | 1456         |\n|    total_timesteps              | 1192000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004766675 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.19        |\n|    explained_variance           | 0.684        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 29.4         |\n|    n_updates                    | 594          |\n|    policy_gradient_loss         | 9.84e-05     |\n|    value_loss                   | 59.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 115          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 34           |\n|    water_produced               | 7.5          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 13.3          |\n| time/                           |               |\n|    fps                          | 818           |\n|    iterations                   | 299           |\n|    time_elapsed                 | 1461          |\n|    total_timesteps              | 1196000       |\n| train/                          |               |\n|    approx_kl                    | 0.00021486692 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.05         |\n|    explained_variance           | 0.82          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 9.98          |\n|    n_updates                    | 596           |\n|    policy_gradient_loss         | -3.63e-05     |\n|    value_loss                   | 18.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 123           |\n|    action_queue_updates_total   | 169           |\n|    ice_dug                      | 8             |\n|    water_produced               | 0             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 13.3         |\n| time/                           |              |\n|    fps                          | 818          |\n|    iterations                   | 300          |\n|    time_elapsed                 | 1466         |\n|    total_timesteps              | 1200000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004866078 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.23        |\n|    explained_variance           | 0.86         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 1.61         |\n|    n_updates                    | 598          |\n|    policy_gradient_loss         | -0.000574    |\n|    value_loss                   | 4.02         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 120          |\n|    water_produced               | 22.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 12.5          |\n| time/                           |               |\n|    fps                          | 818           |\n|    iterations                   | 301           |\n|    time_elapsed                 | 1470          |\n|    total_timesteps              | 1204000       |\n| train/                          |               |\n|    approx_kl                    | 0.00045920373 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.96         |\n|    explained_variance           | 0.687         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 22.6          |\n|    n_updates                    | 600           |\n|    policy_gradient_loss         | -0.000318     |\n|    value_loss                   | 49.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 128           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 30            |\n|    water_produced               | 7.25          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 8.25         |\n| time/                           |              |\n|    fps                          | 818          |\n|    iterations                   | 302          |\n|    time_elapsed                 | 1475         |\n|    total_timesteps              | 1208000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005177533 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.07        |\n|    explained_variance           | 0.764        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 8.45         |\n|    n_updates                    | 602          |\n|    policy_gradient_loss         | -0.000422    |\n|    value_loss                   | 18.4         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 10           |\n|    water_produced               | 2            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 7.44          |\n| time/                           |               |\n|    fps                          | 818           |\n|    iterations                   | 303           |\n|    time_elapsed                 | 1480          |\n|    total_timesteps              | 1212000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035707653 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.2          |\n|    explained_variance           | 0.845         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 3.43          |\n|    n_updates                    | 604           |\n|    policy_gradient_loss         | -4.12e-05     |\n|    value_loss                   | 6.32          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 127           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 26            |\n|    water_produced               | 3.5           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 12.4         |\n| time/                           |              |\n|    fps                          | 819          |\n|    iterations                   | 304          |\n|    time_elapsed                 | 1484         |\n|    total_timesteps              | 1216000      |\n| train/                          |              |\n|    approx_kl                    | 9.287884e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.2         |\n|    explained_variance           | 0.824        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 3.74         |\n|    n_updates                    | 606          |\n|    policy_gradient_loss         | -0.000353    |\n|    value_loss                   | 7.66         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 134          |\n|    water_produced               | 23.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 10.3          |\n| time/                           |               |\n|    fps                          | 819           |\n|    iterations                   | 305           |\n|    time_elapsed                 | 1489          |\n|    total_timesteps              | 1220000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015605132 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.04         |\n|    explained_variance           | 0.596         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 34.3          |\n|    n_updates                    | 608           |\n|    policy_gradient_loss         | -0.000346     |\n|    value_loss                   | 75            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 134           |\n|    action_queue_updates_total   | 169           |\n|    ice_dug                      | 53            |\n|    water_produced               | 12.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 13.8         |\n| time/                           |              |\n|    fps                          | 819          |\n|    iterations                   | 306          |\n|    time_elapsed                 | 1493         |\n|    total_timesteps              | 1224000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002167614 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.19        |\n|    explained_variance           | 0.684        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 16.4         |\n|    n_updates                    | 610          |\n|    policy_gradient_loss         | 0.000101     |\n|    value_loss                   | 30.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 97           |\n|    water_produced               | 24.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 16.7         |\n| time/                           |              |\n|    fps                          | 819          |\n|    iterations                   | 307          |\n|    time_elapsed                 | 1498         |\n|    total_timesteps              | 1228000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002460958 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.2         |\n|    explained_variance           | 0.631        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 26.6         |\n|    n_updates                    | 612          |\n|    policy_gradient_loss         | 0.000139     |\n|    value_loss                   | 66.8         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 86           |\n|    water_produced               | 16           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 18.8          |\n| time/                           |               |\n|    fps                          | 819           |\n|    iterations                   | 308           |\n|    time_elapsed                 | 1502          |\n|    total_timesteps              | 1232000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046287593 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.04         |\n|    explained_variance           | 0.68          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 12.7          |\n|    n_updates                    | 614           |\n|    policy_gradient_loss         | 0.000273      |\n|    value_loss                   | 31            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 60            |\n|    water_produced               | 13.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 17.3         |\n| time/                           |              |\n|    fps                          | 819          |\n|    iterations                   | 309          |\n|    time_elapsed                 | 1507         |\n|    total_timesteps              | 1236000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006344596 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.16        |\n|    explained_variance           | 0.655        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 33.3         |\n|    n_updates                    | 616          |\n|    policy_gradient_loss         | -0.000188    |\n|    value_loss                   | 44.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 127          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 71           |\n|    water_produced               | 17           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 18.2         |\n| time/                           |              |\n|    fps                          | 820          |\n|    iterations                   | 310          |\n|    time_elapsed                 | 1512         |\n|    total_timesteps              | 1240000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002316423 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.2         |\n|    explained_variance           | 0.739        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 9.85         |\n|    n_updates                    | 618          |\n|    policy_gradient_loss         | 7.57e-06     |\n|    value_loss                   | 30.1         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 115          |\n|    water_produced               | 16.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 18           |\n| time/                           |              |\n|    fps                          | 820          |\n|    iterations                   | 311          |\n|    time_elapsed                 | 1516         |\n|    total_timesteps              | 1244000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009554931 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.09        |\n|    explained_variance           | 0.669        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 22.2         |\n|    n_updates                    | 620          |\n|    policy_gradient_loss         | 0.000797     |\n|    value_loss                   | 44.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 103          |\n|    water_produced               | 23           |\n--------------------------------------------------\nEval num_timesteps=1248000, episode_reward=1.88 +/- 3.76\nEpisode length: 301.00 +/- 0.00\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 301           |\n|    mean_reward                  | 1.88          |\n| time/                           |               |\n|    total_timesteps              | 1248000       |\n| train/                          |               |\n|    approx_kl                    | 0.00045636072 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.06         |\n|    explained_variance           | 0.676         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 35.6          |\n|    n_updates                    | 622           |\n|    policy_gradient_loss         | -0.000332     |\n|    value_loss                   | 53.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 132           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 21            |\n|    water_produced               | 2.25          |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 15.1     |\n| time/              |          |\n|    fps             | 819      |\n|    iterations      | 312      |\n|    time_elapsed    | 1523     |\n|    total_timesteps | 1248000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 16.8        |\n| time/                           |             |\n|    fps                          | 819         |\n|    iterations                   | 313         |\n|    time_elapsed                 | 1528        |\n|    total_timesteps              | 1252000     |\n| train/                          |             |\n|    approx_kl                    | 0.002095736 |\n|    clip_fraction                | 0.00188     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -2          |\n|    explained_variance           | 0.841       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 4.02        |\n|    n_updates                    | 624         |\n|    policy_gradient_loss         | -0.000134   |\n|    value_loss                   | 9           |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 135         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 136         |\n|    water_produced               | 21          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 13.2         |\n| time/                           |              |\n|    fps                          | 819          |\n|    iterations                   | 314          |\n|    time_elapsed                 | 1532         |\n|    total_timesteps              | 1256000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011950241 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.98        |\n|    explained_variance           | 0.691        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 21.5         |\n|    n_updates                    | 626          |\n|    policy_gradient_loss         | -0.000476    |\n|    value_loss                   | 52.5         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 0            |\n|    water_produced               | 0            |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 10.5          |\n| time/                           |               |\n|    fps                          | 819           |\n|    iterations                   | 315           |\n|    time_elapsed                 | 1537          |\n|    total_timesteps              | 1260000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046619904 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.32         |\n|    explained_variance           | 0.849         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.98          |\n|    n_updates                    | 628           |\n|    policy_gradient_loss         | -0.000144     |\n|    value_loss                   | 2.52          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 127           |\n|    action_queue_updates_total   | 177           |\n|    ice_dug                      | 16            |\n|    water_produced               | 3.25          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 5.86          |\n| time/                           |               |\n|    fps                          | 819           |\n|    iterations                   | 316           |\n|    time_elapsed                 | 1542          |\n|    total_timesteps              | 1264000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029291006 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.28         |\n|    explained_variance           | 0.828         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 2.18          |\n|    n_updates                    | 630           |\n|    policy_gradient_loss         | -0.000677     |\n|    value_loss                   | 6.11          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 132           |\n|    action_queue_updates_total   | 171           |\n|    ice_dug                      | 5             |\n|    water_produced               | 1             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 7.63         |\n| time/                           |              |\n|    fps                          | 819          |\n|    iterations                   | 317          |\n|    time_elapsed                 | 1547         |\n|    total_timesteps              | 1268000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011448052 |\n|    clip_fraction                | 0.00225      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.23        |\n|    explained_variance           | 0.843        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 1.62         |\n|    n_updates                    | 632          |\n|    policy_gradient_loss         | 0.000466     |\n|    value_loss                   | 3.45         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 56           |\n|    water_produced               | 10.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 4.98          |\n| time/                           |               |\n|    fps                          | 819           |\n|    iterations                   | 318           |\n|    time_elapsed                 | 1551          |\n|    total_timesteps              | 1272000       |\n| train/                          |               |\n|    approx_kl                    | 0.00020211484 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.23         |\n|    explained_variance           | 0.684         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 12.6          |\n|    n_updates                    | 634           |\n|    policy_gradient_loss         | -0.000292     |\n|    value_loss                   | 24            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 36            |\n|    water_produced               | 8.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 6.6           |\n| time/                           |               |\n|    fps                          | 819           |\n|    iterations                   | 319           |\n|    time_elapsed                 | 1556          |\n|    total_timesteps              | 1276000       |\n| train/                          |               |\n|    approx_kl                    | 0.00010213704 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.19         |\n|    explained_variance           | 0.706         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 10.6          |\n|    n_updates                    | 636           |\n|    policy_gradient_loss         | -0.000202     |\n|    value_loss                   | 21.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 173           |\n|    ice_dug                      | 38            |\n|    water_produced               | 7.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 5.92          |\n| time/                           |               |\n|    fps                          | 820           |\n|    iterations                   | 320           |\n|    time_elapsed                 | 1560          |\n|    total_timesteps              | 1280000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031237624 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.22         |\n|    explained_variance           | 0.772         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.48          |\n|    n_updates                    | 638           |\n|    policy_gradient_loss         | 0.000327      |\n|    value_loss                   | 11            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 0             |\n|    water_produced               | 0             |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 5.71         |\n| time/                           |              |\n|    fps                          | 820          |\n|    iterations                   | 321          |\n|    time_elapsed                 | 1564         |\n|    total_timesteps              | 1284000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011285143 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.17        |\n|    explained_variance           | 0.861        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 1.23         |\n|    n_updates                    | 640          |\n|    policy_gradient_loss         | 0.000108     |\n|    value_loss                   | 2.8          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 0            |\n|    water_produced               | 0            |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 5.71         |\n| time/                           |              |\n|    fps                          | 820          |\n|    iterations                   | 322          |\n|    time_elapsed                 | 1569         |\n|    total_timesteps              | 1288000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006486765 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.34        |\n|    explained_variance           | 0.85         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.279        |\n|    n_updates                    | 642          |\n|    policy_gradient_loss         | 0.000494     |\n|    value_loss                   | 0.772        |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 58           |\n|    water_produced               | 10.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 5.09         |\n| time/                           |              |\n|    fps                          | 821          |\n|    iterations                   | 323          |\n|    time_elapsed                 | 1573         |\n|    total_timesteps              | 1292000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002622258 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.25        |\n|    explained_variance           | 0.713        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 8.06         |\n|    n_updates                    | 644          |\n|    policy_gradient_loss         | -0.000331    |\n|    value_loss                   | 16.8         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 25           |\n|    water_produced               | 5.75         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 4.19          |\n| time/                           |               |\n|    fps                          | 821           |\n|    iterations                   | 324           |\n|    time_elapsed                 | 1578          |\n|    total_timesteps              | 1296000       |\n| train/                          |               |\n|    approx_kl                    | 0.00036467708 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.29         |\n|    explained_variance           | 0.688         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.82          |\n|    n_updates                    | 646           |\n|    policy_gradient_loss         | 0.000228      |\n|    value_loss                   | 15            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 174           |\n|    ice_dug                      | 14            |\n|    water_produced               | 3.5           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 4.67         |\n| time/                           |              |\n|    fps                          | 821          |\n|    iterations                   | 325          |\n|    time_elapsed                 | 1582         |\n|    total_timesteps              | 1300000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012498202 |\n|    clip_fraction                | 0.00188      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.27        |\n|    explained_variance           | 0.745        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 5.83         |\n|    n_updates                    | 648          |\n|    policy_gradient_loss         | 0.000499     |\n|    value_loss                   | 7.78         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 12           |\n|    water_produced               | 2.25         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 6.79          |\n| time/                           |               |\n|    fps                          | 821           |\n|    iterations                   | 326           |\n|    time_elapsed                 | 1587          |\n|    total_timesteps              | 1304000       |\n| train/                          |               |\n|    approx_kl                    | 0.00040356535 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.33         |\n|    explained_variance           | 0.785         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 1.41          |\n|    n_updates                    | 650           |\n|    policy_gradient_loss         | -0.000147     |\n|    value_loss                   | 2.61          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 174           |\n|    ice_dug                      | 61            |\n|    water_produced               | 10            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 4.94          |\n| time/                           |               |\n|    fps                          | 821           |\n|    iterations                   | 327           |\n|    time_elapsed                 | 1591          |\n|    total_timesteps              | 1308000       |\n| train/                          |               |\n|    approx_kl                    | 0.00036326153 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.25         |\n|    explained_variance           | 0.609         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 15.5          |\n|    n_updates                    | 652           |\n|    policy_gradient_loss         | -0.00071      |\n|    value_loss                   | 23            |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 176           |\n|    ice_dug                      | 8             |\n|    water_produced               | 2             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 5.37          |\n| time/                           |               |\n|    fps                          | 822           |\n|    iterations                   | 328           |\n|    time_elapsed                 | 1596          |\n|    total_timesteps              | 1312000       |\n| train/                          |               |\n|    approx_kl                    | 0.00085185573 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.27         |\n|    explained_variance           | 0.75          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 2.36          |\n|    n_updates                    | 654           |\n|    policy_gradient_loss         | -0.000123     |\n|    value_loss                   | 4.03          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 177           |\n|    ice_dug                      | 38            |\n|    water_produced               | 7.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 4.69          |\n| time/                           |               |\n|    fps                          | 822           |\n|    iterations                   | 329           |\n|    time_elapsed                 | 1600          |\n|    total_timesteps              | 1316000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029530743 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.31         |\n|    explained_variance           | 0.666         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.53          |\n|    n_updates                    | 656           |\n|    policy_gradient_loss         | 0.000131      |\n|    value_loss                   | 19.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 176           |\n|    ice_dug                      | 1             |\n|    water_produced               | 0.25          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 8.1           |\n| time/                           |               |\n|    fps                          | 822           |\n|    iterations                   | 330           |\n|    time_elapsed                 | 1604          |\n|    total_timesteps              | 1320000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031200075 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.27         |\n|    explained_variance           | 0.901         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.397         |\n|    n_updates                    | 658           |\n|    policy_gradient_loss         | 0.00057       |\n|    value_loss                   | 1.23          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 173           |\n|    ice_dug                      | 94            |\n|    water_produced               | 18.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 6.09         |\n| time/                           |              |\n|    fps                          | 822          |\n|    iterations                   | 331          |\n|    time_elapsed                 | 1609         |\n|    total_timesteps              | 1324000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013709879 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.26        |\n|    explained_variance           | 0.67         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 20.4         |\n|    n_updates                    | 660          |\n|    policy_gradient_loss         | -0.000149    |\n|    value_loss                   | 41.5         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 4            |\n|    water_produced               | 0.5          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 7.66          |\n| time/                           |               |\n|    fps                          | 822           |\n|    iterations                   | 332           |\n|    time_elapsed                 | 1613          |\n|    total_timesteps              | 1328000       |\n| train/                          |               |\n|    approx_kl                    | 0.00023335408 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.33         |\n|    explained_variance           | 0.79          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.576         |\n|    n_updates                    | 662           |\n|    policy_gradient_loss         | 0.000437      |\n|    value_loss                   | 1.34          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 178           |\n|    ice_dug                      | 41            |\n|    water_produced               | 9.5           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 6.24          |\n| time/                           |               |\n|    fps                          | 823           |\n|    iterations                   | 333           |\n|    time_elapsed                 | 1618          |\n|    total_timesteps              | 1332000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015113055 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.23         |\n|    explained_variance           | 0.648         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 8.93          |\n|    n_updates                    | 664           |\n|    policy_gradient_loss         | 1.84e-05      |\n|    value_loss                   | 22.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 178           |\n|    ice_dug                      | 7             |\n|    water_produced               | 1             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 7.13          |\n| time/                           |               |\n|    fps                          | 823           |\n|    iterations                   | 334           |\n|    time_elapsed                 | 1622          |\n|    total_timesteps              | 1336000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029954236 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.29         |\n|    explained_variance           | 0.837         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.535         |\n|    n_updates                    | 666           |\n|    policy_gradient_loss         | -0.000175     |\n|    value_loss                   | 1.15          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 20            |\n|    water_produced               | 4.5           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 4.35          |\n| time/                           |               |\n|    fps                          | 823           |\n|    iterations                   | 335           |\n|    time_elapsed                 | 1626          |\n|    total_timesteps              | 1340000       |\n| train/                          |               |\n|    approx_kl                    | 0.00051399204 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.27         |\n|    explained_variance           | 0.714         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 3.04          |\n|    n_updates                    | 668           |\n|    policy_gradient_loss         | 0.000122      |\n|    value_loss                   | 6.67          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 175           |\n|    ice_dug                      | 29            |\n|    water_produced               | 5.25          |\n---------------------------------------------------\nEval num_timesteps=1344000, episode_reward=0.00 +/- 0.00\nEpisode length: 301.00 +/- 0.00\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 301           |\n|    mean_reward                  | 0             |\n| time/                           |               |\n|    total_timesteps              | 1344000       |\n| train/                          |               |\n|    approx_kl                    | 0.00013514272 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.28         |\n|    explained_variance           | 0.712         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 3.1           |\n|    n_updates                    | 670           |\n|    policy_gradient_loss         | -6.45e-05     |\n|    value_loss                   | 7.63          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 175           |\n|    ice_dug                      | 11            |\n|    water_produced               | 1.5           |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 4.57     |\n| time/              |          |\n|    fps             | 822      |\n|    iterations      | 336      |\n|    time_elapsed    | 1633     |\n|    total_timesteps | 1344000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 2.96         |\n| time/                           |              |\n|    fps                          | 822          |\n|    iterations                   | 337          |\n|    time_elapsed                 | 1638         |\n|    total_timesteps              | 1348000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007206025 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.27        |\n|    explained_variance           | 0.771        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 1.27         |\n|    n_updates                    | 672          |\n|    policy_gradient_loss         | 0.00075      |\n|    value_loss                   | 2.98         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 11           |\n|    water_produced               | 1.75         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 2.74          |\n| time/                           |               |\n|    fps                          | 822           |\n|    iterations                   | 338           |\n|    time_elapsed                 | 1642          |\n|    total_timesteps              | 1352000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046364925 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.33         |\n|    explained_variance           | 0.706         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 1.01          |\n|    n_updates                    | 674           |\n|    policy_gradient_loss         | 0.000686      |\n|    value_loss                   | 2.67          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 176           |\n|    ice_dug                      | 0             |\n|    water_produced               | 0             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 1.97          |\n| time/                           |               |\n|    fps                          | 823           |\n|    iterations                   | 339           |\n|    time_elapsed                 | 1647          |\n|    total_timesteps              | 1356000       |\n| train/                          |               |\n|    approx_kl                    | 0.00054471765 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.34         |\n|    explained_variance           | 0.786         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.183         |\n|    n_updates                    | 676           |\n|    policy_gradient_loss         | -0.000361     |\n|    value_loss                   | 0.426         |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 178           |\n|    ice_dug                      | 8             |\n|    water_produced               | 0.75          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 4.75          |\n| time/                           |               |\n|    fps                          | 823           |\n|    iterations                   | 340           |\n|    time_elapsed                 | 1651          |\n|    total_timesteps              | 1360000       |\n| train/                          |               |\n|    approx_kl                    | 0.00054264773 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.34         |\n|    explained_variance           | 0.456         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.568         |\n|    n_updates                    | 678           |\n|    policy_gradient_loss         | -2.82e-05     |\n|    value_loss                   | 0.885         |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 159           |\n|    action_queue_updates_total   | 174           |\n|    ice_dug                      | 95            |\n|    water_produced               | 18.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 7            |\n| time/                           |              |\n|    fps                          | 823          |\n|    iterations                   | 341          |\n|    time_elapsed                 | 1655         |\n|    total_timesteps              | 1364000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038056516 |\n|    clip_fraction                | 0.0174       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.28        |\n|    explained_variance           | 0.579        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 13.9         |\n|    n_updates                    | 680          |\n|    policy_gradient_loss         | -0.00272     |\n|    value_loss                   | 30.5         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 63           |\n|    water_produced               | 12.3         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 6.79          |\n| time/                           |               |\n|    fps                          | 823           |\n|    iterations                   | 342           |\n|    time_elapsed                 | 1660          |\n|    total_timesteps              | 1368000       |\n| train/                          |               |\n|    approx_kl                    | 0.00065781863 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.22         |\n|    explained_variance           | 0.547         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 12.9          |\n|    n_updates                    | 682           |\n|    policy_gradient_loss         | -0.00121      |\n|    value_loss                   | 29.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 174           |\n|    ice_dug                      | 4             |\n|    water_produced               | 0.75          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 7.12         |\n| time/                           |              |\n|    fps                          | 824          |\n|    iterations                   | 343          |\n|    time_elapsed                 | 1664         |\n|    total_timesteps              | 1372000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011751932 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.3         |\n|    explained_variance           | 0.753        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 0.363        |\n|    n_updates                    | 684          |\n|    policy_gradient_loss         | -6.03e-05    |\n|    value_loss                   | 0.897        |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 15           |\n|    water_produced               | 1.5          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 7.11       |\n| time/                           |            |\n|    fps                          | 824        |\n|    iterations                   | 344        |\n|    time_elapsed                 | 1669       |\n|    total_timesteps              | 1376000    |\n| train/                          |            |\n|    approx_kl                    | 0.00062722 |\n|    clip_fraction                | 0          |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -2.28      |\n|    explained_variance           | 0.51       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 1.68       |\n|    n_updates                    | 686        |\n|    policy_gradient_loss         | 0.000408   |\n|    value_loss                   | 2.47       |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 150        |\n|    action_queue_updates_total   | 172        |\n|    ice_dug                      | 4          |\n|    water_produced               | 0.75       |\n------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 3.44          |\n| time/                           |               |\n|    fps                          | 824           |\n|    iterations                   | 345           |\n|    time_elapsed                 | 1673          |\n|    total_timesteps              | 1380000       |\n| train/                          |               |\n|    approx_kl                    | 0.00057513604 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.29         |\n|    explained_variance           | 0.758         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.232         |\n|    n_updates                    | 688           |\n|    policy_gradient_loss         | 0.00033       |\n|    value_loss                   | 0.693         |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 160           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 11            |\n|    water_produced               | 1             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 2.13          |\n| time/                           |               |\n|    fps                          | 824           |\n|    iterations                   | 346           |\n|    time_elapsed                 | 1678          |\n|    total_timesteps              | 1384000       |\n| train/                          |               |\n|    approx_kl                    | 0.00044133878 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.29         |\n|    explained_variance           | 0.638         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 0.76          |\n|    n_updates                    | 690           |\n|    policy_gradient_loss         | 0.000335      |\n|    value_loss                   | 1.4           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 160           |\n|    action_queue_updates_total   | 173           |\n|    ice_dug                      | 32            |\n|    water_produced               | 6             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 2             |\n| time/                           |               |\n|    fps                          | 824           |\n|    iterations                   | 347           |\n|    time_elapsed                 | 1682          |\n|    total_timesteps              | 1388000       |\n| train/                          |               |\n|    approx_kl                    | 0.00040451757 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.29         |\n|    explained_variance           | 0.724         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 3.55          |\n|    n_updates                    | 692           |\n|    policy_gradient_loss         | -0.00046      |\n|    value_loss                   | 7.14          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 161           |\n|    action_queue_updates_total   | 177           |\n|    ice_dug                      | 13            |\n|    water_produced               | 0             |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 2.39          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 348           |\n|    time_elapsed                 | 1686          |\n|    total_timesteps              | 1392000       |\n| train/                          |               |\n|    approx_kl                    | 0.00014301736 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.32         |\n|    explained_variance           | 0.635         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 2             |\n|    n_updates                    | 694           |\n|    policy_gradient_loss         | -0.000138     |\n|    value_loss                   | 2.84          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 173           |\n|    ice_dug                      | 37            |\n|    water_produced               | 3.25          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 3.02          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 349           |\n|    time_elapsed                 | 1691          |\n|    total_timesteps              | 1396000       |\n| train/                          |               |\n|    approx_kl                    | 0.00038259962 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.28         |\n|    explained_variance           | 0.633         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 2.54          |\n|    n_updates                    | 696           |\n|    policy_gradient_loss         | -0.00137      |\n|    value_loss                   | 6.75          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 173           |\n|    ice_dug                      | 40            |\n|    water_produced               | 3.5           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 4.15          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 350           |\n|    time_elapsed                 | 1695          |\n|    total_timesteps              | 1400000       |\n| train/                          |               |\n|    approx_kl                    | 0.00021880404 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.24         |\n|    explained_variance           | 0.683         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.58          |\n|    n_updates                    | 698           |\n|    policy_gradient_loss         | -0.000548     |\n|    value_loss                   | 9.2           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 158           |\n|    action_queue_updates_total   | 176           |\n|    ice_dug                      | 29            |\n|    water_produced               | 6.5           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 6.19          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 351           |\n|    time_elapsed                 | 1700          |\n|    total_timesteps              | 1404000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025216496 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.25         |\n|    explained_variance           | 0.586         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 6.37          |\n|    n_updates                    | 700           |\n|    policy_gradient_loss         | -0.000681     |\n|    value_loss                   | 18.8          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 159           |\n|    action_queue_updates_total   | 173           |\n|    ice_dug                      | 74            |\n|    water_produced               | 15.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 11.2         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 352          |\n|    time_elapsed                 | 1704         |\n|    total_timesteps              | 1408000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010115396 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.23        |\n|    explained_variance           | 0.577        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 17.8         |\n|    n_updates                    | 702          |\n|    policy_gradient_loss         | -0.000462    |\n|    value_loss                   | 49.6         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 114          |\n|    water_produced               | 24           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 16.3          |\n| time/                           |               |\n|    fps                          | 826           |\n|    iterations                   | 353           |\n|    time_elapsed                 | 1709          |\n|    total_timesteps              | 1412000       |\n| train/                          |               |\n|    approx_kl                    | 0.00075706496 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -2.14         |\n|    explained_variance           | 0.49          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 69.6          |\n|    n_updates                    | 704           |\n|    policy_gradient_loss         | -2.89e-05     |\n|    value_loss                   | 94.5          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 169           |\n|    ice_dug                      | 170           |\n|    water_produced               | 27.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 23.7         |\n| time/                           |              |\n|    fps                          | 826          |\n|    iterations                   | 354          |\n|    time_elapsed                 | 1713         |\n|    total_timesteps              | 1416000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032165137 |\n|    clip_fraction                | 0.0149       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -2.09        |\n|    explained_variance           | 0.565        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 34.9         |\n|    n_updates                    | 706          |\n|    policy_gradient_loss         | -0.000829    |\n|    value_loss                   | 79.1         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 225          |\n|    water_produced               | 38.8         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 28.4        |\n| time/                           |             |\n|    fps                          | 826         |\n|    iterations                   | 355         |\n|    time_elapsed                 | 1717        |\n|    total_timesteps              | 1420000     |\n| train/                          |             |\n|    approx_kl                    | 0.005030956 |\n|    clip_fraction                | 0.0268      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.96       |\n|    explained_variance           | 0.577       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 38.1        |\n|    n_updates                    | 708         |\n|    policy_gradient_loss         | -0.00144    |\n|    value_loss                   | 72.9        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 147         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 206         |\n|    water_produced               | 28.2        |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 42.2        |\n| time/                           |             |\n|    fps                          | 826         |\n|    iterations                   | 356         |\n|    time_elapsed                 | 1721        |\n|    total_timesteps              | 1424000     |\n| train/                          |             |\n|    approx_kl                    | 0.004134828 |\n|    clip_fraction                | 0.0155      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.93       |\n|    explained_variance           | 0.592       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 48.7        |\n|    n_updates                    | 710         |\n|    policy_gradient_loss         | -0.000834   |\n|    value_loss                   | 73.2        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 412         |\n|    water_produced               | 81.2        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 46.9         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 357          |\n|    time_elapsed                 | 1726         |\n|    total_timesteps              | 1428000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011539629 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.83        |\n|    explained_variance           | 0.524        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 126          |\n|    n_updates                    | 712          |\n|    policy_gradient_loss         | -0.000592    |\n|    value_loss                   | 331          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 253          |\n|    water_produced               | 46           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 49           |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 358          |\n|    time_elapsed                 | 1731         |\n|    total_timesteps              | 1432000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038175047 |\n|    clip_fraction                | 0.0161       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.69        |\n|    explained_variance           | 0.502        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 102          |\n|    n_updates                    | 714          |\n|    policy_gradient_loss         | -0.00116     |\n|    value_loss                   | 161          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 132          |\n|    action_queue_updates_total   | 142          |\n|    ice_dug                      | 285          |\n|    water_produced               | 37           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 49.8          |\n| time/                           |               |\n|    fps                          | 827           |\n|    iterations                   | 359           |\n|    time_elapsed                 | 1736          |\n|    total_timesteps              | 1436000       |\n| train/                          |               |\n|    approx_kl                    | 0.00055099506 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.59         |\n|    explained_variance           | 0.555         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 65.4          |\n|    n_updates                    | 716           |\n|    policy_gradient_loss         | -0.000637     |\n|    value_loss                   | 106           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 143           |\n|    ice_dug                      | 209           |\n|    water_produced               | 42.7          |\n---------------------------------------------------\nEval num_timesteps=1440000, episode_reward=100.96 +/- 131.28\nEpisode length: 398.00 +/- 126.24\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 398         |\n|    mean_reward                  | 101         |\n| time/                           |             |\n|    total_timesteps              | 1440000     |\n| train/                          |             |\n|    approx_kl                    | 0.001383229 |\n|    clip_fraction                | 0.00075     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.6        |\n|    explained_variance           | 0.518       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 44.7        |\n|    n_updates                    | 718         |\n|    policy_gradient_loss         | -0.000926   |\n|    value_loss                   | 101         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 141         |\n|    action_queue_updates_total   | 151         |\n|    ice_dug                      | 185         |\n|    water_produced               | 30.8        |\n-------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 50.2     |\n| time/              |          |\n|    fps             | 826      |\n|    iterations      | 360      |\n|    time_elapsed    | 1743     |\n|    total_timesteps | 1440000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 51.2          |\n| time/                           |               |\n|    fps                          | 826           |\n|    iterations                   | 361           |\n|    time_elapsed                 | 1747          |\n|    total_timesteps              | 1444000       |\n| train/                          |               |\n|    approx_kl                    | 0.00087729207 |\n|    clip_fraction                | 0.00363       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.76         |\n|    explained_variance           | 0.538         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 51            |\n|    n_updates                    | 720           |\n|    policy_gradient_loss         | -0.000333     |\n|    value_loss                   | 92.6          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 411           |\n|    water_produced               | 86.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 55.3         |\n| time/                           |              |\n|    fps                          | 826          |\n|    iterations                   | 362          |\n|    time_elapsed                 | 1752         |\n|    total_timesteps              | 1448000      |\n| train/                          |              |\n|    approx_kl                    | 0.0047625764 |\n|    clip_fraction                | 0.0252       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.66        |\n|    explained_variance           | 0.536        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 138          |\n|    n_updates                    | 722          |\n|    policy_gradient_loss         | 0.000488     |\n|    value_loss                   | 244          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 338          |\n|    water_produced               | 65.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 60.7         |\n| time/                           |              |\n|    fps                          | 826          |\n|    iterations                   | 363          |\n|    time_elapsed                 | 1756         |\n|    total_timesteps              | 1452000      |\n| train/                          |              |\n|    approx_kl                    | 0.0066222725 |\n|    clip_fraction                | 0.0409       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.65        |\n|    explained_variance           | 0.467        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 130          |\n|    n_updates                    | 724          |\n|    policy_gradient_loss         | -0.000971    |\n|    value_loss                   | 239          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 123          |\n|    action_queue_updates_total   | 127          |\n|    ice_dug                      | 289          |\n|    water_produced               | 64           |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 68.9        |\n| time/                           |             |\n|    fps                          | 826         |\n|    iterations                   | 364         |\n|    time_elapsed                 | 1761        |\n|    total_timesteps              | 1456000     |\n| train/                          |             |\n|    approx_kl                    | 0.001119815 |\n|    clip_fraction                | 0.000625    |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.3        |\n|    explained_variance           | 0.451       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 108         |\n|    n_updates                    | 726         |\n|    policy_gradient_loss         | 0.000359    |\n|    value_loss                   | 207         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 137         |\n|    action_queue_updates_total   | 148         |\n|    ice_dug                      | 459         |\n|    water_produced               | 81.3        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 74.4         |\n| time/                           |              |\n|    fps                          | 826          |\n|    iterations                   | 365          |\n|    time_elapsed                 | 1766         |\n|    total_timesteps              | 1460000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010913487 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.45        |\n|    explained_variance           | 0.431        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 162          |\n|    n_updates                    | 728          |\n|    policy_gradient_loss         | -0.000715    |\n|    value_loss                   | 307          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 118          |\n|    action_queue_updates_total   | 128          |\n|    ice_dug                      | 255          |\n|    water_produced               | 57.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 62.1         |\n| time/                           |              |\n|    fps                          | 826          |\n|    iterations                   | 366          |\n|    time_elapsed                 | 1770         |\n|    total_timesteps              | 1464000      |\n| train/                          |              |\n|    approx_kl                    | 0.0001394096 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.29        |\n|    explained_variance           | 0.447        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 76.5         |\n|    n_updates                    | 730          |\n|    policy_gradient_loss         | -0.000304    |\n|    value_loss                   | 189          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 123          |\n|    action_queue_updates_total   | 127          |\n|    ice_dug                      | 129          |\n|    water_produced               | 27.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 65.5         |\n| time/                           |              |\n|    fps                          | 826          |\n|    iterations                   | 367          |\n|    time_elapsed                 | 1775         |\n|    total_timesteps              | 1468000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029549673 |\n|    clip_fraction                | 0.0136       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.37        |\n|    explained_variance           | 0.421        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 67.7         |\n|    n_updates                    | 732          |\n|    policy_gradient_loss         | -0.000472    |\n|    value_loss                   | 123          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 416          |\n|    water_produced               | 81.8         |\n--------------------------------------------------\n----------------------------------------------------\n| rollout/                        |                |\n|    ep_len_mean                  | 200            |\n|    ep_rew_mean                  | 68.5           |\n| time/                           |                |\n|    fps                          | 826            |\n|    iterations                   | 368            |\n|    time_elapsed                 | 1780           |\n|    total_timesteps              | 1472000        |\n| train/                          |                |\n|    approx_kl                    | 0.000114817034 |\n|    clip_fraction                | 0              |\n|    clip_range                   | 0.2            |\n|    entropy_loss                 | -1.47          |\n|    explained_variance           | 0.48           |\n|    learning_rate                | 0.0003         |\n|    loss                         | 127            |\n|    n_updates                    | 734            |\n|    policy_gradient_loss         | -9.22e-05      |\n|    value_loss                   | 289            |\n| train_metrics/                  |                |\n|    action_queue_updates_success | 133            |\n|    action_queue_updates_total   | 140            |\n|    ice_dug                      | 397            |\n|    water_produced               | 77.5           |\n----------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 65.7        |\n| time/                           |             |\n|    fps                          | 826         |\n|    iterations                   | 369         |\n|    time_elapsed                 | 1784        |\n|    total_timesteps              | 1476000     |\n| train/                          |             |\n|    approx_kl                    | 0.002678215 |\n|    clip_fraction                | 0.00625     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.4        |\n|    explained_variance           | 0.473       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 94.7        |\n|    n_updates                    | 736         |\n|    policy_gradient_loss         | 2.16e-06    |\n|    value_loss                   | 224         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 129         |\n|    action_queue_updates_total   | 143         |\n|    ice_dug                      | 327         |\n|    water_produced               | 68.8        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 67.5         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 370          |\n|    time_elapsed                 | 1789         |\n|    total_timesteps              | 1480000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002475088 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.45        |\n|    explained_variance           | 0.472        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 71.7         |\n|    n_updates                    | 738          |\n|    policy_gradient_loss         | 0.000381     |\n|    value_loss                   | 208          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 125          |\n|    action_queue_updates_total   | 133          |\n|    ice_dug                      | 401          |\n|    water_produced               | 65.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 70.7          |\n| time/                           |               |\n|    fps                          | 827           |\n|    iterations                   | 371           |\n|    time_elapsed                 | 1793          |\n|    total_timesteps              | 1484000       |\n| train/                          |               |\n|    approx_kl                    | 0.00083621533 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.28         |\n|    explained_variance           | 0.462         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 89.1          |\n|    n_updates                    | 740           |\n|    policy_gradient_loss         | -0.00068      |\n|    value_loss                   | 185           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 123           |\n|    action_queue_updates_total   | 127           |\n|    ice_dug                      | 189           |\n|    water_produced               | 43            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 62.4         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 372          |\n|    time_elapsed                 | 1798         |\n|    total_timesteps              | 1488000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011812802 |\n|    clip_fraction                | 0.00675      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.3         |\n|    explained_variance           | 0.424        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 62.7         |\n|    n_updates                    | 742          |\n|    policy_gradient_loss         | -0.000737    |\n|    value_loss                   | 145          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 139          |\n|    ice_dug                      | 248          |\n|    water_produced               | 41.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 55.3         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 373          |\n|    time_elapsed                 | 1803         |\n|    total_timesteps              | 1492000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007848259 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.41        |\n|    explained_variance           | 0.477        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 48           |\n|    n_updates                    | 744          |\n|    policy_gradient_loss         | -0.000524    |\n|    value_loss                   | 134          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 142          |\n|    ice_dug                      | 233          |\n|    water_produced               | 44           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 47.5         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 374          |\n|    time_elapsed                 | 1808         |\n|    total_timesteps              | 1496000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015707914 |\n|    clip_fraction                | 0.00288      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.45        |\n|    explained_variance           | 0.453        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 69.8         |\n|    n_updates                    | 746          |\n|    policy_gradient_loss         | -0.000135    |\n|    value_loss                   | 158          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 137          |\n|    water_produced               | 31.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 53.1         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 375          |\n|    time_elapsed                 | 1813         |\n|    total_timesteps              | 1500000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036763034 |\n|    clip_fraction                | 0.0166       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.67        |\n|    explained_variance           | 0.51         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 42.8         |\n|    n_updates                    | 748          |\n|    policy_gradient_loss         | -0.000443    |\n|    value_loss                   | 82.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 394          |\n|    water_produced               | 93.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 55.1         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 376          |\n|    time_elapsed                 | 1817         |\n|    total_timesteps              | 1504000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007597172 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.51        |\n|    explained_variance           | 0.516        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 135          |\n|    n_updates                    | 750          |\n|    policy_gradient_loss         | -0.000129    |\n|    value_loss                   | 250          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 422          |\n|    water_produced               | 50.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 48.9         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 377          |\n|    time_elapsed                 | 1822         |\n|    total_timesteps              | 1508000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015540597 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.56        |\n|    explained_variance           | 0.497        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 70.1         |\n|    n_updates                    | 752          |\n|    policy_gradient_loss         | -0.000361    |\n|    value_loss                   | 152          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 65           |\n|    water_produced               | 12.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 51.8         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 378          |\n|    time_elapsed                 | 1827         |\n|    total_timesteps              | 1512000      |\n| train/                          |              |\n|    approx_kl                    | 0.0051081693 |\n|    clip_fraction                | 0.0294       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.67        |\n|    explained_variance           | 0.584        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 12.6         |\n|    n_updates                    | 754          |\n|    policy_gradient_loss         | 0.000933     |\n|    value_loss                   | 27.5         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 330          |\n|    water_produced               | 57.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 63            |\n| time/                           |               |\n|    fps                          | 827           |\n|    iterations                   | 379           |\n|    time_elapsed                 | 1832          |\n|    total_timesteps              | 1516000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017399379 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.61         |\n|    explained_variance           | 0.535         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 89.7          |\n|    n_updates                    | 756           |\n|    policy_gradient_loss         | -0.000171     |\n|    value_loss                   | 179           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 139           |\n|    ice_dug                      | 390           |\n|    water_produced               | 84.2          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 60.9        |\n| time/                           |             |\n|    fps                          | 827         |\n|    iterations                   | 380         |\n|    time_elapsed                 | 1836        |\n|    total_timesteps              | 1520000     |\n| train/                          |             |\n|    approx_kl                    | 0.004943449 |\n|    clip_fraction                | 0.0246      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.35       |\n|    explained_variance           | 0.47        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 99.5        |\n|    n_updates                    | 758         |\n|    policy_gradient_loss         | 0.00129     |\n|    value_loss                   | 230         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 129         |\n|    action_queue_updates_total   | 136         |\n|    ice_dug                      | 465         |\n|    water_produced               | 82.8        |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 50.8        |\n| time/                           |             |\n|    fps                          | 827         |\n|    iterations                   | 381         |\n|    time_elapsed                 | 1841        |\n|    total_timesteps              | 1524000     |\n| train/                          |             |\n|    approx_kl                    | 0.002567702 |\n|    clip_fraction                | 0.00988     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.32       |\n|    explained_variance           | 0.486       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 115         |\n|    n_updates                    | 760         |\n|    policy_gradient_loss         | -0.000433   |\n|    value_loss                   | 229         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 127         |\n|    action_queue_updates_total   | 137         |\n|    ice_dug                      | 17          |\n|    water_produced               | 4           |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 61.8         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 382          |\n|    time_elapsed                 | 1846         |\n|    total_timesteps              | 1528000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011406463 |\n|    clip_fraction                | 0.00412      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.5         |\n|    explained_variance           | 0.537        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 5.79         |\n|    n_updates                    | 762          |\n|    policy_gradient_loss         | -0.000714    |\n|    value_loss                   | 17.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 284          |\n|    water_produced               | 65.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 54.7         |\n| time/                           |              |\n|    fps                          | 827          |\n|    iterations                   | 383          |\n|    time_elapsed                 | 1850         |\n|    total_timesteps              | 1532000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014206026 |\n|    clip_fraction                | 0.0045       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.51        |\n|    explained_variance           | 0.453        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 109          |\n|    n_updates                    | 764          |\n|    policy_gradient_loss         | -0.000753    |\n|    value_loss                   | 254          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 102          |\n|    water_produced               | 24.7         |\n--------------------------------------------------\nEval num_timesteps=1536000, episode_reward=148.20 +/- 180.83\nEpisode length: 442.00 +/- 173.76\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 442          |\n|    mean_reward                  | 148          |\n| time/                           |              |\n|    total_timesteps              | 1536000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005775105 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.64        |\n|    explained_variance           | 0.522        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 34.6         |\n|    n_updates                    | 766          |\n|    policy_gradient_loss         | -0.000153    |\n|    value_loss                   | 69.7         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 172          |\n|    water_produced               | 42.8         |\n--------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 46       |\n| time/              |          |\n|    fps             | 825      |\n|    iterations      | 384      |\n|    time_elapsed    | 1861     |\n|    total_timesteps | 1536000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 35           |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 385          |\n|    time_elapsed                 | 1866         |\n|    total_timesteps              | 1540000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022543606 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.84        |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 57.2         |\n|    n_updates                    | 768          |\n|    policy_gradient_loss         | 0.00069      |\n|    value_loss                   | 117          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 267          |\n|    water_produced               | 29.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 46.6         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 386          |\n|    time_elapsed                 | 1871         |\n|    total_timesteps              | 1544000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012980937 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.76        |\n|    explained_variance           | 0.521        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 45.9         |\n|    n_updates                    | 770          |\n|    policy_gradient_loss         | 0.000118     |\n|    value_loss                   | 99.5         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 246          |\n|    water_produced               | 59.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 40.9         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 387          |\n|    time_elapsed                 | 1875         |\n|    total_timesteps              | 1548000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007145946 |\n|    clip_fraction                | 0.00175      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.8         |\n|    explained_variance           | 0.534        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 95.4         |\n|    n_updates                    | 772          |\n|    policy_gradient_loss         | 0.000478     |\n|    value_loss                   | 190          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 331          |\n|    water_produced               | 36.5         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 41.6        |\n| time/                           |             |\n|    fps                          | 825         |\n|    iterations                   | 388         |\n|    time_elapsed                 | 1880        |\n|    total_timesteps              | 1552000     |\n| train/                          |             |\n|    approx_kl                    | 0.001006267 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.84       |\n|    explained_variance           | 0.537       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 62.9        |\n|    n_updates                    | 774         |\n|    policy_gradient_loss         | 0.000207    |\n|    value_loss                   | 122         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 139         |\n|    action_queue_updates_total   | 144         |\n|    ice_dug                      | 158         |\n|    water_produced               | 27.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 43.3         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 389          |\n|    time_elapsed                 | 1885         |\n|    total_timesteps              | 1556000      |\n| train/                          |              |\n|    approx_kl                    | 0.0034312743 |\n|    clip_fraction                | 0.0119       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.63        |\n|    explained_variance           | 0.544        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 39.5         |\n|    n_updates                    | 776          |\n|    policy_gradient_loss         | -0.000533    |\n|    value_loss                   | 67.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 247          |\n|    water_produced               | 50.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 50.3          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 390           |\n|    time_elapsed                 | 1890          |\n|    total_timesteps              | 1560000       |\n| train/                          |               |\n|    approx_kl                    | 0.00073186384 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.72         |\n|    explained_variance           | 0.538         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 92.2          |\n|    n_updates                    | 778           |\n|    policy_gradient_loss         | 0.000255      |\n|    value_loss                   | 157           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 292           |\n|    water_produced               | 64.5          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 52.2        |\n| time/                           |             |\n|    fps                          | 825         |\n|    iterations                   | 391         |\n|    time_elapsed                 | 1895        |\n|    total_timesteps              | 1564000     |\n| train/                          |             |\n|    approx_kl                    | 0.002189424 |\n|    clip_fraction                | 0.00388     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.6        |\n|    explained_variance           | 0.566       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 103         |\n|    n_updates                    | 780         |\n|    policy_gradient_loss         | -0.000697   |\n|    value_loss                   | 177         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 154         |\n|    ice_dug                      | 326         |\n|    water_produced               | 68.2        |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 61.1        |\n| time/                           |             |\n|    fps                          | 825         |\n|    iterations                   | 392         |\n|    time_elapsed                 | 1900        |\n|    total_timesteps              | 1568000     |\n| train/                          |             |\n|    approx_kl                    | 0.001144874 |\n|    clip_fraction                | 0.000375    |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.64       |\n|    explained_variance           | 0.549       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 89.8        |\n|    n_updates                    | 782         |\n|    policy_gradient_loss         | -9.89e-05   |\n|    value_loss                   | 204         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 138         |\n|    action_queue_updates_total   | 145         |\n|    ice_dug                      | 439         |\n|    water_produced               | 80.3        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 61.7         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 393          |\n|    time_elapsed                 | 1905         |\n|    total_timesteps              | 1572000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023118933 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.48        |\n|    explained_variance           | 0.525        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 123          |\n|    n_updates                    | 784          |\n|    policy_gradient_loss         | -0.000882    |\n|    value_loss                   | 231          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 152          |\n|    water_produced               | 30.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 68.8          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 394           |\n|    time_elapsed                 | 1910          |\n|    total_timesteps              | 1576000       |\n| train/                          |               |\n|    approx_kl                    | 0.00097276305 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.61         |\n|    explained_variance           | 0.503         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 68.6          |\n|    n_updates                    | 786           |\n|    policy_gradient_loss         | -0.000294     |\n|    value_loss                   | 106           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 364           |\n|    water_produced               | 85            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 59.5         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 395          |\n|    time_elapsed                 | 1914         |\n|    total_timesteps              | 1580000      |\n| train/                          |              |\n|    approx_kl                    | 0.0001081898 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.63        |\n|    explained_variance           | 0.586        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 113          |\n|    n_updates                    | 788          |\n|    policy_gradient_loss         | -3e-05       |\n|    value_loss                   | 224          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 91           |\n|    water_produced               | 20.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 55.3          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 396           |\n|    time_elapsed                 | 1919          |\n|    total_timesteps              | 1584000       |\n| train/                          |               |\n|    approx_kl                    | 0.00019883896 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.65         |\n|    explained_variance           | 0.492         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 39.1          |\n|    n_updates                    | 790           |\n|    policy_gradient_loss         | 5.21e-05      |\n|    value_loss                   | 87.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 206           |\n|    water_produced               | 48            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 59.2         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 397          |\n|    time_elapsed                 | 1924         |\n|    total_timesteps              | 1588000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020753383 |\n|    clip_fraction                | 0.0045       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.67        |\n|    explained_variance           | 0.538        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 70.2         |\n|    n_updates                    | 792          |\n|    policy_gradient_loss         | 0.000274     |\n|    value_loss                   | 153          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 471          |\n|    water_produced               | 99.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 68.6         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 398          |\n|    time_elapsed                 | 1929         |\n|    total_timesteps              | 1592000      |\n| train/                          |              |\n|    approx_kl                    | 0.0043610996 |\n|    clip_fraction                | 0.0207       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.53        |\n|    explained_variance           | 0.548        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 141          |\n|    n_updates                    | 794          |\n|    policy_gradient_loss         | 0.00124      |\n|    value_loss                   | 286          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 315          |\n|    water_produced               | 75.7         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 64.5         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 399          |\n|    time_elapsed                 | 1934         |\n|    total_timesteps              | 1596000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007994406 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.47        |\n|    explained_variance           | 0.529        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 116          |\n|    n_updates                    | 796          |\n|    policy_gradient_loss         | -5.19e-05    |\n|    value_loss                   | 226          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 285          |\n|    water_produced               | 65.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 71.2          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 400           |\n|    time_elapsed                 | 1939          |\n|    total_timesteps              | 1600000       |\n| train/                          |               |\n|    approx_kl                    | 0.00010545462 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.57         |\n|    explained_variance           | 0.499         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 133           |\n|    n_updates                    | 798           |\n|    policy_gradient_loss         | -0.000163     |\n|    value_loss                   | 217           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 145           |\n|    ice_dug                      | 348           |\n|    water_produced               | 51.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 73.5          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 401           |\n|    time_elapsed                 | 1944          |\n|    total_timesteps              | 1604000       |\n| train/                          |               |\n|    approx_kl                    | 0.00010798282 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.51         |\n|    explained_variance           | 0.521         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 58            |\n|    n_updates                    | 800           |\n|    policy_gradient_loss         | -1.56e-05     |\n|    value_loss                   | 144           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 279           |\n|    water_produced               | 58.7          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 74.6          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 402           |\n|    time_elapsed                 | 1948          |\n|    total_timesteps              | 1608000       |\n| train/                          |               |\n|    approx_kl                    | 0.00044857958 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.54         |\n|    explained_variance           | 0.554         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 83.7          |\n|    n_updates                    | 802           |\n|    policy_gradient_loss         | 0.000212      |\n|    value_loss                   | 142           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 142           |\n|    ice_dug                      | 517           |\n|    water_produced               | 104           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 69           |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 403          |\n|    time_elapsed                 | 1953         |\n|    total_timesteps              | 1612000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042897267 |\n|    clip_fraction                | 0.0211       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.36        |\n|    explained_variance           | 0.471        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 150          |\n|    n_updates                    | 804          |\n|    policy_gradient_loss         | -0.000508    |\n|    value_loss                   | 309          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 274          |\n|    water_produced               | 48.2         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 66.5        |\n| time/                           |             |\n|    fps                          | 825         |\n|    iterations                   | 404         |\n|    time_elapsed                 | 1958        |\n|    total_timesteps              | 1616000     |\n| train/                          |             |\n|    approx_kl                    | 0.000497521 |\n|    clip_fraction                | 0.00075     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.46       |\n|    explained_variance           | 0.473       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 84.3        |\n|    n_updates                    | 806         |\n|    policy_gradient_loss         | -0.000273   |\n|    value_loss                   | 164         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 132         |\n|    action_queue_updates_total   | 139         |\n|    ice_dug                      | 253         |\n|    water_produced               | 53.5        |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 67.4        |\n| time/                           |             |\n|    fps                          | 825         |\n|    iterations                   | 405         |\n|    time_elapsed                 | 1962        |\n|    total_timesteps              | 1620000     |\n| train/                          |             |\n|    approx_kl                    | 0.003651478 |\n|    clip_fraction                | 0.0194      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.44       |\n|    explained_variance           | 0.476       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 69.6        |\n|    n_updates                    | 808         |\n|    policy_gradient_loss         | 5.27e-05    |\n|    value_loss                   | 153         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 140         |\n|    action_queue_updates_total   | 147         |\n|    ice_dug                      | 271         |\n|    water_produced               | 56.2        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 81.1          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 406           |\n|    time_elapsed                 | 1967          |\n|    total_timesteps              | 1624000       |\n| train/                          |               |\n|    approx_kl                    | 0.00018070725 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.52         |\n|    explained_variance           | 0.509         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 69.5          |\n|    n_updates                    | 810           |\n|    policy_gradient_loss         | -0.000265     |\n|    value_loss                   | 153           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 652           |\n|    water_produced               | 124           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 76.9          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 407           |\n|    time_elapsed                 | 1972          |\n|    total_timesteps              | 1628000       |\n| train/                          |               |\n|    approx_kl                    | 0.00078471424 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.48         |\n|    explained_variance           | 0.523         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 183           |\n|    n_updates                    | 812           |\n|    policy_gradient_loss         | -0.000334     |\n|    value_loss                   | 325           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 417           |\n|    water_produced               | 84            |\n---------------------------------------------------\nEval num_timesteps=1632000, episode_reward=133.24 +/- 205.73\nEpisode length: 428.00 +/- 197.52\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 428          |\n|    mean_reward                  | 133          |\n| time/                           |              |\n|    total_timesteps              | 1632000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036631408 |\n|    clip_fraction                | 0.0126       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.43        |\n|    explained_variance           | 0.518        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 111          |\n|    n_updates                    | 814          |\n|    policy_gradient_loss         | 0.00101      |\n|    value_loss                   | 217          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 138          |\n|    ice_dug                      | 141          |\n|    water_produced               | 21.8         |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 71.3     |\n| time/              |          |\n|    fps             | 824      |\n|    iterations      | 408      |\n|    time_elapsed    | 1980     |\n|    total_timesteps | 1632000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 72.6        |\n| time/                           |             |\n|    fps                          | 824         |\n|    iterations                   | 409         |\n|    time_elapsed                 | 1984        |\n|    total_timesteps              | 1636000     |\n| train/                          |             |\n|    approx_kl                    | 0.004190961 |\n|    clip_fraction                | 0.0254      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.38       |\n|    explained_variance           | 0.537       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 29.6        |\n|    n_updates                    | 816         |\n|    policy_gradient_loss         | -0.0011     |\n|    value_loss                   | 67.5        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 279         |\n|    water_produced               | 59.8        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 80.9          |\n| time/                           |               |\n|    fps                          | 824           |\n|    iterations                   | 410           |\n|    time_elapsed                 | 1989          |\n|    total_timesteps              | 1640000       |\n| train/                          |               |\n|    approx_kl                    | 0.00051521737 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.56         |\n|    explained_variance           | 0.546         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 95            |\n|    n_updates                    | 818           |\n|    policy_gradient_loss         | 9.86e-05      |\n|    value_loss                   | 182           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 457           |\n|    water_produced               | 96            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 63.5         |\n| time/                           |              |\n|    fps                          | 824          |\n|    iterations                   | 411          |\n|    time_elapsed                 | 1994         |\n|    total_timesteps              | 1644000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015219627 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.5         |\n|    explained_variance           | 0.52         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 151          |\n|    n_updates                    | 820          |\n|    policy_gradient_loss         | 0.000269     |\n|    value_loss                   | 287          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 188          |\n|    water_produced               | 41.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 60.7         |\n| time/                           |              |\n|    fps                          | 824          |\n|    iterations                   | 412          |\n|    time_elapsed                 | 1998         |\n|    total_timesteps              | 1648000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035028257 |\n|    clip_fraction                | 0.0134       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.57        |\n|    explained_variance           | 0.521        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 64.9         |\n|    n_updates                    | 822          |\n|    policy_gradient_loss         | 0.000154     |\n|    value_loss                   | 122          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 326          |\n|    water_produced               | 70.7         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 73.9          |\n| time/                           |               |\n|    fps                          | 824           |\n|    iterations                   | 413           |\n|    time_elapsed                 | 2003          |\n|    total_timesteps              | 1652000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025205294 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.65         |\n|    explained_variance           | 0.563         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 116           |\n|    n_updates                    | 824           |\n|    policy_gradient_loss         | 0.000153      |\n|    value_loss                   | 193           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 367           |\n|    water_produced               | 85.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 69.4          |\n| time/                           |               |\n|    fps                          | 824           |\n|    iterations                   | 414           |\n|    time_elapsed                 | 2007          |\n|    total_timesteps              | 1656000       |\n| train/                          |               |\n|    approx_kl                    | 0.00068352977 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.53         |\n|    explained_variance           | 0.582         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 99            |\n|    n_updates                    | 826           |\n|    policy_gradient_loss         | 0.000217      |\n|    value_loss                   | 218           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 134           |\n|    action_queue_updates_total   | 139           |\n|    ice_dug                      | 209           |\n|    water_produced               | 38            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 60.1          |\n| time/                           |               |\n|    fps                          | 824           |\n|    iterations                   | 415           |\n|    time_elapsed                 | 2012          |\n|    total_timesteps              | 1660000       |\n| train/                          |               |\n|    approx_kl                    | 0.00059676403 |\n|    clip_fraction                | 0.001         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.43         |\n|    explained_variance           | 0.545         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 48            |\n|    n_updates                    | 828           |\n|    policy_gradient_loss         | -7.39e-05     |\n|    value_loss                   | 97.9          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 144           |\n|    ice_dug                      | 301           |\n|    water_produced               | 51.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 69.8          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 416           |\n|    time_elapsed                 | 2016          |\n|    total_timesteps              | 1664000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035647216 |\n|    clip_fraction                | 0.001         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.47         |\n|    explained_variance           | 0.532         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 71.6          |\n|    n_updates                    | 830           |\n|    policy_gradient_loss         | -0.000322     |\n|    value_loss                   | 141           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 497           |\n|    water_produced               | 86.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 62.3         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 417          |\n|    time_elapsed                 | 2021         |\n|    total_timesteps              | 1668000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032437718 |\n|    clip_fraction                | 0.00762      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.59        |\n|    explained_variance           | 0.577        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 94.7         |\n|    n_updates                    | 832          |\n|    policy_gradient_loss         | -0.000675    |\n|    value_loss                   | 232          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 201          |\n|    water_produced               | 34.8         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 63.5        |\n| time/                           |             |\n|    fps                          | 825         |\n|    iterations                   | 418         |\n|    time_elapsed                 | 2026        |\n|    total_timesteps              | 1672000     |\n| train/                          |             |\n|    approx_kl                    | 0.001079922 |\n|    clip_fraction                | 0.00138     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.5        |\n|    explained_variance           | 0.577       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 44.2        |\n|    n_updates                    | 834         |\n|    policy_gradient_loss         | -0.00025    |\n|    value_loss                   | 107         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 138         |\n|    action_queue_updates_total   | 144         |\n|    ice_dug                      | 406         |\n|    water_produced               | 91          |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 68.9          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 419           |\n|    time_elapsed                 | 2031          |\n|    total_timesteps              | 1676000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015473705 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.41         |\n|    explained_variance           | 0.542         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 138           |\n|    n_updates                    | 836           |\n|    policy_gradient_loss         | -0.000189     |\n|    value_loss                   | 244           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 284           |\n|    water_produced               | 64.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 83.8          |\n| time/                           |               |\n|    fps                          | 824           |\n|    iterations                   | 420           |\n|    time_elapsed                 | 2036          |\n|    total_timesteps              | 1680000       |\n| train/                          |               |\n|    approx_kl                    | 0.00018151515 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.57         |\n|    explained_variance           | 0.562         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 104           |\n|    n_updates                    | 838           |\n|    policy_gradient_loss         | 0.000307      |\n|    value_loss                   | 188           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 606           |\n|    water_produced               | 123           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 75.1         |\n| time/                           |              |\n|    fps                          | 824          |\n|    iterations                   | 421          |\n|    time_elapsed                 | 2041         |\n|    total_timesteps              | 1684000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006172243 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.46        |\n|    explained_variance           | 0.521        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 166          |\n|    n_updates                    | 840          |\n|    policy_gradient_loss         | -0.000672    |\n|    value_loss                   | 362          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 260          |\n|    water_produced               | 45           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 81           |\n| time/                           |              |\n|    fps                          | 824          |\n|    iterations                   | 422          |\n|    time_elapsed                 | 2046         |\n|    total_timesteps              | 1688000      |\n| train/                          |              |\n|    approx_kl                    | 8.720688e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.47        |\n|    explained_variance           | 0.504        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 116          |\n|    n_updates                    | 842          |\n|    policy_gradient_loss         | 7.55e-05     |\n|    value_loss                   | 186          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 297          |\n|    water_produced               | 63.3         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 68.7         |\n| time/                           |              |\n|    fps                          | 824          |\n|    iterations                   | 423          |\n|    time_elapsed                 | 2051         |\n|    total_timesteps              | 1692000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012443729 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.55        |\n|    explained_variance           | 0.545        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 93.1         |\n|    n_updates                    | 844          |\n|    policy_gradient_loss         | -0.00114     |\n|    value_loss                   | 181          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 189          |\n|    water_produced               | 31.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 59.6         |\n| time/                           |              |\n|    fps                          | 824          |\n|    iterations                   | 424          |\n|    time_elapsed                 | 2056         |\n|    total_timesteps              | 1696000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010985421 |\n|    clip_fraction                | 0.00163      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.58        |\n|    explained_variance           | 0.556        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 49.9         |\n|    n_updates                    | 846          |\n|    policy_gradient_loss         | -0.00045     |\n|    value_loss                   | 99.3         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 184          |\n|    water_produced               | 19.7         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 66.8        |\n| time/                           |             |\n|    fps                          | 824         |\n|    iterations                   | 425         |\n|    time_elapsed                 | 2060        |\n|    total_timesteps              | 1700000     |\n| train/                          |             |\n|    approx_kl                    | 0.005727559 |\n|    clip_fraction                | 0.0261      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.7        |\n|    explained_variance           | 0.566       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 37.4        |\n|    n_updates                    | 848         |\n|    policy_gradient_loss         | 0.000242    |\n|    value_loss                   | 72.5        |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 682         |\n|    water_produced               | 158         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 73.8         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 426          |\n|    time_elapsed                 | 2064         |\n|    total_timesteps              | 1704000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020301088 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.49        |\n|    explained_variance           | 0.59         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 850          |\n|    policy_gradient_loss         | 0.000347     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 477          |\n|    water_produced               | 77.8         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 70.3        |\n| time/                           |             |\n|    fps                          | 825         |\n|    iterations                   | 427         |\n|    time_elapsed                 | 2069        |\n|    total_timesteps              | 1708000     |\n| train/                          |             |\n|    approx_kl                    | 0.004778543 |\n|    clip_fraction                | 0.0247      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.42       |\n|    explained_variance           | 0.538       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 109         |\n|    n_updates                    | 852         |\n|    policy_gradient_loss         | -0.000212   |\n|    value_loss                   | 197         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 140         |\n|    action_queue_updates_total   | 146         |\n|    ice_dug                      | 271         |\n|    water_produced               | 46          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 69.6         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 428          |\n|    time_elapsed                 | 2073         |\n|    total_timesteps              | 1712000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016137175 |\n|    clip_fraction                | 0.00563      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.45        |\n|    explained_variance           | 0.517        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 86.7         |\n|    n_updates                    | 854          |\n|    policy_gradient_loss         | -0.00033     |\n|    value_loss                   | 140          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 139          |\n|    ice_dug                      | 191          |\n|    water_produced               | 28.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 82.5         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 429          |\n|    time_elapsed                 | 2078         |\n|    total_timesteps              | 1716000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033905834 |\n|    clip_fraction                | 0.0171       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.54        |\n|    explained_variance           | 0.579        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 65.5         |\n|    n_updates                    | 856          |\n|    policy_gradient_loss         | 0.00019      |\n|    value_loss                   | 94.9         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 365          |\n|    water_produced               | 82.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 66           |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 430          |\n|    time_elapsed                 | 2082         |\n|    total_timesteps              | 1720000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014947278 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.58        |\n|    explained_variance           | 0.592        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 119          |\n|    n_updates                    | 858          |\n|    policy_gradient_loss         | 1.67e-06     |\n|    value_loss                   | 222          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 335          |\n|    water_produced               | 79.3         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 62.7         |\n| time/                           |              |\n|    fps                          | 826          |\n|    iterations                   | 431          |\n|    time_elapsed                 | 2087         |\n|    total_timesteps              | 1724000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007636421 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.49        |\n|    explained_variance           | 0.544        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 92.2         |\n|    n_updates                    | 860          |\n|    policy_gradient_loss         | 0.000152     |\n|    value_loss                   | 207          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 284          |\n|    water_produced               | 63           |\n--------------------------------------------------\nEval num_timesteps=1728000, episode_reward=69.88 +/- 83.42\nEpisode length: 367.00 +/- 81.08\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 367          |\n|    mean_reward                  | 69.9         |\n| time/                           |              |\n|    total_timesteps              | 1728000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004504029 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.53        |\n|    explained_variance           | 0.495        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 89.1         |\n|    n_updates                    | 862          |\n|    policy_gradient_loss         | -0.000301    |\n|    value_loss                   | 199          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 361          |\n|    water_produced               | 77           |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 69.1     |\n| time/              |          |\n|    fps             | 825      |\n|    iterations      | 432      |\n|    time_elapsed    | 2093     |\n|    total_timesteps | 1728000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 83.1         |\n| time/                           |              |\n|    fps                          | 825          |\n|    iterations                   | 433          |\n|    time_elapsed                 | 2097         |\n|    total_timesteps              | 1732000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013612735 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.46        |\n|    explained_variance           | 0.546        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 87.7         |\n|    n_updates                    | 864          |\n|    policy_gradient_loss         | 0.000347     |\n|    value_loss                   | 182          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 409          |\n|    water_produced               | 96.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 79.3          |\n| time/                           |               |\n|    fps                          | 825           |\n|    iterations                   | 434           |\n|    time_elapsed                 | 2102          |\n|    total_timesteps              | 1736000       |\n| train/                          |               |\n|    approx_kl                    | 0.00043552456 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.49         |\n|    explained_variance           | 0.539         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 146           |\n|    n_updates                    | 866           |\n|    policy_gradient_loss         | 0.000361      |\n|    value_loss                   | 276           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 282           |\n|    water_produced               | 64.3          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 81.1          |\n| time/                           |               |\n|    fps                          | 826           |\n|    iterations                   | 435           |\n|    time_elapsed                 | 2106          |\n|    total_timesteps              | 1740000       |\n| train/                          |               |\n|    approx_kl                    | 0.00030206534 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.48         |\n|    explained_variance           | 0.521         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 85.3          |\n|    n_updates                    | 868           |\n|    policy_gradient_loss         | 0.000212      |\n|    value_loss                   | 170           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 387           |\n|    water_produced               | 87.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 79.5          |\n| time/                           |               |\n|    fps                          | 826           |\n|    iterations                   | 436           |\n|    time_elapsed                 | 2110          |\n|    total_timesteps              | 1744000       |\n| train/                          |               |\n|    approx_kl                    | 0.00037216608 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.55         |\n|    explained_variance           | 0.54          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 121           |\n|    n_updates                    | 870           |\n|    policy_gradient_loss         | -3.02e-05     |\n|    value_loss                   | 260           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 257           |\n|    water_produced               | 55.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 82.9         |\n| time/                           |              |\n|    fps                          | 826          |\n|    iterations                   | 437          |\n|    time_elapsed                 | 2114         |\n|    total_timesteps              | 1748000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010058836 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.52        |\n|    explained_variance           | 0.545        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 81.2         |\n|    n_updates                    | 872          |\n|    policy_gradient_loss         | -0.000306    |\n|    value_loss                   | 171          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 525          |\n|    water_produced               | 92.3         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 77.2          |\n| time/                           |               |\n|    fps                          | 826           |\n|    iterations                   | 438           |\n|    time_elapsed                 | 2118          |\n|    total_timesteps              | 1752000       |\n| train/                          |               |\n|    approx_kl                    | 0.00043419338 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.48         |\n|    explained_variance           | 0.512         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 155           |\n|    n_updates                    | 874           |\n|    policy_gradient_loss         | 0.000169      |\n|    value_loss                   | 294           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 404           |\n|    water_produced               | 68            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 78.8          |\n| time/                           |               |\n|    fps                          | 827           |\n|    iterations                   | 439           |\n|    time_elapsed                 | 2122          |\n|    total_timesteps              | 1756000       |\n| train/                          |               |\n|    approx_kl                    | 0.00019644527 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.49         |\n|    explained_variance           | 0.524         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 114           |\n|    n_updates                    | 876           |\n|    policy_gradient_loss         | 0.000132      |\n|    value_loss                   | 227           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 367           |\n|    water_produced               | 71.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 76.7          |\n| time/                           |               |\n|    fps                          | 827           |\n|    iterations                   | 440           |\n|    time_elapsed                 | 2127          |\n|    total_timesteps              | 1760000       |\n| train/                          |               |\n|    approx_kl                    | 0.00020844644 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.45         |\n|    explained_variance           | 0.559         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 86.2          |\n|    n_updates                    | 878           |\n|    policy_gradient_loss         | -9.26e-05     |\n|    value_loss                   | 175           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 400           |\n|    water_produced               | 77            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 95.7          |\n| time/                           |               |\n|    fps                          | 827           |\n|    iterations                   | 441           |\n|    time_elapsed                 | 2131          |\n|    total_timesteps              | 1764000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032559113 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.42         |\n|    explained_variance           | 0.533         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 109           |\n|    n_updates                    | 880           |\n|    policy_gradient_loss         | -0.000255     |\n|    value_loss                   | 206           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 693           |\n|    water_produced               | 146           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 78.4        |\n| time/                           |             |\n|    fps                          | 827         |\n|    iterations                   | 442         |\n|    time_elapsed                 | 2135        |\n|    total_timesteps              | 1768000     |\n| train/                          |             |\n|    approx_kl                    | 0.002587312 |\n|    clip_fraction                | 0.00987     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.29       |\n|    explained_variance           | 0.539       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 187         |\n|    n_updates                    | 882         |\n|    policy_gradient_loss         | 0.000409    |\n|    value_loss                   | 379         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 138         |\n|    action_queue_updates_total   | 146         |\n|    ice_dug                      | 84          |\n|    water_produced               | 10.2        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 83.7          |\n| time/                           |               |\n|    fps                          | 828           |\n|    iterations                   | 443           |\n|    time_elapsed                 | 2139          |\n|    total_timesteps              | 1772000       |\n| train/                          |               |\n|    approx_kl                    | 0.00018191138 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.42         |\n|    explained_variance           | 0.668         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 24.5          |\n|    n_updates                    | 884           |\n|    policy_gradient_loss         | 0.000452      |\n|    value_loss                   | 55.1          |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 413           |\n|    water_produced               | 94            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 85           |\n| time/                           |              |\n|    fps                          | 828          |\n|    iterations                   | 444          |\n|    time_elapsed                 | 2143         |\n|    total_timesteps              | 1776000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009189613 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.4         |\n|    explained_variance           | 0.559        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 151          |\n|    n_updates                    | 886          |\n|    policy_gradient_loss         | -0.00119     |\n|    value_loss                   | 279          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 441          |\n|    water_produced               | 77.3         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 74.2         |\n| time/                           |              |\n|    fps                          | 828          |\n|    iterations                   | 445          |\n|    time_elapsed                 | 2148         |\n|    total_timesteps              | 1780000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018954424 |\n|    clip_fraction                | 0.00162      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.41        |\n|    explained_variance           | 0.515        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 111          |\n|    n_updates                    | 888          |\n|    policy_gradient_loss         | 0.000834     |\n|    value_loss                   | 211          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 144          |\n|    ice_dug                      | 119          |\n|    water_produced               | 26           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 67.3         |\n| time/                           |              |\n|    fps                          | 828          |\n|    iterations                   | 446          |\n|    time_elapsed                 | 2152         |\n|    total_timesteps              | 1784000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025546248 |\n|    clip_fraction                | 0.0106       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.47        |\n|    explained_variance           | 0.576        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 31.9         |\n|    n_updates                    | 890          |\n|    policy_gradient_loss         | -0.0011      |\n|    value_loss                   | 73.2         |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 576          |\n|    water_produced               | 112          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 80.5          |\n| time/                           |               |\n|    fps                          | 829           |\n|    iterations                   | 447           |\n|    time_elapsed                 | 2156          |\n|    total_timesteps              | 1788000       |\n| train/                          |               |\n|    approx_kl                    | 0.00011663725 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.34         |\n|    explained_variance           | 0.483         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 153           |\n|    n_updates                    | 892           |\n|    policy_gradient_loss         | -0.000155     |\n|    value_loss                   | 334           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 412           |\n|    water_produced               | 73.3          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 76.2          |\n| time/                           |               |\n|    fps                          | 829           |\n|    iterations                   | 448           |\n|    time_elapsed                 | 2160          |\n|    total_timesteps              | 1792000       |\n| train/                          |               |\n|    approx_kl                    | 0.00039348943 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.47         |\n|    explained_variance           | 0.505         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 127           |\n|    n_updates                    | 894           |\n|    policy_gradient_loss         | 8.15e-05      |\n|    value_loss                   | 228           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 399           |\n|    water_produced               | 72.8          |\n---------------------------------------------------\n----------------------------------------------------\n| rollout/                        |                |\n|    ep_len_mean                  | 200            |\n|    ep_rew_mean                  | 76.9           |\n| time/                           |                |\n|    fps                          | 829            |\n|    iterations                   | 449            |\n|    time_elapsed                 | 2164           |\n|    total_timesteps              | 1796000        |\n| train/                          |                |\n|    approx_kl                    | 0.000120795776 |\n|    clip_fraction                | 0              |\n|    clip_range                   | 0.2            |\n|    entropy_loss                 | -1.5           |\n|    explained_variance           | 0.561          |\n|    learning_rate                | 0.0003         |\n|    loss                         | 105            |\n|    n_updates                    | 896            |\n|    policy_gradient_loss         | 0.00012        |\n|    value_loss                   | 193            |\n| train_metrics/                  |                |\n|    action_queue_updates_success | 146            |\n|    action_queue_updates_total   | 156            |\n|    ice_dug                      | 452            |\n|    water_produced               | 80.5           |\n----------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 82.1          |\n| time/                           |               |\n|    fps                          | 829           |\n|    iterations                   | 450           |\n|    time_elapsed                 | 2168          |\n|    total_timesteps              | 1800000       |\n| train/                          |               |\n|    approx_kl                    | 0.00026793292 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.43         |\n|    explained_variance           | 0.533         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 116           |\n|    n_updates                    | 898           |\n|    policy_gradient_loss         | 0.000474      |\n|    value_loss                   | 223           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 141           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 271           |\n|    water_produced               | 50.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 68           |\n| time/                           |              |\n|    fps                          | 830          |\n|    iterations                   | 451          |\n|    time_elapsed                 | 2173         |\n|    total_timesteps              | 1804000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036859326 |\n|    clip_fraction                | 0.0171       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.55        |\n|    explained_variance           | 0.631        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 67           |\n|    n_updates                    | 900          |\n|    policy_gradient_loss         | -0.000209    |\n|    value_loss                   | 179          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 324          |\n|    water_produced               | 44.3         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 64.3         |\n| time/                           |              |\n|    fps                          | 830          |\n|    iterations                   | 452          |\n|    time_elapsed                 | 2178         |\n|    total_timesteps              | 1808000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018166773 |\n|    clip_fraction                | 0.00225      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.51        |\n|    explained_variance           | 0.572        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 74.9         |\n|    n_updates                    | 902          |\n|    policy_gradient_loss         | 0.000275     |\n|    value_loss                   | 150          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 308          |\n|    water_produced               | 55.7         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 59.1          |\n| time/                           |               |\n|    fps                          | 830           |\n|    iterations                   | 453           |\n|    time_elapsed                 | 2182          |\n|    total_timesteps              | 1812000       |\n| train/                          |               |\n|    approx_kl                    | 0.00060997525 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.56         |\n|    explained_variance           | 0.489         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 75.4          |\n|    n_updates                    | 904           |\n|    policy_gradient_loss         | -2.32e-05     |\n|    value_loss                   | 146           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 350           |\n|    water_produced               | 47.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 57            |\n| time/                           |               |\n|    fps                          | 830           |\n|    iterations                   | 454           |\n|    time_elapsed                 | 2186          |\n|    total_timesteps              | 1816000       |\n| train/                          |               |\n|    approx_kl                    | 0.00084881595 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.62         |\n|    explained_variance           | 0.549         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 83.7          |\n|    n_updates                    | 906           |\n|    policy_gradient_loss         | 0.000132      |\n|    value_loss                   | 161           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 330           |\n|    water_produced               | 71.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 66.1          |\n| time/                           |               |\n|    fps                          | 830           |\n|    iterations                   | 455           |\n|    time_elapsed                 | 2190          |\n|    total_timesteps              | 1820000       |\n| train/                          |               |\n|    approx_kl                    | 0.00041178885 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.65         |\n|    explained_variance           | 0.665         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 87.2          |\n|    n_updates                    | 908           |\n|    policy_gradient_loss         | -0.000216     |\n|    value_loss                   | 191           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 499           |\n|    water_produced               | 94            |\n---------------------------------------------------\nEval num_timesteps=1824000, episode_reward=136.60 +/- 165.94\nEpisode length: 430.00 +/- 158.06\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 430          |\n|    mean_reward                  | 137          |\n| time/                           |              |\n|    total_timesteps              | 1824000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010346528 |\n|    clip_fraction                | 0.00175      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.6         |\n|    explained_variance           | 0.597        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 120          |\n|    n_updates                    | 910          |\n|    policy_gradient_loss         | 0.000347     |\n|    value_loss                   | 253          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 221          |\n|    water_produced               | 45.3         |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 66.1     |\n| time/              |          |\n|    fps             | 829      |\n|    iterations      | 456      |\n|    time_elapsed    | 2197     |\n|    total_timesteps | 1824000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 70.9          |\n| time/                           |               |\n|    fps                          | 830           |\n|    iterations                   | 457           |\n|    time_elapsed                 | 2202          |\n|    total_timesteps              | 1828000       |\n| train/                          |               |\n|    approx_kl                    | 0.00016431455 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.58         |\n|    explained_variance           | 0.555         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 57.1          |\n|    n_updates                    | 912           |\n|    policy_gradient_loss         | -0.000173     |\n|    value_loss                   | 121           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 147           |\n|    ice_dug                      | 385           |\n|    water_produced               | 79            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 71.1          |\n| time/                           |               |\n|    fps                          | 830           |\n|    iterations                   | 458           |\n|    time_elapsed                 | 2206          |\n|    total_timesteps              | 1832000       |\n| train/                          |               |\n|    approx_kl                    | 0.00034296457 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.45         |\n|    explained_variance           | 0.535         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 98.2          |\n|    n_updates                    | 914           |\n|    policy_gradient_loss         | -2.82e-05     |\n|    value_loss                   | 245           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 240           |\n|    water_produced               | 49.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 73.4         |\n| time/                           |              |\n|    fps                          | 830          |\n|    iterations                   | 459          |\n|    time_elapsed                 | 2210         |\n|    total_timesteps              | 1836000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005815922 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.52        |\n|    explained_variance           | 0.551        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 65.2         |\n|    n_updates                    | 916          |\n|    policy_gradient_loss         | -0.000518    |\n|    value_loss                   | 136          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 435          |\n|    water_produced               | 81.7         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 68           |\n| time/                           |              |\n|    fps                          | 830          |\n|    iterations                   | 460          |\n|    time_elapsed                 | 2215         |\n|    total_timesteps              | 1840000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011707498 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.47        |\n|    explained_variance           | 0.581        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 127          |\n|    n_updates                    | 918          |\n|    policy_gradient_loss         | -1.23e-05    |\n|    value_loss                   | 213          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 349          |\n|    water_produced               | 68.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 74.4          |\n| time/                           |               |\n|    fps                          | 830           |\n|    iterations                   | 461           |\n|    time_elapsed                 | 2219          |\n|    total_timesteps              | 1844000       |\n| train/                          |               |\n|    approx_kl                    | 0.00027483905 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.48         |\n|    explained_variance           | 0.533         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 114           |\n|    n_updates                    | 920           |\n|    policy_gradient_loss         | -0.000133     |\n|    value_loss                   | 223           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 384           |\n|    water_produced               | 76            |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 79.2        |\n| time/                           |             |\n|    fps                          | 831         |\n|    iterations                   | 462         |\n|    time_elapsed                 | 2223        |\n|    total_timesteps              | 1848000     |\n| train/                          |             |\n|    approx_kl                    | 0.000451012 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.54       |\n|    explained_variance           | 0.547       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 96.5        |\n|    n_updates                    | 922         |\n|    policy_gradient_loss         | -0.000174   |\n|    value_loss                   | 237         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 519         |\n|    water_produced               | 101         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 92          |\n| time/                           |             |\n|    fps                          | 831         |\n|    iterations                   | 463         |\n|    time_elapsed                 | 2227        |\n|    total_timesteps              | 1852000     |\n| train/                          |             |\n|    approx_kl                    | 0.001407727 |\n|    clip_fraction                | 0.00162     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.56       |\n|    explained_variance           | 0.558       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 128         |\n|    n_updates                    | 924         |\n|    policy_gradient_loss         | -0.000251   |\n|    value_loss                   | 262         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 584         |\n|    water_produced               | 110         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 86.3         |\n| time/                           |              |\n|    fps                          | 831          |\n|    iterations                   | 464          |\n|    time_elapsed                 | 2232         |\n|    total_timesteps              | 1856000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042222636 |\n|    clip_fraction                | 0.0174       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.48        |\n|    explained_variance           | 0.571        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 146          |\n|    n_updates                    | 926          |\n|    policy_gradient_loss         | 0.00146      |\n|    value_loss                   | 292          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 138          |\n|    ice_dug                      | 232          |\n|    water_produced               | 55.3         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 83.1         |\n| time/                           |              |\n|    fps                          | 831          |\n|    iterations                   | 465          |\n|    time_elapsed                 | 2236         |\n|    total_timesteps              | 1860000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011341423 |\n|    clip_fraction                | 0.00263      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.3         |\n|    explained_variance           | 0.473        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 65.1         |\n|    n_updates                    | 928          |\n|    policy_gradient_loss         | 0.000123     |\n|    value_loss                   | 150          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 144          |\n|    ice_dug                      | 279          |\n|    water_produced               | 53           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 85.1         |\n| time/                           |              |\n|    fps                          | 831          |\n|    iterations                   | 466          |\n|    time_elapsed                 | 2240         |\n|    total_timesteps              | 1864000      |\n| train/                          |              |\n|    approx_kl                    | 0.0064335777 |\n|    clip_fraction                | 0.0404       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.44        |\n|    explained_variance           | 0.522        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 99.3         |\n|    n_updates                    | 930          |\n|    policy_gradient_loss         | -7.53e-05    |\n|    value_loss                   | 164          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 422          |\n|    water_produced               | 85.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 72.2         |\n| time/                           |              |\n|    fps                          | 831          |\n|    iterations                   | 467          |\n|    time_elapsed                 | 2245         |\n|    total_timesteps              | 1868000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009797883 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.53        |\n|    explained_variance           | 0.629        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 113          |\n|    n_updates                    | 932          |\n|    policy_gradient_loss         | -0.000218    |\n|    value_loss                   | 222          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 183          |\n|    water_produced               | 40.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 61.5         |\n| time/                           |              |\n|    fps                          | 832          |\n|    iterations                   | 468          |\n|    time_elapsed                 | 2249         |\n|    total_timesteps              | 1872000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033152208 |\n|    clip_fraction                | 0.0155       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.53        |\n|    explained_variance           | 0.556        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 84.4         |\n|    n_updates                    | 934          |\n|    policy_gradient_loss         | 0.000314     |\n|    value_loss                   | 145          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 268          |\n|    water_produced               | 59.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 66.8         |\n| time/                           |              |\n|    fps                          | 832          |\n|    iterations                   | 469          |\n|    time_elapsed                 | 2253         |\n|    total_timesteps              | 1876000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009402173 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.7         |\n|    explained_variance           | 0.685        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 96.5         |\n|    n_updates                    | 936          |\n|    policy_gradient_loss         | -0.000678    |\n|    value_loss                   | 175          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 330          |\n|    water_produced               | 80.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 72.7          |\n| time/                           |               |\n|    fps                          | 832           |\n|    iterations                   | 470           |\n|    time_elapsed                 | 2258          |\n|    total_timesteps              | 1880000       |\n| train/                          |               |\n|    approx_kl                    | 0.00041009142 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.65         |\n|    explained_variance           | 0.613         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 115           |\n|    n_updates                    | 938           |\n|    policy_gradient_loss         | 9.32e-05      |\n|    value_loss                   | 241           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 440           |\n|    water_produced               | 81            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 64.8          |\n| time/                           |               |\n|    fps                          | 832           |\n|    iterations                   | 471           |\n|    time_elapsed                 | 2262          |\n|    total_timesteps              | 1884000       |\n| train/                          |               |\n|    approx_kl                    | 0.00075543846 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.71         |\n|    explained_variance           | 0.57          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 139           |\n|    n_updates                    | 940           |\n|    policy_gradient_loss         | 3.84e-06      |\n|    value_loss                   | 270           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 219           |\n|    water_produced               | 48            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 71.4          |\n| time/                           |               |\n|    fps                          | 832           |\n|    iterations                   | 472           |\n|    time_elapsed                 | 2266          |\n|    total_timesteps              | 1888000       |\n| train/                          |               |\n|    approx_kl                    | 0.00024510163 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.5          |\n|    explained_variance           | 0.527         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 74.1          |\n|    n_updates                    | 942           |\n|    policy_gradient_loss         | 2.64e-05      |\n|    value_loss                   | 146           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 158           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 453           |\n|    water_produced               | 70.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 70            |\n| time/                           |               |\n|    fps                          | 833           |\n|    iterations                   | 473           |\n|    time_elapsed                 | 2271          |\n|    total_timesteps              | 1892000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032139808 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.58         |\n|    explained_variance           | 0.562         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 95.4          |\n|    n_updates                    | 944           |\n|    policy_gradient_loss         | -8.95e-05     |\n|    value_loss                   | 209           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 277           |\n|    water_produced               | 52.7          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 70.6          |\n| time/                           |               |\n|    fps                          | 833           |\n|    iterations                   | 474           |\n|    time_elapsed                 | 2275          |\n|    total_timesteps              | 1896000       |\n| train/                          |               |\n|    approx_kl                    | 0.00019400133 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.61         |\n|    explained_variance           | 0.568         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 73.1          |\n|    n_updates                    | 946           |\n|    policy_gradient_loss         | 4.46e-05      |\n|    value_loss                   | 152           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 376           |\n|    water_produced               | 83            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 59.4          |\n| time/                           |               |\n|    fps                          | 833           |\n|    iterations                   | 475           |\n|    time_elapsed                 | 2279          |\n|    total_timesteps              | 1900000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017442036 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.5          |\n|    explained_variance           | 0.541         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 124           |\n|    n_updates                    | 948           |\n|    policy_gradient_loss         | 0.000144      |\n|    value_loss                   | 227           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 141           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 187           |\n|    water_produced               | 27.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 60.5          |\n| time/                           |               |\n|    fps                          | 833           |\n|    iterations                   | 476           |\n|    time_elapsed                 | 2284          |\n|    total_timesteps              | 1904000       |\n| train/                          |               |\n|    approx_kl                    | 0.00016221762 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.59         |\n|    explained_variance           | 0.573         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 51.2          |\n|    n_updates                    | 950           |\n|    policy_gradient_loss         | -4.32e-05     |\n|    value_loss                   | 111           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 310           |\n|    water_produced               | 52.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 64.4         |\n| time/                           |              |\n|    fps                          | 833          |\n|    iterations                   | 477          |\n|    time_elapsed                 | 2288         |\n|    total_timesteps              | 1908000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010714286 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.49        |\n|    explained_variance           | 0.538        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 87           |\n|    n_updates                    | 952          |\n|    policy_gradient_loss         | -0.000912    |\n|    value_loss                   | 190          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 434          |\n|    water_produced               | 90.2         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 63.1        |\n| time/                           |             |\n|    fps                          | 833         |\n|    iterations                   | 478         |\n|    time_elapsed                 | 2292        |\n|    total_timesteps              | 1912000     |\n| train/                          |             |\n|    approx_kl                    | 0.005110504 |\n|    clip_fraction                | 0.0207      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.57       |\n|    explained_variance           | 0.608       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 124         |\n|    n_updates                    | 954         |\n|    policy_gradient_loss         | 0.00151     |\n|    value_loss                   | 225         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 304         |\n|    water_produced               | 46          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 75           |\n| time/                           |              |\n|    fps                          | 834          |\n|    iterations                   | 479          |\n|    time_elapsed                 | 2296         |\n|    total_timesteps              | 1916000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016839042 |\n|    clip_fraction                | 0.00213      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.54        |\n|    explained_variance           | 0.547        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 70.8         |\n|    n_updates                    | 956          |\n|    policy_gradient_loss         | -0.00066     |\n|    value_loss                   | 146          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 615          |\n|    water_produced               | 140          |\n--------------------------------------------------\nEval num_timesteps=1920000, episode_reward=322.60 +/- 369.76\nEpisode length: 573.80 +/- 301.74\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 574         |\n|    mean_reward                  | 323         |\n| time/                           |             |\n|    total_timesteps              | 1920000     |\n| train/                          |             |\n|    approx_kl                    | 0.002281469 |\n|    clip_fraction                | 0.00512     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.41       |\n|    explained_variance           | 0.542       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 214         |\n|    n_updates                    | 958         |\n|    policy_gradient_loss         | -0.000138   |\n|    value_loss                   | 428         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 154         |\n|    ice_dug                      | 301         |\n|    water_produced               | 31          |\n-------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 76       |\n| time/              |          |\n|    fps             | 832      |\n|    iterations      | 480      |\n|    time_elapsed    | 2305     |\n|    total_timesteps | 1920000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 91.3         |\n| time/                           |              |\n|    fps                          | 833          |\n|    iterations                   | 481          |\n|    time_elapsed                 | 2309         |\n|    total_timesteps              | 1924000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002494093 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.46        |\n|    explained_variance           | 0.487        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 66.3         |\n|    n_updates                    | 960          |\n|    policy_gradient_loss         | 0.000605     |\n|    value_loss                   | 142          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 597          |\n|    water_produced               | 126          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 82.5          |\n| time/                           |               |\n|    fps                          | 833           |\n|    iterations                   | 482           |\n|    time_elapsed                 | 2313          |\n|    total_timesteps              | 1928000       |\n| train/                          |               |\n|    approx_kl                    | 0.00020361264 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.3          |\n|    explained_variance           | 0.54          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 161           |\n|    n_updates                    | 962           |\n|    policy_gradient_loss         | -0.000398     |\n|    value_loss                   | 347           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 369           |\n|    water_produced               | 47            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 83.5          |\n| time/                           |               |\n|    fps                          | 833           |\n|    iterations                   | 483           |\n|    time_elapsed                 | 2318          |\n|    total_timesteps              | 1932000       |\n| train/                          |               |\n|    approx_kl                    | 0.00012013786 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.39         |\n|    explained_variance           | 0.482         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 75.2          |\n|    n_updates                    | 964           |\n|    policy_gradient_loss         | -1.85e-05     |\n|    value_loss                   | 174           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 141           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 255           |\n|    water_produced               | 51.8          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 67.8        |\n| time/                           |             |\n|    fps                          | 833         |\n|    iterations                   | 484         |\n|    time_elapsed                 | 2322        |\n|    total_timesteps              | 1936000     |\n| train/                          |             |\n|    approx_kl                    | 0.006209714 |\n|    clip_fraction                | 0.0354      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.51       |\n|    explained_variance           | 0.578       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 95.3        |\n|    n_updates                    | 966         |\n|    policy_gradient_loss         | 0.000136    |\n|    value_loss                   | 184         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 352         |\n|    water_produced               | 64.5        |\n-------------------------------------------------\n----------------------------------------------------\n| rollout/                        |                |\n|    ep_len_mean                  | 200            |\n|    ep_rew_mean                  | 75.2           |\n| time/                           |                |\n|    fps                          | 833            |\n|    iterations                   | 485            |\n|    time_elapsed                 | 2326           |\n|    total_timesteps              | 1940000        |\n| train/                          |                |\n|    approx_kl                    | 0.000117454445 |\n|    clip_fraction                | 0              |\n|    clip_range                   | 0.2            |\n|    entropy_loss                 | -1.53          |\n|    explained_variance           | 0.604          |\n|    learning_rate                | 0.0003         |\n|    loss                         | 91.3           |\n|    n_updates                    | 968            |\n|    policy_gradient_loss         | 1.14e-05       |\n|    value_loss                   | 171            |\n| train_metrics/                  |                |\n|    action_queue_updates_success | 151            |\n|    action_queue_updates_total   | 159            |\n|    ice_dug                      | 404            |\n|    water_produced               | 66.7           |\n----------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 67.4          |\n| time/                           |               |\n|    fps                          | 833           |\n|    iterations                   | 486           |\n|    time_elapsed                 | 2330          |\n|    total_timesteps              | 1944000       |\n| train/                          |               |\n|    approx_kl                    | 0.00013222871 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.56         |\n|    explained_variance           | 0.578         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 82.5          |\n|    n_updates                    | 970           |\n|    policy_gradient_loss         | -5.87e-05     |\n|    value_loss                   | 198           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 156           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 422           |\n|    water_produced               | 89            |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 69.3        |\n| time/                           |             |\n|    fps                          | 834         |\n|    iterations                   | 487         |\n|    time_elapsed                 | 2335        |\n|    total_timesteps              | 1948000     |\n| train/                          |             |\n|    approx_kl                    | 0.001270597 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.61       |\n|    explained_variance           | 0.561       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 173         |\n|    n_updates                    | 972         |\n|    policy_gradient_loss         | -4.4e-05    |\n|    value_loss                   | 314         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 151         |\n|    ice_dug                      | 308         |\n|    water_produced               | 57          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 75.8         |\n| time/                           |              |\n|    fps                          | 834          |\n|    iterations                   | 488          |\n|    time_elapsed                 | 2339         |\n|    total_timesteps              | 1952000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021535524 |\n|    clip_fraction                | 0.005        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.43        |\n|    explained_variance           | 0.501        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 93.6         |\n|    n_updates                    | 974          |\n|    policy_gradient_loss         | 0.000245     |\n|    value_loss                   | 193          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 401          |\n|    water_produced               | 82.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 75.4         |\n| time/                           |              |\n|    fps                          | 834          |\n|    iterations                   | 489          |\n|    time_elapsed                 | 2344         |\n|    total_timesteps              | 1956000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014874988 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.46        |\n|    explained_variance           | 0.613        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 142          |\n|    n_updates                    | 976          |\n|    policy_gradient_loss         | 0.000148     |\n|    value_loss                   | 247          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 352          |\n|    water_produced               | 62.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 82.5          |\n| time/                           |               |\n|    fps                          | 834           |\n|    iterations                   | 490           |\n|    time_elapsed                 | 2348          |\n|    total_timesteps              | 1960000       |\n| train/                          |               |\n|    approx_kl                    | 0.00048441184 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.49         |\n|    explained_variance           | 0.55          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 93.7          |\n|    n_updates                    | 978           |\n|    policy_gradient_loss         | -0.000704     |\n|    value_loss                   | 186           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 501           |\n|    water_produced               | 102           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 81.8         |\n| time/                           |              |\n|    fps                          | 834          |\n|    iterations                   | 491          |\n|    time_elapsed                 | 2353         |\n|    total_timesteps              | 1964000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020809493 |\n|    clip_fraction                | 0.003        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.39        |\n|    explained_variance           | 0.526        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 980          |\n|    policy_gradient_loss         | -1.25e-05    |\n|    value_loss                   | 331          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 446          |\n|    water_produced               | 85           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 96.7          |\n| time/                           |               |\n|    fps                          | 834           |\n|    iterations                   | 492           |\n|    time_elapsed                 | 2357          |\n|    total_timesteps              | 1968000       |\n| train/                          |               |\n|    approx_kl                    | 0.00012971848 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.39         |\n|    explained_variance           | 0.521         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 115           |\n|    n_updates                    | 982           |\n|    policy_gradient_loss         | -0.000148     |\n|    value_loss                   | 240           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 655           |\n|    water_produced               | 128           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 91.7        |\n| time/                           |             |\n|    fps                          | 835         |\n|    iterations                   | 493         |\n|    time_elapsed                 | 2361        |\n|    total_timesteps              | 1972000     |\n| train/                          |             |\n|    approx_kl                    | 0.002349175 |\n|    clip_fraction                | 0.00438     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.29       |\n|    explained_variance           | 0.515       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 203         |\n|    n_updates                    | 984         |\n|    policy_gradient_loss         | 0.000811    |\n|    value_loss                   | 418         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 135         |\n|    action_queue_updates_total   | 149         |\n|    ice_dug                      | 386         |\n|    water_produced               | 58          |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 93.2          |\n| time/                           |               |\n|    fps                          | 835           |\n|    iterations                   | 494           |\n|    time_elapsed                 | 2366          |\n|    total_timesteps              | 1976000       |\n| train/                          |               |\n|    approx_kl                    | 0.00033763057 |\n|    clip_fraction                | 0.00138       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.36         |\n|    explained_variance           | 0.49          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 93.2          |\n|    n_updates                    | 986           |\n|    policy_gradient_loss         | -0.000396     |\n|    value_loss                   | 189           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 337           |\n|    water_produced               | 70.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 89.2         |\n| time/                           |              |\n|    fps                          | 835          |\n|    iterations                   | 495          |\n|    time_elapsed                 | 2370         |\n|    total_timesteps              | 1980000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018863238 |\n|    clip_fraction                | 0.00862      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.45        |\n|    explained_variance           | 0.562        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 116          |\n|    n_updates                    | 988          |\n|    policy_gradient_loss         | -0.00049     |\n|    value_loss                   | 218          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 405          |\n|    water_produced               | 82           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 90.8          |\n| time/                           |               |\n|    fps                          | 835           |\n|    iterations                   | 496           |\n|    time_elapsed                 | 2374          |\n|    total_timesteps              | 1984000       |\n| train/                          |               |\n|    approx_kl                    | 0.00091973227 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.51         |\n|    explained_variance           | 0.575         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 132           |\n|    n_updates                    | 990           |\n|    policy_gradient_loss         | -0.000174     |\n|    value_loss                   | 266           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 427           |\n|    water_produced               | 93.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 91.3          |\n| time/                           |               |\n|    fps                          | 835           |\n|    iterations                   | 497           |\n|    time_elapsed                 | 2378          |\n|    total_timesteps              | 1988000       |\n| train/                          |               |\n|    approx_kl                    | 0.00059180864 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.55         |\n|    explained_variance           | 0.65          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 162           |\n|    n_updates                    | 992           |\n|    policy_gradient_loss         | -5.65e-05     |\n|    value_loss                   | 310           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 611           |\n|    water_produced               | 131           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 105          |\n| time/                           |              |\n|    fps                          | 835          |\n|    iterations                   | 498          |\n|    time_elapsed                 | 2382         |\n|    total_timesteps              | 1992000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019997251 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.42        |\n|    explained_variance           | 0.548        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 197          |\n|    n_updates                    | 994          |\n|    policy_gradient_loss         | 0.000748     |\n|    value_loss                   | 413          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 600          |\n|    water_produced               | 123          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 107          |\n| time/                           |              |\n|    fps                          | 836          |\n|    iterations                   | 499          |\n|    time_elapsed                 | 2387         |\n|    total_timesteps              | 1996000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011542313 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.485        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 996          |\n|    policy_gradient_loss         | 0.00059      |\n|    value_loss                   | 399          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 131          |\n|    action_queue_updates_total   | 137          |\n|    ice_dug                      | 420          |\n|    water_produced               | 82.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 113          |\n| time/                           |              |\n|    fps                          | 836          |\n|    iterations                   | 500          |\n|    time_elapsed                 | 2391         |\n|    total_timesteps              | 2000000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016376562 |\n|    clip_fraction                | 0.00913      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.511        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 133          |\n|    n_updates                    | 998          |\n|    policy_gradient_loss         | -0.000878    |\n|    value_loss                   | 260          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 592          |\n|    water_produced               | 109          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 836          |\n|    iterations                   | 501          |\n|    time_elapsed                 | 2395         |\n|    total_timesteps              | 2004000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022981288 |\n|    clip_fraction                | 0.00375      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.503        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 155          |\n|    n_updates                    | 1000         |\n|    policy_gradient_loss         | 0.00119      |\n|    value_loss                   | 331          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 462          |\n|    water_produced               | 85           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 96.4          |\n| time/                           |               |\n|    fps                          | 836           |\n|    iterations                   | 502           |\n|    time_elapsed                 | 2399          |\n|    total_timesteps              | 2008000       |\n| train/                          |               |\n|    approx_kl                    | 0.00096342043 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.28         |\n|    explained_variance           | 0.505         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 108           |\n|    n_updates                    | 1002          |\n|    policy_gradient_loss         | -0.000682     |\n|    value_loss                   | 265           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 263           |\n|    water_produced               | 59.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 87.6         |\n| time/                           |              |\n|    fps                          | 836          |\n|    iterations                   | 503          |\n|    time_elapsed                 | 2404         |\n|    total_timesteps              | 2012000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030203653 |\n|    clip_fraction                | 0.0113       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.51        |\n|    explained_variance           | 0.56         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 99.1         |\n|    n_updates                    | 1004         |\n|    policy_gradient_loss         | 0.000325     |\n|    value_loss                   | 228          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 468          |\n|    water_produced               | 80.2         |\n--------------------------------------------------\nEval num_timesteps=2016000, episode_reward=127.64 +/- 237.87\nEpisode length: 421.00 +/- 230.07\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 421           |\n|    mean_reward                  | 128           |\n| time/                           |               |\n|    total_timesteps              | 2016000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017715296 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.47         |\n|    explained_variance           | 0.515         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 129           |\n|    n_updates                    | 1006          |\n|    policy_gradient_loss         | 0.000129      |\n|    value_loss                   | 271           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 363           |\n|    water_produced               | 80.7          |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 87.2     |\n| time/              |          |\n|    fps             | 835      |\n|    iterations      | 504      |\n|    time_elapsed    | 2413     |\n|    total_timesteps | 2016000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 86.5          |\n| time/                           |               |\n|    fps                          | 835           |\n|    iterations                   | 505           |\n|    time_elapsed                 | 2417          |\n|    total_timesteps              | 2020000       |\n| train/                          |               |\n|    approx_kl                    | 0.00047398676 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.48         |\n|    explained_variance           | 0.606         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 116           |\n|    n_updates                    | 1008          |\n|    policy_gradient_loss         | 4.73e-06      |\n|    value_loss                   | 212           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 141           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 492           |\n|    water_produced               | 106           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 82.9         |\n| time/                           |              |\n|    fps                          | 835          |\n|    iterations                   | 506          |\n|    time_elapsed                 | 2421         |\n|    total_timesteps              | 2024000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010132516 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.35        |\n|    explained_variance           | 0.512        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 1010         |\n|    policy_gradient_loss         | 0.000481     |\n|    value_loss                   | 333          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 336          |\n|    water_produced               | 68.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 86.4          |\n| time/                           |               |\n|    fps                          | 835           |\n|    iterations                   | 507           |\n|    time_elapsed                 | 2425          |\n|    total_timesteps              | 2028000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025853855 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.44         |\n|    explained_variance           | 0.616         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 98.2          |\n|    n_updates                    | 1012          |\n|    policy_gradient_loss         | 0.000296      |\n|    value_loss                   | 186           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 454           |\n|    water_produced               | 75.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 97.1          |\n| time/                           |               |\n|    fps                          | 836           |\n|    iterations                   | 508           |\n|    time_elapsed                 | 2430          |\n|    total_timesteps              | 2032000       |\n| train/                          |               |\n|    approx_kl                    | 5.0992025e-05 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.41         |\n|    explained_variance           | 0.503         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 109           |\n|    n_updates                    | 1014          |\n|    policy_gradient_loss         | -8.66e-05     |\n|    value_loss                   | 225           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 607           |\n|    water_produced               | 132           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 94.8         |\n| time/                           |              |\n|    fps                          | 836          |\n|    iterations                   | 509          |\n|    time_elapsed                 | 2434         |\n|    total_timesteps              | 2036000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014449267 |\n|    clip_fraction                | 0.00162      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.27        |\n|    explained_variance           | 0.546        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 204          |\n|    n_updates                    | 1016         |\n|    policy_gradient_loss         | 0.000626     |\n|    value_loss                   | 388          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 341          |\n|    water_produced               | 69.5         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 82.6        |\n| time/                           |             |\n|    fps                          | 836         |\n|    iterations                   | 510         |\n|    time_elapsed                 | 2438        |\n|    total_timesteps              | 2040000     |\n| train/                          |             |\n|    approx_kl                    | 0.000563179 |\n|    clip_fraction                | 0.00175     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.41       |\n|    explained_variance           | 0.56        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 91.9        |\n|    n_updates                    | 1018        |\n|    policy_gradient_loss         | -0.000967   |\n|    value_loss                   | 180         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 308         |\n|    water_produced               | 47          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 80.2         |\n| time/                           |              |\n|    fps                          | 836          |\n|    iterations                   | 511          |\n|    time_elapsed                 | 2442         |\n|    total_timesteps              | 2044000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022356354 |\n|    clip_fraction                | 0.0095       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.48        |\n|    explained_variance           | 0.53         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 87.2         |\n|    n_updates                    | 1020         |\n|    policy_gradient_loss         | -0.000551    |\n|    value_loss                   | 158          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 305          |\n|    water_produced               | 56.8         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 85.8        |\n| time/                           |             |\n|    fps                          | 836         |\n|    iterations                   | 512         |\n|    time_elapsed                 | 2447        |\n|    total_timesteps              | 2048000     |\n| train/                          |             |\n|    approx_kl                    | 0.001640199 |\n|    clip_fraction                | 0.000375    |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.6        |\n|    explained_variance           | 0.587       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 81.8        |\n|    n_updates                    | 1022        |\n|    policy_gradient_loss         | -0.000122   |\n|    value_loss                   | 141         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 532         |\n|    water_produced               | 103         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 64.8         |\n| time/                           |              |\n|    fps                          | 836          |\n|    iterations                   | 513          |\n|    time_elapsed                 | 2451         |\n|    total_timesteps              | 2052000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017202385 |\n|    clip_fraction                | 0.00213      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.5         |\n|    explained_variance           | 0.56         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 149          |\n|    n_updates                    | 1024         |\n|    policy_gradient_loss         | 0.000473     |\n|    value_loss                   | 299          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 187          |\n|    water_produced               | 31.8         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 68.8        |\n| time/                           |             |\n|    fps                          | 837         |\n|    iterations                   | 514         |\n|    time_elapsed                 | 2455        |\n|    total_timesteps              | 2056000     |\n| train/                          |             |\n|    approx_kl                    | 0.004675226 |\n|    clip_fraction                | 0.0211      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.52       |\n|    explained_variance           | 0.514       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 63.8        |\n|    n_updates                    | 1026        |\n|    policy_gradient_loss         | 1.96e-05    |\n|    value_loss                   | 110         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 378         |\n|    water_produced               | 89          |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 78.7          |\n| time/                           |               |\n|    fps                          | 837           |\n|    iterations                   | 515           |\n|    time_elapsed                 | 2460          |\n|    total_timesteps              | 2060000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046443223 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.65         |\n|    explained_variance           | 0.624         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 111           |\n|    n_updates                    | 1028          |\n|    policy_gradient_loss         | 0.000336      |\n|    value_loss                   | 218           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 457           |\n|    water_produced               | 95            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 87.6          |\n| time/                           |               |\n|    fps                          | 837           |\n|    iterations                   | 516           |\n|    time_elapsed                 | 2464          |\n|    total_timesteps              | 2064000       |\n| train/                          |               |\n|    approx_kl                    | 0.00080430566 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.49         |\n|    explained_variance           | 0.597         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 164           |\n|    n_updates                    | 1030          |\n|    policy_gradient_loss         | 0.000684      |\n|    value_loss                   | 317           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 657           |\n|    water_produced               | 97.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 78.3          |\n| time/                           |               |\n|    fps                          | 837           |\n|    iterations                   | 517           |\n|    time_elapsed                 | 2469          |\n|    total_timesteps              | 2068000       |\n| train/                          |               |\n|    approx_kl                    | 0.00056332315 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.39         |\n|    explained_variance           | 0.527         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 173           |\n|    n_updates                    | 1032          |\n|    policy_gradient_loss         | -0.000151     |\n|    value_loss                   | 377           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 268           |\n|    water_produced               | 58.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 96.4         |\n| time/                           |              |\n|    fps                          | 837          |\n|    iterations                   | 518          |\n|    time_elapsed                 | 2473         |\n|    total_timesteps              | 2072000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007371899 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.45        |\n|    explained_variance           | 0.626        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 87.4         |\n|    n_updates                    | 1034         |\n|    policy_gradient_loss         | -0.000288    |\n|    value_loss                   | 196          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 654          |\n|    water_produced               | 118          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 97.2         |\n| time/                           |              |\n|    fps                          | 838          |\n|    iterations                   | 519          |\n|    time_elapsed                 | 2477         |\n|    total_timesteps              | 2076000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007756191 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.35        |\n|    explained_variance           | 0.491        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 1036         |\n|    policy_gradient_loss         | -0.000139    |\n|    value_loss                   | 378          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 474          |\n|    water_produced               | 92.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 101           |\n| time/                           |               |\n|    fps                          | 838           |\n|    iterations                   | 520           |\n|    time_elapsed                 | 2481          |\n|    total_timesteps              | 2080000       |\n| train/                          |               |\n|    approx_kl                    | 0.00050476694 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.43         |\n|    explained_variance           | 0.661         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 129           |\n|    n_updates                    | 1038          |\n|    policy_gradient_loss         | 0.000379      |\n|    value_loss                   | 263           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 518           |\n|    water_produced               | 115           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 108           |\n| time/                           |               |\n|    fps                          | 838           |\n|    iterations                   | 521           |\n|    time_elapsed                 | 2485          |\n|    total_timesteps              | 2084000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032445806 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.35         |\n|    explained_variance           | 0.576         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 150           |\n|    n_updates                    | 1040          |\n|    policy_gradient_loss         | 4.08e-05      |\n|    value_loss                   | 330           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 606           |\n|    water_produced               | 130           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 120          |\n| time/                           |              |\n|    fps                          | 838          |\n|    iterations                   | 522          |\n|    time_elapsed                 | 2489         |\n|    total_timesteps              | 2088000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022084273 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.29        |\n|    explained_variance           | 0.551        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 170          |\n|    n_updates                    | 1042         |\n|    policy_gradient_loss         | -0.000463    |\n|    value_loss                   | 359          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 143          |\n|    ice_dug                      | 554          |\n|    water_produced               | 116          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 102           |\n| time/                           |               |\n|    fps                          | 838           |\n|    iterations                   | 523           |\n|    time_elapsed                 | 2494          |\n|    total_timesteps              | 2092000       |\n| train/                          |               |\n|    approx_kl                    | 0.00052849995 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.21         |\n|    explained_variance           | 0.479         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 158           |\n|    n_updates                    | 1044          |\n|    policy_gradient_loss         | -0.000231     |\n|    value_loss                   | 365           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 320           |\n|    water_produced               | 30            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 96.7         |\n| time/                           |              |\n|    fps                          | 838          |\n|    iterations                   | 524          |\n|    time_elapsed                 | 2498         |\n|    total_timesteps              | 2096000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031538096 |\n|    clip_fraction                | 0.0175       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.37        |\n|    explained_variance           | 0.338        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 95.6         |\n|    n_updates                    | 1046         |\n|    policy_gradient_loss         | -0.000563    |\n|    value_loss                   | 160          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 430          |\n|    water_produced               | 68           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 85           |\n| time/                           |              |\n|    fps                          | 839          |\n|    iterations                   | 525          |\n|    time_elapsed                 | 2502         |\n|    total_timesteps              | 2100000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025493987 |\n|    clip_fraction                | 0.00575      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.44        |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 125          |\n|    n_updates                    | 1048         |\n|    policy_gradient_loss         | -0.000754    |\n|    value_loss                   | 206          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 399          |\n|    water_produced               | 58.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 81.7         |\n| time/                           |              |\n|    fps                          | 839          |\n|    iterations                   | 526          |\n|    time_elapsed                 | 2507         |\n|    total_timesteps              | 2104000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009012078 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.44        |\n|    explained_variance           | 0.525        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 86.1         |\n|    n_updates                    | 1050         |\n|    policy_gradient_loss         | -0.000511    |\n|    value_loss                   | 192          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 487          |\n|    water_produced               | 115          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 74.2        |\n| time/                           |             |\n|    fps                          | 839         |\n|    iterations                   | 527         |\n|    time_elapsed                 | 2511        |\n|    total_timesteps              | 2108000     |\n| train/                          |             |\n|    approx_kl                    | 0.001159047 |\n|    clip_fraction                | 0.000875    |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.49       |\n|    explained_variance           | 0.615       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 146         |\n|    n_updates                    | 1052        |\n|    policy_gradient_loss         | 0.000464    |\n|    value_loss                   | 290         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 348         |\n|    water_produced               | 80          |\n-------------------------------------------------\nEval num_timesteps=2112000, episode_reward=32.32 +/- 62.07\nEpisode length: 332.00 +/- 59.53\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 332           |\n|    mean_reward                  | 32.3          |\n| time/                           |               |\n|    total_timesteps              | 2112000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031557115 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.42         |\n|    explained_variance           | 0.537         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 98.8          |\n|    n_updates                    | 1054          |\n|    policy_gradient_loss         | 9.39e-05      |\n|    value_loss                   | 213           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 399           |\n|    water_produced               | 92            |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 86.8     |\n| time/              |          |\n|    fps             | 838      |\n|    iterations      | 528      |\n|    time_elapsed    | 2518     |\n|    total_timesteps | 2112000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 97.1          |\n| time/                           |               |\n|    fps                          | 838           |\n|    iterations                   | 529           |\n|    time_elapsed                 | 2522          |\n|    total_timesteps              | 2116000       |\n| train/                          |               |\n|    approx_kl                    | 0.00022339958 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.5          |\n|    explained_variance           | 0.629         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 129           |\n|    n_updates                    | 1056          |\n|    policy_gradient_loss         | -0.000235     |\n|    value_loss                   | 282           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 568           |\n|    water_produced               | 118           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 116          |\n| time/                           |              |\n|    fps                          | 838          |\n|    iterations                   | 530          |\n|    time_elapsed                 | 2527         |\n|    total_timesteps              | 2120000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013812128 |\n|    clip_fraction                | 0.00125      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.37        |\n|    explained_variance           | 0.589        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 1058         |\n|    policy_gradient_loss         | 0.000198     |\n|    value_loss                   | 322          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 675          |\n|    water_produced               | 151          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 101          |\n| time/                           |              |\n|    fps                          | 838          |\n|    iterations                   | 531          |\n|    time_elapsed                 | 2531         |\n|    total_timesteps              | 2124000      |\n| train/                          |              |\n|    approx_kl                    | 0.0049509266 |\n|    clip_fraction                | 0.0214       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.519        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 1060         |\n|    policy_gradient_loss         | 7.46e-06     |\n|    value_loss                   | 400          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 183          |\n|    water_produced               | 42           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 89.9          |\n| time/                           |               |\n|    fps                          | 839           |\n|    iterations                   | 532           |\n|    time_elapsed                 | 2535          |\n|    total_timesteps              | 2128000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031860647 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.42         |\n|    explained_variance           | 0.586         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 68.9          |\n|    n_updates                    | 1062          |\n|    policy_gradient_loss         | -0.000135     |\n|    value_loss                   | 145           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 142           |\n|    ice_dug                      | 159           |\n|    water_produced               | 26.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 89.9         |\n| time/                           |              |\n|    fps                          | 839          |\n|    iterations                   | 533          |\n|    time_elapsed                 | 2539         |\n|    total_timesteps              | 2132000      |\n| train/                          |              |\n|    approx_kl                    | 0.0077632023 |\n|    clip_fraction                | 0.0566       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.38        |\n|    explained_variance           | 0.558        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 50           |\n|    n_updates                    | 1064         |\n|    policy_gradient_loss         | 0.0016       |\n|    value_loss                   | 139          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 640          |\n|    water_produced               | 89.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 77.7          |\n| time/                           |               |\n|    fps                          | 839           |\n|    iterations                   | 534           |\n|    time_elapsed                 | 2544          |\n|    total_timesteps              | 2136000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017453276 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.5          |\n|    explained_variance           | 0.569         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 162           |\n|    n_updates                    | 1066          |\n|    policy_gradient_loss         | 0.00012       |\n|    value_loss                   | 343           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 315           |\n|    water_produced               | 59.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 73.5          |\n| time/                           |               |\n|    fps                          | 839           |\n|    iterations                   | 535           |\n|    time_elapsed                 | 2548          |\n|    total_timesteps              | 2140000       |\n| train/                          |               |\n|    approx_kl                    | 0.00085628557 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.53         |\n|    explained_variance           | 0.604         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 69.9          |\n|    n_updates                    | 1068          |\n|    policy_gradient_loss         | 0.000105      |\n|    value_loss                   | 180           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 618           |\n|    water_produced               | 130           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 87.6          |\n| time/                           |               |\n|    fps                          | 839           |\n|    iterations                   | 536           |\n|    time_elapsed                 | 2552          |\n|    total_timesteps              | 2144000       |\n| train/                          |               |\n|    approx_kl                    | 0.00053293566 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.41         |\n|    explained_variance           | 0.588         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 226           |\n|    n_updates                    | 1070          |\n|    policy_gradient_loss         | 0.000367      |\n|    value_loss                   | 423           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 558           |\n|    water_produced               | 109           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 88.8        |\n| time/                           |             |\n|    fps                          | 840         |\n|    iterations                   | 537         |\n|    time_elapsed                 | 2556        |\n|    total_timesteps              | 2148000     |\n| train/                          |             |\n|    approx_kl                    | 0.003260569 |\n|    clip_fraction                | 0.0108      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.44       |\n|    explained_variance           | 0.578       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 167         |\n|    n_updates                    | 1072        |\n|    policy_gradient_loss         | -0.000216   |\n|    value_loss                   | 345         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 131         |\n|    action_queue_updates_total   | 147         |\n|    ice_dug                      | 138         |\n|    water_produced               | 33          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 93.9         |\n| time/                           |              |\n|    fps                          | 840          |\n|    iterations                   | 538          |\n|    time_elapsed                 | 2561         |\n|    total_timesteps              | 2152000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036734592 |\n|    clip_fraction                | 0.0174       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.55        |\n|    explained_variance           | 0.674        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 68.2         |\n|    n_updates                    | 1074         |\n|    policy_gradient_loss         | -0.00107     |\n|    value_loss                   | 119          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 638          |\n|    water_produced               | 115          |\n--------------------------------------------------\n----------------------------------------------------\n| rollout/                        |                |\n|    ep_len_mean                  | 200            |\n|    ep_rew_mean                  | 98.6           |\n| time/                           |                |\n|    fps                          | 840            |\n|    iterations                   | 539            |\n|    time_elapsed                 | 2565           |\n|    total_timesteps              | 2156000        |\n| train/                          |                |\n|    approx_kl                    | 0.000115231654 |\n|    clip_fraction                | 0              |\n|    clip_range                   | 0.2            |\n|    entropy_loss                 | -1.47          |\n|    explained_variance           | 0.659          |\n|    learning_rate                | 0.0003         |\n|    loss                         | 167            |\n|    n_updates                    | 1076           |\n|    policy_gradient_loss         | -0.00015       |\n|    value_loss                   | 335            |\n| train_metrics/                  |                |\n|    action_queue_updates_success | 147            |\n|    action_queue_updates_total   | 154            |\n|    ice_dug                      | 466            |\n|    water_produced               | 81.5           |\n----------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 86.2          |\n| time/                           |               |\n|    fps                          | 840           |\n|    iterations                   | 540           |\n|    time_elapsed                 | 2569          |\n|    total_timesteps              | 2160000       |\n| train/                          |               |\n|    approx_kl                    | 0.00023958762 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.38         |\n|    explained_variance           | 0.545         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 134           |\n|    n_updates                    | 1078          |\n|    policy_gradient_loss         | 0.000104      |\n|    value_loss                   | 256           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 437           |\n|    water_produced               | 70.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 99           |\n| time/                           |              |\n|    fps                          | 840          |\n|    iterations                   | 541          |\n|    time_elapsed                 | 2573         |\n|    total_timesteps              | 2164000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011790384 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.44        |\n|    explained_variance           | 0.497        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 149          |\n|    n_updates                    | 1080         |\n|    policy_gradient_loss         | -0.000924    |\n|    value_loss                   | 269          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 814          |\n|    water_produced               | 170          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 113          |\n| time/                           |              |\n|    fps                          | 840          |\n|    iterations                   | 542          |\n|    time_elapsed                 | 2578         |\n|    total_timesteps              | 2168000      |\n| train/                          |              |\n|    approx_kl                    | 0.0045105703 |\n|    clip_fraction                | 0.0198       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.36        |\n|    explained_variance           | 0.577        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 213          |\n|    n_updates                    | 1082         |\n|    policy_gradient_loss         | 0.000448     |\n|    value_loss                   | 400          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 534          |\n|    water_produced               | 97.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 95.7         |\n| time/                           |              |\n|    fps                          | 841          |\n|    iterations                   | 543          |\n|    time_elapsed                 | 2582         |\n|    total_timesteps              | 2172000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009941368 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.58         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 125          |\n|    n_updates                    | 1084         |\n|    policy_gradient_loss         | 0.000139     |\n|    value_loss                   | 272          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 141          |\n|    ice_dug                      | 218          |\n|    water_produced               | 34.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 89.3         |\n| time/                           |              |\n|    fps                          | 841          |\n|    iterations                   | 544          |\n|    time_elapsed                 | 2586         |\n|    total_timesteps              | 2176000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050084954 |\n|    clip_fraction                | 0.0316       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.34        |\n|    explained_variance           | 0.476        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 70           |\n|    n_updates                    | 1086         |\n|    policy_gradient_loss         | -0.0012      |\n|    value_loss                   | 139          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 259          |\n|    water_produced               | 51.5         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 88.2        |\n| time/                           |             |\n|    fps                          | 841         |\n|    iterations                   | 545         |\n|    time_elapsed                 | 2591        |\n|    total_timesteps              | 2180000     |\n| train/                          |             |\n|    approx_kl                    | 0.002437042 |\n|    clip_fraction                | 0.00387     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.61       |\n|    explained_variance           | 0.617       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 79.9        |\n|    n_updates                    | 1088        |\n|    policy_gradient_loss         | -0.000582   |\n|    value_loss                   | 157         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 344         |\n|    water_produced               | 65.7        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 71.5          |\n| time/                           |               |\n|    fps                          | 841           |\n|    iterations                   | 546           |\n|    time_elapsed                 | 2595          |\n|    total_timesteps              | 2184000       |\n| train/                          |               |\n|    approx_kl                    | 0.00022570051 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.57         |\n|    explained_variance           | 0.619         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 107           |\n|    n_updates                    | 1090          |\n|    policy_gradient_loss         | 0.000276      |\n|    value_loss                   | 221           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 159           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 435           |\n|    water_produced               | 90.5          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 69.4        |\n| time/                           |             |\n|    fps                          | 841         |\n|    iterations                   | 547         |\n|    time_elapsed                 | 2599        |\n|    total_timesteps              | 2188000     |\n| train/                          |             |\n|    approx_kl                    | 0.001162275 |\n|    clip_fraction                | 0.000875    |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.54       |\n|    explained_variance           | 0.635       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 154         |\n|    n_updates                    | 1092        |\n|    policy_gradient_loss         | 3.43e-05    |\n|    value_loss                   | 292         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 149         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 413         |\n|    water_produced               | 88.2        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 78            |\n| time/                           |               |\n|    fps                          | 841           |\n|    iterations                   | 548           |\n|    time_elapsed                 | 2603          |\n|    total_timesteps              | 2192000       |\n| train/                          |               |\n|    approx_kl                    | 0.00041231728 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.53         |\n|    explained_variance           | 0.62          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 128           |\n|    n_updates                    | 1094          |\n|    policy_gradient_loss         | 0.000496      |\n|    value_loss                   | 237           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 355           |\n|    water_produced               | 76            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 83.9         |\n| time/                           |              |\n|    fps                          | 842          |\n|    iterations                   | 549          |\n|    time_elapsed                 | 2607         |\n|    total_timesteps              | 2196000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024988535 |\n|    clip_fraction                | 0.00563      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.45        |\n|    explained_variance           | 0.633        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 120          |\n|    n_updates                    | 1096         |\n|    policy_gradient_loss         | -0.000606    |\n|    value_loss                   | 225          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 407          |\n|    water_produced               | 79.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 83.6         |\n| time/                           |              |\n|    fps                          | 842          |\n|    iterations                   | 550          |\n|    time_elapsed                 | 2611         |\n|    total_timesteps              | 2200000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007257621 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.55        |\n|    explained_variance           | 0.663        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 118          |\n|    n_updates                    | 1098         |\n|    policy_gradient_loss         | 0.000338     |\n|    value_loss                   | 242          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 344          |\n|    water_produced               | 64.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 82            |\n| time/                           |               |\n|    fps                          | 842           |\n|    iterations                   | 551           |\n|    time_elapsed                 | 2616          |\n|    total_timesteps              | 2204000       |\n| train/                          |               |\n|    approx_kl                    | 0.00027502354 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.62         |\n|    explained_variance           | 0.637         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 86.6          |\n|    n_updates                    | 1100          |\n|    policy_gradient_loss         | 0.000607      |\n|    value_loss                   | 207           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 473           |\n|    water_produced               | 82            |\n---------------------------------------------------\nEval num_timesteps=2208000, episode_reward=119.56 +/- 182.75\nEpisode length: 414.00 +/- 176.23\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 414          |\n|    mean_reward                  | 120          |\n| time/                           |              |\n|    total_timesteps              | 2208000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019317195 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.53        |\n|    explained_variance           | 0.62         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 124          |\n|    n_updates                    | 1102         |\n|    policy_gradient_loss         | 0.000599     |\n|    value_loss                   | 230          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 270          |\n|    water_produced               | 51           |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 74.2     |\n| time/              |          |\n|    fps             | 841      |\n|    iterations      | 552      |\n|    time_elapsed    | 2624     |\n|    total_timesteps | 2208000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 72.4         |\n| time/                           |              |\n|    fps                          | 841          |\n|    iterations                   | 553          |\n|    time_elapsed                 | 2628         |\n|    total_timesteps              | 2212000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024445863 |\n|    clip_fraction                | 0.00462      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.61        |\n|    explained_variance           | 0.704        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 75.4         |\n|    n_updates                    | 1104         |\n|    policy_gradient_loss         | 9.85e-05     |\n|    value_loss                   | 155          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 346          |\n|    water_produced               | 67           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 77.4         |\n| time/                           |              |\n|    fps                          | 841          |\n|    iterations                   | 554          |\n|    time_elapsed                 | 2632         |\n|    total_timesteps              | 2216000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003551881 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.58        |\n|    explained_variance           | 0.699        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 104          |\n|    n_updates                    | 1106         |\n|    policy_gradient_loss         | -0.000479    |\n|    value_loss                   | 201          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 543          |\n|    water_produced               | 103          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 79.1         |\n| time/                           |              |\n|    fps                          | 841          |\n|    iterations                   | 555          |\n|    time_elapsed                 | 2637         |\n|    total_timesteps              | 2220000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025156545 |\n|    clip_fraction                | 0.00312      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.49        |\n|    explained_variance           | 0.626        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 149          |\n|    n_updates                    | 1108         |\n|    policy_gradient_loss         | -0.00129     |\n|    value_loss                   | 307          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 485          |\n|    water_produced               | 71.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 79.1         |\n| time/                           |              |\n|    fps                          | 842          |\n|    iterations                   | 556          |\n|    time_elapsed                 | 2641         |\n|    total_timesteps              | 2224000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014471563 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.52        |\n|    explained_variance           | 0.588        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 123          |\n|    n_updates                    | 1110         |\n|    policy_gradient_loss         | -0.00057     |\n|    value_loss                   | 249          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 441          |\n|    water_produced               | 82.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 103           |\n| time/                           |               |\n|    fps                          | 842           |\n|    iterations                   | 557           |\n|    time_elapsed                 | 2645          |\n|    total_timesteps              | 2228000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025811925 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.36         |\n|    explained_variance           | 0.543         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 157           |\n|    n_updates                    | 1112          |\n|    policy_gradient_loss         | -9.08e-05     |\n|    value_loss                   | 286           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 752           |\n|    water_produced               | 164           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 98.9         |\n| time/                           |              |\n|    fps                          | 842          |\n|    iterations                   | 558          |\n|    time_elapsed                 | 2649         |\n|    total_timesteps              | 2232000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020759017 |\n|    clip_fraction                | 0.00362      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.31        |\n|    explained_variance           | 0.63         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 1114         |\n|    policy_gradient_loss         | -8.22e-05    |\n|    value_loss                   | 450          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 209          |\n|    water_produced               | 49.7         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 89            |\n| time/                           |               |\n|    fps                          | 842           |\n|    iterations                   | 559           |\n|    time_elapsed                 | 2654          |\n|    total_timesteps              | 2236000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025784466 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.43         |\n|    explained_variance           | 0.693         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 93.6          |\n|    n_updates                    | 1116          |\n|    policy_gradient_loss         | 0.000209      |\n|    value_loss                   | 158           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 141           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 420           |\n|    water_produced               | 54.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 87.3         |\n| time/                           |              |\n|    fps                          | 842          |\n|    iterations                   | 560          |\n|    time_elapsed                 | 2658         |\n|    total_timesteps              | 2240000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021573557 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.39        |\n|    explained_variance           | 0.529        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 101          |\n|    n_updates                    | 1118         |\n|    policy_gradient_loss         | -0.000249    |\n|    value_loss                   | 234          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 295          |\n|    water_produced               | 65.3         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 85.5          |\n| time/                           |               |\n|    fps                          | 842           |\n|    iterations                   | 561           |\n|    time_elapsed                 | 2662          |\n|    total_timesteps              | 2244000       |\n| train/                          |               |\n|    approx_kl                    | 0.00069899095 |\n|    clip_fraction                | 0.00075       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.54         |\n|    explained_variance           | 0.683         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 131           |\n|    n_updates                    | 1120          |\n|    policy_gradient_loss         | -0.000342     |\n|    value_loss                   | 214           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 323           |\n|    water_produced               | 74.2          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 65.7        |\n| time/                           |             |\n|    fps                          | 843         |\n|    iterations                   | 562         |\n|    time_elapsed                 | 2666        |\n|    total_timesteps              | 2248000     |\n| train/                          |             |\n|    approx_kl                    | 0.002874291 |\n|    clip_fraction                | 0.0117      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.49       |\n|    explained_variance           | 0.659       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 130         |\n|    n_updates                    | 1122        |\n|    policy_gradient_loss         | -0.00049    |\n|    value_loss                   | 217         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 382         |\n|    water_produced               | 68.5        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 75.3          |\n| time/                           |               |\n|    fps                          | 843           |\n|    iterations                   | 563           |\n|    time_elapsed                 | 2670          |\n|    total_timesteps              | 2252000       |\n| train/                          |               |\n|    approx_kl                    | 0.00013627535 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.58         |\n|    explained_variance           | 0.632         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 128           |\n|    n_updates                    | 1124          |\n|    policy_gradient_loss         | 2.79e-05      |\n|    value_loss                   | 286           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 528           |\n|    water_produced               | 94.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 77.7         |\n| time/                           |              |\n|    fps                          | 843          |\n|    iterations                   | 564          |\n|    time_elapsed                 | 2675         |\n|    total_timesteps              | 2256000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012543952 |\n|    clip_fraction                | 0.00213      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.58        |\n|    explained_variance           | 0.702        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 173          |\n|    n_updates                    | 1126         |\n|    policy_gradient_loss         | 0.000172     |\n|    value_loss                   | 308          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 392          |\n|    water_produced               | 66.8         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 77.3        |\n| time/                           |             |\n|    fps                          | 843         |\n|    iterations                   | 565         |\n|    time_elapsed                 | 2679        |\n|    total_timesteps              | 2260000     |\n| train/                          |             |\n|    approx_kl                    | 0.000678391 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.43       |\n|    explained_variance           | 0.58        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 114         |\n|    n_updates                    | 1128        |\n|    policy_gradient_loss         | 0.000298    |\n|    value_loss                   | 241         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 300         |\n|    water_produced               | 63.2        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 81           |\n| time/                           |              |\n|    fps                          | 843          |\n|    iterations                   | 566          |\n|    time_elapsed                 | 2683         |\n|    total_timesteps              | 2264000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030722604 |\n|    clip_fraction                | 0.00675      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.51        |\n|    explained_variance           | 0.633        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 107          |\n|    n_updates                    | 1130         |\n|    policy_gradient_loss         | -0.00142     |\n|    value_loss                   | 206          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 473          |\n|    water_produced               | 91.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 81.3         |\n| time/                           |              |\n|    fps                          | 843          |\n|    iterations                   | 567          |\n|    time_elapsed                 | 2687         |\n|    total_timesteps              | 2268000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011873164 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.5         |\n|    explained_variance           | 0.677        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 134          |\n|    n_updates                    | 1132         |\n|    policy_gradient_loss         | 0.000456     |\n|    value_loss                   | 272          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 336          |\n|    water_produced               | 70           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 72.4         |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 568          |\n|    time_elapsed                 | 2691         |\n|    total_timesteps              | 2272000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014100934 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.51        |\n|    explained_variance           | 0.7          |\n|    learning_rate                | 0.0003       |\n|    loss                         | 108          |\n|    n_updates                    | 1134         |\n|    policy_gradient_loss         | 0.000126     |\n|    value_loss                   | 199          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 244          |\n|    water_produced               | 53.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 81.1         |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 569          |\n|    time_elapsed                 | 2696         |\n|    total_timesteps              | 2276000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006888391 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.6         |\n|    explained_variance           | 0.724        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 70           |\n|    n_updates                    | 1136         |\n|    policy_gradient_loss         | -0.000108    |\n|    value_loss                   | 172          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 524          |\n|    water_produced               | 109          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 95.6         |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 570          |\n|    time_elapsed                 | 2700         |\n|    total_timesteps              | 2280000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023013973 |\n|    clip_fraction                | 0.00288      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.52        |\n|    explained_variance           | 0.696        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 157          |\n|    n_updates                    | 1138         |\n|    policy_gradient_loss         | -7.85e-05    |\n|    value_loss                   | 355          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 658          |\n|    water_produced               | 132          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 89.3         |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 571          |\n|    time_elapsed                 | 2704         |\n|    total_timesteps              | 2284000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038332604 |\n|    clip_fraction                | 0.0119       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.562        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 182          |\n|    n_updates                    | 1140         |\n|    policy_gradient_loss         | 0.000654     |\n|    value_loss                   | 382          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 313          |\n|    water_produced               | 61.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 83.9         |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 572          |\n|    time_elapsed                 | 2708         |\n|    total_timesteps              | 2288000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010399838 |\n|    clip_fraction                | 0.00662      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.35        |\n|    explained_variance           | 0.653        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 104          |\n|    n_updates                    | 1142         |\n|    policy_gradient_loss         | -0.000312    |\n|    value_loss                   | 216          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 251          |\n|    water_produced               | 43.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 107          |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 573          |\n|    time_elapsed                 | 2713         |\n|    total_timesteps              | 2292000      |\n| train/                          |              |\n|    approx_kl                    | 0.0034955784 |\n|    clip_fraction                | 0.0172       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.51        |\n|    explained_variance           | 0.564        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 73.7         |\n|    n_updates                    | 1144         |\n|    policy_gradient_loss         | -0.00074     |\n|    value_loss                   | 183          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 842          |\n|    water_produced               | 161          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 97.3         |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 574          |\n|    time_elapsed                 | 2717         |\n|    total_timesteps              | 2296000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029667732 |\n|    clip_fraction                | 0.007        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.3         |\n|    explained_variance           | 0.596        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 248          |\n|    n_updates                    | 1146         |\n|    policy_gradient_loss         | 0.000626     |\n|    value_loss                   | 513          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 380          |\n|    water_produced               | 64.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 91.2          |\n| time/                           |               |\n|    fps                          | 845           |\n|    iterations                   | 575           |\n|    time_elapsed                 | 2721          |\n|    total_timesteps              | 2300000       |\n| train/                          |               |\n|    approx_kl                    | 0.00012024979 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.35         |\n|    explained_variance           | 0.591         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 129           |\n|    n_updates                    | 1148          |\n|    policy_gradient_loss         | -7.48e-05     |\n|    value_loss                   | 244           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 571           |\n|    water_produced               | 102           |\n---------------------------------------------------\nEval num_timesteps=2304000, episode_reward=705.72 +/- 457.89\nEpisode length: 782.40 +/- 283.96\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 782           |\n|    mean_reward                  | 706           |\n| time/                           |               |\n|    total_timesteps              | 2304000       |\n| train/                          |               |\n|    approx_kl                    | 0.00010178434 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.32         |\n|    explained_variance           | 0.537         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 220           |\n|    n_updates                    | 1150          |\n|    policy_gradient_loss         | -8.45e-05     |\n|    value_loss                   | 401           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 439           |\n|    water_produced               | 76            |\n---------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 94.3     |\n| time/              |          |\n|    fps             | 843      |\n|    iterations      | 576      |\n|    time_elapsed    | 2732     |\n|    total_timesteps | 2304000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 96.7          |\n| time/                           |               |\n|    fps                          | 843           |\n|    iterations                   | 577           |\n|    time_elapsed                 | 2736          |\n|    total_timesteps              | 2308000       |\n| train/                          |               |\n|    approx_kl                    | 0.00030699914 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.37         |\n|    explained_variance           | 0.524         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 107           |\n|    n_updates                    | 1152          |\n|    policy_gradient_loss         | 0.000162      |\n|    value_loss                   | 246           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 345           |\n|    water_produced               | 54.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 84.4         |\n| time/                           |              |\n|    fps                          | 843          |\n|    iterations                   | 578          |\n|    time_elapsed                 | 2740         |\n|    total_timesteps              | 2312000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031387876 |\n|    clip_fraction                | 0.0142       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.47        |\n|    explained_variance           | 0.596        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 95.9         |\n|    n_updates                    | 1154         |\n|    policy_gradient_loss         | 0.000508     |\n|    value_loss                   | 183          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 626          |\n|    water_produced               | 101          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 83.1         |\n| time/                           |              |\n|    fps                          | 843          |\n|    iterations                   | 579          |\n|    time_elapsed                 | 2744         |\n|    total_timesteps              | 2316000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038018345 |\n|    clip_fraction                | 0.0103       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.37        |\n|    explained_variance           | 0.565        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 153          |\n|    n_updates                    | 1156         |\n|    policy_gradient_loss         | 0.0011       |\n|    value_loss                   | 355          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 482          |\n|    water_produced               | 56.7         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 81.6          |\n| time/                           |               |\n|    fps                          | 843           |\n|    iterations                   | 580           |\n|    time_elapsed                 | 2749          |\n|    total_timesteps              | 2320000       |\n| train/                          |               |\n|    approx_kl                    | 0.00064384093 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.37         |\n|    explained_variance           | 0.522         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 107           |\n|    n_updates                    | 1158          |\n|    policy_gradient_loss         | -0.000295     |\n|    value_loss                   | 218           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 570           |\n|    water_produced               | 94.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 85.4          |\n| time/                           |               |\n|    fps                          | 844           |\n|    iterations                   | 581           |\n|    time_elapsed                 | 2753          |\n|    total_timesteps              | 2324000       |\n| train/                          |               |\n|    approx_kl                    | 0.00048319227 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.4          |\n|    explained_variance           | 0.589         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 215           |\n|    n_updates                    | 1160          |\n|    policy_gradient_loss         | 0.000499      |\n|    value_loss                   | 330           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 477           |\n|    water_produced               | 94.7          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 87.5          |\n| time/                           |               |\n|    fps                          | 844           |\n|    iterations                   | 582           |\n|    time_elapsed                 | 2757          |\n|    total_timesteps              | 2328000       |\n| train/                          |               |\n|    approx_kl                    | 0.00022110944 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.42         |\n|    explained_variance           | 0.617         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 131           |\n|    n_updates                    | 1162          |\n|    policy_gradient_loss         | -0.000116     |\n|    value_loss                   | 280           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 393           |\n|    water_produced               | 64.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 85.6         |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 583          |\n|    time_elapsed                 | 2761         |\n|    total_timesteps              | 2332000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006369784 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.44        |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 111          |\n|    n_updates                    | 1164         |\n|    policy_gradient_loss         | -0.000509    |\n|    value_loss                   | 205          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 475          |\n|    water_produced               | 93.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 97.6          |\n| time/                           |               |\n|    fps                          | 844           |\n|    iterations                   | 584           |\n|    time_elapsed                 | 2765          |\n|    total_timesteps              | 2336000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015271586 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.44         |\n|    explained_variance           | 0.627         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 152           |\n|    n_updates                    | 1166          |\n|    policy_gradient_loss         | 6.87e-05      |\n|    value_loss                   | 268           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 158           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 629           |\n|    water_produced               | 115           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 94.6         |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 585          |\n|    time_elapsed                 | 2769         |\n|    total_timesteps              | 2340000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011141307 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.33        |\n|    explained_variance           | 0.543        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 186          |\n|    n_updates                    | 1168         |\n|    policy_gradient_loss         | -0.000261    |\n|    value_loss                   | 385          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 456          |\n|    water_produced               | 80.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 87.3         |\n| time/                           |              |\n|    fps                          | 844          |\n|    iterations                   | 586          |\n|    time_elapsed                 | 2774         |\n|    total_timesteps              | 2344000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002482182 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.537        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 122          |\n|    n_updates                    | 1170         |\n|    policy_gradient_loss         | 0.000177     |\n|    value_loss                   | 255          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 342          |\n|    water_produced               | 59.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 107          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 587          |\n|    time_elapsed                 | 2778         |\n|    total_timesteps              | 2348000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009976523 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.44        |\n|    explained_variance           | 0.601        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 91.8         |\n|    n_updates                    | 1172         |\n|    policy_gradient_loss         | -0.000775    |\n|    value_loss                   | 203          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 806          |\n|    water_produced               | 156          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 100          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 588          |\n|    time_elapsed                 | 2782         |\n|    total_timesteps              | 2352000      |\n| train/                          |              |\n|    approx_kl                    | 0.0043101846 |\n|    clip_fraction                | 0.0173       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.566        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 254          |\n|    n_updates                    | 1174         |\n|    policy_gradient_loss         | -4.71e-05    |\n|    value_loss                   | 526          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 310          |\n|    water_produced               | 64.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 100          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 589          |\n|    time_elapsed                 | 2786         |\n|    total_timesteps              | 2356000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004479989 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.586        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 101          |\n|    n_updates                    | 1176         |\n|    policy_gradient_loss         | 0.000372     |\n|    value_loss                   | 214          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 533          |\n|    water_produced               | 116          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 108           |\n| time/                           |               |\n|    fps                          | 845           |\n|    iterations                   | 590           |\n|    time_elapsed                 | 2791          |\n|    total_timesteps              | 2360000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017578367 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.27         |\n|    explained_variance           | 0.55          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 158           |\n|    n_updates                    | 1178          |\n|    policy_gradient_loss         | -0.000121     |\n|    value_loss                   | 322           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 606           |\n|    water_produced               | 117           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 116           |\n| time/                           |               |\n|    fps                          | 845           |\n|    iterations                   | 591           |\n|    time_elapsed                 | 2795          |\n|    total_timesteps              | 2364000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017943865 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.25         |\n|    explained_variance           | 0.565         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 207           |\n|    n_updates                    | 1180          |\n|    policy_gradient_loss         | -2.61e-06     |\n|    value_loss                   | 390           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 524           |\n|    water_produced               | 98.8          |\n---------------------------------------------------\n-----------------------------------------------\n| rollout/                        |           |\n|    ep_len_mean                  | 200       |\n|    ep_rew_mean                  | 103       |\n| time/                           |           |\n|    fps                          | 845       |\n|    iterations                   | 592       |\n|    time_elapsed                 | 2799      |\n|    total_timesteps              | 2368000   |\n| train/                          |           |\n|    approx_kl                    | 0.0001729 |\n|    clip_fraction                | 0         |\n|    clip_range                   | 0.2       |\n|    entropy_loss                 | -1.3      |\n|    explained_variance           | 0.6       |\n|    learning_rate                | 0.0003    |\n|    loss                         | 155       |\n|    n_updates                    | 1182      |\n|    policy_gradient_loss         | -0.000109 |\n|    value_loss                   | 316       |\n| train_metrics/                  |           |\n|    action_queue_updates_success | 139       |\n|    action_queue_updates_total   | 150       |\n|    ice_dug                      | 415       |\n|    water_produced               | 94.5      |\n-----------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 112           |\n| time/                           |               |\n|    fps                          | 846           |\n|    iterations                   | 593           |\n|    time_elapsed                 | 2803          |\n|    total_timesteps              | 2372000       |\n| train/                          |               |\n|    approx_kl                    | 0.00090078387 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.27         |\n|    explained_variance           | 0.574         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 135           |\n|    n_updates                    | 1184          |\n|    policy_gradient_loss         | -0.000139     |\n|    value_loss                   | 272           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 627           |\n|    water_produced               | 108           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 98           |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 594          |\n|    time_elapsed                 | 2808         |\n|    total_timesteps              | 2376000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017124659 |\n|    clip_fraction                | 0.000875     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.519        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 1186         |\n|    policy_gradient_loss         | 0.00066      |\n|    value_loss                   | 338          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 245          |\n|    water_produced               | 47.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 102          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 595          |\n|    time_elapsed                 | 2812         |\n|    total_timesteps              | 2380000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016441371 |\n|    clip_fraction                | 0.006        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.32        |\n|    explained_variance           | 0.63         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 70.1         |\n|    n_updates                    | 1188         |\n|    policy_gradient_loss         | -0.000323    |\n|    value_loss                   | 172          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 662          |\n|    water_produced               | 138          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 110           |\n| time/                           |               |\n|    fps                          | 846           |\n|    iterations                   | 596           |\n|    time_elapsed                 | 2816          |\n|    total_timesteps              | 2384000       |\n| train/                          |               |\n|    approx_kl                    | 0.00011184625 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.23         |\n|    explained_variance           | 0.549         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 199           |\n|    n_updates                    | 1190          |\n|    policy_gradient_loss         | -0.000314     |\n|    value_loss                   | 431           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 751           |\n|    water_produced               | 134           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 106         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 597         |\n|    time_elapsed                 | 2821        |\n|    total_timesteps              | 2388000     |\n| train/                          |             |\n|    approx_kl                    | 0.003461069 |\n|    clip_fraction                | 0.0117      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.17       |\n|    explained_variance           | 0.514       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 197         |\n|    n_updates                    | 1192        |\n|    policy_gradient_loss         | 0.00149     |\n|    value_loss                   | 415         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 142         |\n|    action_queue_updates_total   | 148         |\n|    ice_dug                      | 383         |\n|    water_produced               | 77.2        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 112          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 598          |\n|    time_elapsed                 | 2825         |\n|    total_timesteps              | 2392000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014916355 |\n|    clip_fraction                | 0.0045       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.566        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 118          |\n|    n_updates                    | 1194         |\n|    policy_gradient_loss         | -0.000831    |\n|    value_loss                   | 258          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 763          |\n|    water_produced               | 135          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 113           |\n| time/                           |               |\n|    fps                          | 846           |\n|    iterations                   | 599           |\n|    time_elapsed                 | 2829          |\n|    total_timesteps              | 2396000       |\n| train/                          |               |\n|    approx_kl                    | 0.00052517204 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.18         |\n|    explained_variance           | 0.553         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 205           |\n|    n_updates                    | 1196          |\n|    policy_gradient_loss         | 0.000211      |\n|    value_loss                   | 419           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 147           |\n|    ice_dug                      | 268           |\n|    water_produced               | 50.2          |\n---------------------------------------------------\nEval num_timesteps=2400000, episode_reward=230.24 +/- 313.05\nEpisode length: 501.80 +/- 261.77\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 502           |\n|    mean_reward                  | 230           |\n| time/                           |               |\n|    total_timesteps              | 2400000       |\n| train/                          |               |\n|    approx_kl                    | 0.00034528744 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.26         |\n|    explained_variance           | 0.539         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 127           |\n|    n_updates                    | 1198          |\n|    policy_gradient_loss         | -0.000192     |\n|    value_loss                   | 233           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 624           |\n|    water_produced               | 123           |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 110      |\n| time/              |          |\n|    fps             | 845      |\n|    iterations      | 600      |\n|    time_elapsed    | 2837     |\n|    total_timesteps | 2400000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 94.3         |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 601          |\n|    time_elapsed                 | 2842         |\n|    total_timesteps              | 2404000      |\n| train/                          |              |\n|    approx_kl                    | 6.308836e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.587        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 148          |\n|    n_updates                    | 1200         |\n|    policy_gradient_loss         | -0.000155    |\n|    value_loss                   | 331          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 351          |\n|    water_produced               | 61.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 106           |\n| time/                           |               |\n|    fps                          | 845           |\n|    iterations                   | 602           |\n|    time_elapsed                 | 2846          |\n|    total_timesteps              | 2408000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015246763 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.31         |\n|    explained_variance           | 0.582         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 101           |\n|    n_updates                    | 1202          |\n|    policy_gradient_loss         | -8.05e-05     |\n|    value_loss                   | 203           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 681           |\n|    water_produced               | 131           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 92           |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 603          |\n|    time_elapsed                 | 2850         |\n|    total_timesteps              | 2412000      |\n| train/                          |              |\n|    approx_kl                    | 8.004935e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.524        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 185          |\n|    n_updates                    | 1204         |\n|    policy_gradient_loss         | 6.4e-05      |\n|    value_loss                   | 412          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 385          |\n|    water_produced               | 71.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 104           |\n| time/                           |               |\n|    fps                          | 846           |\n|    iterations                   | 604           |\n|    time_elapsed                 | 2854          |\n|    total_timesteps              | 2416000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029061927 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.23         |\n|    explained_variance           | 0.499         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 118           |\n|    n_updates                    | 1206          |\n|    policy_gradient_loss         | -0.000149     |\n|    value_loss                   | 266           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 597           |\n|    water_produced               | 108           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 95.6         |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 605          |\n|    time_elapsed                 | 2858         |\n|    total_timesteps              | 2420000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005229122 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.543        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 173          |\n|    n_updates                    | 1208         |\n|    policy_gradient_loss         | -0.00065     |\n|    value_loss                   | 393          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 393          |\n|    water_produced               | 82           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 112           |\n| time/                           |               |\n|    fps                          | 846           |\n|    iterations                   | 606           |\n|    time_elapsed                 | 2862          |\n|    total_timesteps              | 2424000       |\n| train/                          |               |\n|    approx_kl                    | 0.00043445537 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.32         |\n|    explained_variance           | 0.608         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 132           |\n|    n_updates                    | 1210          |\n|    policy_gradient_loss         | -0.000355     |\n|    value_loss                   | 237           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 659           |\n|    water_produced               | 140           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 91.5          |\n| time/                           |               |\n|    fps                          | 846           |\n|    iterations                   | 607           |\n|    time_elapsed                 | 2866          |\n|    total_timesteps              | 2428000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015656595 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.34         |\n|    explained_variance           | 0.6           |\n|    learning_rate                | 0.0003        |\n|    loss                         | 197           |\n|    n_updates                    | 1212          |\n|    policy_gradient_loss         | 0.000168      |\n|    value_loss                   | 408           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 190           |\n|    water_produced               | 34.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 109           |\n| time/                           |               |\n|    fps                          | 846           |\n|    iterations                   | 608           |\n|    time_elapsed                 | 2871          |\n|    total_timesteps              | 2432000       |\n| train/                          |               |\n|    approx_kl                    | 0.00018463645 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.4          |\n|    explained_variance           | 0.582         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 57.3          |\n|    n_updates                    | 1214          |\n|    policy_gradient_loss         | -6.19e-05     |\n|    value_loss                   | 158           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 776           |\n|    water_produced               | 156           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 107          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 609          |\n|    time_elapsed                 | 2875         |\n|    total_timesteps              | 2436000      |\n| train/                          |              |\n|    approx_kl                    | 9.825488e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.23        |\n|    explained_variance           | 0.541        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 1216         |\n|    policy_gradient_loss         | 0.000115     |\n|    value_loss                   | 435          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 559          |\n|    water_produced               | 96.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 106           |\n| time/                           |               |\n|    fps                          | 847           |\n|    iterations                   | 610           |\n|    time_elapsed                 | 2880          |\n|    total_timesteps              | 2440000       |\n| train/                          |               |\n|    approx_kl                    | 0.00022847259 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.32         |\n|    explained_variance           | 0.63          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 169           |\n|    n_updates                    | 1218          |\n|    policy_gradient_loss         | 5.91e-05      |\n|    value_loss                   | 336           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 440           |\n|    water_produced               | 75.5          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 105         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 611         |\n|    time_elapsed                 | 2884        |\n|    total_timesteps              | 2444000     |\n| train/                          |             |\n|    approx_kl                    | 0.001663734 |\n|    clip_fraction                | 0.00613     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.28       |\n|    explained_variance           | 0.527       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 114         |\n|    n_updates                    | 1220        |\n|    policy_gradient_loss         | -0.00025    |\n|    value_loss                   | 240         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 638         |\n|    water_produced               | 136         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 125          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 612          |\n|    time_elapsed                 | 2888         |\n|    total_timesteps              | 2448000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019322824 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.32        |\n|    explained_variance           | 0.585        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 165          |\n|    n_updates                    | 1222         |\n|    policy_gradient_loss         | -0.000352    |\n|    value_loss                   | 320          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 579          |\n|    water_produced               | 128          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 613          |\n|    time_elapsed                 | 2892         |\n|    total_timesteps              | 2452000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015608956 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.22        |\n|    explained_variance           | 0.595        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 165          |\n|    n_updates                    | 1224         |\n|    policy_gradient_loss         | 0.000614     |\n|    value_loss                   | 324          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 537          |\n|    water_produced               | 90.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 101          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 614          |\n|    time_elapsed                 | 2896         |\n|    total_timesteps              | 2456000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015142687 |\n|    clip_fraction                | 0.00613      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.531        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 137          |\n|    n_updates                    | 1226         |\n|    policy_gradient_loss         | -0.000739    |\n|    value_loss                   | 297          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 314          |\n|    water_produced               | 48.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 104          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 615          |\n|    time_elapsed                 | 2900         |\n|    total_timesteps              | 2460000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010800475 |\n|    clip_fraction                | 0.00225      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.34        |\n|    explained_variance           | 0.468        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 90.4         |\n|    n_updates                    | 1228         |\n|    policy_gradient_loss         | -0.000416    |\n|    value_loss                   | 205          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 641          |\n|    water_produced               | 91.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 103          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 616          |\n|    time_elapsed                 | 2905         |\n|    total_timesteps              | 2464000      |\n| train/                          |              |\n|    approx_kl                    | 9.593207e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.33        |\n|    explained_variance           | 0.536        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 141          |\n|    n_updates                    | 1230         |\n|    policy_gradient_loss         | -0.000183    |\n|    value_loss                   | 295          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 968          |\n|    water_produced               | 128          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 97.5        |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 617         |\n|    time_elapsed                 | 2909        |\n|    total_timesteps              | 2468000     |\n| train/                          |             |\n|    approx_kl                    | 0.005972528 |\n|    clip_fraction                | 0.0325      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.19       |\n|    explained_variance           | 0.452       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 207         |\n|    n_updates                    | 1232        |\n|    policy_gradient_loss         | 0.000991    |\n|    value_loss                   | 426         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 132         |\n|    action_queue_updates_total   | 142         |\n|    ice_dug                      | 581         |\n|    water_produced               | 99.3        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 98.4          |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 618           |\n|    time_elapsed                 | 2913          |\n|    total_timesteps              | 2472000       |\n| train/                          |               |\n|    approx_kl                    | 0.00011985346 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.16         |\n|    explained_variance           | 0.557         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 157           |\n|    n_updates                    | 1234          |\n|    policy_gradient_loss         | 0.000256      |\n|    value_loss                   | 317           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 462           |\n|    water_produced               | 95.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 98.8         |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 619          |\n|    time_elapsed                 | 2918         |\n|    total_timesteps              | 2476000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013444865 |\n|    clip_fraction                | 0.00638      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.27        |\n|    explained_variance           | 0.588        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 120          |\n|    n_updates                    | 1236         |\n|    policy_gradient_loss         | -0.000768    |\n|    value_loss                   | 263          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 304          |\n|    water_produced               | 50.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 104          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 620          |\n|    time_elapsed                 | 2922         |\n|    total_timesteps              | 2480000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012627675 |\n|    clip_fraction                | 0.00487      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.32        |\n|    explained_variance           | 0.524        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 102          |\n|    n_updates                    | 1238         |\n|    policy_gradient_loss         | -0.000553    |\n|    value_loss                   | 211          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 750          |\n|    water_produced               | 118          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 93.4          |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 621           |\n|    time_elapsed                 | 2926          |\n|    total_timesteps              | 2484000       |\n| train/                          |               |\n|    approx_kl                    | 0.00012068152 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.27         |\n|    explained_variance           | 0.468         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 198           |\n|    n_updates                    | 1240          |\n|    policy_gradient_loss         | -4.97e-05     |\n|    value_loss                   | 408           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 407           |\n|    water_produced               | 79.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 94.7          |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 622           |\n|    time_elapsed                 | 2930          |\n|    total_timesteps              | 2488000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017069366 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.33         |\n|    explained_variance           | 0.554         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 114           |\n|    n_updates                    | 1242          |\n|    policy_gradient_loss         | -9.68e-05     |\n|    value_loss                   | 250           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 540           |\n|    water_produced               | 106           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 97.4          |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 623           |\n|    time_elapsed                 | 2935          |\n|    total_timesteps              | 2492000       |\n| train/                          |               |\n|    approx_kl                    | 0.00019883583 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.37         |\n|    explained_variance           | 0.632         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 158           |\n|    n_updates                    | 1244          |\n|    policy_gradient_loss         | -0.000106     |\n|    value_loss                   | 350           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 635           |\n|    water_produced               | 107           |\n---------------------------------------------------\nEval num_timesteps=2496000, episode_reward=562.44 +/- 589.84\nEpisode length: 630.60 +/- 315.13\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 631           |\n|    mean_reward                  | 562           |\n| time/                           |               |\n|    total_timesteps              | 2496000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032421591 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.26         |\n|    explained_variance           | 0.518         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 227           |\n|    n_updates                    | 1246          |\n|    policy_gradient_loss         | 0.000392      |\n|    value_loss                   | 391           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 574           |\n|    water_produced               | 132           |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 114      |\n| time/              |          |\n|    fps             | 847      |\n|    iterations      | 624      |\n|    time_elapsed    | 2944     |\n|    total_timesteps | 2496000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 97          |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 625         |\n|    time_elapsed                 | 2948        |\n|    total_timesteps              | 2500000     |\n| train/                          |             |\n|    approx_kl                    | 0.000897427 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.27       |\n|    explained_variance           | 0.561       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 205         |\n|    n_updates                    | 1248        |\n|    policy_gradient_loss         | 0.000113    |\n|    value_loss                   | 397         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 147         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 193         |\n|    water_produced               | 37          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 626          |\n|    time_elapsed                 | 2952         |\n|    total_timesteps              | 2504000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009530114 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.32        |\n|    explained_variance           | 0.499        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 57.8         |\n|    n_updates                    | 1250         |\n|    policy_gradient_loss         | -5.25e-05    |\n|    value_loss                   | 132          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 703          |\n|    water_produced               | 148          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 104           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 627           |\n|    time_elapsed                 | 2956          |\n|    total_timesteps              | 2508000       |\n| train/                          |               |\n|    approx_kl                    | 0.00014112925 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.32         |\n|    explained_variance           | 0.561         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 266           |\n|    n_updates                    | 1252          |\n|    policy_gradient_loss         | -0.000168     |\n|    value_loss                   | 576           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 352           |\n|    water_produced               | 72            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 103           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 628           |\n|    time_elapsed                 | 2960          |\n|    total_timesteps              | 2512000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032246578 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.42         |\n|    explained_variance           | 0.684         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 99.5          |\n|    n_updates                    | 1254          |\n|    policy_gradient_loss         | 0.000158      |\n|    value_loss                   | 184           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 565           |\n|    water_produced               | 103           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 92.8         |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 629          |\n|    time_elapsed                 | 2965         |\n|    total_timesteps              | 2516000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008135207 |\n|    clip_fraction                | 0.00175      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.4         |\n|    explained_variance           | 0.678        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 1256         |\n|    policy_gradient_loss         | 0.00027      |\n|    value_loss                   | 322          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 577          |\n|    water_produced               | 80           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 112          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 630          |\n|    time_elapsed                 | 2969         |\n|    total_timesteps              | 2520000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010606634 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.31        |\n|    explained_variance           | 0.643        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 116          |\n|    n_updates                    | 1258         |\n|    policy_gradient_loss         | 0.000106     |\n|    value_loss                   | 279          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 617          |\n|    water_produced               | 127          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 101           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 631           |\n|    time_elapsed                 | 2973          |\n|    total_timesteps              | 2524000       |\n| train/                          |               |\n|    approx_kl                    | 0.00059623516 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.16         |\n|    explained_variance           | 0.518         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 192           |\n|    n_updates                    | 1260          |\n|    policy_gradient_loss         | -0.000257     |\n|    value_loss                   | 380           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 480           |\n|    water_produced               | 98.7          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 107           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 632           |\n|    time_elapsed                 | 2977          |\n|    total_timesteps              | 2528000       |\n| train/                          |               |\n|    approx_kl                    | 0.00088723673 |\n|    clip_fraction                | 0.00475       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.25         |\n|    explained_variance           | 0.588         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 139           |\n|    n_updates                    | 1262          |\n|    policy_gradient_loss         | -0.00062      |\n|    value_loss                   | 283           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 427           |\n|    water_produced               | 98.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 106           |\n| time/                           |               |\n|    fps                          | 849           |\n|    iterations                   | 633           |\n|    time_elapsed                 | 2981          |\n|    total_timesteps              | 2532000       |\n| train/                          |               |\n|    approx_kl                    | 0.00095921726 |\n|    clip_fraction                | 0.00112       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.34         |\n|    explained_variance           | 0.585         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 173           |\n|    n_updates                    | 1264          |\n|    policy_gradient_loss         | -0.000676     |\n|    value_loss                   | 350           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 450           |\n|    water_produced               | 99.5          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 114           |\n| time/                           |               |\n|    fps                          | 849           |\n|    iterations                   | 634           |\n|    time_elapsed                 | 2985          |\n|    total_timesteps              | 2536000       |\n| train/                          |               |\n|    approx_kl                    | 0.00060623855 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.35         |\n|    explained_variance           | 0.599         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 144           |\n|    n_updates                    | 1266          |\n|    policy_gradient_loss         | -0.000307     |\n|    value_loss                   | 281           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 614           |\n|    water_produced               | 122           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 109          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 635          |\n|    time_elapsed                 | 2990         |\n|    total_timesteps              | 2540000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011114461 |\n|    clip_fraction                | 0.00137      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.34        |\n|    explained_variance           | 0.658        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 192          |\n|    n_updates                    | 1268         |\n|    policy_gradient_loss         | 0.000855     |\n|    value_loss                   | 374          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 452          |\n|    water_produced               | 99.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 127           |\n| time/                           |               |\n|    fps                          | 849           |\n|    iterations                   | 636           |\n|    time_elapsed                 | 2994          |\n|    total_timesteps              | 2544000       |\n| train/                          |               |\n|    approx_kl                    | 0.00054490054 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.37         |\n|    explained_variance           | 0.582         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 191           |\n|    n_updates                    | 1270          |\n|    policy_gradient_loss         | 0.000197      |\n|    value_loss                   | 341           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 805           |\n|    water_produced               | 185           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 133         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 637         |\n|    time_elapsed                 | 2998        |\n|    total_timesteps              | 2548000     |\n| train/                          |             |\n|    approx_kl                    | 0.001412501 |\n|    clip_fraction                | 0.003       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.2        |\n|    explained_variance           | 0.626       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 215         |\n|    n_updates                    | 1272        |\n|    policy_gradient_loss         | 0.000493    |\n|    value_loss                   | 472         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 141         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 631         |\n|    water_produced               | 128         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 134          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 638          |\n|    time_elapsed                 | 3002         |\n|    total_timesteps              | 2552000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025307448 |\n|    clip_fraction                | 0.004        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.581        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 151          |\n|    n_updates                    | 1274         |\n|    policy_gradient_loss         | 0.00069      |\n|    value_loss                   | 348          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 143          |\n|    ice_dug                      | 530          |\n|    water_produced               | 104          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 121          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 639          |\n|    time_elapsed                 | 3007         |\n|    total_timesteps              | 2556000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013430894 |\n|    clip_fraction                | 0.00837      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.514        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 1276         |\n|    policy_gradient_loss         | -0.00151     |\n|    value_loss                   | 308          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 279          |\n|    water_produced               | 59.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 122          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 640          |\n|    time_elapsed                 | 3011         |\n|    total_timesteps              | 2560000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010869745 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.646        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 119          |\n|    n_updates                    | 1278         |\n|    policy_gradient_loss         | -0.0003      |\n|    value_loss                   | 214          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 690          |\n|    water_produced               | 103          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 113           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 641           |\n|    time_elapsed                 | 3015          |\n|    total_timesteps              | 2564000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017236511 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.25         |\n|    explained_variance           | 0.521         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 188           |\n|    n_updates                    | 1280          |\n|    policy_gradient_loss         | -4.63e-05     |\n|    value_loss                   | 355           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 687           |\n|    water_produced               | 145           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 106         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 642         |\n|    time_elapsed                 | 3019        |\n|    total_timesteps              | 2568000     |\n| train/                          |             |\n|    approx_kl                    | 0.002177691 |\n|    clip_fraction                | 0.005       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.19       |\n|    explained_variance           | 0.629       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 183         |\n|    n_updates                    | 1282        |\n|    policy_gradient_loss         | -0.000375   |\n|    value_loss                   | 388         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 140         |\n|    action_queue_updates_total   | 154         |\n|    ice_dug                      | 409         |\n|    water_produced               | 92          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 95.3         |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 643          |\n|    time_elapsed                 | 3023         |\n|    total_timesteps              | 2572000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012199559 |\n|    clip_fraction                | 0.00137      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.32        |\n|    explained_variance           | 0.651        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 128          |\n|    n_updates                    | 1284         |\n|    policy_gradient_loss         | -0.00085     |\n|    value_loss                   | 260          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 283          |\n|    water_produced               | 53.5         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 97.5        |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 644         |\n|    time_elapsed                 | 3027        |\n|    total_timesteps              | 2576000     |\n| train/                          |             |\n|    approx_kl                    | 0.002584768 |\n|    clip_fraction                | 0.011       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.29       |\n|    explained_variance           | 0.58        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 106         |\n|    n_updates                    | 1286        |\n|    policy_gradient_loss         | -0.00188    |\n|    value_loss                   | 206         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 147         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 462         |\n|    water_produced               | 69          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 92.3         |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 645          |\n|    time_elapsed                 | 3032         |\n|    total_timesteps              | 2580000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022936692 |\n|    clip_fraction                | 0.0045       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.35        |\n|    explained_variance           | 0.57         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 141          |\n|    n_updates                    | 1288         |\n|    policy_gradient_loss         | -0.000773    |\n|    value_loss                   | 278          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 368          |\n|    water_produced               | 79.8         |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 79.2       |\n| time/                           |            |\n|    fps                          | 851        |\n|    iterations                   | 646        |\n|    time_elapsed                 | 3036       |\n|    total_timesteps              | 2584000    |\n| train/                          |            |\n|    approx_kl                    | 0.00081131 |\n|    clip_fraction                | 0          |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.47      |\n|    explained_variance           | 0.722      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 108        |\n|    n_updates                    | 1290       |\n|    policy_gradient_loss         | 0.000154   |\n|    value_loss                   | 217        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 153        |\n|    action_queue_updates_total   | 166        |\n|    ice_dug                      | 437        |\n|    water_produced               | 82.2       |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 79.2         |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 647          |\n|    time_elapsed                 | 3040         |\n|    total_timesteps              | 2588000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006264704 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.45        |\n|    explained_variance           | 0.634        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 117          |\n|    n_updates                    | 1292         |\n|    policy_gradient_loss         | 0.000385     |\n|    value_loss                   | 270          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 446          |\n|    water_produced               | 91.5         |\n--------------------------------------------------\nEval num_timesteps=2592000, episode_reward=171.00 +/- 208.78\nEpisode length: 464.00 +/- 201.58\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 464           |\n|    mean_reward                  | 171           |\n| time/                           |               |\n|    total_timesteps              | 2592000       |\n| train/                          |               |\n|    approx_kl                    | 0.00056976196 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.35         |\n|    explained_variance           | 0.607         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 146           |\n|    n_updates                    | 1294          |\n|    policy_gradient_loss         | 0.000209      |\n|    value_loss                   | 305           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 500           |\n|    water_produced               | 99.8          |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 88.9     |\n| time/              |          |\n|    fps             | 850      |\n|    iterations      | 648      |\n|    time_elapsed    | 3048     |\n|    total_timesteps | 2592000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 93.2          |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 649           |\n|    time_elapsed                 | 3052          |\n|    total_timesteps              | 2596000       |\n| train/                          |               |\n|    approx_kl                    | 0.00039383452 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.35         |\n|    explained_variance           | 0.609         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 169           |\n|    n_updates                    | 1296          |\n|    policy_gradient_loss         | 0.000283      |\n|    value_loss                   | 325           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 516           |\n|    water_produced               | 90            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 103          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 650          |\n|    time_elapsed                 | 3056         |\n|    total_timesteps              | 2600000      |\n| train/                          |              |\n|    approx_kl                    | 0.0001389735 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.38        |\n|    explained_variance           | 0.675        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 1298         |\n|    policy_gradient_loss         | 0.00016      |\n|    value_loss                   | 327          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 600          |\n|    water_produced               | 125          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 126          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 651          |\n|    time_elapsed                 | 3060         |\n|    total_timesteps              | 2604000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008027341 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.676        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 184          |\n|    n_updates                    | 1300         |\n|    policy_gradient_loss         | 0.000324     |\n|    value_loss                   | 363          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 993          |\n|    water_produced               | 192          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 119          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 652          |\n|    time_elapsed                 | 3065         |\n|    total_timesteps              | 2608000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012126943 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.21        |\n|    explained_variance           | 0.665        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 1302         |\n|    policy_gradient_loss         | 0.000466     |\n|    value_loss                   | 518          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 318          |\n|    water_produced               | 61           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 119           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 653           |\n|    time_elapsed                 | 3069          |\n|    total_timesteps              | 2612000       |\n| train/                          |               |\n|    approx_kl                    | 0.00014993202 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.28         |\n|    explained_variance           | 0.665         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 108           |\n|    n_updates                    | 1304          |\n|    policy_gradient_loss         | 0.000658      |\n|    value_loss                   | 208           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 147           |\n|    ice_dug                      | 482           |\n|    water_produced               | 100           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 129         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 654         |\n|    time_elapsed                 | 3073        |\n|    total_timesteps              | 2616000     |\n| train/                          |             |\n|    approx_kl                    | 0.002012923 |\n|    clip_fraction                | 0.00862     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.24       |\n|    explained_variance           | 0.618       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 137         |\n|    n_updates                    | 1306        |\n|    policy_gradient_loss         | -0.00066    |\n|    value_loss                   | 288         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 597         |\n|    water_produced               | 138         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 131          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 655          |\n|    time_elapsed                 | 3077         |\n|    total_timesteps              | 2620000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013758268 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.28        |\n|    explained_variance           | 0.69         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 179          |\n|    n_updates                    | 1308         |\n|    policy_gradient_loss         | -0.00024     |\n|    value_loss                   | 368          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 595          |\n|    water_produced               | 134          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 109         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 656         |\n|    time_elapsed                 | 3081        |\n|    total_timesteps              | 2624000     |\n| train/                          |             |\n|    approx_kl                    | 0.000628061 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.31       |\n|    explained_variance           | 0.684       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 161         |\n|    n_updates                    | 1310        |\n|    policy_gradient_loss         | -0.000576   |\n|    value_loss                   | 350         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 628         |\n|    water_produced               | 84.5        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 112           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 657           |\n|    time_elapsed                 | 3086          |\n|    total_timesteps              | 2628000       |\n| train/                          |               |\n|    approx_kl                    | 0.00037054895 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.19         |\n|    explained_variance           | 0.502         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 149           |\n|    n_updates                    | 1312          |\n|    policy_gradient_loss         | -1.15e-05     |\n|    value_loss                   | 307           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 341           |\n|    water_produced               | 77            |\n---------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 120        |\n| time/                           |            |\n|    fps                          | 851        |\n|    iterations                   | 658        |\n|    time_elapsed                 | 3090       |\n|    total_timesteps              | 2632000    |\n| train/                          |            |\n|    approx_kl                    | 0.00282006 |\n|    clip_fraction                | 0.0181     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.28      |\n|    explained_variance           | 0.661      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 101        |\n|    n_updates                    | 1314       |\n|    policy_gradient_loss         | -0.000889  |\n|    value_loss                   | 228        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 149        |\n|    action_queue_updates_total   | 159        |\n|    ice_dug                      | 780        |\n|    water_produced               | 139        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 112          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 659          |\n|    time_elapsed                 | 3094         |\n|    total_timesteps              | 2636000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019803436 |\n|    clip_fraction                | 0.0025       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.17        |\n|    explained_variance           | 0.527        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 1316         |\n|    policy_gradient_loss         | 0.000774     |\n|    value_loss                   | 447          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 567          |\n|    water_produced               | 98           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 101          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 660          |\n|    time_elapsed                 | 3098         |\n|    total_timesteps              | 2640000      |\n| train/                          |              |\n|    approx_kl                    | 0.0001579058 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.59         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 1318         |\n|    policy_gradient_loss         | 8.06e-05     |\n|    value_loss                   | 339          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 420          |\n|    water_produced               | 78           |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 114         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 661         |\n|    time_elapsed                 | 3102        |\n|    total_timesteps              | 2644000     |\n| train/                          |             |\n|    approx_kl                    | 0.004179737 |\n|    clip_fraction                | 0.017       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.39       |\n|    explained_variance           | 0.653       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 164         |\n|    n_updates                    | 1320        |\n|    policy_gradient_loss         | -7.79e-05   |\n|    value_loss                   | 318         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 741         |\n|    water_produced               | 149         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 127         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 662         |\n|    time_elapsed                 | 3106        |\n|    total_timesteps              | 2648000     |\n| train/                          |             |\n|    approx_kl                    | 0.002633673 |\n|    clip_fraction                | 0.00688     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.19       |\n|    explained_variance           | 0.591       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 192         |\n|    n_updates                    | 1322        |\n|    policy_gradient_loss         | 0.000764    |\n|    value_loss                   | 392         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 693         |\n|    water_produced               | 138         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 663          |\n|    time_elapsed                 | 3110         |\n|    total_timesteps              | 2652000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026509524 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.12        |\n|    explained_variance           | 0.554        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 1324         |\n|    policy_gradient_loss         | 0.00103      |\n|    value_loss                   | 417          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 295          |\n|    water_produced               | 64           |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 115         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 664         |\n|    time_elapsed                 | 3114        |\n|    total_timesteps              | 2656000     |\n| train/                          |             |\n|    approx_kl                    | 0.002935306 |\n|    clip_fraction                | 0.0195      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.23       |\n|    explained_variance           | 0.549       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 112         |\n|    n_updates                    | 1326        |\n|    policy_gradient_loss         | -0.000462   |\n|    value_loss                   | 229         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 741         |\n|    water_produced               | 117         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 117           |\n| time/                           |               |\n|    fps                          | 852           |\n|    iterations                   | 665           |\n|    time_elapsed                 | 3119          |\n|    total_timesteps              | 2660000       |\n| train/                          |               |\n|    approx_kl                    | 0.00010744711 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.25         |\n|    explained_variance           | 0.603         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 190           |\n|    n_updates                    | 1328          |\n|    policy_gradient_loss         | 5.54e-05      |\n|    value_loss                   | 377           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 426           |\n|    water_produced               | 88            |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 107         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 666         |\n|    time_elapsed                 | 3123        |\n|    total_timesteps              | 2664000     |\n| train/                          |             |\n|    approx_kl                    | 8.82056e-05 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.3        |\n|    explained_variance           | 0.637       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 132         |\n|    n_updates                    | 1330        |\n|    policy_gradient_loss         | -5.62e-05   |\n|    value_loss                   | 271         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 142         |\n|    action_queue_updates_total   | 154         |\n|    ice_dug                      | 455         |\n|    water_produced               | 99.5        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 85.4          |\n| time/                           |               |\n|    fps                          | 852           |\n|    iterations                   | 667           |\n|    time_elapsed                 | 3127          |\n|    total_timesteps              | 2668000       |\n| train/                          |               |\n|    approx_kl                    | 0.00092699274 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.3          |\n|    explained_variance           | 0.645         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 132           |\n|    n_updates                    | 1332          |\n|    policy_gradient_loss         | -0.00124      |\n|    value_loss                   | 238           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 213           |\n|    water_produced               | 36.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 94.5         |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 668          |\n|    time_elapsed                 | 3132         |\n|    total_timesteps              | 2672000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007832539 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.36        |\n|    explained_variance           | 0.652        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 76.8         |\n|    n_updates                    | 1334         |\n|    policy_gradient_loss         | -0.000157    |\n|    value_loss                   | 155          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 578          |\n|    water_produced               | 107          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 94.3          |\n| time/                           |               |\n|    fps                          | 853           |\n|    iterations                   | 669           |\n|    time_elapsed                 | 3136          |\n|    total_timesteps              | 2676000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015394526 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.4          |\n|    explained_variance           | 0.673         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 170           |\n|    n_updates                    | 1336          |\n|    policy_gradient_loss         | -0.000343     |\n|    value_loss                   | 357           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 593           |\n|    water_produced               | 118           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 113         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 670         |\n|    time_elapsed                 | 3140        |\n|    total_timesteps              | 2680000     |\n| train/                          |             |\n|    approx_kl                    | 0.002604583 |\n|    clip_fraction                | 0.00312     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.29       |\n|    explained_variance           | 0.609       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 163         |\n|    n_updates                    | 1338        |\n|    policy_gradient_loss         | 0.000257    |\n|    value_loss                   | 342         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 832         |\n|    water_produced               | 180         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 106          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 671          |\n|    time_elapsed                 | 3144         |\n|    total_timesteps              | 2684000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008336937 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.603        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 1340         |\n|    policy_gradient_loss         | 0.000365     |\n|    value_loss                   | 494          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 343          |\n|    water_produced               | 64.2         |\n--------------------------------------------------\nEval num_timesteps=2688000, episode_reward=715.84 +/- 371.93\nEpisode length: 836.60 +/- 211.79\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 837           |\n|    mean_reward                  | 716           |\n| time/                           |               |\n|    total_timesteps              | 2688000       |\n| train/                          |               |\n|    approx_kl                    | 0.00010114019 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.28         |\n|    explained_variance           | 0.657         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 127           |\n|    n_updates                    | 1342          |\n|    policy_gradient_loss         | 0.000201      |\n|    value_loss                   | 244           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 505           |\n|    water_produced               | 98            |\n---------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 119      |\n| time/              |          |\n|    fps             | 852      |\n|    iterations      | 672      |\n|    time_elapsed    | 3154     |\n|    total_timesteps | 2688000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 133          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 673          |\n|    time_elapsed                 | 3159         |\n|    total_timesteps              | 2692000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021169968 |\n|    clip_fraction                | 0.00563      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.34        |\n|    explained_variance           | 0.684        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 144          |\n|    n_updates                    | 1344         |\n|    policy_gradient_loss         | -0.00194     |\n|    value_loss                   | 313          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 834          |\n|    water_produced               | 177          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 118          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 674          |\n|    time_elapsed                 | 3163         |\n|    total_timesteps              | 2696000      |\n| train/                          |              |\n|    approx_kl                    | 0.0034818538 |\n|    clip_fraction                | 0.0169       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.1         |\n|    explained_variance           | 0.564        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 1346         |\n|    policy_gradient_loss         | 0.000797     |\n|    value_loss                   | 472          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 206          |\n|    water_produced               | 44.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 97           |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 675          |\n|    time_elapsed                 | 3167         |\n|    total_timesteps              | 2700000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002914868 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.605        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 81.1         |\n|    n_updates                    | 1348         |\n|    policy_gradient_loss         | -0.000226    |\n|    value_loss                   | 206          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 367          |\n|    water_produced               | 78.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 106          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 676          |\n|    time_elapsed                 | 3171         |\n|    total_timesteps              | 2704000      |\n| train/                          |              |\n|    approx_kl                    | 0.0041137924 |\n|    clip_fraction                | 0.0248       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.34        |\n|    explained_variance           | 0.667        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 120          |\n|    n_updates                    | 1350         |\n|    policy_gradient_loss         | -0.00165     |\n|    value_loss                   | 265          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 595          |\n|    water_produced               | 107          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 110         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 677         |\n|    time_elapsed                 | 3175        |\n|    total_timesteps              | 2708000     |\n| train/                          |             |\n|    approx_kl                    | 0.000849004 |\n|    clip_fraction                | 0.00175     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.26       |\n|    explained_variance           | 0.562       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 157         |\n|    n_updates                    | 1352        |\n|    policy_gradient_loss         | 0.000248    |\n|    value_loss                   | 353         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 149         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 557         |\n|    water_produced               | 117         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 99.4          |\n| time/                           |               |\n|    fps                          | 852           |\n|    iterations                   | 678           |\n|    time_elapsed                 | 3180          |\n|    total_timesteps              | 2712000       |\n| train/                          |               |\n|    approx_kl                    | 0.00034755905 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.24         |\n|    explained_variance           | 0.649         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 175           |\n|    n_updates                    | 1354          |\n|    policy_gradient_loss         | -1.41e-05     |\n|    value_loss                   | 319           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 674           |\n|    water_produced               | 126           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 101           |\n| time/                           |               |\n|    fps                          | 852           |\n|    iterations                   | 679           |\n|    time_elapsed                 | 3184          |\n|    total_timesteps              | 2716000       |\n| train/                          |               |\n|    approx_kl                    | 0.00040934287 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.18         |\n|    explained_variance           | 0.58          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 183           |\n|    n_updates                    | 1356          |\n|    policy_gradient_loss         | 0.000127      |\n|    value_loss                   | 363           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 245           |\n|    water_produced               | 52            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 99.3         |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 680          |\n|    time_elapsed                 | 3188         |\n|    total_timesteps              | 2720000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018289273 |\n|    clip_fraction                | 0.00762      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.29        |\n|    explained_variance           | 0.569        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 84.3         |\n|    n_updates                    | 1358         |\n|    policy_gradient_loss         | -3.96e-05    |\n|    value_loss                   | 189          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 419          |\n|    water_produced               | 70           |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 107         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 681         |\n|    time_elapsed                 | 3192        |\n|    total_timesteps              | 2724000     |\n| train/                          |             |\n|    approx_kl                    | 0.004896183 |\n|    clip_fraction                | 0.0348      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.34       |\n|    explained_variance           | 0.557       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 135         |\n|    n_updates                    | 1360        |\n|    policy_gradient_loss         | -0.000941   |\n|    value_loss                   | 288         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 725         |\n|    water_produced               | 142         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 106          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 682          |\n|    time_elapsed                 | 3197         |\n|    total_timesteps              | 2728000      |\n| train/                          |              |\n|    approx_kl                    | 0.0034644217 |\n|    clip_fraction                | 0.0136       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.33        |\n|    explained_variance           | 0.62         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 1362         |\n|    policy_gradient_loss         | 0.000439     |\n|    value_loss                   | 432          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 641          |\n|    water_produced               | 111          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 97.8         |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 683          |\n|    time_elapsed                 | 3201         |\n|    total_timesteps              | 2732000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030512686 |\n|    clip_fraction                | 0.009        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.35        |\n|    explained_variance           | 0.729        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 186          |\n|    n_updates                    | 1364         |\n|    policy_gradient_loss         | 0.00152      |\n|    value_loss                   | 358          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 414          |\n|    water_produced               | 89.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 97.8         |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 684          |\n|    time_elapsed                 | 3205         |\n|    total_timesteps              | 2736000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014594579 |\n|    clip_fraction                | 0.00662      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.628        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 144          |\n|    n_updates                    | 1366         |\n|    policy_gradient_loss         | -0.000472    |\n|    value_loss                   | 274          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 320          |\n|    water_produced               | 51.2         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 111         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 685         |\n|    time_elapsed                 | 3209        |\n|    total_timesteps              | 2740000     |\n| train/                          |             |\n|    approx_kl                    | 0.003960146 |\n|    clip_fraction                | 0.0201      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.35       |\n|    explained_variance           | 0.588       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 107         |\n|    n_updates                    | 1368        |\n|    policy_gradient_loss         | -0.00135    |\n|    value_loss                   | 203         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 610         |\n|    water_produced               | 135         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 100          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 686          |\n|    time_elapsed                 | 3213         |\n|    total_timesteps              | 2744000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010711338 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.36        |\n|    explained_variance           | 0.628        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 1370         |\n|    policy_gradient_loss         | -0.000142    |\n|    value_loss                   | 405          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 527          |\n|    water_produced               | 89.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 117           |\n| time/                           |               |\n|    fps                          | 853           |\n|    iterations                   | 687           |\n|    time_elapsed                 | 3218          |\n|    total_timesteps              | 2748000       |\n| train/                          |               |\n|    approx_kl                    | 0.00041630157 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.31         |\n|    explained_variance           | 0.56          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 154           |\n|    n_updates                    | 1372          |\n|    policy_gradient_loss         | 0.000338      |\n|    value_loss                   | 319           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 161           |\n|    action_queue_updates_total   | 169           |\n|    ice_dug                      | 854           |\n|    water_produced               | 191           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 123           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 688           |\n|    time_elapsed                 | 3222          |\n|    total_timesteps              | 2752000       |\n| train/                          |               |\n|    approx_kl                    | 0.00050947524 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.2          |\n|    explained_variance           | 0.574         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 245           |\n|    n_updates                    | 1374          |\n|    policy_gradient_loss         | 0.000196      |\n|    value_loss                   | 495           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 785           |\n|    water_produced               | 119           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 126         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 689         |\n|    time_elapsed                 | 3226        |\n|    total_timesteps              | 2756000     |\n| train/                          |             |\n|    approx_kl                    | 0.002758534 |\n|    clip_fraction                | 0.00988     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.12       |\n|    explained_variance           | 0.51        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 183         |\n|    n_updates                    | 1376        |\n|    policy_gradient_loss         | 0.00203     |\n|    value_loss                   | 388         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 135         |\n|    action_queue_updates_total   | 145         |\n|    ice_dug                      | 330         |\n|    water_produced               | 64.8        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 123          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 690          |\n|    time_elapsed                 | 3230         |\n|    total_timesteps              | 2760000      |\n| train/                          |              |\n|    approx_kl                    | 0.0034578398 |\n|    clip_fraction                | 0.0212       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.23        |\n|    explained_variance           | 0.588        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 100          |\n|    n_updates                    | 1378         |\n|    policy_gradient_loss         | -0.000811    |\n|    value_loss                   | 209          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 683          |\n|    water_produced               | 117          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 130           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 691           |\n|    time_elapsed                 | 3234          |\n|    total_timesteps              | 2764000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017988271 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.22         |\n|    explained_variance           | 0.566         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 175           |\n|    n_updates                    | 1380          |\n|    policy_gradient_loss         | 0.000269      |\n|    value_loss                   | 376           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 565           |\n|    water_produced               | 127           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 692          |\n|    time_elapsed                 | 3238         |\n|    total_timesteps              | 2768000      |\n| train/                          |              |\n|    approx_kl                    | 0.0001338639 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.619        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 213          |\n|    n_updates                    | 1382         |\n|    policy_gradient_loss         | -0.000294    |\n|    value_loss                   | 414          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 603          |\n|    water_produced               | 98.3         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 112          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 693          |\n|    time_elapsed                 | 3243         |\n|    total_timesteps              | 2772000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002952339 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.22        |\n|    explained_variance           | 0.581        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 148          |\n|    n_updates                    | 1384         |\n|    policy_gradient_loss         | 0.000171     |\n|    value_loss                   | 318          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 763          |\n|    water_produced               | 122          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 124          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 694          |\n|    time_elapsed                 | 3247         |\n|    total_timesteps              | 2776000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021373308 |\n|    clip_fraction                | 0.004        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.518        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 210          |\n|    n_updates                    | 1386         |\n|    policy_gradient_loss         | 0.000465     |\n|    value_loss                   | 464          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 628          |\n|    water_produced               | 120          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 129           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 695           |\n|    time_elapsed                 | 3251          |\n|    total_timesteps              | 2780000       |\n| train/                          |               |\n|    approx_kl                    | 0.00038532488 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.17         |\n|    explained_variance           | 0.603         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 191           |\n|    n_updates                    | 1388          |\n|    policy_gradient_loss         | 0.00041       |\n|    value_loss                   | 388           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 131           |\n|    action_queue_updates_total   | 145           |\n|    ice_dug                      | 786           |\n|    water_produced               | 141           |\n---------------------------------------------------\nEval num_timesteps=2784000, episode_reward=435.48 +/- 607.40\nEpisode length: 555.80 +/- 310.91\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 556         |\n|    mean_reward                  | 435         |\n| time/                           |             |\n|    total_timesteps              | 2784000     |\n| train/                          |             |\n|    approx_kl                    | 0.000546136 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.04       |\n|    explained_variance           | 0.525       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 205         |\n|    n_updates                    | 1390        |\n|    policy_gradient_loss         | 0.000432    |\n|    value_loss                   | 398         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 139         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 1.09e+03    |\n|    water_produced               | 213         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 147      |\n| time/              |          |\n|    fps             | 853      |\n|    iterations      | 696      |\n|    time_elapsed    | 3260     |\n|    total_timesteps | 2784000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 155          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 697          |\n|    time_elapsed                 | 3265         |\n|    total_timesteps              | 2788000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036481745 |\n|    clip_fraction                | 0.0211       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.952       |\n|    explained_variance           | 0.546        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 1392         |\n|    policy_gradient_loss         | 0.00204      |\n|    value_loss                   | 504          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 130          |\n|    action_queue_updates_total   | 138          |\n|    ice_dug                      | 715          |\n|    water_produced               | 136          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 137           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 698           |\n|    time_elapsed                 | 3269          |\n|    total_timesteps              | 2792000       |\n| train/                          |               |\n|    approx_kl                    | 0.00039419445 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.972        |\n|    explained_variance           | 0.6           |\n|    learning_rate                | 0.0003        |\n|    loss                         | 182           |\n|    n_updates                    | 1394          |\n|    policy_gradient_loss         | 0.000696      |\n|    value_loss                   | 382           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 128           |\n|    action_queue_updates_total   | 136           |\n|    ice_dug                      | 215           |\n|    water_produced               | 42.2          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 146         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 699         |\n|    time_elapsed                 | 3273        |\n|    total_timesteps              | 2796000     |\n| train/                          |             |\n|    approx_kl                    | 0.004497789 |\n|    clip_fraction                | 0.0266      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.08       |\n|    explained_variance           | 0.62        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 64          |\n|    n_updates                    | 1396        |\n|    policy_gradient_loss         | -0.00167    |\n|    value_loss                   | 167         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 133         |\n|    action_queue_updates_total   | 146         |\n|    ice_dug                      | 752         |\n|    water_produced               | 161         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 126          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 700          |\n|    time_elapsed                 | 3277         |\n|    total_timesteps              | 2800000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005239343 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.1         |\n|    explained_variance           | 0.645        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 1398         |\n|    policy_gradient_loss         | -0.000405    |\n|    value_loss                   | 433          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 273          |\n|    water_produced               | 49.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 102           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 701           |\n|    time_elapsed                 | 3281          |\n|    total_timesteps              | 2804000       |\n| train/                          |               |\n|    approx_kl                    | 0.00042855035 |\n|    clip_fraction                | 0.000875      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.13         |\n|    explained_variance           | 0.548         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 97.3          |\n|    n_updates                    | 1400          |\n|    policy_gradient_loss         | -0.000238     |\n|    value_loss                   | 212           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 542           |\n|    water_produced               | 93.7          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 107          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 702          |\n|    time_elapsed                 | 3286         |\n|    total_timesteps              | 2808000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018844304 |\n|    clip_fraction                | 0.00713      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.21        |\n|    explained_variance           | 0.561        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 175          |\n|    n_updates                    | 1402         |\n|    policy_gradient_loss         | -0.00112     |\n|    value_loss                   | 357          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 719          |\n|    water_produced               | 165          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 117          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 703          |\n|    time_elapsed                 | 3290         |\n|    total_timesteps              | 2812000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032787076 |\n|    clip_fraction                | 0.0144       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.17        |\n|    explained_variance           | 0.673        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 185          |\n|    n_updates                    | 1404         |\n|    policy_gradient_loss         | 0.000369     |\n|    value_loss                   | 384          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 451          |\n|    water_produced               | 86           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 121          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 704          |\n|    time_elapsed                 | 3294         |\n|    total_timesteps              | 2816000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012733059 |\n|    clip_fraction                | 0.0025       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.17        |\n|    explained_variance           | 0.624        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 132          |\n|    n_updates                    | 1406         |\n|    policy_gradient_loss         | -0.000334    |\n|    value_loss                   | 263          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 851          |\n|    water_produced               | 183          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 131           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 705           |\n|    time_elapsed                 | 3298          |\n|    total_timesteps              | 2820000       |\n| train/                          |               |\n|    approx_kl                    | 0.00013145684 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.627         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 223           |\n|    n_updates                    | 1408          |\n|    policy_gradient_loss         | -0.000326     |\n|    value_loss                   | 507           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 461           |\n|    water_produced               | 96            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 136           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 706           |\n|    time_elapsed                 | 3303          |\n|    total_timesteps              | 2824000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017094472 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.22         |\n|    explained_variance           | 0.626         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 150           |\n|    n_updates                    | 1410          |\n|    policy_gradient_loss         | -8.35e-05     |\n|    value_loss                   | 311           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 516           |\n|    water_produced               | 122           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 130          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 707          |\n|    time_elapsed                 | 3307         |\n|    total_timesteps              | 2828000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016091655 |\n|    clip_fraction                | 0.0104       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.63         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 159          |\n|    n_updates                    | 1412         |\n|    policy_gradient_loss         | -0.000512    |\n|    value_loss                   | 335          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 647          |\n|    water_produced               | 134          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 136          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 708          |\n|    time_elapsed                 | 3311         |\n|    total_timesteps              | 2832000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026511173 |\n|    clip_fraction                | 0.005        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.621        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 220          |\n|    n_updates                    | 1414         |\n|    policy_gradient_loss         | 0.000282     |\n|    value_loss                   | 414          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 674          |\n|    water_produced               | 113          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 130           |\n| time/                           |               |\n|    fps                          | 855           |\n|    iterations                   | 709           |\n|    time_elapsed                 | 3315          |\n|    total_timesteps              | 2836000       |\n| train/                          |               |\n|    approx_kl                    | 0.00039106148 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.19         |\n|    explained_variance           | 0.562         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 186           |\n|    n_updates                    | 1416          |\n|    policy_gradient_loss         | 0.000464      |\n|    value_loss                   | 355           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 715           |\n|    water_produced               | 154           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 124          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 710          |\n|    time_elapsed                 | 3319         |\n|    total_timesteps              | 2840000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005919809 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.588        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 1418         |\n|    policy_gradient_loss         | 0.000324     |\n|    value_loss                   | 412          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 310          |\n|    water_produced               | 71           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 124          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 711          |\n|    time_elapsed                 | 3324         |\n|    total_timesteps              | 2844000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008170338 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.506        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 106          |\n|    n_updates                    | 1420         |\n|    policy_gradient_loss         | -0.000944    |\n|    value_loss                   | 247          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 628          |\n|    water_produced               | 120          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 124           |\n| time/                           |               |\n|    fps                          | 855           |\n|    iterations                   | 712           |\n|    time_elapsed                 | 3328          |\n|    total_timesteps              | 2848000       |\n| train/                          |               |\n|    approx_kl                    | 0.00077777106 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.22         |\n|    explained_variance           | 0.557         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 185           |\n|    n_updates                    | 1422          |\n|    policy_gradient_loss         | -0.00157      |\n|    value_loss                   | 366           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 824           |\n|    water_produced               | 131           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 134          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 713          |\n|    time_elapsed                 | 3332         |\n|    total_timesteps              | 2852000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017612316 |\n|    clip_fraction                | 0.00137      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.591        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 1424         |\n|    policy_gradient_loss         | 0.00105      |\n|    value_loss                   | 414          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 747          |\n|    water_produced               | 164          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 132           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 714           |\n|    time_elapsed                 | 3336          |\n|    total_timesteps              | 2856000       |\n| train/                          |               |\n|    approx_kl                    | 0.00073146133 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.14         |\n|    explained_variance           | 0.591         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 220           |\n|    n_updates                    | 1426          |\n|    policy_gradient_loss         | 0.000781      |\n|    value_loss                   | 427           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 637           |\n|    water_produced               | 143           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 141           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 715           |\n|    time_elapsed                 | 3340          |\n|    total_timesteps              | 2860000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025650696 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.1          |\n|    explained_variance           | 0.582         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 195           |\n|    n_updates                    | 1428          |\n|    policy_gradient_loss         | -0.000268     |\n|    value_loss                   | 363           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 631           |\n|    water_produced               | 111           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 129           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 716           |\n|    time_elapsed                 | 3344          |\n|    total_timesteps              | 2864000       |\n| train/                          |               |\n|    approx_kl                    | 0.00018586582 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.21         |\n|    explained_variance           | 0.632         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 151           |\n|    n_updates                    | 1430          |\n|    policy_gradient_loss         | -4.88e-05     |\n|    value_loss                   | 291           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 406           |\n|    water_produced               | 62.5          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 120         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 717         |\n|    time_elapsed                 | 3349        |\n|    total_timesteps              | 2868000     |\n| train/                          |             |\n|    approx_kl                    | 0.002144814 |\n|    clip_fraction                | 0.00663     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.2        |\n|    explained_variance           | 0.524       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 118         |\n|    n_updates                    | 1432        |\n|    policy_gradient_loss         | -0.000512   |\n|    value_loss                   | 242         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 480         |\n|    water_produced               | 92.8        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 110          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 718          |\n|    time_elapsed                 | 3353         |\n|    total_timesteps              | 2872000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025256083 |\n|    clip_fraction                | 0.00737      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.35        |\n|    explained_variance           | 0.606        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 148          |\n|    n_updates                    | 1434         |\n|    policy_gradient_loss         | -0.00186     |\n|    value_loss                   | 310          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 549          |\n|    water_produced               | 113          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 106           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 719           |\n|    time_elapsed                 | 3357          |\n|    total_timesteps              | 2876000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046267896 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.25         |\n|    explained_variance           | 0.584         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 171           |\n|    n_updates                    | 1436          |\n|    policy_gradient_loss         | 0.000325      |\n|    value_loss                   | 348           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 637           |\n|    water_produced               | 124           |\n---------------------------------------------------\nEval num_timesteps=2880000, episode_reward=351.52 +/- 459.87\nEpisode length: 555.80 +/- 307.38\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 556           |\n|    mean_reward                  | 352           |\n| time/                           |               |\n|    total_timesteps              | 2880000       |\n| train/                          |               |\n|    approx_kl                    | 0.00043730755 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.23         |\n|    explained_variance           | 0.581         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 180           |\n|    n_updates                    | 1438          |\n|    policy_gradient_loss         | -0.000122     |\n|    value_loss                   | 355           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 138           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 395           |\n|    water_produced               | 77.5          |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 99       |\n| time/              |          |\n|    fps             | 855      |\n|    iterations      | 720      |\n|    time_elapsed    | 3365     |\n|    total_timesteps | 2880000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 116          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 721          |\n|    time_elapsed                 | 3369         |\n|    total_timesteps              | 2884000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010122166 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.37        |\n|    explained_variance           | 0.881        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 104          |\n|    n_updates                    | 1440         |\n|    policy_gradient_loss         | -0.000503    |\n|    value_loss                   | 225          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 755          |\n|    water_produced               | 146          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 119          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 722          |\n|    time_elapsed                 | 3373         |\n|    total_timesteps              | 2888000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015982976 |\n|    clip_fraction                | 0.0045       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.591        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 1442         |\n|    policy_gradient_loss         | 0.000783     |\n|    value_loss                   | 406          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 539          |\n|    water_produced               | 107          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 114          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 723          |\n|    time_elapsed                 | 3378         |\n|    total_timesteps              | 2892000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002889765 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.22        |\n|    explained_variance           | 0.668        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 175          |\n|    n_updates                    | 1444         |\n|    policy_gradient_loss         | -0.000316    |\n|    value_loss                   | 352          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 446          |\n|    water_produced               | 84.8         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 115         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 724         |\n|    time_elapsed                 | 3382        |\n|    total_timesteps              | 2896000     |\n| train/                          |             |\n|    approx_kl                    | 0.005328182 |\n|    clip_fraction                | 0.0345      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.23       |\n|    explained_variance           | 0.587       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 166         |\n|    n_updates                    | 1446        |\n|    policy_gradient_loss         | -0.00207    |\n|    value_loss                   | 283         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 721         |\n|    water_produced               | 129         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 725          |\n|    time_elapsed                 | 3386         |\n|    total_timesteps              | 2900000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018654227 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.28        |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 1448         |\n|    policy_gradient_loss         | 0.000223     |\n|    value_loss                   | 461          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 337          |\n|    water_produced               | 60.3         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 124         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 726         |\n|    time_elapsed                 | 3390        |\n|    total_timesteps              | 2904000     |\n| train/                          |             |\n|    approx_kl                    | 0.001044097 |\n|    clip_fraction                | 0.00112     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.31       |\n|    explained_variance           | 0.602       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 130         |\n|    n_updates                    | 1450        |\n|    policy_gradient_loss         | 0.000546    |\n|    value_loss                   | 268         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.12e+03    |\n|    water_produced               | 206         |\n-------------------------------------------------\n----------------------------------------------------\n| rollout/                        |                |\n|    ep_len_mean                  | 200            |\n|    ep_rew_mean                  | 125            |\n| time/                           |                |\n|    fps                          | 856            |\n|    iterations                   | 727            |\n|    time_elapsed                 | 3394           |\n|    total_timesteps              | 2908000        |\n| train/                          |                |\n|    approx_kl                    | 0.000109096836 |\n|    clip_fraction                | 0              |\n|    clip_range                   | 0.2            |\n|    entropy_loss                 | -1.17          |\n|    explained_variance           | 0.562          |\n|    learning_rate                | 0.0003         |\n|    loss                         | 270            |\n|    n_updates                    | 1452           |\n|    policy_gradient_loss         | -0.00015       |\n|    value_loss                   | 618            |\n| train_metrics/                  |                |\n|    action_queue_updates_success | 149            |\n|    action_queue_updates_total   | 159            |\n|    ice_dug                      | 616            |\n|    water_produced               | 112            |\n----------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 135          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 728          |\n|    time_elapsed                 | 3398         |\n|    total_timesteps              | 2912000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011714306 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.27        |\n|    explained_variance           | 0.663        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 193          |\n|    n_updates                    | 1454         |\n|    policy_gradient_loss         | 0.000841     |\n|    value_loss                   | 374          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 615          |\n|    water_produced               | 136          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 139           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 729           |\n|    time_elapsed                 | 3403          |\n|    total_timesteps              | 2916000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046103113 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.28         |\n|    explained_variance           | 0.691         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 197           |\n|    n_updates                    | 1456          |\n|    policy_gradient_loss         | -0.000307     |\n|    value_loss                   | 406           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 159           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 626           |\n|    water_produced               | 149           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 139          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 730          |\n|    time_elapsed                 | 3407         |\n|    total_timesteps              | 2920000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010349905 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.12        |\n|    explained_variance           | 0.603        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 175          |\n|    n_updates                    | 1458         |\n|    policy_gradient_loss         | 0.000214     |\n|    value_loss                   | 371          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 321          |\n|    water_produced               | 60           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 124          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 731          |\n|    time_elapsed                 | 3412         |\n|    total_timesteps              | 2924000      |\n| train/                          |              |\n|    approx_kl                    | 0.0034915186 |\n|    clip_fraction                | 0.022        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.571        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 96.4         |\n|    n_updates                    | 1460         |\n|    policy_gradient_loss         | 0.000444     |\n|    value_loss                   | 227          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 606          |\n|    water_produced               | 135          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 141          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 732          |\n|    time_elapsed                 | 3416         |\n|    total_timesteps              | 2928000      |\n| train/                          |              |\n|    approx_kl                    | 0.0001342512 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.704        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 1462         |\n|    policy_gradient_loss         | -0.000146    |\n|    value_loss                   | 358          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 955          |\n|    water_produced               | 196          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 130          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 733          |\n|    time_elapsed                 | 3420         |\n|    total_timesteps              | 2932000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022235587 |\n|    clip_fraction                | 0.00787      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.17        |\n|    explained_variance           | 0.694        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 313          |\n|    n_updates                    | 1464         |\n|    policy_gradient_loss         | 0.000931     |\n|    value_loss                   | 572          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 514          |\n|    water_produced               | 80           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 117           |\n| time/                           |               |\n|    fps                          | 857           |\n|    iterations                   | 734           |\n|    time_elapsed                 | 3424          |\n|    total_timesteps              | 2936000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015836512 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.12         |\n|    explained_variance           | 0.585         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 154           |\n|    n_updates                    | 1466          |\n|    policy_gradient_loss         | 0.000467      |\n|    value_loss                   | 315           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 439           |\n|    water_produced               | 87.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 133          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 735          |\n|    time_elapsed                 | 3428         |\n|    total_timesteps              | 2940000      |\n| train/                          |              |\n|    approx_kl                    | 0.0040933834 |\n|    clip_fraction                | 0.0242       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.23        |\n|    explained_variance           | 0.593        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 148          |\n|    n_updates                    | 1468         |\n|    policy_gradient_loss         | -0.00177     |\n|    value_loss                   | 303          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 753          |\n|    water_produced               | 136          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 134          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 736          |\n|    time_elapsed                 | 3432         |\n|    total_timesteps              | 2944000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013155795 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.554        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 1470         |\n|    policy_gradient_loss         | 0.000324     |\n|    value_loss                   | 435          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 582          |\n|    water_produced               | 136          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 112          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 737          |\n|    time_elapsed                 | 3436         |\n|    total_timesteps              | 2948000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006180347 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.616        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 160          |\n|    n_updates                    | 1472         |\n|    policy_gradient_loss         | -0.000186    |\n|    value_loss                   | 341          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 422          |\n|    water_produced               | 92           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 117          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 738          |\n|    time_elapsed                 | 3441         |\n|    total_timesteps              | 2952000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021804466 |\n|    clip_fraction                | 0.00962      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.27        |\n|    explained_variance           | 0.716        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 149          |\n|    n_updates                    | 1474         |\n|    policy_gradient_loss         | -0.00138     |\n|    value_loss                   | 285          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 762          |\n|    water_produced               | 102          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 141           |\n| time/                           |               |\n|    fps                          | 857           |\n|    iterations                   | 739           |\n|    time_elapsed                 | 3445          |\n|    total_timesteps              | 2956000       |\n| train/                          |               |\n|    approx_kl                    | 0.00071115623 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.09         |\n|    explained_variance           | 0.505         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 189           |\n|    n_updates                    | 1476          |\n|    policy_gradient_loss         | 0.000589      |\n|    value_loss                   | 416           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 1e+03         |\n|    water_produced               | 204           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 131          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 740          |\n|    time_elapsed                 | 3449         |\n|    total_timesteps              | 2960000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021057448 |\n|    clip_fraction                | 0.0109       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.02        |\n|    explained_variance           | 0.601        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 257          |\n|    n_updates                    | 1478         |\n|    policy_gradient_loss         | 0.000779     |\n|    value_loss                   | 530          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 447          |\n|    water_produced               | 87.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 111           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 741           |\n|    time_elapsed                 | 3453          |\n|    total_timesteps              | 2964000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015956354 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.14         |\n|    explained_variance           | 0.717         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 108           |\n|    n_updates                    | 1480          |\n|    policy_gradient_loss         | 0.00023       |\n|    value_loss                   | 261           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 135           |\n|    action_queue_updates_total   | 147           |\n|    ice_dug                      | 221           |\n|    water_produced               | 37.8          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 104         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 742         |\n|    time_elapsed                 | 3457        |\n|    total_timesteps              | 2968000     |\n| train/                          |             |\n|    approx_kl                    | 0.006936831 |\n|    clip_fraction                | 0.0415      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.23       |\n|    explained_variance           | 0.755       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 70.1        |\n|    n_updates                    | 1482        |\n|    policy_gradient_loss         | -0.000515   |\n|    value_loss                   | 148         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 300         |\n|    water_produced               | 63          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 102          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 743          |\n|    time_elapsed                 | 3462         |\n|    total_timesteps              | 2972000      |\n| train/                          |              |\n|    approx_kl                    | 0.0051955422 |\n|    clip_fraction                | 0.0326       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.33        |\n|    explained_variance           | 0.681        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 116          |\n|    n_updates                    | 1484         |\n|    policy_gradient_loss         | -0.000664    |\n|    value_loss                   | 229          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 710          |\n|    water_produced               | 88.5         |\n--------------------------------------------------\nEval num_timesteps=2976000, episode_reward=581.40 +/- 712.93\nEpisode length: 580.60 +/- 342.44\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 581          |\n|    mean_reward                  | 581          |\n| time/                           |              |\n|    total_timesteps              | 2976000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019510478 |\n|    clip_fraction                | 0.00775      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.21        |\n|    explained_variance           | 0.55         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 197          |\n|    n_updates                    | 1486         |\n|    policy_gradient_loss         | -0.000131    |\n|    value_loss                   | 383          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 535          |\n|    water_produced               | 102          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 80.2     |\n| time/              |          |\n|    fps             | 857      |\n|    iterations      | 744      |\n|    time_elapsed    | 3470     |\n|    total_timesteps | 2976000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 80.3         |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 745          |\n|    time_elapsed                 | 3474         |\n|    total_timesteps              | 2980000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011633064 |\n|    clip_fraction                | 0.004        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.3         |\n|    explained_variance           | 0.737        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 136          |\n|    n_updates                    | 1488         |\n|    policy_gradient_loss         | 0.000827     |\n|    value_loss                   | 300          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 428          |\n|    water_produced               | 88.2         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 88.5        |\n| time/                           |             |\n|    fps                          | 857         |\n|    iterations                   | 746         |\n|    time_elapsed                 | 3478        |\n|    total_timesteps              | 2984000     |\n| train/                          |             |\n|    approx_kl                    | 0.002475318 |\n|    clip_fraction                | 0.0141      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.18       |\n|    explained_variance           | 0.592       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 147         |\n|    n_updates                    | 1490        |\n|    policy_gradient_loss         | -0.00148    |\n|    value_loss                   | 289         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 474         |\n|    water_produced               | 76.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 110          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 747          |\n|    time_elapsed                 | 3482         |\n|    total_timesteps              | 2988000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010834713 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.32        |\n|    explained_variance           | 0.707        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 131          |\n|    n_updates                    | 1492         |\n|    policy_gradient_loss         | -0.000559    |\n|    value_loss                   | 275          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 921          |\n|    water_produced               | 164          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 748          |\n|    time_elapsed                 | 3486         |\n|    total_timesteps              | 2992000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038001235 |\n|    clip_fraction                | 0.0169       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.576        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 285          |\n|    n_updates                    | 1494         |\n|    policy_gradient_loss         | 0.00144      |\n|    value_loss                   | 559          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 471          |\n|    water_produced               | 98           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 113           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 749           |\n|    time_elapsed                 | 3491          |\n|    total_timesteps              | 2996000       |\n| train/                          |               |\n|    approx_kl                    | 0.00028766337 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.26         |\n|    explained_variance           | 0.74          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 142           |\n|    n_updates                    | 1496          |\n|    policy_gradient_loss         | 0.000437      |\n|    value_loss                   | 320           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 487           |\n|    water_produced               | 112           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 125         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 750         |\n|    time_elapsed                 | 3495        |\n|    total_timesteps              | 3000000     |\n| train/                          |             |\n|    approx_kl                    | 0.002143147 |\n|    clip_fraction                | 0.0129      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.16       |\n|    explained_variance           | 0.652       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 175         |\n|    n_updates                    | 1498        |\n|    policy_gradient_loss         | -0.00097    |\n|    value_loss                   | 313         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 151         |\n|    ice_dug                      | 664         |\n|    water_produced               | 145         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 144           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 751           |\n|    time_elapsed                 | 3499          |\n|    total_timesteps              | 3004000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025214456 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.08         |\n|    explained_variance           | 0.619         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 186           |\n|    n_updates                    | 1500          |\n|    policy_gradient_loss         | 0.000196      |\n|    value_loss                   | 377           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 758           |\n|    water_produced               | 166           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 142          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 752          |\n|    time_elapsed                 | 3503         |\n|    total_timesteps              | 3008000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011257192 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.692        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 1502         |\n|    policy_gradient_loss         | 0.000852     |\n|    value_loss                   | 438          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 778          |\n|    water_produced               | 157          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 144          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 753          |\n|    time_elapsed                 | 3507         |\n|    total_timesteps              | 3012000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011944144 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.07        |\n|    explained_variance           | 0.634        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 1504         |\n|    policy_gradient_loss         | 0.000517     |\n|    value_loss                   | 403          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 857          |\n|    water_produced               | 106          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 149          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 754          |\n|    time_elapsed                 | 3512         |\n|    total_timesteps              | 3016000      |\n| train/                          |              |\n|    approx_kl                    | 8.617905e-05 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.537        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 1506         |\n|    policy_gradient_loss         | 0.000131     |\n|    value_loss                   | 395          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 604          |\n|    water_produced               | 133          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 148           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 755           |\n|    time_elapsed                 | 3516          |\n|    total_timesteps              | 3020000       |\n| train/                          |               |\n|    approx_kl                    | 0.00030796582 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.12         |\n|    explained_variance           | 0.679         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 175           |\n|    n_updates                    | 1508          |\n|    policy_gradient_loss         | -0.000348     |\n|    value_loss                   | 340           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 804           |\n|    water_produced               | 139           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 141           |\n| time/                           |               |\n|    fps                          | 859           |\n|    iterations                   | 756           |\n|    time_elapsed                 | 3520          |\n|    total_timesteps              | 3024000       |\n| train/                          |               |\n|    approx_kl                    | 0.00045377397 |\n|    clip_fraction                | 0.00162       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.04         |\n|    explained_variance           | 0.586         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 186           |\n|    n_updates                    | 1510          |\n|    policy_gradient_loss         | -0.000637     |\n|    value_loss                   | 369           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 634           |\n|    water_produced               | 133           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 130          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 757          |\n|    time_elapsed                 | 3524         |\n|    total_timesteps              | 3028000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011649255 |\n|    clip_fraction                | 0.00913      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.653        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 188          |\n|    n_updates                    | 1512         |\n|    policy_gradient_loss         | -0.00124     |\n|    value_loss                   | 374          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 584          |\n|    water_produced               | 105          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 115          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 758          |\n|    time_elapsed                 | 3528         |\n|    total_timesteps              | 3032000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021346426 |\n|    clip_fraction                | 0.00962      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.593        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 171          |\n|    n_updates                    | 1514         |\n|    policy_gradient_loss         | -0.00125     |\n|    value_loss                   | 350          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 437          |\n|    water_produced               | 36           |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 117         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 759         |\n|    time_elapsed                 | 3532        |\n|    total_timesteps              | 3036000     |\n| train/                          |             |\n|    approx_kl                    | 0.002147718 |\n|    clip_fraction                | 0.0101      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.24       |\n|    explained_variance           | 0.494       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 138         |\n|    n_updates                    | 1516        |\n|    policy_gradient_loss         | -0.000383   |\n|    value_loss                   | 246         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 812         |\n|    water_produced               | 139         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 104          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 760          |\n|    time_elapsed                 | 3537         |\n|    total_timesteps              | 3040000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008921047 |\n|    clip_fraction                | 0.00312      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.598        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 1518         |\n|    policy_gradient_loss         | 0.00037      |\n|    value_loss                   | 459          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 500          |\n|    water_produced               | 77.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 99.3          |\n| time/                           |               |\n|    fps                          | 859           |\n|    iterations                   | 761           |\n|    time_elapsed                 | 3541          |\n|    total_timesteps              | 3044000       |\n| train/                          |               |\n|    approx_kl                    | 0.00028616347 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.24         |\n|    explained_variance           | 0.703         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 125           |\n|    n_updates                    | 1520          |\n|    policy_gradient_loss         | 0.000149      |\n|    value_loss                   | 257           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 611           |\n|    water_produced               | 110           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 103           |\n| time/                           |               |\n|    fps                          | 859           |\n|    iterations                   | 762           |\n|    time_elapsed                 | 3545          |\n|    total_timesteps              | 3048000       |\n| train/                          |               |\n|    approx_kl                    | 0.00037229055 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.17         |\n|    explained_variance           | 0.601         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 167           |\n|    n_updates                    | 1522          |\n|    policy_gradient_loss         | 0.000226      |\n|    value_loss                   | 357           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 653           |\n|    water_produced               | 120           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 118          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 763          |\n|    time_elapsed                 | 3549         |\n|    total_timesteps              | 3052000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009812021 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.666        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 1524         |\n|    policy_gradient_loss         | 0.000785     |\n|    value_loss                   | 358          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 592          |\n|    water_produced               | 110          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 122           |\n| time/                           |               |\n|    fps                          | 859           |\n|    iterations                   | 764           |\n|    time_elapsed                 | 3553          |\n|    total_timesteps              | 3056000       |\n| train/                          |               |\n|    approx_kl                    | 0.00092389557 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.28         |\n|    explained_variance           | 0.764         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 157           |\n|    n_updates                    | 1526          |\n|    policy_gradient_loss         | 6.29e-05      |\n|    value_loss                   | 336           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 768           |\n|    water_produced               | 161           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 135          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 765          |\n|    time_elapsed                 | 3558         |\n|    total_timesteps              | 3060000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016794801 |\n|    clip_fraction                | 0.00312      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.707        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 212          |\n|    n_updates                    | 1528         |\n|    policy_gradient_loss         | 0.00065      |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 753          |\n|    water_produced               | 142          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 135           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 766           |\n|    time_elapsed                 | 3562          |\n|    total_timesteps              | 3064000       |\n| train/                          |               |\n|    approx_kl                    | 0.00052332267 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.12         |\n|    explained_variance           | 0.615         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 183           |\n|    n_updates                    | 1530          |\n|    policy_gradient_loss         | -0.00054      |\n|    value_loss                   | 398           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 528           |\n|    water_produced               | 107           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 767          |\n|    time_elapsed                 | 3566         |\n|    total_timesteps              | 3068000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023889448 |\n|    clip_fraction                | 0.0138       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.655        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 158          |\n|    n_updates                    | 1532         |\n|    policy_gradient_loss         | -0.000954    |\n|    value_loss                   | 334          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 748          |\n|    water_produced               | 134          |\n--------------------------------------------------\nEval num_timesteps=3072000, episode_reward=675.00 +/- 417.45\nEpisode length: 829.60 +/- 268.57\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 830          |\n|    mean_reward                  | 675          |\n| time/                           |              |\n|    total_timesteps              | 3072000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007186954 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.649        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 197          |\n|    n_updates                    | 1534         |\n|    policy_gradient_loss         | 0.000228     |\n|    value_loss                   | 409          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 542          |\n|    water_produced               | 126          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 141      |\n| time/              |          |\n|    fps             | 858      |\n|    iterations      | 768      |\n|    time_elapsed    | 3578     |\n|    total_timesteps | 3072000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 119           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 769           |\n|    time_elapsed                 | 3582          |\n|    total_timesteps              | 3076000       |\n| train/                          |               |\n|    approx_kl                    | 0.00037352165 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.31         |\n|    explained_variance           | 0.772         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 170           |\n|    n_updates                    | 1536          |\n|    policy_gradient_loss         | -0.000276     |\n|    value_loss                   | 400           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 394           |\n|    water_produced               | 58.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 113          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 770          |\n|    time_elapsed                 | 3586         |\n|    total_timesteps              | 3080000      |\n| train/                          |              |\n|    approx_kl                    | 0.0034607672 |\n|    clip_fraction                | 0.0149       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.27        |\n|    explained_variance           | 0.728        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 129          |\n|    n_updates                    | 1538         |\n|    policy_gradient_loss         | -0.000469    |\n|    value_loss                   | 235          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 585          |\n|    water_produced               | 113          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 111           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 771           |\n|    time_elapsed                 | 3590          |\n|    total_timesteps              | 3084000       |\n| train/                          |               |\n|    approx_kl                    | 0.00048253834 |\n|    clip_fraction                | 0.001         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.25         |\n|    explained_variance           | 0.635         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 175           |\n|    n_updates                    | 1540          |\n|    policy_gradient_loss         | 0.000142      |\n|    value_loss                   | 364           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 474           |\n|    water_produced               | 98            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 117          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 772          |\n|    time_elapsed                 | 3594         |\n|    total_timesteps              | 3088000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010842064 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.695        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 154          |\n|    n_updates                    | 1542         |\n|    policy_gradient_loss         | 2.89e-05     |\n|    value_loss                   | 298          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 894          |\n|    water_produced               | 162          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 125          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 773          |\n|    time_elapsed                 | 3599         |\n|    total_timesteps              | 3092000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025237622 |\n|    clip_fraction                | 0.0117       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.589        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 212          |\n|    n_updates                    | 1544         |\n|    policy_gradient_loss         | 0.00239      |\n|    value_loss                   | 451          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 803          |\n|    water_produced               | 164          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 148          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 774          |\n|    time_elapsed                 | 3603         |\n|    total_timesteps              | 3096000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027451054 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.65         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 251          |\n|    n_updates                    | 1546         |\n|    policy_gradient_loss         | -8.62e-05    |\n|    value_loss                   | 519          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 756          |\n|    water_produced               | 165          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 144          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 775          |\n|    time_elapsed                 | 3607         |\n|    total_timesteps              | 3100000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011141917 |\n|    clip_fraction                | 0.00362      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.622        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 206          |\n|    n_updates                    | 1548         |\n|    policy_gradient_loss         | -0.000833    |\n|    value_loss                   | 418          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 495          |\n|    water_produced               | 96           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 151          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 776          |\n|    time_elapsed                 | 3611         |\n|    total_timesteps              | 3104000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016959856 |\n|    clip_fraction                | 0.00975      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.597        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 151          |\n|    n_updates                    | 1550         |\n|    policy_gradient_loss         | -0.000477    |\n|    value_loss                   | 325          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 678          |\n|    water_produced               | 131          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 135           |\n| time/                           |               |\n|    fps                          | 859           |\n|    iterations                   | 777           |\n|    time_elapsed                 | 3615          |\n|    total_timesteps              | 3108000       |\n| train/                          |               |\n|    approx_kl                    | 0.00028377917 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.11         |\n|    explained_variance           | 0.571         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 190           |\n|    n_updates                    | 1552          |\n|    policy_gradient_loss         | 0.000152      |\n|    value_loss                   | 405           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 487           |\n|    water_produced               | 87.2          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 124         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 778         |\n|    time_elapsed                 | 3619        |\n|    total_timesteps              | 3112000     |\n| train/                          |             |\n|    approx_kl                    | 0.000563284 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.17       |\n|    explained_variance           | 0.71        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 167         |\n|    n_updates                    | 1554        |\n|    policy_gradient_loss         | 0.000124    |\n|    value_loss                   | 313         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 143         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 589         |\n|    water_produced               | 109         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 124          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 779          |\n|    time_elapsed                 | 3623         |\n|    total_timesteps              | 3116000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019949481 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.659        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 187          |\n|    n_updates                    | 1556         |\n|    policy_gradient_loss         | -3.28e-05    |\n|    value_loss                   | 390          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 743          |\n|    water_produced               | 164          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 140          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 780          |\n|    time_elapsed                 | 3627         |\n|    total_timesteps              | 3120000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026203056 |\n|    clip_fraction                | 0.0124       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.596        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 230          |\n|    n_updates                    | 1558         |\n|    policy_gradient_loss         | 0.00109      |\n|    value_loss                   | 472          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 811          |\n|    water_produced               | 176          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 781          |\n|    time_elapsed                 | 3632         |\n|    total_timesteps              | 3124000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011274373 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.693        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 208          |\n|    n_updates                    | 1560         |\n|    policy_gradient_loss         | 0.000877     |\n|    value_loss                   | 431          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 595          |\n|    water_produced               | 118          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 137          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 782          |\n|    time_elapsed                 | 3636         |\n|    total_timesteps              | 3128000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011781773 |\n|    clip_fraction                | 0.00738      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.671        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 169          |\n|    n_updates                    | 1562         |\n|    policy_gradient_loss         | -0.000767    |\n|    value_loss                   | 324          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 493          |\n|    water_produced               | 83           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 135          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 783          |\n|    time_elapsed                 | 3640         |\n|    total_timesteps              | 3132000      |\n| train/                          |              |\n|    approx_kl                    | 0.0066692336 |\n|    clip_fraction                | 0.0337       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.596        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 186          |\n|    n_updates                    | 1564         |\n|    policy_gradient_loss         | 0.000318     |\n|    value_loss                   | 336          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 668          |\n|    water_produced               | 99.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 131           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 784           |\n|    time_elapsed                 | 3645          |\n|    total_timesteps              | 3136000       |\n| train/                          |               |\n|    approx_kl                    | 0.00059950247 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.25         |\n|    explained_variance           | 0.692         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 193           |\n|    n_updates                    | 1566          |\n|    policy_gradient_loss         | -0.000171     |\n|    value_loss                   | 388           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 749           |\n|    water_produced               | 144           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 124          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 785          |\n|    time_elapsed                 | 3649         |\n|    total_timesteps              | 3140000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021468014 |\n|    clip_fraction                | 0.0106       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.18        |\n|    explained_variance           | 0.661        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 235          |\n|    n_updates                    | 1568         |\n|    policy_gradient_loss         | 0.000311     |\n|    value_loss                   | 474          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 738          |\n|    water_produced               | 144          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 128          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 786          |\n|    time_elapsed                 | 3653         |\n|    total_timesteps              | 3144000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015426188 |\n|    clip_fraction                | 0.0045       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.2         |\n|    explained_variance           | 0.703        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 236          |\n|    n_updates                    | 1570         |\n|    policy_gradient_loss         | 0.000433     |\n|    value_loss                   | 436          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 615          |\n|    water_produced               | 137          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 128          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 787          |\n|    time_elapsed                 | 3657         |\n|    total_timesteps              | 3148000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006053903 |\n|    clip_fraction                | 0.0035       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.608        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 1572         |\n|    policy_gradient_loss         | -0.000492    |\n|    value_loss                   | 428          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 455          |\n|    water_produced               | 83.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 147          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 788          |\n|    time_elapsed                 | 3661         |\n|    total_timesteps              | 3152000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019902517 |\n|    clip_fraction                | 0.00863      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.33        |\n|    explained_variance           | 0.806        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 206          |\n|    n_updates                    | 1574         |\n|    policy_gradient_loss         | -0.000711    |\n|    value_loss                   | 386          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 892          |\n|    water_produced               | 191          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 141          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 789          |\n|    time_elapsed                 | 3665         |\n|    total_timesteps              | 3156000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008636278 |\n|    clip_fraction                | 0.00387      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.649        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 263          |\n|    n_updates                    | 1576         |\n|    policy_gradient_loss         | 0.000335     |\n|    value_loss                   | 539          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 600          |\n|    water_produced               | 116          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 143          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 790          |\n|    time_elapsed                 | 3670         |\n|    total_timesteps              | 3160000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003544642 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.725        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 206          |\n|    n_updates                    | 1578         |\n|    policy_gradient_loss         | 8.11e-05     |\n|    value_loss                   | 417          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 749          |\n|    water_produced               | 151          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 137           |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 791           |\n|    time_elapsed                 | 3674          |\n|    total_timesteps              | 3164000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046641362 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.17         |\n|    explained_variance           | 0.671         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 214           |\n|    n_updates                    | 1580          |\n|    policy_gradient_loss         | 0.000402      |\n|    value_loss                   | 455           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 147           |\n|    ice_dug                      | 624           |\n|    water_produced               | 111           |\n---------------------------------------------------\nEval num_timesteps=3168000, episode_reward=303.24 +/- 157.46\nEpisode length: 591.00 +/- 150.10\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 591         |\n|    mean_reward                  | 303         |\n| time/                           |             |\n|    total_timesteps              | 3168000     |\n| train/                          |             |\n|    approx_kl                    | 0.001206147 |\n|    clip_fraction                | 0.00275     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.09       |\n|    explained_variance           | 0.636       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 134         |\n|    n_updates                    | 1582        |\n|    policy_gradient_loss         | -0.000661   |\n|    value_loss                   | 288         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 140         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 257         |\n|    water_produced               | 29.8        |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 126      |\n| time/              |          |\n|    fps             | 860      |\n|    iterations      | 792      |\n|    time_elapsed    | 3682     |\n|    total_timesteps | 3168000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 103         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 793         |\n|    time_elapsed                 | 3686        |\n|    total_timesteps              | 3172000     |\n| train/                          |             |\n|    approx_kl                    | 0.007954204 |\n|    clip_fraction                | 0.0594      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.44       |\n|    explained_variance           | 0.77        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 127         |\n|    n_updates                    | 1584        |\n|    policy_gradient_loss         | -0.000208   |\n|    value_loss                   | 260         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 367         |\n|    water_produced               | 82.8        |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 113         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 794         |\n|    time_elapsed                 | 3690        |\n|    total_timesteps              | 3176000     |\n| train/                          |             |\n|    approx_kl                    | 0.003163359 |\n|    clip_fraction                | 0.0121      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.48       |\n|    explained_variance           | 0.805       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 158         |\n|    n_updates                    | 1586        |\n|    policy_gradient_loss         | 0.000409    |\n|    value_loss                   | 319         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 782         |\n|    water_produced               | 162         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 98.1       |\n| time/                           |            |\n|    fps                          | 860        |\n|    iterations                   | 795        |\n|    time_elapsed                 | 3694       |\n|    total_timesteps              | 3180000    |\n| train/                          |            |\n|    approx_kl                    | 0.00400863 |\n|    clip_fraction                | 0.0226     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.29      |\n|    explained_variance           | 0.702      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 252        |\n|    n_updates                    | 1588       |\n|    policy_gradient_loss         | 0.000897   |\n|    value_loss                   | 519        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 150        |\n|    action_queue_updates_total   | 159        |\n|    ice_dug                      | 361        |\n|    water_produced               | 81.5       |\n------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 105           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 796           |\n|    time_elapsed                 | 3698          |\n|    total_timesteps              | 3184000       |\n| train/                          |               |\n|    approx_kl                    | 0.00076113536 |\n|    clip_fraction                | 0.00137       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.35         |\n|    explained_variance           | 0.735         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 143           |\n|    n_updates                    | 1590          |\n|    policy_gradient_loss         | 0.000152      |\n|    value_loss                   | 279           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 686           |\n|    water_produced               | 146           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 115           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 797           |\n|    time_elapsed                 | 3702          |\n|    total_timesteps              | 3188000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029658945 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.33         |\n|    explained_variance           | 0.745         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 223           |\n|    n_updates                    | 1592          |\n|    policy_gradient_loss         | 0.000505      |\n|    value_loss                   | 465           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 413           |\n|    water_produced               | 78            |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 113           |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 798           |\n|    time_elapsed                 | 3706          |\n|    total_timesteps              | 3192000       |\n| train/                          |               |\n|    approx_kl                    | 0.00050449173 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.43         |\n|    explained_variance           | 0.791         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 157           |\n|    n_updates                    | 1594          |\n|    policy_gradient_loss         | 1.58e-05      |\n|    value_loss                   | 307           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 558           |\n|    water_produced               | 71.2          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 89.9          |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 799           |\n|    time_elapsed                 | 3711          |\n|    total_timesteps              | 3196000       |\n| train/                          |               |\n|    approx_kl                    | 0.00059355964 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.39         |\n|    explained_variance           | 0.713         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 183           |\n|    n_updates                    | 1596          |\n|    policy_gradient_loss         | -0.000509     |\n|    value_loss                   | 381           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 291           |\n|    water_produced               | 49            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 87.9         |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 800          |\n|    time_elapsed                 | 3715         |\n|    total_timesteps              | 3200000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030051891 |\n|    clip_fraction                | 0.0126       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.37        |\n|    explained_variance           | 0.726        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 109          |\n|    n_updates                    | 1598         |\n|    policy_gradient_loss         | -3.47e-05    |\n|    value_loss                   | 242          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 417          |\n|    water_produced               | 71           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 83.1         |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 801          |\n|    time_elapsed                 | 3719         |\n|    total_timesteps              | 3204000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013145724 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.48        |\n|    explained_variance           | 0.799        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 161          |\n|    n_updates                    | 1600         |\n|    policy_gradient_loss         | 0.000601     |\n|    value_loss                   | 313          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 617          |\n|    water_produced               | 123          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 97          |\n| time/                           |             |\n|    fps                          | 861         |\n|    iterations                   | 802         |\n|    time_elapsed                 | 3723        |\n|    total_timesteps              | 3208000     |\n| train/                          |             |\n|    approx_kl                    | 0.001836686 |\n|    clip_fraction                | 0.00562     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.31       |\n|    explained_variance           | 0.786       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 175         |\n|    n_updates                    | 1602        |\n|    policy_gradient_loss         | 0.000779    |\n|    value_loss                   | 368         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 688         |\n|    water_produced               | 145         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 108          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 803          |\n|    time_elapsed                 | 3728         |\n|    total_timesteps              | 3212000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013636245 |\n|    clip_fraction                | 0.00175      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.44        |\n|    explained_variance           | 0.873        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 1604         |\n|    policy_gradient_loss         | 0.000308     |\n|    value_loss                   | 402          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 625          |\n|    water_produced               | 126          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 120           |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 804           |\n|    time_elapsed                 | 3732          |\n|    total_timesteps              | 3216000       |\n| train/                          |               |\n|    approx_kl                    | 0.00080404774 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.25         |\n|    explained_variance           | 0.836         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 151           |\n|    n_updates                    | 1606          |\n|    policy_gradient_loss         | 0.000714      |\n|    value_loss                   | 313           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 588           |\n|    water_produced               | 106           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 133          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 805          |\n|    time_elapsed                 | 3736         |\n|    total_timesteps              | 3220000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013029298 |\n|    clip_fraction                | 0.0101       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.27        |\n|    explained_variance           | 0.712        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 1608         |\n|    policy_gradient_loss         | -0.00118     |\n|    value_loss                   | 414          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 732          |\n|    water_produced               | 133          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 134          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 806          |\n|    time_elapsed                 | 3740         |\n|    total_timesteps              | 3224000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026881788 |\n|    clip_fraction                | 0.00738      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.714        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 204          |\n|    n_updates                    | 1610         |\n|    policy_gradient_loss         | -0.000206    |\n|    value_loss                   | 445          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 578          |\n|    water_produced               | 127          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 137          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 807          |\n|    time_elapsed                 | 3744         |\n|    total_timesteps              | 3228000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004624853 |\n|    clip_fraction                | 0.00125      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.13        |\n|    explained_variance           | 0.662        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 187          |\n|    n_updates                    | 1612         |\n|    policy_gradient_loss         | -0.000358    |\n|    value_loss                   | 359          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 946          |\n|    water_produced               | 159          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 125          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 808          |\n|    time_elapsed                 | 3748         |\n|    total_timesteps              | 3232000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011785654 |\n|    clip_fraction                | 0.00137      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.618        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 1614         |\n|    policy_gradient_loss         | 0.000401     |\n|    value_loss                   | 536          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 393          |\n|    water_produced               | 69           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 115           |\n| time/                           |               |\n|    fps                          | 862           |\n|    iterations                   | 809           |\n|    time_elapsed                 | 3752          |\n|    total_timesteps              | 3236000       |\n| train/                          |               |\n|    approx_kl                    | 0.00027792907 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.24         |\n|    explained_variance           | 0.763         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 122           |\n|    n_updates                    | 1616          |\n|    policy_gradient_loss         | -5.36e-05     |\n|    value_loss                   | 313           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 141           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 329           |\n|    water_produced               | 59.2          |\n---------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 120        |\n| time/                           |            |\n|    fps                          | 862        |\n|    iterations                   | 810        |\n|    time_elapsed                 | 3757       |\n|    total_timesteps              | 3240000    |\n| train/                          |            |\n|    approx_kl                    | 0.00688719 |\n|    clip_fraction                | 0.0493     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.32      |\n|    explained_variance           | 0.856      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 113        |\n|    n_updates                    | 1618       |\n|    policy_gradient_loss         | -0.000915  |\n|    value_loss                   | 219        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 152        |\n|    action_queue_updates_total   | 165        |\n|    ice_dug                      | 737        |\n|    water_produced               | 156        |\n------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 129           |\n| time/                           |               |\n|    fps                          | 862           |\n|    iterations                   | 811           |\n|    time_elapsed                 | 3761          |\n|    total_timesteps              | 3244000       |\n| train/                          |               |\n|    approx_kl                    | 0.00073076825 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.29         |\n|    explained_variance           | 0.871         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 207           |\n|    n_updates                    | 1620          |\n|    policy_gradient_loss         | 0.000352      |\n|    value_loss                   | 467           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 789           |\n|    water_produced               | 169           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 114         |\n| time/                           |             |\n|    fps                          | 862         |\n|    iterations                   | 812         |\n|    time_elapsed                 | 3765        |\n|    total_timesteps              | 3248000     |\n| train/                          |             |\n|    approx_kl                    | 0.002666649 |\n|    clip_fraction                | 0.00825     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.19       |\n|    explained_variance           | 0.761       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 183         |\n|    n_updates                    | 1622        |\n|    policy_gradient_loss         | 0.00063     |\n|    value_loss                   | 422         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 147         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 485         |\n|    water_produced               | 87.2        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 122           |\n| time/                           |               |\n|    fps                          | 862           |\n|    iterations                   | 813           |\n|    time_elapsed                 | 3769          |\n|    total_timesteps              | 3252000       |\n| train/                          |               |\n|    approx_kl                    | 0.00084782374 |\n|    clip_fraction                | 0.000875      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.32         |\n|    explained_variance           | 0.776         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 170           |\n|    n_updates                    | 1624          |\n|    policy_gradient_loss         | -0.000585     |\n|    value_loss                   | 400           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 158           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 507           |\n|    water_produced               | 107           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 814          |\n|    time_elapsed                 | 3774         |\n|    total_timesteps              | 3256000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020034888 |\n|    clip_fraction                | 0.00888      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.18        |\n|    explained_variance           | 0.68         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 196          |\n|    n_updates                    | 1626         |\n|    policy_gradient_loss         | 0.000347     |\n|    value_loss                   | 392          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 705          |\n|    water_produced               | 136          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 144         |\n| time/                           |             |\n|    fps                          | 862         |\n|    iterations                   | 815         |\n|    time_elapsed                 | 3778        |\n|    total_timesteps              | 3260000     |\n| train/                          |             |\n|    approx_kl                    | 0.001203205 |\n|    clip_fraction                | 0.00312     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.21       |\n|    explained_variance           | 0.78        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 194         |\n|    n_updates                    | 1628        |\n|    policy_gradient_loss         | -0.000159   |\n|    value_loss                   | 403         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 917         |\n|    water_produced               | 187         |\n-------------------------------------------------\nEval num_timesteps=3264000, episode_reward=447.32 +/- 547.45\nEpisode length: 580.60 +/- 342.44\n------------------------------------------------\n| eval/                           |            |\n|    mean_ep_length               | 581        |\n|    mean_reward                  | 447        |\n| time/                           |            |\n|    total_timesteps              | 3264000    |\n| train/                          |            |\n|    approx_kl                    | 0.00186159 |\n|    clip_fraction                | 0.00388    |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.15      |\n|    explained_variance           | 0.662      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 277        |\n|    n_updates                    | 1630       |\n|    policy_gradient_loss         | -0.000725  |\n|    value_loss                   | 574        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 146        |\n|    action_queue_updates_total   | 160        |\n|    ice_dug                      | 222        |\n|    water_produced               | 51.8       |\n------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 120      |\n| time/              |          |\n|    fps             | 861      |\n|    iterations      | 816      |\n|    time_elapsed    | 3788     |\n|    total_timesteps | 3264000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 130          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 817          |\n|    time_elapsed                 | 3792         |\n|    total_timesteps              | 3268000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003727448 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.36        |\n|    explained_variance           | 0.825        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 111          |\n|    n_updates                    | 1632         |\n|    policy_gradient_loss         | 2.17e-05     |\n|    value_loss                   | 269          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 750          |\n|    water_produced               | 136          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 126           |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 818           |\n|    time_elapsed                 | 3796          |\n|    total_timesteps              | 3272000       |\n| train/                          |               |\n|    approx_kl                    | 0.00012506449 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.11         |\n|    explained_variance           | 0.57          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 234           |\n|    n_updates                    | 1634          |\n|    policy_gradient_loss         | -0.000543     |\n|    value_loss                   | 459           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 410           |\n|    water_produced               | 91.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 115           |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 819           |\n|    time_elapsed                 | 3800          |\n|    total_timesteps              | 3276000       |\n| train/                          |               |\n|    approx_kl                    | 0.00068211247 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.21         |\n|    explained_variance           | 0.667         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 169           |\n|    n_updates                    | 1636          |\n|    policy_gradient_loss         | 5.81e-05      |\n|    value_loss                   | 301           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 468           |\n|    water_produced               | 79            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 98.1         |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 820          |\n|    time_elapsed                 | 3804         |\n|    total_timesteps              | 3280000      |\n| train/                          |              |\n|    approx_kl                    | 0.0052304678 |\n|    clip_fraction                | 0.0303       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.23        |\n|    explained_variance           | 0.704        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 157          |\n|    n_updates                    | 1638         |\n|    policy_gradient_loss         | 0.000304     |\n|    value_loss                   | 278          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 540          |\n|    water_produced               | 108          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 103          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 821          |\n|    time_elapsed                 | 3808         |\n|    total_timesteps              | 3284000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004492939 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.4         |\n|    explained_variance           | 0.764        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 1640         |\n|    policy_gradient_loss         | -0.000185    |\n|    value_loss                   | 426          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 465          |\n|    water_produced               | 72           |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 115         |\n| time/                           |             |\n|    fps                          | 862         |\n|    iterations                   | 822         |\n|    time_elapsed                 | 3813        |\n|    total_timesteps              | 3288000     |\n| train/                          |             |\n|    approx_kl                    | 0.001581848 |\n|    clip_fraction                | 0.00462     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.33       |\n|    explained_variance           | 0.665       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 141         |\n|    n_updates                    | 1642        |\n|    policy_gradient_loss         | 0.000113    |\n|    value_loss                   | 300         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 939         |\n|    water_produced               | 194         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 132          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 823          |\n|    time_elapsed                 | 3817         |\n|    total_timesteps              | 3292000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037736855 |\n|    clip_fraction                | 0.0187       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.697        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 273          |\n|    n_updates                    | 1644         |\n|    policy_gradient_loss         | 0.000281     |\n|    value_loss                   | 543          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 786          |\n|    water_produced               | 173          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 139          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 824          |\n|    time_elapsed                 | 3821         |\n|    total_timesteps              | 3296000      |\n| train/                          |              |\n|    approx_kl                    | 0.0044597527 |\n|    clip_fraction                | 0.0201       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.1         |\n|    explained_variance           | 0.668        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 227          |\n|    n_updates                    | 1646         |\n|    policy_gradient_loss         | -0.000415    |\n|    value_loss                   | 484          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 708          |\n|    water_produced               | 114          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 825          |\n|    time_elapsed                 | 3825         |\n|    total_timesteps              | 3300000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013119265 |\n|    clip_fraction                | 0.00862      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.563        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 183          |\n|    n_updates                    | 1648         |\n|    policy_gradient_loss         | -0.000802    |\n|    value_loss                   | 347          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 545          |\n|    water_produced               | 103          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 159          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 826          |\n|    time_elapsed                 | 3829         |\n|    total_timesteps              | 3304000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018769869 |\n|    clip_fraction                | 0.00313      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.2         |\n|    explained_variance           | 0.667        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 213          |\n|    n_updates                    | 1650         |\n|    policy_gradient_loss         | -0.00105     |\n|    value_loss                   | 384          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 752          |\n|    water_produced               | 174          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 142          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 827          |\n|    time_elapsed                 | 3833         |\n|    total_timesteps              | 3308000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017805485 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.629        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 236          |\n|    n_updates                    | 1652         |\n|    policy_gradient_loss         | 0.000544     |\n|    value_loss                   | 468          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 562          |\n|    water_produced               | 113          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 828          |\n|    time_elapsed                 | 3838         |\n|    total_timesteps              | 3312000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010190783 |\n|    clip_fraction                | 0.00538      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.778        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 188          |\n|    n_updates                    | 1654         |\n|    policy_gradient_loss         | -0.000968    |\n|    value_loss                   | 348          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 682          |\n|    water_produced               | 152          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 147           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 829           |\n|    time_elapsed                 | 3842          |\n|    total_timesteps              | 3316000       |\n| train/                          |               |\n|    approx_kl                    | 0.00034957356 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.19         |\n|    explained_variance           | 0.74          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 205           |\n|    n_updates                    | 1656          |\n|    policy_gradient_loss         | -4.89e-05     |\n|    value_loss                   | 419           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 875           |\n|    water_produced               | 157           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 162          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 830          |\n|    time_elapsed                 | 3846         |\n|    total_timesteps              | 3320000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017245694 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.573        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 249          |\n|    n_updates                    | 1658         |\n|    policy_gradient_loss         | 0.000476     |\n|    value_loss                   | 490          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 909          |\n|    water_produced               | 176          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 139          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 831          |\n|    time_elapsed                 | 3850         |\n|    total_timesteps              | 3324000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026222514 |\n|    clip_fraction                | 0.0135       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.07        |\n|    explained_variance           | 0.509        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 261          |\n|    n_updates                    | 1660         |\n|    policy_gradient_loss         | 0.000446     |\n|    value_loss                   | 536          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 285          |\n|    water_produced               | 64.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 143          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 832          |\n|    time_elapsed                 | 3854         |\n|    total_timesteps              | 3328000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009570945 |\n|    clip_fraction                | 0.00362      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.1         |\n|    explained_variance           | 0.604        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 116          |\n|    n_updates                    | 1662         |\n|    policy_gradient_loss         | -0.000378    |\n|    value_loss                   | 278          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 625          |\n|    water_produced               | 130          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 146         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 833         |\n|    time_elapsed                 | 3858        |\n|    total_timesteps              | 3332000     |\n| train/                          |             |\n|    approx_kl                    | 0.005883287 |\n|    clip_fraction                | 0.0374      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.14       |\n|    explained_variance           | 0.635       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 167         |\n|    n_updates                    | 1664        |\n|    policy_gradient_loss         | -0.00134    |\n|    value_loss                   | 361         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 768         |\n|    water_produced               | 167         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 141          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 834          |\n|    time_elapsed                 | 3863         |\n|    total_timesteps              | 3336000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018572144 |\n|    clip_fraction                | 0.00637      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.708        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 1666         |\n|    policy_gradient_loss         | 0.000448     |\n|    value_loss                   | 466          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 690          |\n|    water_produced               | 135          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 116           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 835           |\n|    time_elapsed                 | 3867          |\n|    total_timesteps              | 3340000       |\n| train/                          |               |\n|    approx_kl                    | 0.00019078523 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.11         |\n|    explained_variance           | 0.594         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 186           |\n|    n_updates                    | 1668          |\n|    policy_gradient_loss         | -0.000121     |\n|    value_loss                   | 385           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 558           |\n|    water_produced               | 55.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 133          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 836          |\n|    time_elapsed                 | 3871         |\n|    total_timesteps              | 3344000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013759205 |\n|    clip_fraction                | 0.00213      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.593        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 152          |\n|    n_updates                    | 1670         |\n|    policy_gradient_loss         | -0.000252    |\n|    value_loss                   | 307          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 691          |\n|    water_produced               | 146          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 123           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 837           |\n|    time_elapsed                 | 3875          |\n|    total_timesteps              | 3348000       |\n| train/                          |               |\n|    approx_kl                    | 0.00026795652 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.19         |\n|    explained_variance           | 0.666         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 190           |\n|    n_updates                    | 1672          |\n|    policy_gradient_loss         | 5.27e-05      |\n|    value_loss                   | 392           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 374           |\n|    water_produced               | 79            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 121          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 838          |\n|    time_elapsed                 | 3879         |\n|    total_timesteps              | 3352000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021312432 |\n|    clip_fraction                | 0.0101       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.665        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 108          |\n|    n_updates                    | 1674         |\n|    policy_gradient_loss         | 0.000312     |\n|    value_loss                   | 237          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 776          |\n|    water_produced               | 161          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 129           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 839           |\n|    time_elapsed                 | 3883          |\n|    total_timesteps              | 3356000       |\n| train/                          |               |\n|    approx_kl                    | 0.00016690473 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.24         |\n|    explained_variance           | 0.67          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 227           |\n|    n_updates                    | 1676          |\n|    policy_gradient_loss         | 3.58e-05      |\n|    value_loss                   | 453           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 159           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 851           |\n|    water_produced               | 171           |\n---------------------------------------------------\nEval num_timesteps=3360000, episode_reward=482.40 +/- 410.73\nEpisode length: 697.60 +/- 326.49\n------------------------------------------------\n| eval/                           |            |\n|    mean_ep_length               | 698        |\n|    mean_reward                  | 482        |\n| time/                           |            |\n|    total_timesteps              | 3360000    |\n| train/                          |            |\n|    approx_kl                    | 0.00493486 |\n|    clip_fraction                | 0.0242     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.17      |\n|    explained_variance           | 0.668      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 194        |\n|    n_updates                    | 1678       |\n|    policy_gradient_loss         | -0.000344  |\n|    value_loss                   | 480        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 144        |\n|    action_queue_updates_total   | 160        |\n|    ice_dug                      | 489        |\n|    water_produced               | 72.8       |\n------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 132      |\n| time/              |          |\n|    fps             | 863      |\n|    iterations      | 840      |\n|    time_elapsed    | 3893     |\n|    total_timesteps | 3360000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 113          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 841          |\n|    time_elapsed                 | 3897         |\n|    total_timesteps              | 3364000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021083087 |\n|    clip_fraction                | 0.00562      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.29        |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 155          |\n|    n_updates                    | 1680         |\n|    policy_gradient_loss         | 0.000528     |\n|    value_loss                   | 316          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 289          |\n|    water_produced               | 54           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 131          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 842          |\n|    time_elapsed                 | 3901         |\n|    total_timesteps              | 3368000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035799257 |\n|    clip_fraction                | 0.018        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.37        |\n|    explained_variance           | 0.766        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 134          |\n|    n_updates                    | 1682         |\n|    policy_gradient_loss         | -4.36e-05    |\n|    value_loss                   | 239          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 715          |\n|    water_produced               | 164          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 110           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 843           |\n|    time_elapsed                 | 3905          |\n|    total_timesteps              | 3372000       |\n| train/                          |               |\n|    approx_kl                    | 0.00021406915 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.28         |\n|    explained_variance           | 0.709         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 254           |\n|    n_updates                    | 1684          |\n|    policy_gradient_loss         | -0.000216     |\n|    value_loss                   | 513           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 165           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 267           |\n|    water_produced               | 59.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 103           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 844           |\n|    time_elapsed                 | 3909          |\n|    total_timesteps              | 3376000       |\n| train/                          |               |\n|    approx_kl                    | 0.00058842695 |\n|    clip_fraction                | 0.0015        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.32         |\n|    explained_variance           | 0.737         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 126           |\n|    n_updates                    | 1686          |\n|    policy_gradient_loss         | -0.00028      |\n|    value_loss                   | 268           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 609           |\n|    water_produced               | 140           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 125           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 845           |\n|    time_elapsed                 | 3913          |\n|    total_timesteps              | 3380000       |\n| train/                          |               |\n|    approx_kl                    | 0.00012784913 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.31         |\n|    explained_variance           | 0.735         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 202           |\n|    n_updates                    | 1688          |\n|    policy_gradient_loss         | 5.69e-05      |\n|    value_loss                   | 416           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 1.02e+03      |\n|    water_produced               | 176           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 130         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 846         |\n|    time_elapsed                 | 3918        |\n|    total_timesteps              | 3384000     |\n| train/                          |             |\n|    approx_kl                    | 0.006295579 |\n|    clip_fraction                | 0.0403      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.2        |\n|    explained_variance           | 0.624       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 279         |\n|    n_updates                    | 1690        |\n|    policy_gradient_loss         | 0.00101     |\n|    value_loss                   | 589         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 343         |\n|    water_produced               | 78.3        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 115           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 847           |\n|    time_elapsed                 | 3922          |\n|    total_timesteps              | 3388000       |\n| train/                          |               |\n|    approx_kl                    | 0.00050574675 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.22         |\n|    explained_variance           | 0.765         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 175           |\n|    n_updates                    | 1692          |\n|    policy_gradient_loss         | 0.000456      |\n|    value_loss                   | 349           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 564           |\n|    water_produced               | 90            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 120          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 848          |\n|    time_elapsed                 | 3926         |\n|    total_timesteps              | 3392000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033152953 |\n|    clip_fraction                | 0.0207       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.619        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 182          |\n|    n_updates                    | 1694         |\n|    policy_gradient_loss         | 2.43e-05     |\n|    value_loss                   | 362          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 426          |\n|    water_produced               | 85.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 126          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 849          |\n|    time_elapsed                 | 3930         |\n|    total_timesteps              | 3396000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026130944 |\n|    clip_fraction                | 0.0137       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.685        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 178          |\n|    n_updates                    | 1696         |\n|    policy_gradient_loss         | -0.00117     |\n|    value_loss                   | 422          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 730          |\n|    water_produced               | 167          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 126          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 850          |\n|    time_elapsed                 | 3934         |\n|    total_timesteps              | 3400000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004228176 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.3         |\n|    explained_variance           | 0.798        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 233          |\n|    n_updates                    | 1698         |\n|    policy_gradient_loss         | -0.000372    |\n|    value_loss                   | 517          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 818          |\n|    water_produced               | 182          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 137          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 851          |\n|    time_elapsed                 | 3938         |\n|    total_timesteps              | 3404000      |\n| train/                          |              |\n|    approx_kl                    | 0.0041781305 |\n|    clip_fraction                | 0.0181       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.2         |\n|    explained_variance           | 0.747        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 229          |\n|    n_updates                    | 1700         |\n|    policy_gradient_loss         | 0.00183      |\n|    value_loss                   | 465          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 617          |\n|    water_produced               | 130          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 145          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 852          |\n|    time_elapsed                 | 3942         |\n|    total_timesteps              | 3408000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005818376 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.718        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 176          |\n|    n_updates                    | 1702         |\n|    policy_gradient_loss         | 0.000586     |\n|    value_loss                   | 382          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 593          |\n|    water_produced               | 129          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 162         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 853         |\n|    time_elapsed                 | 3946        |\n|    total_timesteps              | 3412000     |\n| train/                          |             |\n|    approx_kl                    | 0.002952995 |\n|    clip_fraction                | 0.0156      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.1        |\n|    explained_variance           | 0.526       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 198         |\n|    n_updates                    | 1704        |\n|    policy_gradient_loss         | -0.000972   |\n|    value_loss                   | 435         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 921         |\n|    water_produced               | 163         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 149          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 854          |\n|    time_elapsed                 | 3950         |\n|    total_timesteps              | 3416000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019043416 |\n|    clip_fraction                | 0.00875      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.73         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 245          |\n|    n_updates                    | 1706         |\n|    policy_gradient_loss         | -2.96e-05    |\n|    value_loss                   | 534          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 549          |\n|    water_produced               | 108          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 148          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 855          |\n|    time_elapsed                 | 3955         |\n|    total_timesteps              | 3420000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007697983 |\n|    clip_fraction                | 0.00187      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.17        |\n|    explained_variance           | 0.625        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 1708         |\n|    policy_gradient_loss         | -0.000213    |\n|    value_loss                   | 385          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 758          |\n|    water_produced               | 174          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 152           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 856           |\n|    time_elapsed                 | 3959          |\n|    total_timesteps              | 3424000       |\n| train/                          |               |\n|    approx_kl                    | 0.00095825794 |\n|    clip_fraction                | 0.00163       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.12         |\n|    explained_variance           | 0.683         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 220           |\n|    n_updates                    | 1710          |\n|    policy_gradient_loss         | -0.000351     |\n|    value_loss                   | 456           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 640           |\n|    water_produced               | 150           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 159           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 857           |\n|    time_elapsed                 | 3963          |\n|    total_timesteps              | 3428000       |\n| train/                          |               |\n|    approx_kl                    | 0.00039708856 |\n|    clip_fraction                | 0.00112       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.69          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 217           |\n|    n_updates                    | 1712          |\n|    policy_gradient_loss         | -0.000501     |\n|    value_loss                   | 446           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 802           |\n|    water_produced               | 162           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 156         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 858         |\n|    time_elapsed                 | 3967        |\n|    total_timesteps              | 3432000     |\n| train/                          |             |\n|    approx_kl                    | 0.000494761 |\n|    clip_fraction                | 0           |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.09       |\n|    explained_variance           | 0.645       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 236         |\n|    n_updates                    | 1714        |\n|    policy_gradient_loss         | 0.000133    |\n|    value_loss                   | 463         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 730         |\n|    water_produced               | 152         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 168          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 859          |\n|    time_elapsed                 | 3971         |\n|    total_timesteps              | 3436000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008767783 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.679        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 197          |\n|    n_updates                    | 1716         |\n|    policy_gradient_loss         | -0.000435    |\n|    value_loss                   | 464          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 784          |\n|    water_produced               | 166          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 155          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 860          |\n|    time_elapsed                 | 3976         |\n|    total_timesteps              | 3440000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020093934 |\n|    clip_fraction                | 0.004        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.754        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 1718         |\n|    policy_gradient_loss         | 0.000597     |\n|    value_loss                   | 510          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 610          |\n|    water_produced               | 109          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 147          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 861          |\n|    time_elapsed                 | 3980         |\n|    total_timesteps              | 3444000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028036383 |\n|    clip_fraction                | 0.0152       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.715        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 1720         |\n|    policy_gradient_loss         | 0.0007       |\n|    value_loss                   | 473          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 657          |\n|    water_produced               | 111          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 130          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 862          |\n|    time_elapsed                 | 3985         |\n|    total_timesteps              | 3448000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019695477 |\n|    clip_fraction                | 0.0116       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.13        |\n|    explained_variance           | 0.672        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 1722         |\n|    policy_gradient_loss         | -0.000731    |\n|    value_loss                   | 449          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 541          |\n|    water_produced               | 75.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 132          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 863          |\n|    time_elapsed                 | 3989         |\n|    total_timesteps              | 3452000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013898236 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.31        |\n|    explained_variance           | 0.785        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 166          |\n|    n_updates                    | 1724         |\n|    policy_gradient_loss         | 4.76e-05     |\n|    value_loss                   | 367          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 774          |\n|    water_produced               | 165          |\n--------------------------------------------------\nEval num_timesteps=3456000, episode_reward=595.68 +/- 504.79\nEpisode length: 701.60 +/- 267.52\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 702          |\n|    mean_reward                  | 596          |\n| time/                           |              |\n|    total_timesteps              | 3456000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021764338 |\n|    clip_fraction                | 0.012        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 255          |\n|    n_updates                    | 1726         |\n|    policy_gradient_loss         | 0.000318     |\n|    value_loss                   | 497          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 588          |\n|    water_produced               | 127          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 124      |\n| time/              |          |\n|    fps             | 863      |\n|    iterations      | 864      |\n|    time_elapsed    | 4000     |\n|    total_timesteps | 3456000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 132          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 865          |\n|    time_elapsed                 | 4005         |\n|    total_timesteps              | 3460000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010178426 |\n|    clip_fraction                | 0.00488      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.12        |\n|    explained_variance           | 0.686        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 228          |\n|    n_updates                    | 1728         |\n|    policy_gradient_loss         | -0.000314    |\n|    value_loss                   | 418          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 794          |\n|    water_produced               | 150          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 143           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 866           |\n|    time_elapsed                 | 4009          |\n|    total_timesteps              | 3464000       |\n| train/                          |               |\n|    approx_kl                    | 0.00037706565 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.22         |\n|    explained_variance           | 0.773         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 263           |\n|    n_updates                    | 1730          |\n|    policy_gradient_loss         | 7.47e-05      |\n|    value_loss                   | 509           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 735           |\n|    water_produced               | 164           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 133         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 867         |\n|    time_elapsed                 | 4014        |\n|    total_timesteps              | 3468000     |\n| train/                          |             |\n|    approx_kl                    | 0.002403729 |\n|    clip_fraction                | 0.009       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.17       |\n|    explained_variance           | 0.791       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 245         |\n|    n_updates                    | 1732        |\n|    policy_gradient_loss         | -0.00119    |\n|    value_loss                   | 480         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 211         |\n|    water_produced               | 31.8        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 147          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 868          |\n|    time_elapsed                 | 4018         |\n|    total_timesteps              | 3472000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024676593 |\n|    clip_fraction                | 0.0151       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.32        |\n|    explained_variance           | 0.845        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 81.1         |\n|    n_updates                    | 1734         |\n|    policy_gradient_loss         | 1.86e-05     |\n|    value_loss                   | 220          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.06e+03     |\n|    water_produced               | 230          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 144          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 869          |\n|    time_elapsed                 | 4023         |\n|    total_timesteps              | 3476000      |\n| train/                          |              |\n|    approx_kl                    | 0.0001495812 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.726        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 280          |\n|    n_updates                    | 1736         |\n|    policy_gradient_loss         | -0.000167    |\n|    value_loss                   | 587          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 597          |\n|    water_produced               | 113          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 130           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 870           |\n|    time_elapsed                 | 4027          |\n|    total_timesteps              | 3480000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017477456 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.14         |\n|    explained_variance           | 0.698         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 247           |\n|    n_updates                    | 1738          |\n|    policy_gradient_loss         | -0.00012      |\n|    value_loss                   | 431           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 531           |\n|    water_produced               | 81.3          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 112          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 871          |\n|    time_elapsed                 | 4031         |\n|    total_timesteps              | 3484000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014333718 |\n|    clip_fraction                | 0.00387      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.801        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 187          |\n|    n_updates                    | 1740         |\n|    policy_gradient_loss         | 0.000256     |\n|    value_loss                   | 350          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 435          |\n|    water_produced               | 74           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 139           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 872           |\n|    time_elapsed                 | 4036          |\n|    total_timesteps              | 3488000       |\n| train/                          |               |\n|    approx_kl                    | 0.00082169956 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.27         |\n|    explained_variance           | 0.715         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 148           |\n|    n_updates                    | 1742          |\n|    policy_gradient_loss         | 0.000173      |\n|    value_loss                   | 313           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 731           |\n|    water_produced               | 161           |\n---------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 110        |\n| time/                           |            |\n|    fps                          | 864        |\n|    iterations                   | 873        |\n|    time_elapsed                 | 4040       |\n|    total_timesteps              | 3492000    |\n| train/                          |            |\n|    approx_kl                    | 0.00189564 |\n|    clip_fraction                | 0.00637    |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.28      |\n|    explained_variance           | 0.77       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 318        |\n|    n_updates                    | 1744       |\n|    policy_gradient_loss         | 0.00048    |\n|    value_loss                   | 564        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 152        |\n|    action_queue_updates_total   | 162        |\n|    ice_dug                      | 552        |\n|    water_produced               | 91.2       |\n------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 117           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 874           |\n|    time_elapsed                 | 4045          |\n|    total_timesteps              | 3496000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025431396 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.67          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 210           |\n|    n_updates                    | 1746          |\n|    policy_gradient_loss         | 0.000412      |\n|    value_loss                   | 392           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 809           |\n|    water_produced               | 148           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 139           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 875           |\n|    time_elapsed                 | 4049          |\n|    total_timesteps              | 3500000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015785333 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.729         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 249           |\n|    n_updates                    | 1748          |\n|    policy_gradient_loss         | -0.000359     |\n|    value_loss                   | 476           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 823           |\n|    water_produced               | 187           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 144         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 876         |\n|    time_elapsed                 | 4053        |\n|    total_timesteps              | 3504000     |\n| train/                          |             |\n|    approx_kl                    | 0.005885332 |\n|    clip_fraction                | 0.0345      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.12       |\n|    explained_variance           | 0.732       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 237         |\n|    n_updates                    | 1750        |\n|    policy_gradient_loss         | 0.00244     |\n|    value_loss                   | 538         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 522         |\n|    water_produced               | 99.2        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 146          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 877          |\n|    time_elapsed                 | 4057         |\n|    total_timesteps              | 3508000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025424322 |\n|    clip_fraction                | 0.0128       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.692        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 162          |\n|    n_updates                    | 1752         |\n|    policy_gradient_loss         | -0.000163    |\n|    value_loss                   | 308          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 770          |\n|    water_produced               | 168          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 169           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 878           |\n|    time_elapsed                 | 4062          |\n|    total_timesteps              | 3512000       |\n| train/                          |               |\n|    approx_kl                    | 0.00014129549 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.09         |\n|    explained_variance           | 0.682         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 214           |\n|    n_updates                    | 1754          |\n|    policy_gradient_loss         | -5.31e-05     |\n|    value_loss                   | 482           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 1.02e+03      |\n|    water_produced               | 202           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 158          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 879          |\n|    time_elapsed                 | 4066         |\n|    total_timesteps              | 3516000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031205683 |\n|    clip_fraction                | 0.0152       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.985       |\n|    explained_variance           | 0.647        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 1756         |\n|    policy_gradient_loss         | 0.00149      |\n|    value_loss                   | 516          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 620          |\n|    water_produced               | 97           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 148           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 880           |\n|    time_elapsed                 | 4070          |\n|    total_timesteps              | 3520000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032586307 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.01         |\n|    explained_variance           | 0.537         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 188           |\n|    n_updates                    | 1758          |\n|    policy_gradient_loss         | 5.25e-05      |\n|    value_loss                   | 357           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 702           |\n|    water_produced               | 137           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 150          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 881          |\n|    time_elapsed                 | 4075         |\n|    total_timesteps              | 3524000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011876796 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.664        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 1760         |\n|    policy_gradient_loss         | -0.000843    |\n|    value_loss                   | 451          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 543          |\n|    water_produced               | 109          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 146          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 882          |\n|    time_elapsed                 | 4079         |\n|    total_timesteps              | 3528000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014746042 |\n|    clip_fraction                | 0.0045       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.772        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 162          |\n|    n_updates                    | 1762         |\n|    policy_gradient_loss         | -0.000376    |\n|    value_loss                   | 346          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 860          |\n|    water_produced               | 146          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 122           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 883           |\n|    time_elapsed                 | 4084          |\n|    total_timesteps              | 3532000       |\n| train/                          |               |\n|    approx_kl                    | 0.00030394417 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.631         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 222           |\n|    n_updates                    | 1764          |\n|    policy_gradient_loss         | -0.00019      |\n|    value_loss                   | 487           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 158           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 461           |\n|    water_produced               | 88.8          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 125          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 884          |\n|    time_elapsed                 | 4088         |\n|    total_timesteps              | 3536000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004102636 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.27        |\n|    explained_variance           | 0.768        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 155          |\n|    n_updates                    | 1766         |\n|    policy_gradient_loss         | -0.000178    |\n|    value_loss                   | 336          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 770          |\n|    water_produced               | 111          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 126           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 885           |\n|    time_elapsed                 | 4092          |\n|    total_timesteps              | 3540000       |\n| train/                          |               |\n|    approx_kl                    | 0.00044803842 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.23         |\n|    explained_variance           | 0.731         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 224           |\n|    n_updates                    | 1768          |\n|    policy_gradient_loss         | 0.000166      |\n|    value_loss                   | 446           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 663           |\n|    water_produced               | 143           |\n---------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 132        |\n| time/                           |            |\n|    fps                          | 864        |\n|    iterations                   | 886        |\n|    time_elapsed                 | 4097       |\n|    total_timesteps              | 3544000    |\n| train/                          |            |\n|    approx_kl                    | 0.00043828 |\n|    clip_fraction                | 0.00025    |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.27      |\n|    explained_variance           | 0.821      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 226        |\n|    n_updates                    | 1770       |\n|    policy_gradient_loss         | 0.000105   |\n|    value_loss                   | 480        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 158        |\n|    action_queue_updates_total   | 167        |\n|    ice_dug                      | 647        |\n|    water_produced               | 137        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 135          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 887          |\n|    time_elapsed                 | 4101         |\n|    total_timesteps              | 3548000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006242351 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.21        |\n|    explained_variance           | 0.71         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 230          |\n|    n_updates                    | 1772         |\n|    policy_gradient_loss         | -0.000232    |\n|    value_loss                   | 460          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 788          |\n|    water_produced               | 160          |\n--------------------------------------------------\nEval num_timesteps=3552000, episode_reward=1113.00 +/- 794.91\nEpisode length: 790.40 +/- 279.55\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 790           |\n|    mean_reward                  | 1.11e+03      |\n| time/                           |               |\n|    total_timesteps              | 3552000       |\n| train/                          |               |\n|    approx_kl                    | 0.00026841927 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.05         |\n|    explained_variance           | 0.576         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 242           |\n|    n_updates                    | 1774          |\n|    policy_gradient_loss         | -1.73e-05     |\n|    value_loss                   | 506           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 609           |\n|    water_produced               | 137           |\n---------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 145      |\n| time/              |          |\n|    fps             | 863      |\n|    iterations      | 888      |\n|    time_elapsed    | 4114     |\n|    total_timesteps | 3552000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 161           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 889           |\n|    time_elapsed                 | 4118          |\n|    total_timesteps              | 3556000       |\n| train/                          |               |\n|    approx_kl                    | 0.00094293413 |\n|    clip_fraction                | 0.0035        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.19         |\n|    explained_variance           | 0.744         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 239           |\n|    n_updates                    | 1776          |\n|    policy_gradient_loss         | 0.000496      |\n|    value_loss                   | 452           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 843           |\n|    water_produced               | 194           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 167          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 890          |\n|    time_elapsed                 | 4122         |\n|    total_timesteps              | 3560000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009492772 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.697        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 278          |\n|    n_updates                    | 1778         |\n|    policy_gradient_loss         | -9.49e-05    |\n|    value_loss                   | 523          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 838          |\n|    water_produced               | 170          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 151         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 891         |\n|    time_elapsed                 | 4127        |\n|    total_timesteps              | 3564000     |\n| train/                          |             |\n|    approx_kl                    | 0.003784415 |\n|    clip_fraction                | 0.0186      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.02       |\n|    explained_variance           | 0.621       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 265         |\n|    n_updates                    | 1780        |\n|    policy_gradient_loss         | 0.000288    |\n|    value_loss                   | 540         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 299         |\n|    water_produced               | 61.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 136          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 892          |\n|    time_elapsed                 | 4131         |\n|    total_timesteps              | 3568000      |\n| train/                          |              |\n|    approx_kl                    | 0.0040692263 |\n|    clip_fraction                | 0.0221       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.675        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 124          |\n|    n_updates                    | 1782         |\n|    policy_gradient_loss         | 0.000564     |\n|    value_loss                   | 286          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 485          |\n|    water_produced               | 86.8         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 127         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 893         |\n|    time_elapsed                 | 4135        |\n|    total_timesteps              | 3572000     |\n| train/                          |             |\n|    approx_kl                    | 0.004737006 |\n|    clip_fraction                | 0.0315      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.21       |\n|    explained_variance           | 0.755       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 159         |\n|    n_updates                    | 1784        |\n|    policy_gradient_loss         | 0.000463    |\n|    value_loss                   | 322         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 438         |\n|    water_produced               | 95.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 128          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 894          |\n|    time_elapsed                 | 4139         |\n|    total_timesteps              | 3576000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017165432 |\n|    clip_fraction                | 0.004        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.28        |\n|    explained_variance           | 0.778        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 166          |\n|    n_updates                    | 1786         |\n|    policy_gradient_loss         | -0.000791    |\n|    value_loss                   | 352          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 888          |\n|    water_produced               | 197          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 117          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 895          |\n|    time_elapsed                 | 4144         |\n|    total_timesteps              | 3580000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021050598 |\n|    clip_fraction                | 0.011        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.13        |\n|    explained_variance           | 0.668        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 274          |\n|    n_updates                    | 1788         |\n|    policy_gradient_loss         | -0.000367    |\n|    value_loss                   | 581          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 629          |\n|    water_produced               | 114          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 116           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 896           |\n|    time_elapsed                 | 4148          |\n|    total_timesteps              | 3584000       |\n| train/                          |               |\n|    approx_kl                    | 0.00063432514 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.17         |\n|    explained_variance           | 0.759         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 156           |\n|    n_updates                    | 1790          |\n|    policy_gradient_loss         | 0.000696      |\n|    value_loss                   | 345           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 422           |\n|    water_produced               | 59.5          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 134         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 897         |\n|    time_elapsed                 | 4152        |\n|    total_timesteps              | 3588000     |\n| train/                          |             |\n|    approx_kl                    | 0.006095521 |\n|    clip_fraction                | 0.0395      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.39       |\n|    explained_variance           | 0.836       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 186         |\n|    n_updates                    | 1792        |\n|    policy_gradient_loss         | 0.00107     |\n|    value_loss                   | 306         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 937         |\n|    water_produced               | 172         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 139          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 898          |\n|    time_elapsed                 | 4156         |\n|    total_timesteps              | 3592000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022119875 |\n|    clip_fraction                | 0.0131       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.18        |\n|    explained_variance           | 0.701        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 321          |\n|    n_updates                    | 1794         |\n|    policy_gradient_loss         | -0.000189    |\n|    value_loss                   | 625          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 713          |\n|    water_produced               | 114          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 139           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 899           |\n|    time_elapsed                 | 4160          |\n|    total_timesteps              | 3596000       |\n| train/                          |               |\n|    approx_kl                    | 0.00036181652 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.74          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 238           |\n|    n_updates                    | 1796          |\n|    policy_gradient_loss         | 4.08e-05      |\n|    value_loss                   | 444           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 1.02e+03      |\n|    water_produced               | 199           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 148           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 900           |\n|    time_elapsed                 | 4164          |\n|    total_timesteps              | 3600000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046097176 |\n|    clip_fraction                | 0.000875      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.07         |\n|    explained_variance           | 0.703         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 317           |\n|    n_updates                    | 1798          |\n|    policy_gradient_loss         | -3.83e-05     |\n|    value_loss                   | 587           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 752           |\n|    water_produced               | 156           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 164           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 901           |\n|    time_elapsed                 | 4169          |\n|    total_timesteps              | 3604000       |\n| train/                          |               |\n|    approx_kl                    | 0.00094737066 |\n|    clip_fraction                | 0.00262       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.25         |\n|    explained_variance           | 0.866         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 229           |\n|    n_updates                    | 1800          |\n|    policy_gradient_loss         | 0.00082       |\n|    value_loss                   | 466           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 732           |\n|    water_produced               | 136           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 150          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 902          |\n|    time_elapsed                 | 4173         |\n|    total_timesteps              | 3608000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007442803 |\n|    clip_fraction                | 0.00238      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.665        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 195          |\n|    n_updates                    | 1802         |\n|    policy_gradient_loss         | -0.000553    |\n|    value_loss                   | 429          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 628          |\n|    water_produced               | 106          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 144          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 903          |\n|    time_elapsed                 | 4177         |\n|    total_timesteps              | 3612000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029133162 |\n|    clip_fraction                | 0.0167       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.55         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 262          |\n|    n_updates                    | 1804         |\n|    policy_gradient_loss         | 0.000378     |\n|    value_loss                   | 453          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 419          |\n|    water_produced               | 88.7         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 129          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 904          |\n|    time_elapsed                 | 4181         |\n|    total_timesteps              | 3616000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025237228 |\n|    clip_fraction                | 0.0126       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.795        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 146          |\n|    n_updates                    | 1806         |\n|    policy_gradient_loss         | 0.00108      |\n|    value_loss                   | 298          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 712          |\n|    water_produced               | 125          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 123           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 905           |\n|    time_elapsed                 | 4185          |\n|    total_timesteps              | 3620000       |\n| train/                          |               |\n|    approx_kl                    | 0.00036104248 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.71          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 223           |\n|    n_updates                    | 1808          |\n|    policy_gradient_loss         | -7.66e-05     |\n|    value_loss                   | 475           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 701           |\n|    water_produced               | 129           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 128          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 906          |\n|    time_elapsed                 | 4190         |\n|    total_timesteps              | 3624000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005823321 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.12        |\n|    explained_variance           | 0.732        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 233          |\n|    n_updates                    | 1810         |\n|    policy_gradient_loss         | 0.000394     |\n|    value_loss                   | 486          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 813          |\n|    water_produced               | 159          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 154          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 907          |\n|    time_elapsed                 | 4194         |\n|    total_timesteps              | 3628000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022282014 |\n|    clip_fraction                | 0.00687      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.766        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 248          |\n|    n_updates                    | 1812         |\n|    policy_gradient_loss         | -0.000388    |\n|    value_loss                   | 495          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.03e+03     |\n|    water_produced               | 230          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 152         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 908         |\n|    time_elapsed                 | 4198        |\n|    total_timesteps              | 3632000     |\n| train/                          |             |\n|    approx_kl                    | 0.004578226 |\n|    clip_fraction                | 0.0244      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.956      |\n|    explained_variance           | 0.624       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 267         |\n|    n_updates                    | 1814        |\n|    policy_gradient_loss         | 0.000394    |\n|    value_loss                   | 590         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 141         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 678         |\n|    water_produced               | 76.5        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 159           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 909           |\n|    time_elapsed                 | 4202          |\n|    total_timesteps              | 3636000       |\n| train/                          |               |\n|    approx_kl                    | 0.00021936283 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.05         |\n|    explained_variance           | 0.705         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 189           |\n|    n_updates                    | 1816          |\n|    policy_gradient_loss         | -0.000127     |\n|    value_loss                   | 366           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 802           |\n|    water_produced               | 161           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 158         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 910         |\n|    time_elapsed                 | 4206        |\n|    total_timesteps              | 3640000     |\n| train/                          |             |\n|    approx_kl                    | 0.000715661 |\n|    clip_fraction                | 0.00462     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.01       |\n|    explained_variance           | 0.633       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 178         |\n|    n_updates                    | 1818        |\n|    policy_gradient_loss         | -0.00103    |\n|    value_loss                   | 424         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 541         |\n|    water_produced               | 126         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 163           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 911           |\n|    time_elapsed                 | 4210          |\n|    total_timesteps              | 3644000       |\n| train/                          |               |\n|    approx_kl                    | 0.00066637667 |\n|    clip_fraction                | 0.00413       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.1          |\n|    explained_variance           | 0.717         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 184           |\n|    n_updates                    | 1820          |\n|    policy_gradient_loss         | -0.000249     |\n|    value_loss                   | 369           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 908           |\n|    water_produced               | 183           |\n---------------------------------------------------\nEval num_timesteps=3648000, episode_reward=917.36 +/- 377.90\nEpisode length: 924.40 +/- 117.74\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 924           |\n|    mean_reward                  | 917           |\n| time/                           |               |\n|    total_timesteps              | 3648000       |\n| train/                          |               |\n|    approx_kl                    | 0.00040313212 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.972        |\n|    explained_variance           | 0.566         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 313           |\n|    n_updates                    | 1822          |\n|    policy_gradient_loss         | 0.000251      |\n|    value_loss                   | 587           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 680           |\n|    water_produced               | 145           |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 146      |\n| time/              |          |\n|    fps             | 864      |\n|    iterations      | 912      |\n|    time_elapsed    | 4221     |\n|    total_timesteps | 3648000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 150           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 913           |\n|    time_elapsed                 | 4225          |\n|    total_timesteps              | 3652000       |\n| train/                          |               |\n|    approx_kl                    | 0.00013203085 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.01         |\n|    explained_variance           | 0.667         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 225           |\n|    n_updates                    | 1824          |\n|    policy_gradient_loss         | 4.09e-05      |\n|    value_loss                   | 453           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 456           |\n|    water_produced               | 102           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 150          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 914          |\n|    time_elapsed                 | 4229         |\n|    total_timesteps              | 3656000      |\n| train/                          |              |\n|    approx_kl                    | 0.0079609305 |\n|    clip_fraction                | 0.044        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.1         |\n|    explained_variance           | 0.622        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 159          |\n|    n_updates                    | 1826         |\n|    policy_gradient_loss         | -4.99e-05    |\n|    value_loss                   | 336          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 729          |\n|    water_produced               | 162          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 159          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 915          |\n|    time_elapsed                 | 4233         |\n|    total_timesteps              | 3660000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005601546 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.762        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 1828         |\n|    policy_gradient_loss         | -0.000366    |\n|    value_loss                   | 473          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 835          |\n|    water_produced               | 169          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 149         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 916         |\n|    time_elapsed                 | 4238        |\n|    total_timesteps              | 3664000     |\n| train/                          |             |\n|    approx_kl                    | 0.002462327 |\n|    clip_fraction                | 0.00925     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.11       |\n|    explained_variance           | 0.725       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 259         |\n|    n_updates                    | 1830        |\n|    policy_gradient_loss         | -4.25e-05   |\n|    value_loss                   | 543         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 599         |\n|    water_produced               | 133         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 140          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 917          |\n|    time_elapsed                 | 4242         |\n|    total_timesteps              | 3668000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009619015 |\n|    clip_fraction                | 0.00462      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.679        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 227          |\n|    n_updates                    | 1832         |\n|    policy_gradient_loss         | -0.000627    |\n|    value_loss                   | 424          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 622          |\n|    water_produced               | 100          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 146          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 918          |\n|    time_elapsed                 | 4246         |\n|    total_timesteps              | 3672000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014745533 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.723        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 204          |\n|    n_updates                    | 1834         |\n|    policy_gradient_loss         | 0.0003       |\n|    value_loss                   | 390          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 682          |\n|    water_produced               | 133          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 145           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 919           |\n|    time_elapsed                 | 4250          |\n|    total_timesteps              | 3676000       |\n| train/                          |               |\n|    approx_kl                    | 0.00021097032 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.1          |\n|    explained_variance           | 0.671         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 249           |\n|    n_updates                    | 1836          |\n|    policy_gradient_loss         | -0.000207     |\n|    value_loss                   | 483           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 691           |\n|    water_produced               | 157           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 152           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 920           |\n|    time_elapsed                 | 4254          |\n|    total_timesteps              | 3680000       |\n| train/                          |               |\n|    approx_kl                    | 0.00068674405 |\n|    clip_fraction                | 0.00137       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.772         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 223           |\n|    n_updates                    | 1838          |\n|    policy_gradient_loss         | 0.000618      |\n|    value_loss                   | 466           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 160           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 911           |\n|    water_produced               | 199           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 150          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 921          |\n|    time_elapsed                 | 4258         |\n|    total_timesteps              | 3684000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026981216 |\n|    clip_fraction                | 0.0101       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.672        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 240          |\n|    n_updates                    | 1840         |\n|    policy_gradient_loss         | 0.000438     |\n|    value_loss                   | 517          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 624          |\n|    water_produced               | 125          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 166           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 922           |\n|    time_elapsed                 | 4263          |\n|    total_timesteps              | 3688000       |\n| train/                          |               |\n|    approx_kl                    | 0.00028535357 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.09         |\n|    explained_variance           | 0.672         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 234           |\n|    n_updates                    | 1842          |\n|    policy_gradient_loss         | -0.000166     |\n|    value_loss                   | 471           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 904           |\n|    water_produced               | 178           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 164           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 923           |\n|    time_elapsed                 | 4268          |\n|    total_timesteps              | 3692000       |\n| train/                          |               |\n|    approx_kl                    | 0.00016430419 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.994        |\n|    explained_variance           | 0.648         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 274           |\n|    n_updates                    | 1844          |\n|    policy_gradient_loss         | -0.000153     |\n|    value_loss                   | 562           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 565           |\n|    water_produced               | 126           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 161           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 924           |\n|    time_elapsed                 | 4271          |\n|    total_timesteps              | 3696000       |\n| train/                          |               |\n|    approx_kl                    | 0.00036623646 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.06         |\n|    explained_variance           | 0.743         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 165           |\n|    n_updates                    | 1846          |\n|    policy_gradient_loss         | 0.000133      |\n|    value_loss                   | 360           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 891           |\n|    water_produced               | 136           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 152           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 925           |\n|    time_elapsed                 | 4276          |\n|    total_timesteps              | 3700000       |\n| train/                          |               |\n|    approx_kl                    | 0.00028985384 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.12         |\n|    explained_variance           | 0.686         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 335           |\n|    n_updates                    | 1848          |\n|    policy_gradient_loss         | -8.25e-05     |\n|    value_loss                   | 607           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 893           |\n|    water_produced               | 154           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 159         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 926         |\n|    time_elapsed                 | 4280        |\n|    total_timesteps              | 3704000     |\n| train/                          |             |\n|    approx_kl                    | 0.003541942 |\n|    clip_fraction                | 0.0171      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.982      |\n|    explained_variance           | 0.692       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 245         |\n|    n_updates                    | 1850        |\n|    policy_gradient_loss         | 0.00194     |\n|    value_loss                   | 482         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 141         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 731         |\n|    water_produced               | 162         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 131          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 927          |\n|    time_elapsed                 | 4284         |\n|    total_timesteps              | 3708000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012442276 |\n|    clip_fraction                | 0.00437      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.991       |\n|    explained_variance           | 0.656        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 197          |\n|    n_updates                    | 1852         |\n|    policy_gradient_loss         | -0.000668    |\n|    value_loss                   | 435          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 224          |\n|    water_produced               | 44.5         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 128         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 928         |\n|    time_elapsed                 | 4288        |\n|    total_timesteps              | 3712000     |\n| train/                          |             |\n|    approx_kl                    | 0.003873571 |\n|    clip_fraction                | 0.0187      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.14       |\n|    explained_variance           | 0.726       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 114         |\n|    n_updates                    | 1854        |\n|    policy_gradient_loss         | -0.000122   |\n|    value_loss                   | 244         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 556         |\n|    water_produced               | 110         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 126          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 929          |\n|    time_elapsed                 | 4292         |\n|    total_timesteps              | 3716000      |\n| train/                          |              |\n|    approx_kl                    | 0.0059181256 |\n|    clip_fraction                | 0.0408       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.2         |\n|    explained_variance           | 0.748        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 177          |\n|    n_updates                    | 1856         |\n|    policy_gradient_loss         | 0.00148      |\n|    value_loss                   | 361          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 801          |\n|    water_produced               | 129          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 126          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 930          |\n|    time_elapsed                 | 4296         |\n|    total_timesteps              | 3720000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022269115 |\n|    clip_fraction                | 0.00962      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.792        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 1858         |\n|    policy_gradient_loss         | 0.000411     |\n|    value_loss                   | 511          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 661          |\n|    water_produced               | 153          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 117          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 931          |\n|    time_elapsed                 | 4301         |\n|    total_timesteps              | 3724000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012596288 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.788        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 1860         |\n|    policy_gradient_loss         | -0.0007      |\n|    value_loss                   | 488          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 518          |\n|    water_produced               | 120          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 123         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 932         |\n|    time_elapsed                 | 4305        |\n|    total_timesteps              | 3728000     |\n| train/                          |             |\n|    approx_kl                    | 0.003309812 |\n|    clip_fraction                | 0.0185      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.22       |\n|    explained_variance           | 0.8         |\n|    learning_rate                | 0.0003      |\n|    loss                         | 224         |\n|    n_updates                    | 1862        |\n|    policy_gradient_loss         | 0.000543    |\n|    value_loss                   | 449         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 133         |\n|    action_queue_updates_total   | 140         |\n|    ice_dug                      | 386         |\n|    water_produced               | 72          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 124          |\n| time/                           |              |\n|    fps                          | 866          |\n|    iterations                   | 933          |\n|    time_elapsed                 | 4309         |\n|    total_timesteps              | 3732000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022351048 |\n|    clip_fraction                | 0.0149       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.86         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 158          |\n|    n_updates                    | 1864         |\n|    policy_gradient_loss         | -0.000272    |\n|    value_loss                   | 325          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 596          |\n|    water_produced               | 118          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 123          |\n| time/                           |              |\n|    fps                          | 866          |\n|    iterations                   | 934          |\n|    time_elapsed                 | 4313         |\n|    total_timesteps              | 3736000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005656585 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.758        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 264          |\n|    n_updates                    | 1866         |\n|    policy_gradient_loss         | -0.000328    |\n|    value_loss                   | 545          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 611          |\n|    water_produced               | 124          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 103          |\n| time/                           |              |\n|    fps                          | 866          |\n|    iterations                   | 935          |\n|    time_elapsed                 | 4317         |\n|    total_timesteps              | 3740000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019626273 |\n|    clip_fraction                | 0.00538      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.42        |\n|    explained_variance           | 0.85         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 1868         |\n|    policy_gradient_loss         | -0.000832    |\n|    value_loss                   | 502          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 435          |\n|    water_produced               | 56           |\n--------------------------------------------------\nEval num_timesteps=3744000, episode_reward=829.24 +/- 780.08\nEpisode length: 731.40 +/- 329.43\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 731          |\n|    mean_reward                  | 829          |\n| time/                           |              |\n|    total_timesteps              | 3744000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014912272 |\n|    clip_fraction                | 0.00375      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.23        |\n|    explained_variance           | 0.728        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 210          |\n|    n_updates                    | 1870         |\n|    policy_gradient_loss         | -0.000726    |\n|    value_loss                   | 389          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 920          |\n|    water_produced               | 209          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 122      |\n| time/              |          |\n|    fps             | 865      |\n|    iterations      | 936      |\n|    time_elapsed    | 4327     |\n|    total_timesteps | 3744000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 130          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 937          |\n|    time_elapsed                 | 4331         |\n|    total_timesteps              | 3748000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012721072 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.797        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 299          |\n|    n_updates                    | 1872         |\n|    policy_gradient_loss         | -0.00018     |\n|    value_loss                   | 656          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 513          |\n|    water_produced               | 111          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 150          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 938          |\n|    time_elapsed                 | 4335         |\n|    total_timesteps              | 3752000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005181523 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.31        |\n|    explained_variance           | 0.815        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 289          |\n|    n_updates                    | 1874         |\n|    policy_gradient_loss         | 7.47e-05     |\n|    value_loss                   | 465          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 943          |\n|    water_produced               | 214          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 165          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 939          |\n|    time_elapsed                 | 4340         |\n|    total_timesteps              | 3756000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018455129 |\n|    clip_fraction                | 0.0045       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.18        |\n|    explained_variance           | 0.83         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 326          |\n|    n_updates                    | 1876         |\n|    policy_gradient_loss         | -1.2e-05     |\n|    value_loss                   | 658          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 918          |\n|    water_produced               | 198          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 175          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 940          |\n|    time_elapsed                 | 4345         |\n|    total_timesteps              | 3760000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037339584 |\n|    clip_fraction                | 0.0201       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.07        |\n|    explained_variance           | 0.805        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 351          |\n|    n_updates                    | 1878         |\n|    policy_gradient_loss         | 0.00305      |\n|    value_loss                   | 648          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 512          |\n|    water_produced               | 103          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 155          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 941          |\n|    time_elapsed                 | 4350         |\n|    total_timesteps              | 3764000      |\n| train/                          |              |\n|    approx_kl                    | 0.0047358344 |\n|    clip_fraction                | 0.0215       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.22        |\n|    explained_variance           | 0.798        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 166          |\n|    n_updates                    | 1880         |\n|    policy_gradient_loss         | -0.000864    |\n|    value_loss                   | 382          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 654          |\n|    water_produced               | 113          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 158          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 942          |\n|    time_elapsed                 | 4355         |\n|    total_timesteps              | 3768000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005950335 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.29        |\n|    explained_variance           | 0.836        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 207          |\n|    n_updates                    | 1882         |\n|    policy_gradient_loss         | -0.000176    |\n|    value_loss                   | 433          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 674          |\n|    water_produced               | 124          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 141          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 943          |\n|    time_elapsed                 | 4360         |\n|    total_timesteps              | 3772000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017778017 |\n|    clip_fraction                | 0.008        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.761        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 1884         |\n|    policy_gradient_loss         | 0.000324     |\n|    value_loss                   | 457          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 678          |\n|    water_produced               | 133          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 127        |\n| time/                           |            |\n|    fps                          | 865        |\n|    iterations                   | 944        |\n|    time_elapsed                 | 4365       |\n|    total_timesteps              | 3776000    |\n| train/                          |            |\n|    approx_kl                    | 0.00276604 |\n|    clip_fraction                | 0.0157     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.27      |\n|    explained_variance           | 0.814      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 238        |\n|    n_updates                    | 1886       |\n|    policy_gradient_loss         | 2.44e-05   |\n|    value_loss                   | 516        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 150        |\n|    action_queue_updates_total   | 157        |\n|    ice_dug                      | 586        |\n|    water_produced               | 131        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 133          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 945          |\n|    time_elapsed                 | 4369         |\n|    total_timesteps              | 3780000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008883128 |\n|    clip_fraction                | 0.00162      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.13        |\n|    explained_variance           | 0.789        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 242          |\n|    n_updates                    | 1888         |\n|    policy_gradient_loss         | -0.000369    |\n|    value_loss                   | 476          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 651          |\n|    water_produced               | 133          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 143          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 946          |\n|    time_elapsed                 | 4374         |\n|    total_timesteps              | 3784000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011989844 |\n|    clip_fraction                | 0.00288      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.28        |\n|    explained_variance           | 0.842        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 257          |\n|    n_updates                    | 1890         |\n|    policy_gradient_loss         | -0.000635    |\n|    value_loss                   | 515          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 703          |\n|    water_produced               | 158          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 148          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 947          |\n|    time_elapsed                 | 4378         |\n|    total_timesteps              | 3788000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010975874 |\n|    clip_fraction                | 0.00612      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.825        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 234          |\n|    n_updates                    | 1892         |\n|    policy_gradient_loss         | -0.000249    |\n|    value_loss                   | 489          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 841          |\n|    water_produced               | 149          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 151          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 948          |\n|    time_elapsed                 | 4383         |\n|    total_timesteps              | 3792000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013024809 |\n|    clip_fraction                | 0.00237      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.708        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 230          |\n|    n_updates                    | 1894         |\n|    policy_gradient_loss         | -0.000398    |\n|    value_loss                   | 514          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 630          |\n|    water_produced               | 151          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 152           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 949           |\n|    time_elapsed                 | 4387          |\n|    total_timesteps              | 3796000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025010423 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.18         |\n|    explained_variance           | 0.833         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 214           |\n|    n_updates                    | 1896          |\n|    policy_gradient_loss         | -0.000142     |\n|    value_loss                   | 402           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 763           |\n|    water_produced               | 132           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 157          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 950          |\n|    time_elapsed                 | 4392         |\n|    total_timesteps              | 3800000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002326922 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.1         |\n|    explained_variance           | 0.727        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 254          |\n|    n_updates                    | 1898         |\n|    policy_gradient_loss         | -0.000242    |\n|    value_loss                   | 543          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 769          |\n|    water_produced               | 157          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 150           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 951           |\n|    time_elapsed                 | 4397          |\n|    total_timesteps              | 3804000       |\n| train/                          |               |\n|    approx_kl                    | 0.00062179274 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.11         |\n|    explained_variance           | 0.827         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 253           |\n|    n_updates                    | 1900          |\n|    policy_gradient_loss         | 3.07e-05      |\n|    value_loss                   | 514           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 534           |\n|    water_produced               | 124           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 164           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 952           |\n|    time_elapsed                 | 4401          |\n|    total_timesteps              | 3808000       |\n| train/                          |               |\n|    approx_kl                    | 0.00053001335 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.19         |\n|    explained_variance           | 0.821         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 202           |\n|    n_updates                    | 1902          |\n|    policy_gradient_loss         | -0.000282     |\n|    value_loss                   | 454           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 1.02e+03      |\n|    water_produced               | 217           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 154          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 953          |\n|    time_elapsed                 | 4405         |\n|    total_timesteps              | 3812000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024547824 |\n|    clip_fraction                | 0.0141       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.981       |\n|    explained_variance           | 0.685        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 313          |\n|    n_updates                    | 1904         |\n|    policy_gradient_loss         | 0.000179     |\n|    value_loss                   | 602          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 474          |\n|    water_produced               | 103          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 159           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 954           |\n|    time_elapsed                 | 4410          |\n|    total_timesteps              | 3816000       |\n| train/                          |               |\n|    approx_kl                    | 0.00040380395 |\n|    clip_fraction                | 0.00188       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.05         |\n|    explained_variance           | 0.766         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 156           |\n|    n_updates                    | 1906          |\n|    policy_gradient_loss         | -4.26e-05     |\n|    value_loss                   | 356           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 731           |\n|    water_produced               | 158           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 154          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 955          |\n|    time_elapsed                 | 4414         |\n|    total_timesteps              | 3820000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012456087 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.66         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 252          |\n|    n_updates                    | 1908         |\n|    policy_gradient_loss         | -0.000332    |\n|    value_loss                   | 471          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 596          |\n|    water_produced               | 137          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 150         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 956         |\n|    time_elapsed                 | 4419        |\n|    total_timesteps              | 3824000     |\n| train/                          |             |\n|    approx_kl                    | 0.000739325 |\n|    clip_fraction                | 0.002       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.2        |\n|    explained_variance           | 0.834       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 217         |\n|    n_updates                    | 1910        |\n|    policy_gradient_loss         | -0.000295   |\n|    value_loss                   | 415         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 566         |\n|    water_produced               | 102         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 132          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 957          |\n|    time_elapsed                 | 4423         |\n|    total_timesteps              | 3828000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042835413 |\n|    clip_fraction                | 0.0258       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.12        |\n|    explained_variance           | 0.683        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 169          |\n|    n_updates                    | 1912         |\n|    policy_gradient_loss         | 0.00215      |\n|    value_loss                   | 385          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 698          |\n|    water_produced               | 130          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 139          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 958          |\n|    time_elapsed                 | 4428         |\n|    total_timesteps              | 3832000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014085465 |\n|    clip_fraction                | 0.00237      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.1         |\n|    explained_variance           | 0.703        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 1914         |\n|    policy_gradient_loss         | 0.000805     |\n|    value_loss                   | 479          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 696          |\n|    water_produced               | 136          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 134           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 959           |\n|    time_elapsed                 | 4432          |\n|    total_timesteps              | 3836000       |\n| train/                          |               |\n|    approx_kl                    | 0.00024406644 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.12         |\n|    explained_variance           | 0.811         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 272           |\n|    n_updates                    | 1916          |\n|    policy_gradient_loss         | -4.08e-05     |\n|    value_loss                   | 493           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 667           |\n|    water_produced               | 132           |\n---------------------------------------------------\nEval num_timesteps=3840000, episode_reward=525.96 +/- 518.86\nEpisode length: 644.60 +/- 301.43\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 645         |\n|    mean_reward                  | 526         |\n| time/                           |             |\n|    total_timesteps              | 3840000     |\n| train/                          |             |\n|    approx_kl                    | 0.001063436 |\n|    clip_fraction                | 0.0035      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.08       |\n|    explained_variance           | 0.736       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 191         |\n|    n_updates                    | 1918        |\n|    policy_gradient_loss         | -0.00035    |\n|    value_loss                   | 417         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.14e+03    |\n|    water_produced               | 246         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 157      |\n| time/              |          |\n|    fps             | 864      |\n|    iterations      | 960      |\n|    time_elapsed    | 4443     |\n|    total_timesteps | 3840000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 160          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 961          |\n|    time_elapsed                 | 4448         |\n|    total_timesteps              | 3844000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025564022 |\n|    clip_fraction                | 0.0122       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.955       |\n|    explained_variance           | 0.702        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 297          |\n|    n_updates                    | 1920         |\n|    policy_gradient_loss         | 0.00123      |\n|    value_loss                   | 627          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 713          |\n|    water_produced               | 117          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 155           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 962           |\n|    time_elapsed                 | 4452          |\n|    total_timesteps              | 3848000       |\n| train/                          |               |\n|    approx_kl                    | 0.00026743853 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.07         |\n|    explained_variance           | 0.776         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 219           |\n|    n_updates                    | 1922          |\n|    policy_gradient_loss         | 3.38e-05      |\n|    value_loss                   | 427           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 466           |\n|    water_produced               | 109           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 156         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 963         |\n|    time_elapsed                 | 4457        |\n|    total_timesteps              | 3852000     |\n| train/                          |             |\n|    approx_kl                    | 0.004982966 |\n|    clip_fraction                | 0.0371      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.17       |\n|    explained_variance           | 0.794       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 193         |\n|    n_updates                    | 1924        |\n|    policy_gradient_loss         | 5.11e-05    |\n|    value_loss                   | 350         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 642         |\n|    water_produced               | 140         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 173          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 964          |\n|    time_elapsed                 | 4461         |\n|    total_timesteps              | 3856000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014024327 |\n|    clip_fraction                | 0.00737      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.735        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 1926         |\n|    policy_gradient_loss         | -8.74e-06    |\n|    value_loss                   | 447          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.22e+03     |\n|    water_produced               | 212          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 159          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 965          |\n|    time_elapsed                 | 4465         |\n|    total_timesteps              | 3860000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017718195 |\n|    clip_fraction                | 0.00412      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.12        |\n|    explained_variance           | 0.803        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 355          |\n|    n_updates                    | 1928         |\n|    policy_gradient_loss         | -0.000987    |\n|    value_loss                   | 772          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 979          |\n|    water_produced               | 177          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 140         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 966         |\n|    time_elapsed                 | 4470        |\n|    total_timesteps              | 3864000     |\n| train/                          |             |\n|    approx_kl                    | 0.007210174 |\n|    clip_fraction                | 0.0431      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.996      |\n|    explained_variance           | 0.699       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 259         |\n|    n_updates                    | 1930        |\n|    policy_gradient_loss         | 0.00113     |\n|    value_loss                   | 544         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 289         |\n|    water_produced               | 27.2        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 170          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 967          |\n|    time_elapsed                 | 4474         |\n|    total_timesteps              | 3868000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028452503 |\n|    clip_fraction                | 0.0141       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.653        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 116          |\n|    n_updates                    | 1932         |\n|    policy_gradient_loss         | 0.000238     |\n|    value_loss                   | 250          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.18e+03     |\n|    water_produced               | 250          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 162           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 968           |\n|    time_elapsed                 | 4478          |\n|    total_timesteps              | 3872000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017093026 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.991        |\n|    explained_variance           | 0.741         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 347           |\n|    n_updates                    | 1934          |\n|    policy_gradient_loss         | 0.000141      |\n|    value_loss                   | 742           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 469           |\n|    water_produced               | 99.8          |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 144           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 969           |\n|    time_elapsed                 | 4483          |\n|    total_timesteps              | 3876000       |\n| train/                          |               |\n|    approx_kl                    | 0.00020557603 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.12         |\n|    explained_variance           | 0.8           |\n|    learning_rate                | 0.0003        |\n|    loss                         | 167           |\n|    n_updates                    | 1936          |\n|    policy_gradient_loss         | 0.000128      |\n|    value_loss                   | 409           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 673           |\n|    water_produced               | 132           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 153          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 970          |\n|    time_elapsed                 | 4487         |\n|    total_timesteps              | 3880000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017231194 |\n|    clip_fraction                | 0.0133       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.07        |\n|    explained_variance           | 0.719        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 1938         |\n|    policy_gradient_loss         | 0.000345     |\n|    value_loss                   | 449          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 969          |\n|    water_produced               | 220          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 179          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 971          |\n|    time_elapsed                 | 4492         |\n|    total_timesteps              | 3884000      |\n| train/                          |              |\n|    approx_kl                    | 0.0043318234 |\n|    clip_fraction                | 0.0198       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.04        |\n|    explained_variance           | 0.756        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 321          |\n|    n_updates                    | 1940         |\n|    policy_gradient_loss         | -0.00109     |\n|    value_loss                   | 641          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 756          |\n|    water_produced               | 154          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 145           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 972           |\n|    time_elapsed                 | 4496          |\n|    total_timesteps              | 3888000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032398905 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.967        |\n|    explained_variance           | 0.644         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 250           |\n|    n_updates                    | 1942          |\n|    policy_gradient_loss         | 0.00014       |\n|    value_loss                   | 516           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 370           |\n|    water_produced               | 88.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 973          |\n|    time_elapsed                 | 4500         |\n|    total_timesteps              | 3892000      |\n| train/                          |              |\n|    approx_kl                    | 0.0069763744 |\n|    clip_fraction                | 0.0303       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.745        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 141          |\n|    n_updates                    | 1944         |\n|    policy_gradient_loss         | 0.000317     |\n|    value_loss                   | 332          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 327          |\n|    water_produced               | 66.3         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 132         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 974         |\n|    time_elapsed                 | 4505        |\n|    total_timesteps              | 3896000     |\n| train/                          |             |\n|    approx_kl                    | 0.006868679 |\n|    clip_fraction                | 0.0326      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.16       |\n|    explained_variance           | 0.72        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 137         |\n|    n_updates                    | 1946        |\n|    policy_gradient_loss         | 0.00166     |\n|    value_loss                   | 281         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 149         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 521         |\n|    water_produced               | 102         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 97.3         |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 975          |\n|    time_elapsed                 | 4509         |\n|    total_timesteps              | 3900000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007316078 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.793        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 188          |\n|    n_updates                    | 1948         |\n|    policy_gradient_loss         | -0.000308    |\n|    value_loss                   | 416          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 238          |\n|    water_produced               | 53           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 87.6         |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 976          |\n|    time_elapsed                 | 4513         |\n|    total_timesteps              | 3904000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013701856 |\n|    clip_fraction                | 0.00237      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.28        |\n|    explained_variance           | 0.811        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 129          |\n|    n_updates                    | 1950         |\n|    policy_gradient_loss         | 0.000786     |\n|    value_loss                   | 254          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 545          |\n|    water_produced               | 108          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 93           |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 977          |\n|    time_elapsed                 | 4518         |\n|    total_timesteps              | 3908000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006705302 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.31        |\n|    explained_variance           | 0.839        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 226          |\n|    n_updates                    | 1952         |\n|    policy_gradient_loss         | 0.000286     |\n|    value_loss                   | 443          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 582          |\n|    water_produced               | 114          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 130          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 978          |\n|    time_elapsed                 | 4522         |\n|    total_timesteps              | 3912000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029511198 |\n|    clip_fraction                | 0.0175       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.36        |\n|    explained_variance           | 0.799        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 276          |\n|    n_updates                    | 1954         |\n|    policy_gradient_loss         | -2.42e-05    |\n|    value_loss                   | 580          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.1e+03      |\n|    water_produced               | 244          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 132          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 979          |\n|    time_elapsed                 | 4527         |\n|    total_timesteps              | 3916000      |\n| train/                          |              |\n|    approx_kl                    | 0.0048628836 |\n|    clip_fraction                | 0.0255       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.828        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 341          |\n|    n_updates                    | 1956         |\n|    policy_gradient_loss         | 0.000452     |\n|    value_loss                   | 719          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 542          |\n|    water_produced               | 111          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 135           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 980           |\n|    time_elapsed                 | 4531          |\n|    total_timesteps              | 3920000       |\n| train/                          |               |\n|    approx_kl                    | 0.00043561394 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.09         |\n|    explained_variance           | 0.709         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 207           |\n|    n_updates                    | 1958          |\n|    policy_gradient_loss         | -6.26e-05     |\n|    value_loss                   | 472           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 317           |\n|    water_produced               | 67.8          |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 146         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 981         |\n|    time_elapsed                 | 4535        |\n|    total_timesteps              | 3924000     |\n| train/                          |             |\n|    approx_kl                    | 0.008293719 |\n|    clip_fraction                | 0.0565      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.41       |\n|    explained_variance           | 0.897       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 147         |\n|    n_updates                    | 1960        |\n|    policy_gradient_loss         | 0.000155    |\n|    value_loss                   | 275         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 886         |\n|    water_produced               | 158         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 157          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 982          |\n|    time_elapsed                 | 4540         |\n|    total_timesteps              | 3928000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029305555 |\n|    clip_fraction                | 0.015        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.708        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 284          |\n|    n_updates                    | 1962         |\n|    policy_gradient_loss         | -0.000519    |\n|    value_loss                   | 644          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 842          |\n|    water_produced               | 166          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 139          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 983          |\n|    time_elapsed                 | 4544         |\n|    total_timesteps              | 3932000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014638748 |\n|    clip_fraction                | 0.00262      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.994       |\n|    explained_variance           | 0.773        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 206          |\n|    n_updates                    | 1964         |\n|    policy_gradient_loss         | 0.000117     |\n|    value_loss                   | 472          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 800          |\n|    water_produced               | 157          |\n--------------------------------------------------\nEval num_timesteps=3936000, episode_reward=711.60 +/- 889.16\nEpisode length: 585.60 +/- 338.48\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 586           |\n|    mean_reward                  | 712           |\n| time/                           |               |\n|    total_timesteps              | 3936000       |\n| train/                          |               |\n|    approx_kl                    | 0.00041145724 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.13         |\n|    explained_variance           | 0.76          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 247           |\n|    n_updates                    | 1966          |\n|    policy_gradient_loss         | -1.73e-05     |\n|    value_loss                   | 510           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 255           |\n|    water_produced               | 50            |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 126      |\n| time/              |          |\n|    fps             | 863      |\n|    iterations      | 984      |\n|    time_elapsed    | 4557     |\n|    total_timesteps | 3936000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 157          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 985          |\n|    time_elapsed                 | 4561         |\n|    total_timesteps              | 3940000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010053519 |\n|    clip_fraction                | 0.00188      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.18        |\n|    explained_variance           | 0.838        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 129          |\n|    n_updates                    | 1968         |\n|    policy_gradient_loss         | -2.94e-05    |\n|    value_loss                   | 258          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.02e+03     |\n|    water_produced               | 216          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 986          |\n|    time_elapsed                 | 4565         |\n|    total_timesteps              | 3944000      |\n| train/                          |              |\n|    approx_kl                    | 0.0001566699 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.788        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 355          |\n|    n_updates                    | 1970         |\n|    policy_gradient_loss         | -0.000181    |\n|    value_loss                   | 653          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 422          |\n|    water_produced               | 68.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 129           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 987           |\n|    time_elapsed                 | 4569          |\n|    total_timesteps              | 3948000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017140507 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.22         |\n|    explained_variance           | 0.869         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 195           |\n|    n_updates                    | 1972          |\n|    policy_gradient_loss         | -7.88e-07     |\n|    value_loss                   | 384           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 719           |\n|    water_produced               | 121           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 134          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 988          |\n|    time_elapsed                 | 4574         |\n|    total_timesteps              | 3952000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015727956 |\n|    clip_fraction                | 0.00125      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.32        |\n|    explained_variance           | 0.854        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 272          |\n|    n_updates                    | 1974         |\n|    policy_gradient_loss         | -0.000454    |\n|    value_loss                   | 531          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 843          |\n|    water_produced               | 180          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 152         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 989         |\n|    time_elapsed                 | 4578        |\n|    total_timesteps              | 3956000     |\n| train/                          |             |\n|    approx_kl                    | 0.004890873 |\n|    clip_fraction                | 0.0273      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.1        |\n|    explained_variance           | 0.829       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 238         |\n|    n_updates                    | 1976        |\n|    policy_gradient_loss         | 0.00146     |\n|    value_loss                   | 528         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 599         |\n|    water_produced               | 136         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 133          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 990          |\n|    time_elapsed                 | 4583         |\n|    total_timesteps              | 3960000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023275749 |\n|    clip_fraction                | 0.0124       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.69         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 1978         |\n|    policy_gradient_loss         | -0.000783    |\n|    value_loss                   | 455          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 741          |\n|    water_produced               | 128          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 163          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 991          |\n|    time_elapsed                 | 4587         |\n|    total_timesteps              | 3964000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016142331 |\n|    clip_fraction                | 0.01         |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.12        |\n|    explained_variance           | 0.778        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 230          |\n|    n_updates                    | 1980         |\n|    policy_gradient_loss         | -0.00124     |\n|    value_loss                   | 473          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.14e+03     |\n|    water_produced               | 210          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 160          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 992          |\n|    time_elapsed                 | 4591         |\n|    total_timesteps              | 3968000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028484273 |\n|    clip_fraction                | 0.0154       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1           |\n|    explained_variance           | 0.691        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 322          |\n|    n_updates                    | 1982         |\n|    policy_gradient_loss         | 0.000476     |\n|    value_loss                   | 629          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 481          |\n|    water_produced               | 106          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 141           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 993           |\n|    time_elapsed                 | 4596          |\n|    total_timesteps              | 3972000       |\n| train/                          |               |\n|    approx_kl                    | 0.00027472404 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.08         |\n|    explained_variance           | 0.726         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 245           |\n|    n_updates                    | 1984          |\n|    policy_gradient_loss         | 0.000262      |\n|    value_loss                   | 451           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 417           |\n|    water_produced               | 93            |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 131         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 994         |\n|    time_elapsed                 | 4600        |\n|    total_timesteps              | 3976000     |\n| train/                          |             |\n|    approx_kl                    | 0.007118202 |\n|    clip_fraction                | 0.0379      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.19       |\n|    explained_variance           | 0.822       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 173         |\n|    n_updates                    | 1986        |\n|    policy_gradient_loss         | 0.00133     |\n|    value_loss                   | 329         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 554         |\n|    water_produced               | 84.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 135          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 995          |\n|    time_elapsed                 | 4604         |\n|    total_timesteps              | 3980000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013469576 |\n|    clip_fraction                | 0.00362      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.769        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 184          |\n|    n_updates                    | 1988         |\n|    policy_gradient_loss         | 0.000339     |\n|    value_loss                   | 390          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 663          |\n|    water_produced               | 150          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 118          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 996          |\n|    time_elapsed                 | 4609         |\n|    total_timesteps              | 3984000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010190783 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.821        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 1990         |\n|    policy_gradient_loss         | -0.000249    |\n|    value_loss                   | 525          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 638          |\n|    water_produced               | 128          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 113           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 997           |\n|    time_elapsed                 | 4613          |\n|    total_timesteps              | 3988000       |\n| train/                          |               |\n|    approx_kl                    | 0.00071842066 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.2          |\n|    explained_variance           | 0.859         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 236           |\n|    n_updates                    | 1992          |\n|    policy_gradient_loss         | -1.85e-05     |\n|    value_loss                   | 450           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 158           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 527           |\n|    water_produced               | 79.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 106          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 998          |\n|    time_elapsed                 | 4618         |\n|    total_timesteps              | 3992000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030512768 |\n|    clip_fraction                | 0.0126       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.72         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 171          |\n|    n_updates                    | 1994         |\n|    policy_gradient_loss         | -0.000239    |\n|    value_loss                   | 366          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 251          |\n|    water_produced               | 62.2         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 105         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 999         |\n|    time_elapsed                 | 4622        |\n|    total_timesteps              | 3996000     |\n| train/                          |             |\n|    approx_kl                    | 0.004425644 |\n|    clip_fraction                | 0.0196      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.56       |\n|    explained_variance           | 0.875       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 170         |\n|    n_updates                    | 1996        |\n|    policy_gradient_loss         | 0.000328    |\n|    value_loss                   | 317         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 469         |\n|    water_produced               | 80.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 108          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1000         |\n|    time_elapsed                 | 4626         |\n|    total_timesteps              | 4000000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013513925 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.41        |\n|    explained_variance           | 0.862        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 1998         |\n|    policy_gradient_loss         | -0.000155    |\n|    value_loss                   | 386          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 703          |\n|    water_produced               | 164          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 120          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1001         |\n|    time_elapsed                 | 4631         |\n|    total_timesteps              | 4004000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032865957 |\n|    clip_fraction                | 0.019        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.22        |\n|    explained_variance           | 0.807        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 237          |\n|    n_updates                    | 2000         |\n|    policy_gradient_loss         | -0.00205     |\n|    value_loss                   | 483          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 871          |\n|    water_produced               | 187          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 124          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1002         |\n|    time_elapsed                 | 4635         |\n|    total_timesteps              | 4008000      |\n| train/                          |              |\n|    approx_kl                    | 0.0051933452 |\n|    clip_fraction                | 0.0256       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.792        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 290          |\n|    n_updates                    | 2002         |\n|    policy_gradient_loss         | 0.00105      |\n|    value_loss                   | 632          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 539          |\n|    water_produced               | 99           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 121           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1003          |\n|    time_elapsed                 | 4639          |\n|    total_timesteps              | 4012000       |\n| train/                          |               |\n|    approx_kl                    | 0.00038432138 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.34         |\n|    explained_variance           | 0.891         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 180           |\n|    n_updates                    | 2004          |\n|    policy_gradient_loss         | -2.76e-05     |\n|    value_loss                   | 428           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 292           |\n|    water_produced               | 47            |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 122         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 1004        |\n|    time_elapsed                 | 4644        |\n|    total_timesteps              | 4016000     |\n| train/                          |             |\n|    approx_kl                    | 0.009788178 |\n|    clip_fraction                | 0.0526      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.26       |\n|    explained_variance           | 0.836       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 130         |\n|    n_updates                    | 2006        |\n|    policy_gradient_loss         | 0.00102     |\n|    value_loss                   | 272         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 463         |\n|    water_produced               | 82.3        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 114          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1005         |\n|    time_elapsed                 | 4648         |\n|    total_timesteps              | 4020000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019265652 |\n|    clip_fraction                | 0.00838      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.39        |\n|    explained_variance           | 0.883        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 178          |\n|    n_updates                    | 2008         |\n|    policy_gradient_loss         | -9.96e-05    |\n|    value_loss                   | 388          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 595          |\n|    water_produced               | 127          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 110           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1006          |\n|    time_elapsed                 | 4652          |\n|    total_timesteps              | 4024000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017925029 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.27         |\n|    explained_variance           | 0.812         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 272           |\n|    n_updates                    | 2010          |\n|    policy_gradient_loss         | 0.000273      |\n|    value_loss                   | 507           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 768           |\n|    water_produced               | 168           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 110          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1007         |\n|    time_elapsed                 | 4657         |\n|    total_timesteps              | 4028000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013663216 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1           |\n|    explained_variance           | 0.789        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 2012         |\n|    policy_gradient_loss         | -0.000352    |\n|    value_loss                   | 459          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 561          |\n|    water_produced               | 97.8         |\n--------------------------------------------------\nEval num_timesteps=4032000, episode_reward=14.00 +/- 18.28\nEpisode length: 308.00 +/- 9.80\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 308          |\n|    mean_reward                  | 14           |\n| time/                           |              |\n|    total_timesteps              | 4032000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005057937 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.734        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 2014         |\n|    policy_gradient_loss         | -0.00022     |\n|    value_loss                   | 424          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 628          |\n|    water_produced               | 125          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 126      |\n| time/              |          |\n|    fps             | 864      |\n|    iterations      | 1008     |\n|    time_elapsed    | 4663     |\n|    total_timesteps | 4032000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 130         |\n| time/                           |             |\n|    fps                          | 864         |\n|    iterations                   | 1009        |\n|    time_elapsed                 | 4668        |\n|    total_timesteps              | 4036000     |\n| train/                          |             |\n|    approx_kl                    | 0.001691705 |\n|    clip_fraction                | 0.00488     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.18       |\n|    explained_variance           | 0.836       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 260         |\n|    n_updates                    | 2016        |\n|    policy_gradient_loss         | 0.000887    |\n|    value_loss                   | 467         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 141         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 539         |\n|    water_produced               | 101         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 113          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1010         |\n|    time_elapsed                 | 4672         |\n|    total_timesteps              | 4040000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011208189 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.21        |\n|    explained_variance           | 0.873        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 186          |\n|    n_updates                    | 2018         |\n|    policy_gradient_loss         | -0.000138    |\n|    value_loss                   | 394          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 340          |\n|    water_produced               | 44.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 103          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1011         |\n|    time_elapsed                 | 4676         |\n|    total_timesteps              | 4044000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038461431 |\n|    clip_fraction                | 0.0211       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.21        |\n|    explained_variance           | 0.86         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 132          |\n|    n_updates                    | 2020         |\n|    policy_gradient_loss         | -0.000198    |\n|    value_loss                   | 274          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 639          |\n|    water_produced               | 121          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 105           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1012          |\n|    time_elapsed                 | 4681          |\n|    total_timesteps              | 4048000       |\n| train/                          |               |\n|    approx_kl                    | 0.00039101485 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.03         |\n|    explained_variance           | 0.729         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 198           |\n|    n_updates                    | 2022          |\n|    policy_gradient_loss         | -0.000376     |\n|    value_loss                   | 452           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 779           |\n|    water_produced               | 104           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 108          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1013         |\n|    time_elapsed                 | 4685         |\n|    total_timesteps              | 4052000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028943692 |\n|    clip_fraction                | 0.0101       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.732        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 2024         |\n|    policy_gradient_loss         | 0.000726     |\n|    value_loss                   | 525          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 635          |\n|    water_produced               | 140          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 112           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1014          |\n|    time_elapsed                 | 4689          |\n|    total_timesteps              | 4056000       |\n| train/                          |               |\n|    approx_kl                    | 0.00082051224 |\n|    clip_fraction                | 0.00275       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.02         |\n|    explained_variance           | 0.772         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 181           |\n|    n_updates                    | 2026          |\n|    policy_gradient_loss         | -0.000596     |\n|    value_loss                   | 432           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 155           |\n|    ice_dug                      | 598           |\n|    water_produced               | 120           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 127          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1015         |\n|    time_elapsed                 | 4694         |\n|    total_timesteps              | 4060000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022900098 |\n|    clip_fraction                | 0.0085       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.805        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 2028         |\n|    policy_gradient_loss         | -0.00142     |\n|    value_loss                   | 414          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 597          |\n|    water_produced               | 118          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 133           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1016          |\n|    time_elapsed                 | 4698          |\n|    total_timesteps              | 4064000       |\n| train/                          |               |\n|    approx_kl                    | 0.00087875983 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.985        |\n|    explained_variance           | 0.704         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 159           |\n|    n_updates                    | 2030          |\n|    policy_gradient_loss         | -0.000626     |\n|    value_loss                   | 435           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 150           |\n|    ice_dug                      | 824           |\n|    water_produced               | 151           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 147          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1017         |\n|    time_elapsed                 | 4703         |\n|    total_timesteps              | 4068000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017678959 |\n|    clip_fraction                | 0.006        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.96        |\n|    explained_variance           | 0.702        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 305          |\n|    n_updates                    | 2032         |\n|    policy_gradient_loss         | 0.000211     |\n|    value_loss                   | 582          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 875          |\n|    water_produced               | 170          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 135          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1018         |\n|    time_elapsed                 | 4707         |\n|    total_timesteps              | 4072000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028289792 |\n|    clip_fraction                | 0.013        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.963       |\n|    explained_variance           | 0.758        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 190          |\n|    n_updates                    | 2034         |\n|    policy_gradient_loss         | 0.00062      |\n|    value_loss                   | 473          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 370          |\n|    water_produced               | 84.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 145          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1019         |\n|    time_elapsed                 | 4712         |\n|    total_timesteps              | 4076000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006319519 |\n|    clip_fraction                | 0.00263      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.04        |\n|    explained_variance           | 0.776        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 2036         |\n|    policy_gradient_loss         | 0.00014      |\n|    value_loss                   | 323          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 855          |\n|    water_produced               | 167          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 148           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1020          |\n|    time_elapsed                 | 4716          |\n|    total_timesteps              | 4080000       |\n| train/                          |               |\n|    approx_kl                    | 0.00023529562 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.913        |\n|    explained_variance           | 0.672         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 226           |\n|    n_updates                    | 2038          |\n|    policy_gradient_loss         | -0.000701     |\n|    value_loss                   | 474           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 667           |\n|    water_produced               | 134           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 138           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1021          |\n|    time_elapsed                 | 4720          |\n|    total_timesteps              | 4084000       |\n| train/                          |               |\n|    approx_kl                    | 0.00040312382 |\n|    clip_fraction                | 0.002         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1            |\n|    explained_variance           | 0.795         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 221           |\n|    n_updates                    | 2040          |\n|    policy_gradient_loss         | -0.000277     |\n|    value_loss                   | 394           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 533           |\n|    water_produced               | 100           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 119         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1022        |\n|    time_elapsed                 | 4724        |\n|    total_timesteps              | 4088000     |\n| train/                          |             |\n|    approx_kl                    | 0.005610506 |\n|    clip_fraction                | 0.0235      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.13       |\n|    explained_variance           | 0.834       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 195         |\n|    n_updates                    | 2042        |\n|    policy_gradient_loss         | 0.000846    |\n|    value_loss                   | 394         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 140         |\n|    action_queue_updates_total   | 149         |\n|    ice_dug                      | 514         |\n|    water_produced               | 81.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 119          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1023         |\n|    time_elapsed                 | 4729         |\n|    total_timesteps              | 4092000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026362347 |\n|    clip_fraction                | 0.0139       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.02        |\n|    explained_variance           | 0.694        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 195          |\n|    n_updates                    | 2044         |\n|    policy_gradient_loss         | 0.00086      |\n|    value_loss                   | 392          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 428          |\n|    water_produced               | 80.8         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 118         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1024        |\n|    time_elapsed                 | 4733        |\n|    total_timesteps              | 4096000     |\n| train/                          |             |\n|    approx_kl                    | 0.002092079 |\n|    clip_fraction                | 0.0111      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.16       |\n|    explained_variance           | 0.773       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 177         |\n|    n_updates                    | 2046        |\n|    policy_gradient_loss         | -9.25e-05   |\n|    value_loss                   | 377         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 143         |\n|    action_queue_updates_total   | 154         |\n|    ice_dug                      | 745         |\n|    water_produced               | 166         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 122          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1025         |\n|    time_elapsed                 | 4738         |\n|    total_timesteps              | 4100000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038964287 |\n|    clip_fraction                | 0.0198       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.98        |\n|    explained_variance           | 0.671        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 306          |\n|    n_updates                    | 2048         |\n|    policy_gradient_loss         | 0.000329     |\n|    value_loss                   | 572          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 729          |\n|    water_produced               | 153          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 110          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1026         |\n|    time_elapsed                 | 4742         |\n|    total_timesteps              | 4104000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025645206 |\n|    clip_fraction                | 0.00963      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.763        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 251          |\n|    n_updates                    | 2050         |\n|    policy_gradient_loss         | 0.000161     |\n|    value_loss                   | 547          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 250          |\n|    water_produced               | 42.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1027         |\n|    time_elapsed                 | 4746         |\n|    total_timesteps              | 4108000      |\n| train/                          |              |\n|    approx_kl                    | 0.0059789517 |\n|    clip_fraction                | 0.0325       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.22        |\n|    explained_variance           | 0.791        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 139          |\n|    n_updates                    | 2052         |\n|    policy_gradient_loss         | -0.000376    |\n|    value_loss                   | 279          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 474          |\n|    water_produced               | 84.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 110           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1028          |\n|    time_elapsed                 | 4751          |\n|    total_timesteps              | 4112000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046603003 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.28         |\n|    explained_variance           | 0.812         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 183           |\n|    n_updates                    | 2054          |\n|    policy_gradient_loss         | -0.000168     |\n|    value_loss                   | 347           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 392           |\n|    water_produced               | 80            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 90.8         |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1029         |\n|    time_elapsed                 | 4755         |\n|    total_timesteps              | 4116000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013197018 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.8          |\n|    learning_rate                | 0.0003       |\n|    loss                         | 176          |\n|    n_updates                    | 2056         |\n|    policy_gradient_loss         | 0.000121     |\n|    value_loss                   | 431          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 365          |\n|    water_produced               | 71.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 87           |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1030         |\n|    time_elapsed                 | 4759         |\n|    total_timesteps              | 4120000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024067387 |\n|    clip_fraction                | 0.00888      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.29        |\n|    explained_variance           | 0.795        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 193          |\n|    n_updates                    | 2058         |\n|    policy_gradient_loss         | 0.00115      |\n|    value_loss                   | 358          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 701          |\n|    water_produced               | 134          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 97          |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1031        |\n|    time_elapsed                 | 4763        |\n|    total_timesteps              | 4124000     |\n| train/                          |             |\n|    approx_kl                    | 0.005356825 |\n|    clip_fraction                | 0.0292      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.17       |\n|    explained_variance           | 0.786       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 263         |\n|    n_updates                    | 2060        |\n|    policy_gradient_loss         | -0.000684   |\n|    value_loss                   | 503         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 157         |\n|    ice_dug                      | 421         |\n|    water_produced               | 91          |\n-------------------------------------------------\nEval num_timesteps=4128000, episode_reward=842.00 +/- 761.07\nEpisode length: 778.60 +/- 249.64\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 779          |\n|    mean_reward                  | 842          |\n| time/                           |              |\n|    total_timesteps              | 4128000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009053246 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.752        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 208          |\n|    n_updates                    | 2062         |\n|    policy_gradient_loss         | -0.000393    |\n|    value_loss                   | 411          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 707          |\n|    water_produced               | 104          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 101      |\n| time/              |          |\n|    fps             | 864      |\n|    iterations      | 1032     |\n|    time_elapsed    | 4772     |\n|    total_timesteps | 4128000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 112           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1033          |\n|    time_elapsed                 | 4776          |\n|    total_timesteps              | 4132000       |\n| train/                          |               |\n|    approx_kl                    | 0.00076230697 |\n|    clip_fraction                | 0.001         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.757         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 291           |\n|    n_updates                    | 2064          |\n|    policy_gradient_loss         | 8.52e-05      |\n|    value_loss                   | 527           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 678           |\n|    water_produced               | 130           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1034         |\n|    time_elapsed                 | 4780         |\n|    total_timesteps              | 4136000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020180447 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.02        |\n|    explained_variance           | 0.705        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 254          |\n|    n_updates                    | 2066         |\n|    policy_gradient_loss         | -0.000251    |\n|    value_loss                   | 505          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 445          |\n|    water_produced               | 64.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 100          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1035         |\n|    time_elapsed                 | 4785         |\n|    total_timesteps              | 4140000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029380298 |\n|    clip_fraction                | 0.0181       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.822        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 206          |\n|    n_updates                    | 2068         |\n|    policy_gradient_loss         | 0.0013       |\n|    value_loss                   | 350          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 477          |\n|    water_produced               | 83.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 116           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1036          |\n|    time_elapsed                 | 4789          |\n|    total_timesteps              | 4144000       |\n| train/                          |               |\n|    approx_kl                    | 0.00063781545 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.16         |\n|    explained_variance           | 0.782         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 221           |\n|    n_updates                    | 2070          |\n|    policy_gradient_loss         | 0.000194      |\n|    value_loss                   | 385           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 887           |\n|    water_produced               | 168           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 110         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1037        |\n|    time_elapsed                 | 4793        |\n|    total_timesteps              | 4148000     |\n| train/                          |             |\n|    approx_kl                    | 0.004950649 |\n|    clip_fraction                | 0.0219      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.16       |\n|    explained_variance           | 0.832       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 291         |\n|    n_updates                    | 2072        |\n|    policy_gradient_loss         | 0.0021      |\n|    value_loss                   | 620         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 136         |\n|    action_queue_updates_total   | 148         |\n|    ice_dug                      | 475         |\n|    water_produced               | 73.5        |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 110           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1038          |\n|    time_elapsed                 | 4798          |\n|    total_timesteps              | 4152000       |\n| train/                          |               |\n|    approx_kl                    | 0.00055386557 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.11         |\n|    explained_variance           | 0.824         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 179           |\n|    n_updates                    | 2074          |\n|    policy_gradient_loss         | 0.000243      |\n|    value_loss                   | 332           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 658           |\n|    water_produced               | 133           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 112           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1039          |\n|    time_elapsed                 | 4803          |\n|    total_timesteps              | 4156000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025622838 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.13         |\n|    explained_variance           | 0.822         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 242           |\n|    n_updates                    | 2076          |\n|    policy_gradient_loss         | -0.000183     |\n|    value_loss                   | 512           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 436           |\n|    water_produced               | 75.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 141          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1040         |\n|    time_elapsed                 | 4807         |\n|    total_timesteps              | 4160000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011731951 |\n|    clip_fraction                | 0.00438      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.1         |\n|    explained_variance           | 0.817        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 176          |\n|    n_updates                    | 2078         |\n|    policy_gradient_loss         | -0.000513    |\n|    value_loss                   | 372          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 963          |\n|    water_produced               | 220          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 122         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1041        |\n|    time_elapsed                 | 4812        |\n|    total_timesteps              | 4164000     |\n| train/                          |             |\n|    approx_kl                    | 0.000712034 |\n|    clip_fraction                | 0.00187     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.975      |\n|    explained_variance           | 0.734       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 325         |\n|    n_updates                    | 2080        |\n|    policy_gradient_loss         | 0.000172    |\n|    value_loss                   | 691         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 142         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 431         |\n|    water_produced               | 78          |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 118           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1042          |\n|    time_elapsed                 | 4816          |\n|    total_timesteps              | 4168000       |\n| train/                          |               |\n|    approx_kl                    | 0.00017299286 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.18         |\n|    explained_variance           | 0.821         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 211           |\n|    n_updates                    | 2082          |\n|    policy_gradient_loss         | -2.83e-05     |\n|    value_loss                   | 344           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 132           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 263           |\n|    water_produced               | 58            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 114          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1043         |\n|    time_elapsed                 | 4821         |\n|    total_timesteps              | 4172000      |\n| train/                          |              |\n|    approx_kl                    | 0.0055891946 |\n|    clip_fraction                | 0.0395       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.846        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 97.1         |\n|    n_updates                    | 2084         |\n|    policy_gradient_loss         | 0.000542     |\n|    value_loss                   | 210          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 863          |\n|    water_produced               | 110          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 123          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1044         |\n|    time_elapsed                 | 4825         |\n|    total_timesteps              | 4176000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030706704 |\n|    clip_fraction                | 0.0165       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.701        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 301          |\n|    n_updates                    | 2086         |\n|    policy_gradient_loss         | 0.0013       |\n|    value_loss                   | 579          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 659          |\n|    water_produced               | 116          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 99.8         |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1045         |\n|    time_elapsed                 | 4829         |\n|    total_timesteps              | 4180000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026295863 |\n|    clip_fraction                | 0.0199       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.15        |\n|    explained_variance           | 0.774        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 258          |\n|    n_updates                    | 2088         |\n|    policy_gradient_loss         | 0.00195      |\n|    value_loss                   | 460          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 622          |\n|    water_produced               | 109          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 123         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1046        |\n|    time_elapsed                 | 4834        |\n|    total_timesteps              | 4184000     |\n| train/                          |             |\n|    approx_kl                    | 0.001669666 |\n|    clip_fraction                | 0.00875     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.08       |\n|    explained_variance           | 0.807       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 202         |\n|    n_updates                    | 2090        |\n|    policy_gradient_loss         | -0.00121    |\n|    value_loss                   | 465         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 878         |\n|    water_produced               | 188         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 132          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1047         |\n|    time_elapsed                 | 4838         |\n|    total_timesteps              | 4188000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024021275 |\n|    clip_fraction                | 0.011        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.04        |\n|    explained_variance           | 0.798        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 332          |\n|    n_updates                    | 2092         |\n|    policy_gradient_loss         | -0.0003      |\n|    value_loss                   | 573          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 141          |\n|    ice_dug                      | 516          |\n|    water_produced               | 99.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 142           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1048          |\n|    time_elapsed                 | 4842          |\n|    total_timesteps              | 4192000       |\n| train/                          |               |\n|    approx_kl                    | 0.00051722035 |\n|    clip_fraction                | 0.0015        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.03         |\n|    explained_variance           | 0.777         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 164           |\n|    n_updates                    | 2094          |\n|    policy_gradient_loss         | 0.000442      |\n|    value_loss                   | 361           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 761           |\n|    water_produced               | 161           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 155           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1049          |\n|    time_elapsed                 | 4846          |\n|    total_timesteps              | 4196000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029450128 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.986        |\n|    explained_variance           | 0.743         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 226           |\n|    n_updates                    | 2096          |\n|    policy_gradient_loss         | -0.000707     |\n|    value_loss                   | 493           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 835           |\n|    water_produced               | 181           |\n---------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 182        |\n| time/                           |            |\n|    fps                          | 865        |\n|    iterations                   | 1050       |\n|    time_elapsed                 | 4851       |\n|    total_timesteps              | 4200000    |\n| train/                          |            |\n|    approx_kl                    | 0.00225269 |\n|    clip_fraction                | 0.012      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.06      |\n|    explained_variance           | 0.808      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 297        |\n|    n_updates                    | 2098       |\n|    policy_gradient_loss         | 0.00193    |\n|    value_loss                   | 577        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 141        |\n|    action_queue_updates_total   | 151        |\n|    ice_dug                      | 1.1e+03    |\n|    water_produced               | 241        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 161         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1051        |\n|    time_elapsed                 | 4855        |\n|    total_timesteps              | 4204000     |\n| train/                          |             |\n|    approx_kl                    | 0.003723845 |\n|    clip_fraction                | 0.0262      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.888      |\n|    explained_variance           | 0.757       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 279         |\n|    n_updates                    | 2100        |\n|    policy_gradient_loss         | 0.00195     |\n|    value_loss                   | 624         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 143         |\n|    action_queue_updates_total   | 148         |\n|    ice_dug                      | 472         |\n|    water_produced               | 85.3        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 168          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1052         |\n|    time_elapsed                 | 4859         |\n|    total_timesteps              | 4208000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022972838 |\n|    clip_fraction                | 0.0105       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.953       |\n|    explained_variance           | 0.719        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 154          |\n|    n_updates                    | 2102         |\n|    policy_gradient_loss         | -0.000882    |\n|    value_loss                   | 337          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 624          |\n|    water_produced               | 132          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 161          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1053         |\n|    time_elapsed                 | 4864         |\n|    total_timesteps              | 4212000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014130014 |\n|    clip_fraction                | 0.0149       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.875        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 195          |\n|    n_updates                    | 2104         |\n|    policy_gradient_loss         | -0.000635    |\n|    value_loss                   | 426          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 674          |\n|    water_produced               | 130          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 164           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1054          |\n|    time_elapsed                 | 4868          |\n|    total_timesteps              | 4216000       |\n| train/                          |               |\n|    approx_kl                    | 0.00045417986 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.04         |\n|    explained_variance           | 0.765         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 242           |\n|    n_updates                    | 2106          |\n|    policy_gradient_loss         | -0.000152     |\n|    value_loss                   | 437           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 992           |\n|    water_produced               | 195           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 142         |\n| time/                           |             |\n|    fps                          | 866         |\n|    iterations                   | 1055        |\n|    time_elapsed                 | 4872        |\n|    total_timesteps              | 4220000     |\n| train/                          |             |\n|    approx_kl                    | 0.001196165 |\n|    clip_fraction                | 0.00713     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.92       |\n|    explained_variance           | 0.64        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 289         |\n|    n_updates                    | 2108        |\n|    policy_gradient_loss         | 0.000197    |\n|    value_loss                   | 581         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 618         |\n|    water_produced               | 134         |\n-------------------------------------------------\nEval num_timesteps=4224000, episode_reward=679.12 +/- 651.54\nEpisode length: 680.60 +/- 298.84\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 681           |\n|    mean_reward                  | 679           |\n| time/                           |               |\n|    total_timesteps              | 4224000       |\n| train/                          |               |\n|    approx_kl                    | 0.00013690685 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.16         |\n|    explained_variance           | 0.864         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 204           |\n|    n_updates                    | 2110          |\n|    policy_gradient_loss         | -0.000109     |\n|    value_loss                   | 404           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 139           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 761           |\n|    water_produced               | 118           |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 149      |\n| time/              |          |\n|    fps             | 865      |\n|    iterations      | 1056     |\n|    time_elapsed    | 4882     |\n|    total_timesteps | 4224000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 158          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1057         |\n|    time_elapsed                 | 4886         |\n|    total_timesteps              | 4228000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014276818 |\n|    clip_fraction                | 0.00338      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.796        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 2112         |\n|    policy_gradient_loss         | -0.00013     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 753          |\n|    water_produced               | 174          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 163          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1058         |\n|    time_elapsed                 | 4891         |\n|    total_timesteps              | 4232000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015555104 |\n|    clip_fraction                | 0.0104       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.843        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 237          |\n|    n_updates                    | 2114         |\n|    policy_gradient_loss         | 0.00199      |\n|    value_loss                   | 465          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 663          |\n|    water_produced               | 158          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 135          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1059         |\n|    time_elapsed                 | 4895         |\n|    total_timesteps              | 4236000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018595163 |\n|    clip_fraction                | 0.0133       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.786        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 2116         |\n|    policy_gradient_loss         | -0.00152     |\n|    value_loss                   | 411          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 326          |\n|    water_produced               | 61.2         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 147         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1060        |\n|    time_elapsed                 | 4900        |\n|    total_timesteps              | 4240000     |\n| train/                          |             |\n|    approx_kl                    | 0.003736542 |\n|    clip_fraction                | 0.0216      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.31       |\n|    explained_variance           | 0.866       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 132         |\n|    n_updates                    | 2118        |\n|    policy_gradient_loss         | 0.000564    |\n|    value_loss                   | 279         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 837         |\n|    water_produced               | 192         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 151          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1061         |\n|    time_elapsed                 | 4904         |\n|    total_timesteps              | 4244000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003765389 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1           |\n|    explained_variance           | 0.756        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 260          |\n|    n_updates                    | 2120         |\n|    policy_gradient_loss         | 4.88e-05     |\n|    value_loss                   | 532          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 616          |\n|    water_produced               | 138          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 152           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1062          |\n|    time_elapsed                 | 4908          |\n|    total_timesteps              | 4248000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035668505 |\n|    clip_fraction                | 0.00113       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.11         |\n|    explained_variance           | 0.794         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 224           |\n|    n_updates                    | 2122          |\n|    policy_gradient_loss         | -5.02e-05     |\n|    value_loss                   | 426           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 952           |\n|    water_produced               | 179           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 151          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1063         |\n|    time_elapsed                 | 4912         |\n|    total_timesteps              | 4252000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010974228 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.972       |\n|    explained_variance           | 0.67         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 291          |\n|    n_updates                    | 2124         |\n|    policy_gradient_loss         | 0.000515     |\n|    value_loss                   | 549          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 662          |\n|    water_produced               | 152          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 176           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1064          |\n|    time_elapsed                 | 4917          |\n|    total_timesteps              | 4256000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025615536 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.03         |\n|    explained_variance           | 0.786         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 255           |\n|    n_updates                    | 2126          |\n|    policy_gradient_loss         | 0.000139      |\n|    value_loss                   | 503           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 885           |\n|    water_produced               | 179           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 167           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1065          |\n|    time_elapsed                 | 4921          |\n|    total_timesteps              | 4260000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032608747 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.03         |\n|    explained_variance           | 0.777         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 207           |\n|    n_updates                    | 2128          |\n|    policy_gradient_loss         | -6.54e-06     |\n|    value_loss                   | 507           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 649           |\n|    water_produced               | 151           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 176          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1066         |\n|    time_elapsed                 | 4926         |\n|    total_timesteps              | 4264000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004478233 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.07        |\n|    explained_variance           | 0.79         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 2130         |\n|    policy_gradient_loss         | 0.000116     |\n|    value_loss                   | 463          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 808          |\n|    water_produced               | 180          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 153           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1067          |\n|    time_elapsed                 | 4930          |\n|    total_timesteps              | 4268000       |\n| train/                          |               |\n|    approx_kl                    | 0.00047187833 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.06         |\n|    explained_variance           | 0.814         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 265           |\n|    n_updates                    | 2132          |\n|    policy_gradient_loss         | 0.000394      |\n|    value_loss                   | 525           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 137           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 299           |\n|    water_produced               | 71.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 148          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1068         |\n|    time_elapsed                 | 4934         |\n|    total_timesteps              | 4272000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027277714 |\n|    clip_fraction                | 0.0136       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.35        |\n|    explained_variance           | 0.894        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 123          |\n|    n_updates                    | 2134         |\n|    policy_gradient_loss         | -0.000357    |\n|    value_loss                   | 289          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 589          |\n|    water_produced               | 127          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 143          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1069         |\n|    time_elapsed                 | 4938         |\n|    total_timesteps              | 4276000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025319876 |\n|    clip_fraction                | 0.0184       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.792        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 2136         |\n|    policy_gradient_loss         | -0.00048     |\n|    value_loss                   | 439          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 777          |\n|    water_produced               | 154          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 149          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1070         |\n|    time_elapsed                 | 4943         |\n|    total_timesteps              | 4280000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021769523 |\n|    clip_fraction                | 0.01         |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.966       |\n|    explained_variance           | 0.665        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 292          |\n|    n_updates                    | 2138         |\n|    policy_gradient_loss         | 0.00142      |\n|    value_loss                   | 517          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 828          |\n|    water_produced               | 182          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 133          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1071         |\n|    time_elapsed                 | 4947         |\n|    total_timesteps              | 4284000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005398019 |\n|    clip_fraction                | 0.00162      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.769        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 251          |\n|    n_updates                    | 2140         |\n|    policy_gradient_loss         | 4.87e-05     |\n|    value_loss                   | 506          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 522          |\n|    water_produced               | 102          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 157         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1072        |\n|    time_elapsed                 | 4951        |\n|    total_timesteps              | 4288000     |\n| train/                          |             |\n|    approx_kl                    | 0.002022386 |\n|    clip_fraction                | 0.00788     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.09       |\n|    explained_variance           | 0.798       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 184         |\n|    n_updates                    | 2142        |\n|    policy_gradient_loss         | -0.000231   |\n|    value_loss                   | 377         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 975         |\n|    water_produced               | 186         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 154           |\n| time/                           |               |\n|    fps                          | 866           |\n|    iterations                   | 1073          |\n|    time_elapsed                 | 4956          |\n|    total_timesteps              | 4292000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035946746 |\n|    clip_fraction                | 0.000875      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.04         |\n|    explained_variance           | 0.778         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 287           |\n|    n_updates                    | 2144          |\n|    policy_gradient_loss         | -0.000283     |\n|    value_loss                   | 540           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 492           |\n|    water_produced               | 112           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 141           |\n| time/                           |               |\n|    fps                          | 866           |\n|    iterations                   | 1074          |\n|    time_elapsed                 | 4960          |\n|    total_timesteps              | 4296000       |\n| train/                          |               |\n|    approx_kl                    | 0.00053370337 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.26         |\n|    explained_variance           | 0.864         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 213           |\n|    n_updates                    | 2146          |\n|    policy_gradient_loss         | 8.37e-05      |\n|    value_loss                   | 435           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 548           |\n|    water_produced               | 92.2          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 154          |\n| time/                           |              |\n|    fps                          | 866          |\n|    iterations                   | 1075         |\n|    time_elapsed                 | 4964         |\n|    total_timesteps              | 4300000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035442263 |\n|    clip_fraction                | 0.0241       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.13        |\n|    explained_variance           | 0.735        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 204          |\n|    n_updates                    | 2148         |\n|    policy_gradient_loss         | -0.000196    |\n|    value_loss                   | 451          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.03e+03     |\n|    water_produced               | 241          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 145          |\n| time/                           |              |\n|    fps                          | 866          |\n|    iterations                   | 1076         |\n|    time_elapsed                 | 4969         |\n|    total_timesteps              | 4304000      |\n| train/                          |              |\n|    approx_kl                    | 0.0047901412 |\n|    clip_fraction                | 0.0224       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.937       |\n|    explained_variance           | 0.732        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 314          |\n|    n_updates                    | 2150         |\n|    policy_gradient_loss         | 0.00136      |\n|    value_loss                   | 619          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 344          |\n|    water_produced               | 59.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 129           |\n| time/                           |               |\n|    fps                          | 866           |\n|    iterations                   | 1077          |\n|    time_elapsed                 | 4973          |\n|    total_timesteps              | 4308000       |\n| train/                          |               |\n|    approx_kl                    | 0.00050774135 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.16         |\n|    explained_variance           | 0.843         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 168           |\n|    n_updates                    | 2152          |\n|    policy_gradient_loss         | 0.000335      |\n|    value_loss                   | 338           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 133           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 537           |\n|    water_produced               | 112           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 129          |\n| time/                           |              |\n|    fps                          | 866          |\n|    iterations                   | 1078         |\n|    time_elapsed                 | 4977         |\n|    total_timesteps              | 4312000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036817542 |\n|    clip_fraction                | 0.0259       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.21        |\n|    explained_variance           | 0.841        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 2154         |\n|    policy_gradient_loss         | -0.000453    |\n|    value_loss                   | 416          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 620          |\n|    water_produced               | 112          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 129          |\n| time/                           |              |\n|    fps                          | 866          |\n|    iterations                   | 1079         |\n|    time_elapsed                 | 4982         |\n|    total_timesteps              | 4316000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013555523 |\n|    clip_fraction                | 0.00475      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.13        |\n|    explained_variance           | 0.803        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 2156         |\n|    policy_gradient_loss         | 0.000761     |\n|    value_loss                   | 467          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 431          |\n|    water_produced               | 92.2         |\n--------------------------------------------------\nEval num_timesteps=4320000, episode_reward=800.36 +/- 491.01\nEpisode length: 835.40 +/- 271.48\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 835          |\n|    mean_reward                  | 800          |\n| time/                           |              |\n|    total_timesteps              | 4320000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019192394 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.23        |\n|    explained_variance           | 0.854        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 176          |\n|    n_updates                    | 2158         |\n|    policy_gradient_loss         | -0.000147    |\n|    value_loss                   | 386          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 724          |\n|    water_produced               | 157          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 112      |\n| time/              |          |\n|    fps             | 864      |\n|    iterations      | 1080     |\n|    time_elapsed    | 4995     |\n|    total_timesteps | 4320000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 105          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1081         |\n|    time_elapsed                 | 4999         |\n|    total_timesteps              | 4324000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026610438 |\n|    clip_fraction                | 0.0151       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.28        |\n|    explained_variance           | 0.854        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 274          |\n|    n_updates                    | 2160         |\n|    policy_gradient_loss         | 0.00126      |\n|    value_loss                   | 526          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 128          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 125          |\n|    water_produced               | 29.7         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 101          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1082         |\n|    time_elapsed                 | 5003         |\n|    total_timesteps              | 4328000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026196293 |\n|    clip_fraction                | 0.009        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.61        |\n|    explained_variance           | 0.925        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 66.6         |\n|    n_updates                    | 2162         |\n|    policy_gradient_loss         | -0.000489    |\n|    value_loss                   | 188          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 511          |\n|    water_produced               | 88.8         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 91.5          |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1083          |\n|    time_elapsed                 | 5008          |\n|    total_timesteps              | 4332000       |\n| train/                          |               |\n|    approx_kl                    | 0.00054770167 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.53         |\n|    explained_variance           | 0.859         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 245           |\n|    n_updates                    | 2164          |\n|    policy_gradient_loss         | 0.000458      |\n|    value_loss                   | 464           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 432           |\n|    water_produced               | 68            |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 90.8         |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1084         |\n|    time_elapsed                 | 5012         |\n|    total_timesteps              | 4336000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021324274 |\n|    clip_fraction                | 0.0075       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.35        |\n|    explained_variance           | 0.868        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 178          |\n|    n_updates                    | 2166         |\n|    policy_gradient_loss         | -0.000625    |\n|    value_loss                   | 343          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 459          |\n|    water_produced               | 88           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 78.8         |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1085         |\n|    time_elapsed                 | 5016         |\n|    total_timesteps              | 4340000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011501261 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.38        |\n|    explained_variance           | 0.874        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 188          |\n|    n_updates                    | 2168         |\n|    policy_gradient_loss         | 0.00101      |\n|    value_loss                   | 366          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 426          |\n|    water_produced               | 99.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 93.1         |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1086         |\n|    time_elapsed                 | 5021         |\n|    total_timesteps              | 4344000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020500047 |\n|    clip_fraction                | 0.008        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.57        |\n|    explained_variance           | 0.922        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 2170         |\n|    policy_gradient_loss         | 0.00216      |\n|    value_loss                   | 335          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 544          |\n|    water_produced               | 97.5         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 89.8          |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1087          |\n|    time_elapsed                 | 5025          |\n|    total_timesteps              | 4348000       |\n| train/                          |               |\n|    approx_kl                    | 0.00028578952 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.27         |\n|    explained_variance           | 0.875         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 171           |\n|    n_updates                    | 2172          |\n|    policy_gradient_loss         | -0.000522     |\n|    value_loss                   | 372           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 327           |\n|    water_produced               | 74            |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 96.6        |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1088        |\n|    time_elapsed                 | 5030        |\n|    total_timesteps              | 4352000     |\n| train/                          |             |\n|    approx_kl                    | 0.005201536 |\n|    clip_fraction                | 0.0205      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.32       |\n|    explained_variance           | 0.868       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 130         |\n|    n_updates                    | 2174        |\n|    policy_gradient_loss         | 0.00114     |\n|    value_loss                   | 278         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 529         |\n|    water_produced               | 101         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 113          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1089         |\n|    time_elapsed                 | 5034         |\n|    total_timesteps              | 4356000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018626403 |\n|    clip_fraction                | 0.00762      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.842        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 2176         |\n|    policy_gradient_loss         | -0.000429    |\n|    value_loss                   | 415          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 724          |\n|    water_produced               | 167          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 123          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1090         |\n|    time_elapsed                 | 5038         |\n|    total_timesteps              | 4360000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017696085 |\n|    clip_fraction                | 0.00513      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.21        |\n|    explained_variance           | 0.864        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 224          |\n|    n_updates                    | 2178         |\n|    policy_gradient_loss         | -0.000547    |\n|    value_loss                   | 430          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 647          |\n|    water_produced               | 146          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 122         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1091        |\n|    time_elapsed                 | 5043        |\n|    total_timesteps              | 4364000     |\n| train/                          |             |\n|    approx_kl                    | 0.001019317 |\n|    clip_fraction                | 0.00338     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.03       |\n|    explained_variance           | 0.825       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 212         |\n|    n_updates                    | 2180        |\n|    policy_gradient_loss         | 0.00132     |\n|    value_loss                   | 370         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 141         |\n|    action_queue_updates_total   | 154         |\n|    ice_dug                      | 401         |\n|    water_produced               | 94.2        |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 127         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1092        |\n|    time_elapsed                 | 5047        |\n|    total_timesteps              | 4368000     |\n| train/                          |             |\n|    approx_kl                    | 0.005331176 |\n|    clip_fraction                | 0.0249      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.25       |\n|    explained_variance           | 0.869       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 198         |\n|    n_updates                    | 2182        |\n|    policy_gradient_loss         | 0.00132     |\n|    value_loss                   | 323         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 572         |\n|    water_produced               | 97          |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 137          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1093         |\n|    time_elapsed                 | 5052         |\n|    total_timesteps              | 4372000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005393768 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.84         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 2184         |\n|    policy_gradient_loss         | -2.33e-05    |\n|    value_loss                   | 455          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 851          |\n|    water_produced               | 149          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 125         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1094        |\n|    time_elapsed                 | 5056        |\n|    total_timesteps              | 4376000     |\n| train/                          |             |\n|    approx_kl                    | 0.005521917 |\n|    clip_fraction                | 0.0253      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.02       |\n|    explained_variance           | 0.732       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 282         |\n|    n_updates                    | 2186        |\n|    policy_gradient_loss         | 0.000515    |\n|    value_loss                   | 562         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 543         |\n|    water_produced               | 109         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 112          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1095         |\n|    time_elapsed                 | 5061         |\n|    total_timesteps              | 4380000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002603036 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.07        |\n|    explained_variance           | 0.81         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 197          |\n|    n_updates                    | 2188         |\n|    policy_gradient_loss         | 0.000605     |\n|    value_loss                   | 391          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 485          |\n|    water_produced               | 83.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 120          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1096         |\n|    time_elapsed                 | 5065         |\n|    total_timesteps              | 4384000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035532888 |\n|    clip_fraction                | 0.0188       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.79         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 2190         |\n|    policy_gradient_loss         | -0.000342    |\n|    value_loss                   | 394          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 578          |\n|    water_produced               | 130          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 133          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1097         |\n|    time_elapsed                 | 5069         |\n|    total_timesteps              | 4388000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017441377 |\n|    clip_fraction                | 0.00662      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.22        |\n|    explained_variance           | 0.838        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 2192         |\n|    policy_gradient_loss         | -0.00014     |\n|    value_loss                   | 453          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 840          |\n|    water_produced               | 163          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 121         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1098        |\n|    time_elapsed                 | 5074        |\n|    total_timesteps              | 4392000     |\n| train/                          |             |\n|    approx_kl                    | 0.002408314 |\n|    clip_fraction                | 0.00763     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.06       |\n|    explained_variance           | 0.829       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 255         |\n|    n_updates                    | 2194        |\n|    policy_gradient_loss         | 0.000931    |\n|    value_loss                   | 572         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 134         |\n|    action_queue_updates_total   | 145         |\n|    ice_dug                      | 522         |\n|    water_produced               | 92          |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 113         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1099        |\n|    time_elapsed                 | 5078        |\n|    total_timesteps              | 4396000     |\n| train/                          |             |\n|    approx_kl                    | 0.001991477 |\n|    clip_fraction                | 0.0085      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.05       |\n|    explained_variance           | 0.742       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 172         |\n|    n_updates                    | 2196        |\n|    policy_gradient_loss         | 0.00106     |\n|    value_loss                   | 414         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 134         |\n|    action_queue_updates_total   | 147         |\n|    ice_dug                      | 394         |\n|    water_produced               | 69.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 123          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1100         |\n|    time_elapsed                 | 5082         |\n|    total_timesteps              | 4400000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028229835 |\n|    clip_fraction                | 0.0172       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.12        |\n|    explained_variance           | 0.825        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 143          |\n|    n_updates                    | 2198         |\n|    policy_gradient_loss         | 0.000664     |\n|    value_loss                   | 300          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 597          |\n|    water_produced               | 128          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 116          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1101         |\n|    time_elapsed                 | 5087         |\n|    total_timesteps              | 4404000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010133192 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.18        |\n|    explained_variance           | 0.837        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 246          |\n|    n_updates                    | 2200         |\n|    policy_gradient_loss         | 0.000155     |\n|    value_loss                   | 456          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 127          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 561          |\n|    water_produced               | 96.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 104           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1102          |\n|    time_elapsed                 | 5091          |\n|    total_timesteps              | 4408000       |\n| train/                          |               |\n|    approx_kl                    | 0.00079595967 |\n|    clip_fraction                | 0.00175       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.1          |\n|    explained_variance           | 0.809         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 226           |\n|    n_updates                    | 2202          |\n|    policy_gradient_loss         | 0.000167      |\n|    value_loss                   | 437           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 507           |\n|    water_produced               | 106           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 110          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1103         |\n|    time_elapsed                 | 5096         |\n|    total_timesteps              | 4412000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008897487 |\n|    clip_fraction                | 0.00362      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.983       |\n|    explained_variance           | 0.731        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 195          |\n|    n_updates                    | 2204         |\n|    policy_gradient_loss         | -0.000397    |\n|    value_loss                   | 425          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 648          |\n|    water_produced               | 123          |\n--------------------------------------------------\nEval num_timesteps=4416000, episode_reward=614.00 +/- 965.69\nEpisode length: 548.80 +/- 307.63\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 549          |\n|    mean_reward                  | 614          |\n| time/                           |              |\n|    total_timesteps              | 4416000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003875412 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.803        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 2206         |\n|    policy_gradient_loss         | 0.000122     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 143          |\n|    ice_dug                      | 906          |\n|    water_produced               | 182          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 133      |\n| time/              |          |\n|    fps             | 864      |\n|    iterations      | 1104     |\n|    time_elapsed    | 5105     |\n|    total_timesteps | 4416000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 135         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1105        |\n|    time_elapsed                 | 5109        |\n|    total_timesteps              | 4420000     |\n| train/                          |             |\n|    approx_kl                    | 0.002552854 |\n|    clip_fraction                | 0.0117      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.888      |\n|    explained_variance           | 0.716       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 226         |\n|    n_updates                    | 2208        |\n|    policy_gradient_loss         | 0.0018      |\n|    value_loss                   | 503         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 143         |\n|    action_queue_updates_total   | 153         |\n|    ice_dug                      | 641         |\n|    water_produced               | 138         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 140          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1106         |\n|    time_elapsed                 | 5114         |\n|    total_timesteps              | 4424000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011226004 |\n|    clip_fraction                | 0.0085       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.815        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 178          |\n|    n_updates                    | 2210         |\n|    policy_gradient_loss         | 0.000503     |\n|    value_loss                   | 397          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 528          |\n|    water_produced               | 117          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 158          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1107         |\n|    time_elapsed                 | 5118         |\n|    total_timesteps              | 4428000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042164437 |\n|    clip_fraction                | 0.0224       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.814        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 2212         |\n|    policy_gradient_loss         | 0.00189      |\n|    value_loss                   | 397          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 935          |\n|    water_produced               | 195          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 143         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1108        |\n|    time_elapsed                 | 5123        |\n|    total_timesteps              | 4432000     |\n| train/                          |             |\n|    approx_kl                    | 0.003047246 |\n|    clip_fraction                | 0.0124      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.936      |\n|    explained_variance           | 0.749       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 248         |\n|    n_updates                    | 2214        |\n|    policy_gradient_loss         | 0.000101    |\n|    value_loss                   | 529         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 130         |\n|    action_queue_updates_total   | 143         |\n|    ice_dug                      | 312         |\n|    water_produced               | 51.2        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1109         |\n|    time_elapsed                 | 5127         |\n|    total_timesteps              | 4436000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003652941 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.793        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 156          |\n|    n_updates                    | 2216         |\n|    policy_gradient_loss         | 0.00067      |\n|    value_loss                   | 341          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 142          |\n|    ice_dug                      | 748          |\n|    water_produced               | 157          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 132          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1110         |\n|    time_elapsed                 | 5132         |\n|    total_timesteps              | 4440000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002708155 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.919       |\n|    explained_variance           | 0.765        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 261          |\n|    n_updates                    | 2218         |\n|    policy_gradient_loss         | -0.000287    |\n|    value_loss                   | 481          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 631          |\n|    water_produced               | 109          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 139          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1111         |\n|    time_elapsed                 | 5136         |\n|    total_timesteps              | 4444000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016706068 |\n|    clip_fraction                | 0.00925      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.759        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 224          |\n|    n_updates                    | 2220         |\n|    policy_gradient_loss         | -0.000455    |\n|    value_loss                   | 468          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 700          |\n|    water_produced               | 150          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 125          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1112         |\n|    time_elapsed                 | 5140         |\n|    total_timesteps              | 4448000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007435311 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.743        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 2222         |\n|    policy_gradient_loss         | -0.000369    |\n|    value_loss                   | 438          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 608          |\n|    water_produced               | 129          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 136          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1113         |\n|    time_elapsed                 | 5144         |\n|    total_timesteps              | 4452000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009062254 |\n|    clip_fraction                | 0.00463      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.13        |\n|    explained_variance           | 0.846        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 2224         |\n|    policy_gradient_loss         | -0.000413    |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 574          |\n|    water_produced               | 100          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 136         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1114        |\n|    time_elapsed                 | 5149        |\n|    total_timesteps              | 4456000     |\n| train/                          |             |\n|    approx_kl                    | 0.001088863 |\n|    clip_fraction                | 0.00412     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.08       |\n|    explained_variance           | 0.761       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 174         |\n|    n_updates                    | 2226        |\n|    policy_gradient_loss         | -0.000432   |\n|    value_loss                   | 384         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 849         |\n|    water_produced               | 160         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 131          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1115         |\n|    time_elapsed                 | 5153         |\n|    total_timesteps              | 4460000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025983867 |\n|    clip_fraction                | 0.00975      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.796        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 2228         |\n|    policy_gradient_loss         | 0.000349     |\n|    value_loss                   | 532          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 433          |\n|    water_produced               | 84.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 117          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1116         |\n|    time_elapsed                 | 5158         |\n|    total_timesteps              | 4464000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023539294 |\n|    clip_fraction                | 0.013        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.761        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 171          |\n|    n_updates                    | 2230         |\n|    policy_gradient_loss         | 0.00022      |\n|    value_loss                   | 330          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 470          |\n|    water_produced               | 83.2         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 122          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1117         |\n|    time_elapsed                 | 5162         |\n|    total_timesteps              | 4468000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020908029 |\n|    clip_fraction                | 0.0106       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.3         |\n|    explained_variance           | 0.836        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 157          |\n|    n_updates                    | 2232         |\n|    policy_gradient_loss         | 0.00134      |\n|    value_loss                   | 428          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 848          |\n|    water_produced               | 150          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 122          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1118         |\n|    time_elapsed                 | 5166         |\n|    total_timesteps              | 4472000      |\n| train/                          |              |\n|    approx_kl                    | 0.0055037728 |\n|    clip_fraction                | 0.0282       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.955       |\n|    explained_variance           | 0.692        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 268          |\n|    n_updates                    | 2234         |\n|    policy_gradient_loss         | 0.00241      |\n|    value_loss                   | 595          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 488          |\n|    water_produced               | 98.8         |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 116        |\n| time/                           |            |\n|    fps                          | 865        |\n|    iterations                   | 1119       |\n|    time_elapsed                 | 5171       |\n|    total_timesteps              | 4476000    |\n| train/                          |            |\n|    approx_kl                    | 0.00184751 |\n|    clip_fraction                | 0.006      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.2       |\n|    explained_variance           | 0.861      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 159        |\n|    n_updates                    | 2236       |\n|    policy_gradient_loss         | 0.000229   |\n|    value_loss                   | 356        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 134        |\n|    action_queue_updates_total   | 158        |\n|    ice_dug                      | 625        |\n|    water_produced               | 137        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 127          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1120         |\n|    time_elapsed                 | 5175         |\n|    total_timesteps              | 4480000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018627349 |\n|    clip_fraction                | 0.008        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.18        |\n|    explained_variance           | 0.914        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 235          |\n|    n_updates                    | 2238         |\n|    policy_gradient_loss         | 0.000306     |\n|    value_loss                   | 451          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 647          |\n|    water_produced               | 135          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 134           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1121          |\n|    time_elapsed                 | 5180          |\n|    total_timesteps              | 4484000       |\n| train/                          |               |\n|    approx_kl                    | 0.00027813268 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1            |\n|    explained_variance           | 0.834         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 193           |\n|    n_updates                    | 2240          |\n|    policy_gradient_loss         | 0.000191      |\n|    value_loss                   | 397           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 136           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 729           |\n|    water_produced               | 116           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 129           |\n| time/                           |               |\n|    fps                          | 865           |\n|    iterations                   | 1122          |\n|    time_elapsed                 | 5185          |\n|    total_timesteps              | 4488000       |\n| train/                          |               |\n|    approx_kl                    | 0.00062850834 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.05         |\n|    explained_variance           | 0.765         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 202           |\n|    n_updates                    | 2242          |\n|    policy_gradient_loss         | 0.000211      |\n|    value_loss                   | 466           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 563           |\n|    water_produced               | 126           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 148          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1123         |\n|    time_elapsed                 | 5189         |\n|    total_timesteps              | 4492000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015427172 |\n|    clip_fraction                | 0.00763      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.816        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 182          |\n|    n_updates                    | 2244         |\n|    policy_gradient_loss         | 1.66e-05     |\n|    value_loss                   | 408          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 896          |\n|    water_produced               | 194          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 136          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1124         |\n|    time_elapsed                 | 5193         |\n|    total_timesteps              | 4496000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016228709 |\n|    clip_fraction                | 0.00462      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.981       |\n|    explained_variance           | 0.802        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 223          |\n|    n_updates                    | 2246         |\n|    policy_gradient_loss         | 0.00149      |\n|    value_loss                   | 517          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 411          |\n|    water_produced               | 75.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 132          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1125         |\n|    time_elapsed                 | 5197         |\n|    total_timesteps              | 4500000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027189981 |\n|    clip_fraction                | 0.0115       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.14        |\n|    explained_variance           | 0.82         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 150          |\n|    n_updates                    | 2248         |\n|    policy_gradient_loss         | -0.000487    |\n|    value_loss                   | 330          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 576          |\n|    water_produced               | 114          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 156          |\n| time/                           |              |\n|    fps                          | 865          |\n|    iterations                   | 1126         |\n|    time_elapsed                 | 5202         |\n|    total_timesteps              | 4504000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018364688 |\n|    clip_fraction                | 0.0153       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.19        |\n|    explained_variance           | 0.862        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 210          |\n|    n_updates                    | 2250         |\n|    policy_gradient_loss         | -0.000543    |\n|    value_loss                   | 386          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.1e+03      |\n|    water_produced               | 234          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 147         |\n| time/                           |             |\n|    fps                          | 865         |\n|    iterations                   | 1127        |\n|    time_elapsed                 | 5207        |\n|    total_timesteps              | 4508000     |\n| train/                          |             |\n|    approx_kl                    | 0.006853243 |\n|    clip_fraction                | 0.0341      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.856      |\n|    explained_variance           | 0.684       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 283         |\n|    n_updates                    | 2252        |\n|    policy_gradient_loss         | 0.00239     |\n|    value_loss                   | 575         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 138         |\n|    action_queue_updates_total   | 149         |\n|    ice_dug                      | 456         |\n|    water_produced               | 84          |\n-------------------------------------------------\nEval num_timesteps=4512000, episode_reward=657.32 +/- 507.99\nEpisode length: 720.60 +/- 234.53\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 721          |\n|    mean_reward                  | 657          |\n| time/                           |              |\n|    total_timesteps              | 4512000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003574458 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.814        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 206          |\n|    n_updates                    | 2254         |\n|    policy_gradient_loss         | 3.73e-05     |\n|    value_loss                   | 390          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 664          |\n|    water_produced               | 152          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 138      |\n| time/              |          |\n|    fps             | 864      |\n|    iterations      | 1128     |\n|    time_elapsed    | 5216     |\n|    total_timesteps | 4512000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 141          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1129         |\n|    time_elapsed                 | 5221         |\n|    total_timesteps              | 4516000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011327362 |\n|    clip_fraction                | 0.00675      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.04        |\n|    explained_variance           | 0.824        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 189          |\n|    n_updates                    | 2256         |\n|    policy_gradient_loss         | -1.13e-05    |\n|    value_loss                   | 407          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 138          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 524          |\n|    water_produced               | 90           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 145          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1130         |\n|    time_elapsed                 | 5226         |\n|    total_timesteps              | 4520000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013608116 |\n|    clip_fraction                | 0.00725      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.765        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 165          |\n|    n_updates                    | 2258         |\n|    policy_gradient_loss         | -0.000186    |\n|    value_loss                   | 366          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 696          |\n|    water_produced               | 133          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 112          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1131         |\n|    time_elapsed                 | 5230         |\n|    total_timesteps              | 4524000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011620992 |\n|    clip_fraction                | 0.0035       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.792        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 2260         |\n|    policy_gradient_loss         | 0.000307     |\n|    value_loss                   | 463          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 412          |\n|    water_produced               | 74.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 122          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1132         |\n|    time_elapsed                 | 5235         |\n|    total_timesteps              | 4528000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020952062 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.2         |\n|    explained_variance           | 0.835        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 186          |\n|    n_updates                    | 2262         |\n|    policy_gradient_loss         | -7.68e-05    |\n|    value_loss                   | 352          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 137          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 724          |\n|    water_produced               | 130          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 122           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1133          |\n|    time_elapsed                 | 5240          |\n|    total_timesteps              | 4532000       |\n| train/                          |               |\n|    approx_kl                    | 0.00059515215 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.1          |\n|    explained_variance           | 0.83          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 239           |\n|    n_updates                    | 2264          |\n|    policy_gradient_loss         | -0.000357     |\n|    value_loss                   | 465           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 807           |\n|    water_produced               | 150           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 134          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1134         |\n|    time_elapsed                 | 5245         |\n|    total_timesteps              | 4536000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023546007 |\n|    clip_fraction                | 0.0131       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.754        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 252          |\n|    n_updates                    | 2266         |\n|    policy_gradient_loss         | 0.00106      |\n|    value_loss                   | 514          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 134          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 714          |\n|    water_produced               | 148          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 125          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1135         |\n|    time_elapsed                 | 5250         |\n|    total_timesteps              | 4540000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012643654 |\n|    clip_fraction                | 0.00175      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.839        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 196          |\n|    n_updates                    | 2268         |\n|    policy_gradient_loss         | 4.18e-05     |\n|    value_loss                   | 384          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 584          |\n|    water_produced               | 91.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 129          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1136         |\n|    time_elapsed                 | 5255         |\n|    total_timesteps              | 4544000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037490954 |\n|    clip_fraction                | 0.0184       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.843        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 237          |\n|    n_updates                    | 2270         |\n|    policy_gradient_loss         | 0.000442     |\n|    value_loss                   | 487          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 406          |\n|    water_produced               | 91.7         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 136          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1137         |\n|    time_elapsed                 | 5259         |\n|    total_timesteps              | 4548000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022935295 |\n|    clip_fraction                | 0.00838      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.33        |\n|    explained_variance           | 0.877        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 178          |\n|    n_updates                    | 2272         |\n|    policy_gradient_loss         | -0.0011      |\n|    value_loss                   | 375          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 816          |\n|    water_produced               | 166          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1138         |\n|    time_elapsed                 | 5264         |\n|    total_timesteps              | 4552000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030160332 |\n|    clip_fraction                | 0.0162       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.16        |\n|    explained_variance           | 0.839        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 2274         |\n|    policy_gradient_loss         | 0.000685     |\n|    value_loss                   | 500          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 815          |\n|    water_produced               | 161          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 130          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1139         |\n|    time_elapsed                 | 5268         |\n|    total_timesteps              | 4556000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023011276 |\n|    clip_fraction                | 0.0156       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.11        |\n|    explained_variance           | 0.817        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 248          |\n|    n_updates                    | 2276         |\n|    policy_gradient_loss         | 0.00131      |\n|    value_loss                   | 496          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 516          |\n|    water_produced               | 110          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 128          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1140         |\n|    time_elapsed                 | 5273         |\n|    total_timesteps              | 4560000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009118061 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.25        |\n|    explained_variance           | 0.88         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 164          |\n|    n_updates                    | 2278         |\n|    policy_gradient_loss         | -0.000404    |\n|    value_loss                   | 358          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 410          |\n|    water_produced               | 83.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 141          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1141         |\n|    time_elapsed                 | 5278         |\n|    total_timesteps              | 4564000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024091857 |\n|    clip_fraction                | 0.0116       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.3         |\n|    explained_variance           | 0.879        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 158          |\n|    n_updates                    | 2280         |\n|    policy_gradient_loss         | 0.000601     |\n|    value_loss                   | 297          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 741          |\n|    water_produced               | 153          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 122           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1142          |\n|    time_elapsed                 | 5282          |\n|    total_timesteps              | 4568000       |\n| train/                          |               |\n|    approx_kl                    | 0.00024748975 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.18         |\n|    explained_variance           | 0.892         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 160           |\n|    n_updates                    | 2282          |\n|    policy_gradient_loss         | -0.000352     |\n|    value_loss                   | 377           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 342           |\n|    water_produced               | 72.5          |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 111          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1143         |\n|    time_elapsed                 | 5287         |\n|    total_timesteps              | 4572000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008962507 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.24        |\n|    explained_variance           | 0.876        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 164          |\n|    n_updates                    | 2284         |\n|    policy_gradient_loss         | -0.000385    |\n|    value_loss                   | 300          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 485          |\n|    water_produced               | 111          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 119          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1144         |\n|    time_elapsed                 | 5291         |\n|    total_timesteps              | 4576000      |\n| train/                          |              |\n|    approx_kl                    | 0.0039044016 |\n|    clip_fraction                | 0.0279       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.22        |\n|    explained_variance           | 0.813        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 2286         |\n|    policy_gradient_loss         | 0.00107      |\n|    value_loss                   | 400          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 670          |\n|    water_produced               | 146          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 129          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1145         |\n|    time_elapsed                 | 5296         |\n|    total_timesteps              | 4580000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036825761 |\n|    clip_fraction                | 0.0183       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.22        |\n|    explained_variance           | 0.863        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 2288         |\n|    policy_gradient_loss         | 0.000158     |\n|    value_loss                   | 477          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 596          |\n|    water_produced               | 136          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 120          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1146         |\n|    time_elapsed                 | 5300         |\n|    total_timesteps              | 4584000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016470801 |\n|    clip_fraction                | 0.00637      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.18        |\n|    explained_variance           | 0.874        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 188          |\n|    n_updates                    | 2290         |\n|    policy_gradient_loss         | -0.000719    |\n|    value_loss                   | 349          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 601          |\n|    water_produced               | 107          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 130          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1147         |\n|    time_elapsed                 | 5305         |\n|    total_timesteps              | 4588000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015263658 |\n|    clip_fraction                | 0.005        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.26        |\n|    explained_variance           | 0.866        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 196          |\n|    n_updates                    | 2292         |\n|    policy_gradient_loss         | -0.000303    |\n|    value_loss                   | 401          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 545          |\n|    water_produced               | 118          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 139           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1148          |\n|    time_elapsed                 | 5310          |\n|    total_timesteps              | 4592000       |\n| train/                          |               |\n|    approx_kl                    | 0.00074689474 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.15         |\n|    explained_variance           | 0.847         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 217           |\n|    n_updates                    | 2294          |\n|    policy_gradient_loss         | -5.4e-05      |\n|    value_loss                   | 436           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 764           |\n|    water_produced               | 154           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1149         |\n|    time_elapsed                 | 5314         |\n|    total_timesteps              | 4596000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019798903 |\n|    clip_fraction                | 0.00875      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.02        |\n|    explained_variance           | 0.761        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 2296         |\n|    policy_gradient_loss         | -0.000116    |\n|    value_loss                   | 562          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 679          |\n|    water_produced               | 143          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 140          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1150         |\n|    time_elapsed                 | 5319         |\n|    total_timesteps              | 4600000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006222604 |\n|    clip_fraction                | 0.003        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.12        |\n|    explained_variance           | 0.853        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 273          |\n|    n_updates                    | 2298         |\n|    policy_gradient_loss         | -4.02e-05    |\n|    value_loss                   | 459          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 660          |\n|    water_produced               | 144          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 152          |\n| time/                           |              |\n|    fps                          | 864          |\n|    iterations                   | 1151         |\n|    time_elapsed                 | 5323         |\n|    total_timesteps              | 4604000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009183511 |\n|    clip_fraction                | 0.0035       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.834        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 235          |\n|    n_updates                    | 2300         |\n|    policy_gradient_loss         | -0.000595    |\n|    value_loss                   | 492          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 731          |\n|    water_produced               | 167          |\n--------------------------------------------------\nEval num_timesteps=4608000, episode_reward=449.56 +/- 568.77\nEpisode length: 583.60 +/- 340.03\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 584          |\n|    mean_reward                  | 450          |\n| time/                           |              |\n|    total_timesteps              | 4608000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007526081 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.825        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 2302         |\n|    policy_gradient_loss         | -6.36e-05    |\n|    value_loss                   | 444          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 859          |\n|    water_produced               | 187          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 167      |\n| time/              |          |\n|    fps             | 863      |\n|    iterations      | 1152     |\n|    time_elapsed    | 5333     |\n|    total_timesteps | 4608000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 152          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1153         |\n|    time_elapsed                 | 5338         |\n|    total_timesteps              | 4612000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008887725 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.92        |\n|    explained_variance           | 0.742        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 248          |\n|    n_updates                    | 2304         |\n|    policy_gradient_loss         | 0.000122     |\n|    value_loss                   | 490          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 410          |\n|    water_produced               | 87           |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 139          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1154         |\n|    time_elapsed                 | 5343         |\n|    total_timesteps              | 4616000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035933312 |\n|    clip_fraction                | 0.0189       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.13        |\n|    explained_variance           | 0.864        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 149          |\n|    n_updates                    | 2306         |\n|    policy_gradient_loss         | 0.000304     |\n|    value_loss                   | 305          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 371          |\n|    water_produced               | 78.5         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 154         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 1155        |\n|    time_elapsed                 | 5347        |\n|    total_timesteps              | 4620000     |\n| train/                          |             |\n|    approx_kl                    | 0.006331549 |\n|    clip_fraction                | 0.0301      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.23       |\n|    explained_variance           | 0.871       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 146         |\n|    n_updates                    | 2308        |\n|    policy_gradient_loss         | 0.0006      |\n|    value_loss                   | 325         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 1e+03       |\n|    water_produced               | 218         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 131          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1156         |\n|    time_elapsed                 | 5352         |\n|    total_timesteps              | 4624000      |\n| train/                          |              |\n|    approx_kl                    | 0.0039966204 |\n|    clip_fraction                | 0.0255       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.798        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 297          |\n|    n_updates                    | 2310         |\n|    policy_gradient_loss         | 0.000808     |\n|    value_loss                   | 651          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 335          |\n|    water_produced               | 54           |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 121           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 1157          |\n|    time_elapsed                 | 5356          |\n|    total_timesteps              | 4628000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031168497 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.16         |\n|    explained_variance           | 0.847         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 146           |\n|    n_updates                    | 2312          |\n|    policy_gradient_loss         | 0.000277      |\n|    value_loss                   | 315           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 145           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 669           |\n|    water_produced               | 140           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 126           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 1158          |\n|    time_elapsed                 | 5361          |\n|    total_timesteps              | 4632000       |\n| train/                          |               |\n|    approx_kl                    | 0.00038641365 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.997        |\n|    explained_variance           | 0.672         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 258           |\n|    n_updates                    | 2314          |\n|    policy_gradient_loss         | -0.00011      |\n|    value_loss                   | 513           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 520           |\n|    water_produced               | 111           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 147           |\n| time/                           |               |\n|    fps                          | 864           |\n|    iterations                   | 1159          |\n|    time_elapsed                 | 5365          |\n|    total_timesteps              | 4636000       |\n| train/                          |               |\n|    approx_kl                    | 0.00067113637 |\n|    clip_fraction                | 0.00162       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.12         |\n|    explained_variance           | 0.817         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 195           |\n|    n_updates                    | 2316          |\n|    policy_gradient_loss         | -0.000166     |\n|    value_loss                   | 411           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 141           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 882           |\n|    water_produced               | 178           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 137          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1160         |\n|    time_elapsed                 | 5370         |\n|    total_timesteps              | 4640000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015509452 |\n|    clip_fraction                | 0.00937      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1           |\n|    explained_variance           | 0.773        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 314          |\n|    n_updates                    | 2318         |\n|    policy_gradient_loss         | 4.39e-05     |\n|    value_loss                   | 605          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 843          |\n|    water_produced               | 168          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 166          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1161         |\n|    time_elapsed                 | 5375         |\n|    total_timesteps              | 4644000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016220415 |\n|    clip_fraction                | 0.016        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.958       |\n|    explained_variance           | 0.775        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 276          |\n|    n_updates                    | 2320         |\n|    policy_gradient_loss         | 0.00121      |\n|    value_loss                   | 502          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 898          |\n|    water_produced               | 193          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 170           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 1162          |\n|    time_elapsed                 | 5380          |\n|    total_timesteps              | 4648000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031756615 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.05         |\n|    explained_variance           | 0.864         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 228           |\n|    n_updates                    | 2322          |\n|    policy_gradient_loss         | 0.000205      |\n|    value_loss                   | 492           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 140           |\n|    action_queue_updates_total   | 148           |\n|    ice_dug                      | 763           |\n|    water_produced               | 158           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 166           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 1163          |\n|    time_elapsed                 | 5384          |\n|    total_timesteps              | 4652000       |\n| train/                          |               |\n|    approx_kl                    | 0.00097407185 |\n|    clip_fraction                | 0.00775       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.959        |\n|    explained_variance           | 0.78          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 200           |\n|    n_updates                    | 2324          |\n|    policy_gradient_loss         | -0.000489     |\n|    value_loss                   | 417           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 143           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 431           |\n|    water_produced               | 95            |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 140         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 1164        |\n|    time_elapsed                 | 5389        |\n|    total_timesteps              | 4656000     |\n| train/                          |             |\n|    approx_kl                    | 0.004810691 |\n|    clip_fraction                | 0.029       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.09       |\n|    explained_variance           | 0.813       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 191         |\n|    n_updates                    | 2326        |\n|    policy_gradient_loss         | 0.000557    |\n|    value_loss                   | 326         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 130         |\n|    action_queue_updates_total   | 148         |\n|    ice_dug                      | 262         |\n|    water_produced               | 53.5        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 134          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1165         |\n|    time_elapsed                 | 5393         |\n|    total_timesteps              | 4660000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028610372 |\n|    clip_fraction                | 0.0126       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.27        |\n|    explained_variance           | 0.909        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 124          |\n|    n_updates                    | 2328         |\n|    policy_gradient_loss         | 0.000532     |\n|    value_loss                   | 273          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 744          |\n|    water_produced               | 140          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 124          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1166         |\n|    time_elapsed                 | 5398         |\n|    total_timesteps              | 4664000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018520955 |\n|    clip_fraction                | 0.0118       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.762        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 291          |\n|    n_updates                    | 2330         |\n|    policy_gradient_loss         | 0.000122     |\n|    value_loss                   | 595          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 772          |\n|    water_produced               | 143          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 129          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1167         |\n|    time_elapsed                 | 5403         |\n|    total_timesteps              | 4668000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031778633 |\n|    clip_fraction                | 0.0251       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.829        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 228          |\n|    n_updates                    | 2332         |\n|    policy_gradient_loss         | 0.00116      |\n|    value_loss                   | 503          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 818          |\n|    water_produced               | 181          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 143          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1168         |\n|    time_elapsed                 | 5407         |\n|    total_timesteps              | 4672000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007331525 |\n|    clip_fraction                | 0.00137      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.957       |\n|    explained_variance           | 0.787        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 2334         |\n|    policy_gradient_loss         | 0.000726     |\n|    value_loss                   | 469          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 724          |\n|    water_produced               | 162          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 147          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1169         |\n|    time_elapsed                 | 5412         |\n|    total_timesteps              | 4676000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014834765 |\n|    clip_fraction                | 0.00263      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.819        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 2336         |\n|    policy_gradient_loss         | -0.000933    |\n|    value_loss                   | 467          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 139          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 573          |\n|    water_produced               | 72.8         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 159          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1170         |\n|    time_elapsed                 | 5417         |\n|    total_timesteps              | 4680000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024797255 |\n|    clip_fraction                | 0.0179       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.09        |\n|    explained_variance           | 0.797        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 184          |\n|    n_updates                    | 2338         |\n|    policy_gradient_loss         | -0.000318    |\n|    value_loss                   | 426          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 925          |\n|    water_produced               | 197          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 156        |\n| time/                           |            |\n|    fps                          | 863        |\n|    iterations                   | 1171       |\n|    time_elapsed                 | 5422       |\n|    total_timesteps              | 4684000    |\n| train/                          |            |\n|    approx_kl                    | 0.00458574 |\n|    clip_fraction                | 0.0235     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.07      |\n|    explained_variance           | 0.851      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 313        |\n|    n_updates                    | 2340       |\n|    policy_gradient_loss         | 0.00135    |\n|    value_loss                   | 592        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 134        |\n|    action_queue_updates_total   | 151        |\n|    ice_dug                      | 654        |\n|    water_produced               | 129        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 142         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 1172        |\n|    time_elapsed                 | 5427        |\n|    total_timesteps              | 4688000     |\n| train/                          |             |\n|    approx_kl                    | 0.003568828 |\n|    clip_fraction                | 0.0244      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.14       |\n|    explained_variance           | 0.873       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 200         |\n|    n_updates                    | 2342        |\n|    policy_gradient_loss         | 0.00171     |\n|    value_loss                   | 408         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 149         |\n|    ice_dug                      | 557         |\n|    water_produced               | 112         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 158         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 1173        |\n|    time_elapsed                 | 5431        |\n|    total_timesteps              | 4692000     |\n| train/                          |             |\n|    approx_kl                    | 0.002947481 |\n|    clip_fraction                | 0.014       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.954      |\n|    explained_variance           | 0.667       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 183         |\n|    n_updates                    | 2344        |\n|    policy_gradient_loss         | -0.000112   |\n|    value_loss                   | 417         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 1.11e+03    |\n|    water_produced               | 238         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 171          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1174         |\n|    time_elapsed                 | 5436         |\n|    total_timesteps              | 4696000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009502582 |\n|    clip_fraction                | 0.00287      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.942       |\n|    explained_variance           | 0.756        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 342          |\n|    n_updates                    | 2346         |\n|    policy_gradient_loss         | -0.00024     |\n|    value_loss                   | 672          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 679          |\n|    water_produced               | 140          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 156          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1175         |\n|    time_elapsed                 | 5441         |\n|    total_timesteps              | 4700000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006175308 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.791        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 258          |\n|    n_updates                    | 2348         |\n|    policy_gradient_loss         | 0.00129      |\n|    value_loss                   | 461          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 146          |\n|    ice_dug                      | 714          |\n|    water_produced               | 123          |\n--------------------------------------------------\nEval num_timesteps=4704000, episode_reward=388.96 +/- 648.96\nEpisode length: 493.80 +/- 273.12\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 494          |\n|    mean_reward                  | 389          |\n| time/                           |              |\n|    total_timesteps              | 4704000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014080632 |\n|    clip_fraction                | 0.00737      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.942       |\n|    explained_variance           | 0.643        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 225          |\n|    n_updates                    | 2350         |\n|    policy_gradient_loss         | -0.000549    |\n|    value_loss                   | 475          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 574          |\n|    water_produced               | 72.8         |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 144      |\n| time/              |          |\n|    fps             | 863      |\n|    iterations      | 1176     |\n|    time_elapsed    | 5450     |\n|    total_timesteps | 4704000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 152          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1177         |\n|    time_elapsed                 | 5455         |\n|    total_timesteps              | 4708000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010874744 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1           |\n|    explained_variance           | 0.735        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 166          |\n|    n_updates                    | 2352         |\n|    policy_gradient_loss         | -0.00121     |\n|    value_loss                   | 338          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 719          |\n|    water_produced               | 148          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 138          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1178         |\n|    time_elapsed                 | 5460         |\n|    total_timesteps              | 4712000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019423015 |\n|    clip_fraction                | 0.00737      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.996       |\n|    explained_variance           | 0.758        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 2354         |\n|    policy_gradient_loss         | -0.000724    |\n|    value_loss                   | 473          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 878          |\n|    water_produced               | 171          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 147          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1179         |\n|    time_elapsed                 | 5465         |\n|    total_timesteps              | 4716000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012257566 |\n|    clip_fraction                | 0.005        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.933       |\n|    explained_variance           | 0.713        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 278          |\n|    n_updates                    | 2356         |\n|    policy_gradient_loss         | 0.00146      |\n|    value_loss                   | 533          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 964          |\n|    water_produced               | 183          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 147          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1180         |\n|    time_elapsed                 | 5470         |\n|    total_timesteps              | 4720000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013956061 |\n|    clip_fraction                | 0.00675      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.963       |\n|    explained_variance           | 0.784        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 260          |\n|    n_updates                    | 2358         |\n|    policy_gradient_loss         | 0.00184      |\n|    value_loss                   | 511          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 530          |\n|    water_produced               | 122          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 153        |\n| time/                           |            |\n|    fps                          | 862        |\n|    iterations                   | 1181       |\n|    time_elapsed                 | 5474       |\n|    total_timesteps              | 4724000    |\n| train/                          |            |\n|    approx_kl                    | 0.00455239 |\n|    clip_fraction                | 0.0216     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.964     |\n|    explained_variance           | 0.718      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 139        |\n|    n_updates                    | 2360       |\n|    policy_gradient_loss         | -0.00219   |\n|    value_loss                   | 334        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 162        |\n|    action_queue_updates_total   | 165        |\n|    ice_dug                      | 579        |\n|    water_produced               | 102        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 154          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1182         |\n|    time_elapsed                 | 5479         |\n|    total_timesteps              | 4728000      |\n| train/                          |              |\n|    approx_kl                    | 0.0062106396 |\n|    clip_fraction                | 0.0406       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.1         |\n|    explained_variance           | 0.699        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 2362         |\n|    policy_gradient_loss         | 0.00139      |\n|    value_loss                   | 500          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 754          |\n|    water_produced               | 157          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 161         |\n| time/                           |             |\n|    fps                          | 862         |\n|    iterations                   | 1183        |\n|    time_elapsed                 | 5484        |\n|    total_timesteps              | 4732000     |\n| train/                          |             |\n|    approx_kl                    | 0.002781445 |\n|    clip_fraction                | 0.0155      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.02       |\n|    explained_variance           | 0.755       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 293         |\n|    n_updates                    | 2364        |\n|    policy_gradient_loss         | 0.0012      |\n|    value_loss                   | 565         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 948         |\n|    water_produced               | 203         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 164          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1184         |\n|    time_elapsed                 | 5488         |\n|    total_timesteps              | 4736000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015576503 |\n|    clip_fraction                | 0.007        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.944       |\n|    explained_variance           | 0.734        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 291          |\n|    n_updates                    | 2366         |\n|    policy_gradient_loss         | 0.00124      |\n|    value_loss                   | 588          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 989          |\n|    water_produced               | 195          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 168          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1185         |\n|    time_elapsed                 | 5493         |\n|    total_timesteps              | 4740000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031685669 |\n|    clip_fraction                | 0.0206       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.913       |\n|    explained_variance           | 0.737        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 247          |\n|    n_updates                    | 2368         |\n|    policy_gradient_loss         | 0.00174      |\n|    value_loss                   | 521          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 645          |\n|    water_produced               | 142          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 186          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1186         |\n|    time_elapsed                 | 5498         |\n|    total_timesteps              | 4744000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015757954 |\n|    clip_fraction                | 0.00925      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.07        |\n|    explained_variance           | 0.88         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 193          |\n|    n_updates                    | 2370         |\n|    policy_gradient_loss         | -0.000646    |\n|    value_loss                   | 337          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 897          |\n|    water_produced               | 191          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 189         |\n| time/                           |             |\n|    fps                          | 862         |\n|    iterations                   | 1187        |\n|    time_elapsed                 | 5502        |\n|    total_timesteps              | 4748000     |\n| train/                          |             |\n|    approx_kl                    | 0.001870644 |\n|    clip_fraction                | 0.00125     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.892      |\n|    explained_variance           | 0.684       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 259         |\n|    n_updates                    | 2372        |\n|    policy_gradient_loss         | 0.00023     |\n|    value_loss                   | 517         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 141         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 723         |\n|    water_produced               | 172         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 176          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1188         |\n|    time_elapsed                 | 5507         |\n|    total_timesteps              | 4752000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022806723 |\n|    clip_fraction                | 0.0105       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.832        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 2374         |\n|    policy_gradient_loss         | -0.00191     |\n|    value_loss                   | 390          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 665          |\n|    water_produced               | 143          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 164          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1189         |\n|    time_elapsed                 | 5511         |\n|    total_timesteps              | 4756000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011113872 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.02        |\n|    explained_variance           | 0.796        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 188          |\n|    n_updates                    | 2376         |\n|    policy_gradient_loss         | 0.000127     |\n|    value_loss                   | 373          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 593          |\n|    water_produced               | 135          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 163          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1190         |\n|    time_elapsed                 | 5515         |\n|    total_timesteps              | 4760000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012139551 |\n|    clip_fraction                | 0.00387      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.795        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 189          |\n|    n_updates                    | 2378         |\n|    policy_gradient_loss         | -0.00106     |\n|    value_loss                   | 399          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 717          |\n|    water_produced               | 138          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 152          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1191         |\n|    time_elapsed                 | 5520         |\n|    total_timesteps              | 4764000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014105473 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.964       |\n|    explained_variance           | 0.76         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 2380         |\n|    policy_gradient_loss         | -0.000222    |\n|    value_loss                   | 464          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 140          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 701          |\n|    water_produced               | 137          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 141          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1192         |\n|    time_elapsed                 | 5524         |\n|    total_timesteps              | 4768000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006987244 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1           |\n|    explained_variance           | 0.802        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 208          |\n|    n_updates                    | 2382         |\n|    policy_gradient_loss         | -4.07e-05    |\n|    value_loss                   | 421          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 616          |\n|    water_produced               | 118          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 158         |\n| time/                           |             |\n|    fps                          | 862         |\n|    iterations                   | 1193        |\n|    time_elapsed                 | 5529        |\n|    total_timesteps              | 4772000     |\n| train/                          |             |\n|    approx_kl                    | 0.003406427 |\n|    clip_fraction                | 0.0151      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.03       |\n|    explained_variance           | 0.708       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 263         |\n|    n_updates                    | 2384        |\n|    policy_gradient_loss         | 3.09e-05    |\n|    value_loss                   | 528         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.09e+03    |\n|    water_produced               | 223         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 153         |\n| time/                           |             |\n|    fps                          | 862         |\n|    iterations                   | 1194        |\n|    time_elapsed                 | 5534        |\n|    total_timesteps              | 4776000     |\n| train/                          |             |\n|    approx_kl                    | 0.003227453 |\n|    clip_fraction                | 0.0209      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.906      |\n|    explained_variance           | 0.682       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 344         |\n|    n_updates                    | 2386        |\n|    policy_gradient_loss         | 0.00178     |\n|    value_loss                   | 614         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 128         |\n|    action_queue_updates_total   | 143         |\n|    ice_dug                      | 648         |\n|    water_produced               | 109         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 165           |\n| time/                           |               |\n|    fps                          | 863           |\n|    iterations                   | 1195          |\n|    time_elapsed                 | 5538          |\n|    total_timesteps              | 4780000       |\n| train/                          |               |\n|    approx_kl                    | 0.00019976016 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.01         |\n|    explained_variance           | 0.809         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 188           |\n|    n_updates                    | 2388          |\n|    policy_gradient_loss         | -0.000201     |\n|    value_loss                   | 380           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 859           |\n|    water_produced               | 199           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 167          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1196         |\n|    time_elapsed                 | 5543         |\n|    total_timesteps              | 4784000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008965723 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.07        |\n|    explained_variance           | 0.875        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 240          |\n|    n_updates                    | 2390         |\n|    policy_gradient_loss         | 0.000537     |\n|    value_loss                   | 465          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 662          |\n|    water_produced               | 144          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 169          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1197         |\n|    time_elapsed                 | 5547         |\n|    total_timesteps              | 4788000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003384774 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.999       |\n|    explained_variance           | 0.82         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 195          |\n|    n_updates                    | 2392         |\n|    policy_gradient_loss         | 9.04e-06     |\n|    value_loss                   | 401          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 136          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 691          |\n|    water_produced               | 129          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 145         |\n| time/                           |             |\n|    fps                          | 863         |\n|    iterations                   | 1198        |\n|    time_elapsed                 | 5552        |\n|    total_timesteps              | 4792000     |\n| train/                          |             |\n|    approx_kl                    | 0.000563039 |\n|    clip_fraction                | 0.000125    |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.06       |\n|    explained_variance           | 0.855       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 172         |\n|    n_updates                    | 2394        |\n|    policy_gradient_loss         | -0.000868   |\n|    value_loss                   | 365         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 588         |\n|    water_produced               | 110         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 166          |\n| time/                           |              |\n|    fps                          | 863          |\n|    iterations                   | 1199         |\n|    time_elapsed                 | 5556         |\n|    total_timesteps              | 4796000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009899444 |\n|    clip_fraction                | 0.00575      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.771        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 2396         |\n|    policy_gradient_loss         | -0.00029     |\n|    value_loss                   | 409          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 913          |\n|    water_produced               | 208          |\n--------------------------------------------------\nEval num_timesteps=4800000, episode_reward=1276.80 +/- 687.97\nEpisode length: 898.40 +/- 196.27\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 898           |\n|    mean_reward                  | 1.28e+03      |\n| time/                           |               |\n|    total_timesteps              | 4800000       |\n| train/                          |               |\n|    approx_kl                    | 0.00062930677 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.912        |\n|    explained_variance           | 0.676         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 204           |\n|    n_updates                    | 2398          |\n|    policy_gradient_loss         | 9.23e-05      |\n|    value_loss                   | 454           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 148           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 1.01e+03      |\n|    water_produced               | 188           |\n---------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 164      |\n| time/              |          |\n|    fps             | 861      |\n|    iterations      | 1200     |\n|    time_elapsed    | 5570     |\n|    total_timesteps | 4800000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 152         |\n| time/                           |             |\n|    fps                          | 861         |\n|    iterations                   | 1201        |\n|    time_elapsed                 | 5574        |\n|    total_timesteps              | 4804000     |\n| train/                          |             |\n|    approx_kl                    | 0.002604638 |\n|    clip_fraction                | 0.00775     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.875      |\n|    explained_variance           | 0.678       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 209         |\n|    n_updates                    | 2400        |\n|    policy_gradient_loss         | 0.00142     |\n|    value_loss                   | 446         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 443         |\n|    water_produced               | 90.2        |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 153         |\n| time/                           |             |\n|    fps                          | 861         |\n|    iterations                   | 1202        |\n|    time_elapsed                 | 5579        |\n|    total_timesteps              | 4808000     |\n| train/                          |             |\n|    approx_kl                    | 0.006226608 |\n|    clip_fraction                | 0.0305      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.98       |\n|    explained_variance           | 0.733       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 161         |\n|    n_updates                    | 2402        |\n|    policy_gradient_loss         | -0.000202   |\n|    value_loss                   | 314         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 561         |\n|    water_produced               | 132         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 165          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1203         |\n|    time_elapsed                 | 5583         |\n|    total_timesteps              | 4812000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022344892 |\n|    clip_fraction                | 0.0223       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.74         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 2404         |\n|    policy_gradient_loss         | -0.000356    |\n|    value_loss                   | 431          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 861          |\n|    water_produced               | 169          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 171          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1204         |\n|    time_elapsed                 | 5588         |\n|    total_timesteps              | 4816000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016853008 |\n|    clip_fraction                | 0.0137       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.936       |\n|    explained_variance           | 0.764        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 254          |\n|    n_updates                    | 2406         |\n|    policy_gradient_loss         | 0.000789     |\n|    value_loss                   | 525          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.02e+03     |\n|    water_produced               | 238          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 162          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1205         |\n|    time_elapsed                 | 5592         |\n|    total_timesteps              | 4820000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018627696 |\n|    clip_fraction                | 0.0118       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.902       |\n|    explained_variance           | 0.712        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 287          |\n|    n_updates                    | 2408         |\n|    policy_gradient_loss         | 0.000244     |\n|    value_loss                   | 597          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 929          |\n|    water_produced               | 142          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 169          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1206         |\n|    time_elapsed                 | 5597         |\n|    total_timesteps              | 4824000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006494915 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.839       |\n|    explained_variance           | 0.524        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 239          |\n|    n_updates                    | 2410         |\n|    policy_gradient_loss         | 0.00109      |\n|    value_loss                   | 484          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 671          |\n|    water_produced               | 122          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 190         |\n| time/                           |             |\n|    fps                          | 861         |\n|    iterations                   | 1207        |\n|    time_elapsed                 | 5601        |\n|    total_timesteps              | 4828000     |\n| train/                          |             |\n|    approx_kl                    | 0.004998129 |\n|    clip_fraction                | 0.0266      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.924      |\n|    explained_variance           | 0.605       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 217         |\n|    n_updates                    | 2412        |\n|    policy_gradient_loss         | -0.00109    |\n|    value_loss                   | 405         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.13e+03    |\n|    water_produced               | 231         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 177          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1208         |\n|    time_elapsed                 | 5606         |\n|    total_timesteps              | 4832000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018074192 |\n|    clip_fraction                | 0.0106       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.872       |\n|    explained_variance           | 0.669        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 273          |\n|    n_updates                    | 2414         |\n|    policy_gradient_loss         | 0.000257     |\n|    value_loss                   | 611          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 133          |\n|    action_queue_updates_total   | 144          |\n|    ice_dug                      | 602          |\n|    water_produced               | 109          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 158           |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 1209          |\n|    time_elapsed                 | 5610          |\n|    total_timesteps              | 4836000       |\n| train/                          |               |\n|    approx_kl                    | 0.00058298715 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.968        |\n|    explained_variance           | 0.745         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 203           |\n|    n_updates                    | 2416          |\n|    policy_gradient_loss         | -0.000241     |\n|    value_loss                   | 427           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 142           |\n|    action_queue_updates_total   | 153           |\n|    ice_dug                      | 666           |\n|    water_produced               | 144           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 167          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1210         |\n|    time_elapsed                 | 5615         |\n|    total_timesteps              | 4840000      |\n| train/                          |              |\n|    approx_kl                    | 0.0047343364 |\n|    clip_fraction                | 0.033        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.06        |\n|    explained_variance           | 0.834        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 171          |\n|    n_updates                    | 2418         |\n|    policy_gradient_loss         | -0.00167     |\n|    value_loss                   | 401          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 832          |\n|    water_produced               | 192          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 181        |\n| time/                           |            |\n|    fps                          | 861        |\n|    iterations                   | 1211       |\n|    time_elapsed                 | 5619       |\n|    total_timesteps              | 4844000    |\n| train/                          |            |\n|    approx_kl                    | 0.00160629 |\n|    clip_fraction                | 0.0095     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.03      |\n|    explained_variance           | 0.826      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 217        |\n|    n_updates                    | 2420       |\n|    policy_gradient_loss         | 0.00101    |\n|    value_loss                   | 472        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 148        |\n|    action_queue_updates_total   | 156        |\n|    ice_dug                      | 889        |\n|    water_produced               | 189        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 173          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1212         |\n|    time_elapsed                 | 5624         |\n|    total_timesteps              | 4848000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006759522 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.94        |\n|    explained_variance           | 0.777        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 2422         |\n|    policy_gradient_loss         | 0.000707     |\n|    value_loss                   | 463          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 855          |\n|    water_produced               | 192          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 175          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1213         |\n|    time_elapsed                 | 5628         |\n|    total_timesteps              | 4852000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005921972 |\n|    clip_fraction                | 0.0025       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.802        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 2424         |\n|    policy_gradient_loss         | 0.000497     |\n|    value_loss                   | 485          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 550          |\n|    water_produced               | 121          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 168          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1214         |\n|    time_elapsed                 | 5633         |\n|    total_timesteps              | 4856000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050845193 |\n|    clip_fraction                | 0.0303       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.604        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 187          |\n|    n_updates                    | 2426         |\n|    policy_gradient_loss         | 0.000368     |\n|    value_loss                   | 364          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 526          |\n|    water_produced               | 110          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 177          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1215         |\n|    time_elapsed                 | 5637         |\n|    total_timesteps              | 4860000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013808312 |\n|    clip_fraction                | 0.00675      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.13        |\n|    explained_variance           | 0.822        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 226          |\n|    n_updates                    | 2428         |\n|    policy_gradient_loss         | -0.000682    |\n|    value_loss                   | 450          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.10e+03     |\n|    water_produced               | 232          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 168        |\n| time/                           |            |\n|    fps                          | 862        |\n|    iterations                   | 1216       |\n|    time_elapsed                 | 5642       |\n|    total_timesteps              | 4864000    |\n| train/                          |            |\n|    approx_kl                    | 0.00375277 |\n|    clip_fraction                | 0.0216     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.972     |\n|    explained_variance           | 0.726      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 344        |\n|    n_updates                    | 2430       |\n|    policy_gradient_loss         | 0.00224    |\n|    value_loss                   | 646        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 144        |\n|    action_queue_updates_total   | 153        |\n|    ice_dug                      | 815        |\n|    water_produced               | 146        |\n------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 160           |\n| time/                           |               |\n|    fps                          | 862           |\n|    iterations                   | 1217          |\n|    time_elapsed                 | 5646          |\n|    total_timesteps              | 4868000       |\n| train/                          |               |\n|    approx_kl                    | 0.00026533654 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.958        |\n|    explained_variance           | 0.742         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 212           |\n|    n_updates                    | 2432          |\n|    policy_gradient_loss         | 0.000325      |\n|    value_loss                   | 459           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 759           |\n|    water_produced               | 151           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 169          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1218         |\n|    time_elapsed                 | 5651         |\n|    total_timesteps              | 4872000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023111785 |\n|    clip_fraction                | 0.012        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.02        |\n|    explained_variance           | 0.744        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 228          |\n|    n_updates                    | 2434         |\n|    policy_gradient_loss         | -0.00148     |\n|    value_loss                   | 458          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 871          |\n|    water_produced               | 164          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 187          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1219         |\n|    time_elapsed                 | 5656         |\n|    total_timesteps              | 4876000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005669798 |\n|    clip_fraction                | 0.00137      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.942       |\n|    explained_variance           | 0.644        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 2436         |\n|    policy_gradient_loss         | 0.000242     |\n|    value_loss                   | 461          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 878          |\n|    water_produced               | 196          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 177          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1220         |\n|    time_elapsed                 | 5660         |\n|    total_timesteps              | 4880000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008143483 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.966       |\n|    explained_variance           | 0.755        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 2438         |\n|    policy_gradient_loss         | 0.000651     |\n|    value_loss                   | 486          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 876          |\n|    water_produced               | 186          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 178          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1221         |\n|    time_elapsed                 | 5665         |\n|    total_timesteps              | 4884000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014475283 |\n|    clip_fraction                | 0.00287      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.985       |\n|    explained_variance           | 0.718        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 304          |\n|    n_updates                    | 2440         |\n|    policy_gradient_loss         | 0.0011       |\n|    value_loss                   | 569          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 864          |\n|    water_produced               | 148          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 177          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1222         |\n|    time_elapsed                 | 5669         |\n|    total_timesteps              | 4888000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029034987 |\n|    clip_fraction                | 0.0065       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.958       |\n|    explained_variance           | 0.806        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 220          |\n|    n_updates                    | 2442         |\n|    policy_gradient_loss         | -0.00112     |\n|    value_loss                   | 416          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 836          |\n|    water_produced               | 147          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 166          |\n| time/                           |              |\n|    fps                          | 862          |\n|    iterations                   | 1223         |\n|    time_elapsed                 | 5674         |\n|    total_timesteps              | 4892000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013738696 |\n|    clip_fraction                | 0.0055       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.929       |\n|    explained_variance           | 0.659        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 2444         |\n|    policy_gradient_loss         | -0.00125     |\n|    value_loss                   | 476          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 595          |\n|    water_produced               | 110          |\n--------------------------------------------------\nEval num_timesteps=4896000, episode_reward=1022.36 +/- 730.05\nEpisode length: 820.40 +/- 270.90\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 820          |\n|    mean_reward                  | 1.02e+03     |\n| time/                           |              |\n|    total_timesteps              | 4896000      |\n| train/                          |              |\n|    approx_kl                    | 0.0040754555 |\n|    clip_fraction                | 0.0222       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.04        |\n|    explained_variance           | 0.72         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 2446         |\n|    policy_gradient_loss         | -0.00152     |\n|    value_loss                   | 509          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 804          |\n|    water_produced               | 160          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 158      |\n| time/              |          |\n|    fps             | 861      |\n|    iterations      | 1224     |\n|    time_elapsed    | 5684     |\n|    total_timesteps | 4896000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 156         |\n| time/                           |             |\n|    fps                          | 861         |\n|    iterations                   | 1225        |\n|    time_elapsed                 | 5689        |\n|    total_timesteps              | 4900000     |\n| train/                          |             |\n|    approx_kl                    | 0.002704022 |\n|    clip_fraction                | 0.0154      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.988      |\n|    explained_variance           | 0.774       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 281         |\n|    n_updates                    | 2448        |\n|    policy_gradient_loss         | 0.00128     |\n|    value_loss                   | 517         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 153         |\n|    ice_dug                      | 878         |\n|    water_produced               | 176         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 162          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1226         |\n|    time_elapsed                 | 5693         |\n|    total_timesteps              | 4904000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020651144 |\n|    clip_fraction                | 0.016        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.952       |\n|    explained_variance           | 0.741        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 297          |\n|    n_updates                    | 2450         |\n|    policy_gradient_loss         | 0.00244      |\n|    value_loss                   | 577          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 821          |\n|    water_produced               | 178          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 166          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1227         |\n|    time_elapsed                 | 5698         |\n|    total_timesteps              | 4908000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007711067 |\n|    clip_fraction                | 0.00375      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.915       |\n|    explained_variance           | 0.687        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 225          |\n|    n_updates                    | 2452         |\n|    policy_gradient_loss         | -0.00176     |\n|    value_loss                   | 441          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 772          |\n|    water_produced               | 170          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 180          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1228         |\n|    time_elapsed                 | 5702         |\n|    total_timesteps              | 4912000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017258307 |\n|    clip_fraction                | 0.0085       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.02        |\n|    explained_variance           | 0.844        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 284          |\n|    n_updates                    | 2454         |\n|    policy_gradient_loss         | -0.00128     |\n|    value_loss                   | 487          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 980          |\n|    water_produced               | 174          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 176          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1229         |\n|    time_elapsed                 | 5707         |\n|    total_timesteps              | 4916000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010319221 |\n|    clip_fraction                | 0.00137      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.884       |\n|    explained_variance           | 0.613        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 263          |\n|    n_updates                    | 2456         |\n|    policy_gradient_loss         | -0.000202    |\n|    value_loss                   | 547          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 791          |\n|    water_produced               | 140          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 168          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1230         |\n|    time_elapsed                 | 5711         |\n|    total_timesteps              | 4920000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016655428 |\n|    clip_fraction                | 0.01         |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.918       |\n|    explained_variance           | 0.632        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 2458         |\n|    policy_gradient_loss         | -0.00146     |\n|    value_loss                   | 415          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 144          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 609          |\n|    water_produced               | 136          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 170          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1231         |\n|    time_elapsed                 | 5716         |\n|    total_timesteps              | 4924000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018990717 |\n|    clip_fraction                | 0.0125       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.824        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 187          |\n|    n_updates                    | 2460         |\n|    policy_gradient_loss         | -0.000874    |\n|    value_loss                   | 375          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 835          |\n|    water_produced               | 188          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 179          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1232         |\n|    time_elapsed                 | 5721         |\n|    total_timesteps              | 4928000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012641378 |\n|    clip_fraction                | 0.0055       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.963       |\n|    explained_variance           | 0.687        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 290          |\n|    n_updates                    | 2462         |\n|    policy_gradient_loss         | 0.000104     |\n|    value_loss                   | 533          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.02e+03     |\n|    water_produced               | 216          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 174          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1233         |\n|    time_elapsed                 | 5725         |\n|    total_timesteps              | 4932000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022347195 |\n|    clip_fraction                | 0.00388      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.898       |\n|    explained_variance           | 0.666        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 252          |\n|    n_updates                    | 2464         |\n|    policy_gradient_loss         | 0.00165      |\n|    value_loss                   | 469          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 876          |\n|    water_produced               | 149          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 176          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1234         |\n|    time_elapsed                 | 5729         |\n|    total_timesteps              | 4936000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019466868 |\n|    clip_fraction                | 0.0152       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.899       |\n|    explained_variance           | 0.674        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 225          |\n|    n_updates                    | 2466         |\n|    policy_gradient_loss         | -0.00114     |\n|    value_loss                   | 407          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 801          |\n|    water_produced               | 147          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 179          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1235         |\n|    time_elapsed                 | 5734         |\n|    total_timesteps              | 4940000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008934109 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.976       |\n|    explained_variance           | 0.661        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 2468         |\n|    policy_gradient_loss         | 3.73e-05     |\n|    value_loss                   | 499          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 674          |\n|    water_produced               | 150          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 180          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1236         |\n|    time_elapsed                 | 5738         |\n|    total_timesteps              | 4944000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024739932 |\n|    clip_fraction                | 0.00937      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.961       |\n|    explained_variance           | 0.717        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 192          |\n|    n_updates                    | 2470         |\n|    policy_gradient_loss         | 6.57e-05     |\n|    value_loss                   | 379          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 915          |\n|    water_produced               | 193          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 183          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1237         |\n|    time_elapsed                 | 5743         |\n|    total_timesteps              | 4948000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007386965 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.964       |\n|    explained_variance           | 0.737        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 261          |\n|    n_updates                    | 2472         |\n|    policy_gradient_loss         | 0.001        |\n|    value_loss                   | 466          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.12e+03     |\n|    water_produced               | 234          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 179          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1238         |\n|    time_elapsed                 | 5747         |\n|    total_timesteps              | 4952000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014542429 |\n|    clip_fraction                | 0.00387      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.885       |\n|    explained_variance           | 0.605        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 264          |\n|    n_updates                    | 2474         |\n|    policy_gradient_loss         | 0.00091      |\n|    value_loss                   | 539          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 753          |\n|    water_produced               | 127          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 189          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1239         |\n|    time_elapsed                 | 5752         |\n|    total_timesteps              | 4956000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011588814 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.95        |\n|    explained_variance           | 0.574        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 2476         |\n|    policy_gradient_loss         | -0.000638    |\n|    value_loss                   | 430          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 995          |\n|    water_produced               | 197          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 208           |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 1240          |\n|    time_elapsed                 | 5757          |\n|    total_timesteps              | 4960000       |\n| train/                          |               |\n|    approx_kl                    | 0.00026213392 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.979        |\n|    explained_variance           | 0.656         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 214           |\n|    n_updates                    | 2478          |\n|    policy_gradient_loss         | -0.000573     |\n|    value_loss                   | 453           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 150           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 1.12e+03      |\n|    water_produced               | 237           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 181         |\n| time/                           |             |\n|    fps                          | 861         |\n|    iterations                   | 1241        |\n|    time_elapsed                 | 5761        |\n|    total_timesteps              | 4964000     |\n| train/                          |             |\n|    approx_kl                    | 0.001681172 |\n|    clip_fraction                | 0.00262     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.905      |\n|    explained_variance           | 0.761       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 247         |\n|    n_updates                    | 2480        |\n|    policy_gradient_loss         | 0.00256     |\n|    value_loss                   | 515         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 140         |\n|    action_queue_updates_total   | 147         |\n|    ice_dug                      | 364         |\n|    water_produced               | 64.2        |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 164          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1242         |\n|    time_elapsed                 | 5766         |\n|    total_timesteps              | 4968000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050515435 |\n|    clip_fraction                | 0.0336       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.801        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 184          |\n|    n_updates                    | 2482         |\n|    policy_gradient_loss         | -0.000131    |\n|    value_loss                   | 382          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 740          |\n|    water_produced               | 153          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 178          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1243         |\n|    time_elapsed                 | 5770         |\n|    total_timesteps              | 4972000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017909097 |\n|    clip_fraction                | 0.00475      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.08        |\n|    explained_variance           | 0.831        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 2484         |\n|    policy_gradient_loss         | -0.00143     |\n|    value_loss                   | 419          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 966          |\n|    water_produced               | 198          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 187          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1244         |\n|    time_elapsed                 | 5774         |\n|    total_timesteps              | 4976000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023857527 |\n|    clip_fraction                | 0.0152       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.969       |\n|    explained_variance           | 0.571        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 266          |\n|    n_updates                    | 2486         |\n|    policy_gradient_loss         | 0.00124      |\n|    value_loss                   | 592          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.12e+03     |\n|    water_produced               | 237          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 157          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1245         |\n|    time_elapsed                 | 5779         |\n|    total_timesteps              | 4980000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026380476 |\n|    clip_fraction                | 0.0162       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.919       |\n|    explained_variance           | 0.646        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 2488         |\n|    policy_gradient_loss         | 0.00127      |\n|    value_loss                   | 507          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 588          |\n|    water_produced               | 96.2         |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 167           |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 1246          |\n|    time_elapsed                 | 5783          |\n|    total_timesteps              | 4984000       |\n| train/                          |               |\n|    approx_kl                    | 0.00030673685 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.969        |\n|    explained_variance           | 0.713         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 203           |\n|    n_updates                    | 2490          |\n|    policy_gradient_loss         | 0.000118      |\n|    value_loss                   | 408           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 541           |\n|    water_produced               | 111           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 167          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1247         |\n|    time_elapsed                 | 5788         |\n|    total_timesteps              | 4988000      |\n| train/                          |              |\n|    approx_kl                    | 0.0063164122 |\n|    clip_fraction                | 0.0381       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.02        |\n|    explained_variance           | 0.814        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 144          |\n|    n_updates                    | 2492         |\n|    policy_gradient_loss         | -0.000705    |\n|    value_loss                   | 333          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 871          |\n|    water_produced               | 151          |\n--------------------------------------------------\nEval num_timesteps=4992000, episode_reward=1158.32 +/- 400.91\nEpisode length: 932.20 +/- 135.60\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 932           |\n|    mean_reward                  | 1.16e+03      |\n| time/                           |               |\n|    total_timesteps              | 4992000       |\n| train/                          |               |\n|    approx_kl                    | 0.00016465587 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.997        |\n|    explained_variance           | 0.751         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 223           |\n|    n_updates                    | 2494          |\n|    policy_gradient_loss         | -0.000332     |\n|    value_loss                   | 453           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 160           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 1e+03         |\n|    water_produced               | 206           |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 168      |\n| time/              |          |\n|    fps             | 860      |\n|    iterations      | 1248     |\n|    time_elapsed    | 5799     |\n|    total_timesteps | 4992000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 153          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1249         |\n|    time_elapsed                 | 5804         |\n|    total_timesteps              | 4996000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019501399 |\n|    clip_fraction                | 0.0139       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.933       |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 301          |\n|    n_updates                    | 2496         |\n|    policy_gradient_loss         | 0.00197      |\n|    value_loss                   | 576          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 796          |\n|    water_produced               | 163          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 158          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1250         |\n|    time_elapsed                 | 5808         |\n|    total_timesteps              | 5000000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020462763 |\n|    clip_fraction                | 0.0124       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.941       |\n|    explained_variance           | 0.719        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 246          |\n|    n_updates                    | 2498         |\n|    policy_gradient_loss         | -0.00157     |\n|    value_loss                   | 423          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 793          |\n|    water_produced               | 119          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 174         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1251        |\n|    time_elapsed                 | 5813        |\n|    total_timesteps              | 5004000     |\n| train/                          |             |\n|    approx_kl                    | 0.003255504 |\n|    clip_fraction                | 0.0191      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.952      |\n|    explained_variance           | 0.583       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 243         |\n|    n_updates                    | 2500        |\n|    policy_gradient_loss         | -5.89e-05   |\n|    value_loss                   | 471         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 794         |\n|    water_produced               | 186         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 187          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1252         |\n|    time_elapsed                 | 5817         |\n|    total_timesteps              | 5008000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009180064 |\n|    clip_fraction                | 0.00225      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.997       |\n|    explained_variance           | 0.783        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 224          |\n|    n_updates                    | 2502         |\n|    policy_gradient_loss         | -0.000585    |\n|    value_loss                   | 460          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 996          |\n|    water_produced               | 218          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 187          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1253         |\n|    time_elapsed                 | 5822         |\n|    total_timesteps              | 5012000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038778111 |\n|    clip_fraction                | 0.0236       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.921       |\n|    explained_variance           | 0.62         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 267          |\n|    n_updates                    | 2504         |\n|    policy_gradient_loss         | 0.00327      |\n|    value_loss                   | 543          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.06e+03     |\n|    water_produced               | 206          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 172          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1254         |\n|    time_elapsed                 | 5826         |\n|    total_timesteps              | 5016000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025569354 |\n|    clip_fraction                | 0.0161       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.878       |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 255          |\n|    n_updates                    | 2506         |\n|    policy_gradient_loss         | 0.00247      |\n|    value_loss                   | 504          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 487          |\n|    water_produced               | 90.5         |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 198          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1255         |\n|    time_elapsed                 | 5831         |\n|    total_timesteps              | 5020000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036148906 |\n|    clip_fraction                | 0.0201       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.978       |\n|    explained_variance           | 0.727        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 150          |\n|    n_updates                    | 2508         |\n|    policy_gradient_loss         | -0.00134     |\n|    value_loss                   | 321          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.2e+03      |\n|    water_produced               | 243          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 204          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1256         |\n|    time_elapsed                 | 5835         |\n|    total_timesteps              | 5024000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002492661 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.871       |\n|    explained_variance           | 0.527        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 282          |\n|    n_updates                    | 2510         |\n|    policy_gradient_loss         | -0.000864    |\n|    value_loss                   | 539          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1e+03        |\n|    water_produced               | 212          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 206         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1257        |\n|    time_elapsed                 | 5840        |\n|    total_timesteps              | 5028000     |\n| train/                          |             |\n|    approx_kl                    | 0.002606114 |\n|    clip_fraction                | 0.0195      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.895      |\n|    explained_variance           | 0.593       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 265         |\n|    n_updates                    | 2512        |\n|    policy_gradient_loss         | 0.00199     |\n|    value_loss                   | 530         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 151         |\n|    ice_dug                      | 1.04e+03    |\n|    water_produced               | 230         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 189           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1258          |\n|    time_elapsed                 | 5844          |\n|    total_timesteps              | 5032000       |\n| train/                          |               |\n|    approx_kl                    | 0.00080728746 |\n|    clip_fraction                | 0.00263       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.879        |\n|    explained_variance           | 0.72          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 237           |\n|    n_updates                    | 2514          |\n|    policy_gradient_loss         | 4.37e-05      |\n|    value_loss                   | 450           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 582           |\n|    water_produced               | 125           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 209         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1259        |\n|    time_elapsed                 | 5849        |\n|    total_timesteps              | 5036000     |\n| train/                          |             |\n|    approx_kl                    | 0.005927415 |\n|    clip_fraction                | 0.0277      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.01       |\n|    explained_variance           | 0.744       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 165         |\n|    n_updates                    | 2516        |\n|    policy_gradient_loss         | 0.00129     |\n|    value_loss                   | 345         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 892         |\n|    water_produced               | 189         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 198           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1260          |\n|    time_elapsed                 | 5853          |\n|    total_timesteps              | 5040000       |\n| train/                          |               |\n|    approx_kl                    | 0.00033429204 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.03         |\n|    explained_variance           | 0.768         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 237           |\n|    n_updates                    | 2518          |\n|    policy_gradient_loss         | 1.01e-05      |\n|    value_loss                   | 490           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 162           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 900           |\n|    water_produced               | 191           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 190          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1261         |\n|    time_elapsed                 | 5858         |\n|    total_timesteps              | 5044000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018087495 |\n|    clip_fraction                | 0.0129       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1           |\n|    explained_variance           | 0.584        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 253          |\n|    n_updates                    | 2520         |\n|    policy_gradient_loss         | 0.00116      |\n|    value_loss                   | 540          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 878          |\n|    water_produced               | 173          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 185          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1262         |\n|    time_elapsed                 | 5862         |\n|    total_timesteps              | 5048000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014519941 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.57         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 2522         |\n|    policy_gradient_loss         | -6.81e-05    |\n|    value_loss                   | 466          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.02e+03     |\n|    water_produced               | 204          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 195          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1263         |\n|    time_elapsed                 | 5866         |\n|    total_timesteps              | 5052000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023968904 |\n|    clip_fraction                | 0.016        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.971       |\n|    explained_variance           | 0.56         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 223          |\n|    n_updates                    | 2524         |\n|    policy_gradient_loss         | 0.000532     |\n|    value_loss                   | 467          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 729          |\n|    water_produced               | 173          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 191          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1264         |\n|    time_elapsed                 | 5871         |\n|    total_timesteps              | 5056000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024621848 |\n|    clip_fraction                | 0.00863      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.759        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 177          |\n|    n_updates                    | 2526         |\n|    policy_gradient_loss         | -0.000617    |\n|    value_loss                   | 347          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 852          |\n|    water_produced               | 170          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 184          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1265         |\n|    time_elapsed                 | 5876         |\n|    total_timesteps              | 5060000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025863044 |\n|    clip_fraction                | 0.0185       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.02        |\n|    explained_variance           | 0.567        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 176          |\n|    n_updates                    | 2528         |\n|    policy_gradient_loss         | -0.000579    |\n|    value_loss                   | 396          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 772          |\n|    water_produced               | 159          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 184          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1266         |\n|    time_elapsed                 | 5880         |\n|    total_timesteps              | 5064000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017367287 |\n|    clip_fraction                | 0.0108       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.04        |\n|    explained_variance           | 0.687        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 165          |\n|    n_updates                    | 2530         |\n|    policy_gradient_loss         | -0.00245     |\n|    value_loss                   | 342          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 851          |\n|    water_produced               | 171          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 180           |\n| time/                           |               |\n|    fps                          | 861           |\n|    iterations                   | 1267          |\n|    time_elapsed                 | 5885          |\n|    total_timesteps              | 5068000       |\n| train/                          |               |\n|    approx_kl                    | 0.00037884427 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.05         |\n|    explained_variance           | 0.588         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 238           |\n|    n_updates                    | 2532          |\n|    policy_gradient_loss         | -0.000772     |\n|    value_loss                   | 493           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 854           |\n|    water_produced               | 186           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 181          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1268         |\n|    time_elapsed                 | 5889         |\n|    total_timesteps              | 5072000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012866517 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.708        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 2534         |\n|    policy_gradient_loss         | 0.000503     |\n|    value_loss                   | 466          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 855          |\n|    water_produced               | 174          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 185          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1269         |\n|    time_elapsed                 | 5894         |\n|    total_timesteps              | 5076000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004205879 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.664        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 225          |\n|    n_updates                    | 2536         |\n|    policy_gradient_loss         | 4.24e-05     |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 971          |\n|    water_produced               | 189          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 193          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1270         |\n|    time_elapsed                 | 5898         |\n|    total_timesteps              | 5080000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010343001 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.783        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 2538         |\n|    policy_gradient_loss         | 0.000138     |\n|    value_loss                   | 480          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 977          |\n|    water_produced               | 197          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 186          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1271         |\n|    time_elapsed                 | 5903         |\n|    total_timesteps              | 5084000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028731092 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.92        |\n|    explained_variance           | 0.661        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 2540         |\n|    policy_gradient_loss         | -0.00122     |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 674          |\n|    water_produced               | 138          |\n--------------------------------------------------\nEval num_timesteps=5088000, episode_reward=989.84 +/- 856.82\nEpisode length: 720.40 +/- 342.44\n------------------------------------------------\n| eval/                           |            |\n|    mean_ep_length               | 720        |\n|    mean_reward                  | 990        |\n| time/                           |            |\n|    total_timesteps              | 5088000    |\n| train/                          |            |\n|    approx_kl                    | 0.00469558 |\n|    clip_fraction                | 0.0283     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.947     |\n|    explained_variance           | 0.735      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 201        |\n|    n_updates                    | 2542       |\n|    policy_gradient_loss         | -0.00103   |\n|    value_loss                   | 391        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 152        |\n|    action_queue_updates_total   | 160        |\n|    ice_dug                      | 1.03e+03   |\n|    water_produced               | 186        |\n------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 186      |\n| time/              |          |\n|    fps             | 860      |\n|    iterations      | 1272     |\n|    time_elapsed    | 5913     |\n|    total_timesteps | 5088000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 192          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1273         |\n|    time_elapsed                 | 5917         |\n|    total_timesteps              | 5092000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014758706 |\n|    clip_fraction                | 0.00875      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.926       |\n|    explained_variance           | 0.627        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 302          |\n|    n_updates                    | 2544         |\n|    policy_gradient_loss         | 0.000954     |\n|    value_loss                   | 569          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 925          |\n|    water_produced               | 204          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 199         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1274        |\n|    time_elapsed                 | 5921        |\n|    total_timesteps              | 5096000     |\n| train/                          |             |\n|    approx_kl                    | 0.003192896 |\n|    clip_fraction                | 0.0239      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.957      |\n|    explained_variance           | 0.821       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 225         |\n|    n_updates                    | 2546        |\n|    policy_gradient_loss         | 0.00247     |\n|    value_loss                   | 467         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 1.01e+03    |\n|    water_produced               | 224         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 201          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1275         |\n|    time_elapsed                 | 5926         |\n|    total_timesteps              | 5100000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020406798 |\n|    clip_fraction                | 0.0075       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.925       |\n|    explained_variance           | 0.654        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 240          |\n|    n_updates                    | 2548         |\n|    policy_gradient_loss         | -0.000312    |\n|    value_loss                   | 507          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 991          |\n|    water_produced               | 204          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 214          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1276         |\n|    time_elapsed                 | 5930         |\n|    total_timesteps              | 5104000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008826993 |\n|    clip_fraction                | 0.0035       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.933       |\n|    explained_variance           | 0.662        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 241          |\n|    n_updates                    | 2550         |\n|    policy_gradient_loss         | -0.000729    |\n|    value_loss                   | 465          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 934          |\n|    water_produced               | 200          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 211          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1277         |\n|    time_elapsed                 | 5934         |\n|    total_timesteps              | 5108000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014492713 |\n|    clip_fraction                | 0.00337      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.902       |\n|    explained_variance           | 0.64         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 2552         |\n|    policy_gradient_loss         | -0.00142     |\n|    value_loss                   | 474          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 952          |\n|    water_produced               | 175          |\n--------------------------------------------------\n-----------------------------------------------\n| rollout/                        |           |\n|    ep_len_mean                  | 200       |\n|    ep_rew_mean                  | 208       |\n| time/                           |           |\n|    fps                          | 860       |\n|    iterations                   | 1278      |\n|    time_elapsed                 | 5939      |\n|    total_timesteps              | 5112000   |\n| train/                          |           |\n|    approx_kl                    | 0.0025548 |\n|    clip_fraction                | 0.0128    |\n|    clip_range                   | 0.2       |\n|    entropy_loss                 | -0.875    |\n|    explained_variance           | 0.557     |\n|    learning_rate                | 0.0003    |\n|    loss                         | 233       |\n|    n_updates                    | 2554      |\n|    policy_gradient_loss         | 7.32e-05  |\n|    value_loss                   | 463       |\n| train_metrics/                  |           |\n|    action_queue_updates_success | 150       |\n|    action_queue_updates_total   | 154       |\n|    ice_dug                      | 904       |\n|    water_produced               | 190       |\n-----------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 208          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1279         |\n|    time_elapsed                 | 5944         |\n|    total_timesteps              | 5116000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020647165 |\n|    clip_fraction                | 0.0055       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.898       |\n|    explained_variance           | 0.675        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 210          |\n|    n_updates                    | 2556         |\n|    policy_gradient_loss         | -0.000278    |\n|    value_loss                   | 442          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.05e+03     |\n|    water_produced               | 221          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 202         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1280        |\n|    time_elapsed                 | 5948        |\n|    total_timesteps              | 5120000     |\n| train/                          |             |\n|    approx_kl                    | 0.002137261 |\n|    clip_fraction                | 0.018       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.912      |\n|    explained_variance           | 0.712       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 215         |\n|    n_updates                    | 2558        |\n|    policy_gradient_loss         | 0.00111     |\n|    value_loss                   | 441         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 153         |\n|    ice_dug                      | 953         |\n|    water_produced               | 175         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 206           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1281          |\n|    time_elapsed                 | 5953          |\n|    total_timesteps              | 5124000       |\n| train/                          |               |\n|    approx_kl                    | 0.00095041876 |\n|    clip_fraction                | 0.00287       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.959        |\n|    explained_variance           | 0.744         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 214           |\n|    n_updates                    | 2560          |\n|    policy_gradient_loss         | -0.00065      |\n|    value_loss                   | 432           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 989           |\n|    water_produced               | 218           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 215          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1282         |\n|    time_elapsed                 | 5957         |\n|    total_timesteps              | 5128000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018457333 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.897       |\n|    explained_variance           | 0.667        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 2562         |\n|    policy_gradient_loss         | -0.00106     |\n|    value_loss                   | 439          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.03e+03     |\n|    water_produced               | 219          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 221          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1283         |\n|    time_elapsed                 | 5962         |\n|    total_timesteps              | 5132000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027984702 |\n|    clip_fraction                | 0.0149       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.864       |\n|    explained_variance           | 0.599        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 271          |\n|    n_updates                    | 2564         |\n|    policy_gradient_loss         | -0.000254    |\n|    value_loss                   | 534          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.14e+03     |\n|    water_produced               | 218          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 230         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1284        |\n|    time_elapsed                 | 5966        |\n|    total_timesteps              | 5136000     |\n| train/                          |             |\n|    approx_kl                    | 0.001526764 |\n|    clip_fraction                | 0.00463     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.861      |\n|    explained_variance           | 0.695       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 250         |\n|    n_updates                    | 2566        |\n|    policy_gradient_loss         | 0.00105     |\n|    value_loss                   | 479         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.3e+03     |\n|    water_produced               | 267         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 220          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1285         |\n|    time_elapsed                 | 5971         |\n|    total_timesteps              | 5140000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029513563 |\n|    clip_fraction                | 0.02         |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.849       |\n|    explained_variance           | 0.654        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 266          |\n|    n_updates                    | 2568         |\n|    policy_gradient_loss         | 0.00272      |\n|    value_loss                   | 521          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 609          |\n|    water_produced               | 126          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 204          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1286         |\n|    time_elapsed                 | 5975         |\n|    total_timesteps              | 5144000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010017622 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.901       |\n|    explained_variance           | 0.58         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 186          |\n|    n_updates                    | 2570         |\n|    policy_gradient_loss         | 0.000427     |\n|    value_loss                   | 400          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 734          |\n|    water_produced               | 142          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 197         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1287        |\n|    time_elapsed                 | 5980        |\n|    total_timesteps              | 5148000     |\n| train/                          |             |\n|    approx_kl                    | 0.008658966 |\n|    clip_fraction                | 0.0426      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.951      |\n|    explained_variance           | 0.615       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 141         |\n|    n_updates                    | 2572        |\n|    policy_gradient_loss         | -0.000805   |\n|    value_loss                   | 331         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 839         |\n|    water_produced               | 187         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 183           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1288          |\n|    time_elapsed                 | 5984          |\n|    total_timesteps              | 5152000       |\n| train/                          |               |\n|    approx_kl                    | 0.00065776973 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -1.06         |\n|    explained_variance           | 0.874         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 219           |\n|    n_updates                    | 2574          |\n|    policy_gradient_loss         | -0.000749     |\n|    value_loss                   | 445           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 716           |\n|    water_produced               | 150           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 174           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1289          |\n|    time_elapsed                 | 5989          |\n|    total_timesteps              | 5156000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029213345 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.962        |\n|    explained_variance           | 0.73          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 181           |\n|    n_updates                    | 2576          |\n|    policy_gradient_loss         | 6.57e-05      |\n|    value_loss                   | 370           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 1.19e+03      |\n|    water_produced               | 224           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 203           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1290          |\n|    time_elapsed                 | 5993          |\n|    total_timesteps              | 5160000       |\n| train/                          |               |\n|    approx_kl                    | 0.00015935891 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.897        |\n|    explained_variance           | 0.596         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 227           |\n|    n_updates                    | 2578          |\n|    policy_gradient_loss         | -0.000371     |\n|    value_loss                   | 476           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 163           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 1.17e+03      |\n|    water_produced               | 266           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 215         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1291        |\n|    time_elapsed                 | 5998        |\n|    total_timesteps              | 5164000     |\n| train/                          |             |\n|    approx_kl                    | 0.004563016 |\n|    clip_fraction                | 0.0329      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.854      |\n|    explained_variance           | 0.662       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 229         |\n|    n_updates                    | 2580        |\n|    policy_gradient_loss         | 0.00398     |\n|    value_loss                   | 446         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 1.03e+03    |\n|    water_produced               | 200         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 231          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1292         |\n|    time_elapsed                 | 6002         |\n|    total_timesteps              | 5168000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031303528 |\n|    clip_fraction                | 0.0201       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.891       |\n|    explained_variance           | 0.666        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 228          |\n|    n_updates                    | 2582         |\n|    policy_gradient_loss         | -0.000953    |\n|    value_loss                   | 473          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.16e+03     |\n|    water_produced               | 262          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 232          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1293         |\n|    time_elapsed                 | 6007         |\n|    total_timesteps              | 5172000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012422425 |\n|    clip_fraction                | 0.00462      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.891       |\n|    explained_variance           | 0.661        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 247          |\n|    n_updates                    | 2584         |\n|    policy_gradient_loss         | 0.00102      |\n|    value_loss                   | 481          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 776          |\n|    water_produced               | 154          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 241         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1294        |\n|    time_elapsed                 | 6011        |\n|    total_timesteps              | 5176000     |\n| train/                          |             |\n|    approx_kl                    | 0.002812496 |\n|    clip_fraction                | 0.00687     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.956      |\n|    explained_variance           | 0.564       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 193         |\n|    n_updates                    | 2586        |\n|    policy_gradient_loss         | -0.00157    |\n|    value_loss                   | 438         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.26e+03    |\n|    water_produced               | 271         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 212          |\n| time/                           |              |\n|    fps                          | 861          |\n|    iterations                   | 1295         |\n|    time_elapsed                 | 6016         |\n|    total_timesteps              | 5180000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013737059 |\n|    clip_fraction                | 0.00238      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.941       |\n|    explained_variance           | 0.722        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 223          |\n|    n_updates                    | 2588         |\n|    policy_gradient_loss         | 0.000565     |\n|    value_loss                   | 455          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 757          |\n|    water_produced               | 124          |\n--------------------------------------------------\nEval num_timesteps=5184000, episode_reward=1326.88 +/- 718.98\nEpisode length: 860.20 +/- 279.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 860          |\n|    mean_reward                  | 1.33e+03     |\n| time/                           |              |\n|    total_timesteps              | 5184000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005791501 |\n|    clip_fraction                | 0.00312      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.993       |\n|    explained_variance           | 0.526        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 208          |\n|    n_updates                    | 2590         |\n|    policy_gradient_loss         | -0.000153    |\n|    value_loss                   | 451          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 884          |\n|    water_produced               | 158          |\n--------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 203      |\n| time/              |          |\n|    fps             | 860      |\n|    iterations      | 1296     |\n|    time_elapsed    | 6026     |\n|    total_timesteps | 5184000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 182          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1297         |\n|    time_elapsed                 | 6030         |\n|    total_timesteps              | 5188000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026252568 |\n|    clip_fraction                | 0.0148       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1           |\n|    explained_variance           | 0.676        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 2592         |\n|    policy_gradient_loss         | -0.00113     |\n|    value_loss                   | 440          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 727          |\n|    water_produced               | 159          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 193          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1298         |\n|    time_elapsed                 | 6035         |\n|    total_timesteps              | 5192000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010876751 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.03        |\n|    explained_variance           | 0.609        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 239          |\n|    n_updates                    | 2594         |\n|    policy_gradient_loss         | -0.000395    |\n|    value_loss                   | 468          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.06e+03     |\n|    water_produced               | 208          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 184          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1299         |\n|    time_elapsed                 | 6039         |\n|    total_timesteps              | 5196000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012039392 |\n|    clip_fraction                | 0.00612      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.659        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 2596         |\n|    policy_gradient_loss         | 0.000251     |\n|    value_loss                   | 490          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.04e+03     |\n|    water_produced               | 229          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 201          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1300         |\n|    time_elapsed                 | 6044         |\n|    total_timesteps              | 5200000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025502346 |\n|    clip_fraction                | 0.0156       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.936       |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 210          |\n|    n_updates                    | 2598         |\n|    policy_gradient_loss         | 0.00165      |\n|    value_loss                   | 430          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.12e+03     |\n|    water_produced               | 202          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 218          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1301         |\n|    time_elapsed                 | 6048         |\n|    total_timesteps              | 5204000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018573817 |\n|    clip_fraction                | 0.00588      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.929       |\n|    explained_variance           | 0.677        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 2600         |\n|    policy_gradient_loss         | -0.00189     |\n|    value_loss                   | 414          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.14e+03     |\n|    water_produced               | 240          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 230          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1302         |\n|    time_elapsed                 | 6053         |\n|    total_timesteps              | 5208000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012210689 |\n|    clip_fraction                | 0.00125      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.887       |\n|    explained_variance           | 0.662        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 2602         |\n|    policy_gradient_loss         | 0.000526     |\n|    value_loss                   | 415          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.1e+03      |\n|    water_produced               | 215          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 219          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1303         |\n|    time_elapsed                 | 6057         |\n|    total_timesteps              | 5212000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006522266 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.877       |\n|    explained_variance           | 0.576        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 266          |\n|    n_updates                    | 2604         |\n|    policy_gradient_loss         | 0.000253     |\n|    value_loss                   | 542          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 785          |\n|    water_produced               | 160          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 224         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1304        |\n|    time_elapsed                 | 6062        |\n|    total_timesteps              | 5216000     |\n| train/                          |             |\n|    approx_kl                    | 0.001811316 |\n|    clip_fraction                | 0.00688     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.896      |\n|    explained_variance           | 0.612       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 215         |\n|    n_updates                    | 2606        |\n|    policy_gradient_loss         | -0.00115    |\n|    value_loss                   | 438         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.23e+03    |\n|    water_produced               | 249         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 216           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1305          |\n|    time_elapsed                 | 6067          |\n|    total_timesteps              | 5220000       |\n| train/                          |               |\n|    approx_kl                    | 0.00037764115 |\n|    clip_fraction                | 0.00112       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.872        |\n|    explained_variance           | 0.518         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 280           |\n|    n_updates                    | 2608          |\n|    policy_gradient_loss         | -0.000535     |\n|    value_loss                   | 562           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 159           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 834           |\n|    water_produced               | 168           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 206           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1306          |\n|    time_elapsed                 | 6071          |\n|    total_timesteps              | 5224000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035967308 |\n|    clip_fraction                | 0.000875      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.933        |\n|    explained_variance           | 0.632         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 212           |\n|    n_updates                    | 2610          |\n|    policy_gradient_loss         | -0.000179     |\n|    value_loss                   | 431           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 156           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 903           |\n|    water_produced               | 189           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 213          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1307         |\n|    time_elapsed                 | 6075         |\n|    total_timesteps              | 5228000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013730439 |\n|    clip_fraction                | 0.00487      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.959       |\n|    explained_variance           | 0.694        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 249          |\n|    n_updates                    | 2612         |\n|    policy_gradient_loss         | -0.00156     |\n|    value_loss                   | 492          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.4e+03      |\n|    water_produced               | 248          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 236         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1308        |\n|    time_elapsed                 | 6080        |\n|    total_timesteps              | 5232000     |\n| train/                          |             |\n|    approx_kl                    | 0.002840797 |\n|    clip_fraction                | 0.0178      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.876      |\n|    explained_variance           | 0.48        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 291         |\n|    n_updates                    | 2614        |\n|    policy_gradient_loss         | 0.000992    |\n|    value_loss                   | 585         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.27e+03    |\n|    water_produced               | 268         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 225          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1309         |\n|    time_elapsed                 | 6084         |\n|    total_timesteps              | 5236000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028502806 |\n|    clip_fraction                | 0.0151       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.871       |\n|    explained_variance           | 0.62         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 224          |\n|    n_updates                    | 2616         |\n|    policy_gradient_loss         | 0.00293      |\n|    value_loss                   | 457          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 999          |\n|    water_produced               | 197          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 229         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1310        |\n|    time_elapsed                 | 6089        |\n|    total_timesteps              | 5240000     |\n| train/                          |             |\n|    approx_kl                    | 0.002197938 |\n|    clip_fraction                | 0.0164      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.933      |\n|    explained_variance           | 0.588       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 208         |\n|    n_updates                    | 2618        |\n|    policy_gradient_loss         | -0.000763   |\n|    value_loss                   | 442         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 865         |\n|    water_produced               | 187         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 246          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1311         |\n|    time_elapsed                 | 6093         |\n|    total_timesteps              | 5244000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015123845 |\n|    clip_fraction                | 0.00437      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.962       |\n|    explained_variance           | 0.598        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 2620         |\n|    policy_gradient_loss         | -0.00105     |\n|    value_loss                   | 455          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 274          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 245           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1312          |\n|    time_elapsed                 | 6098          |\n|    total_timesteps              | 5248000       |\n| train/                          |               |\n|    approx_kl                    | 0.00071143004 |\n|    clip_fraction                | 0.00137       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.922        |\n|    explained_variance           | 0.572         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 211           |\n|    n_updates                    | 2622          |\n|    policy_gradient_loss         | 0.000391      |\n|    value_loss                   | 433           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 154           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 1.1e+03       |\n|    water_produced               | 245           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 230         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1313        |\n|    time_elapsed                 | 6102        |\n|    total_timesteps              | 5252000     |\n| train/                          |             |\n|    approx_kl                    | 0.003521863 |\n|    clip_fraction                | 0.02        |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.904      |\n|    explained_variance           | 0.56        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 227         |\n|    n_updates                    | 2624        |\n|    policy_gradient_loss         | 0.00142     |\n|    value_loss                   | 438         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 918         |\n|    water_produced               | 196         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 226          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1314         |\n|    time_elapsed                 | 6107         |\n|    total_timesteps              | 5256000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020735725 |\n|    clip_fraction                | 0.0126       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.937       |\n|    explained_variance           | 0.644        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 165          |\n|    n_updates                    | 2626         |\n|    policy_gradient_loss         | -0.00152     |\n|    value_loss                   | 354          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 794          |\n|    water_produced               | 178          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 236         |\n| time/                           |             |\n|    fps                          | 860         |\n|    iterations                   | 1315        |\n|    time_elapsed                 | 6111        |\n|    total_timesteps              | 5260000     |\n| train/                          |             |\n|    approx_kl                    | 0.004917353 |\n|    clip_fraction                | 0.0254      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.959      |\n|    explained_variance           | 0.755       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 169         |\n|    n_updates                    | 2628        |\n|    policy_gradient_loss         | -0.00216    |\n|    value_loss                   | 350         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.18e+03    |\n|    water_produced               | 233         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 223           |\n| time/                           |               |\n|    fps                          | 860           |\n|    iterations                   | 1316          |\n|    time_elapsed                 | 6116          |\n|    total_timesteps              | 5264000       |\n| train/                          |               |\n|    approx_kl                    | 0.00050143275 |\n|    clip_fraction                | 0.00113       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.919        |\n|    explained_variance           | 0.575         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 238           |\n|    n_updates                    | 2630          |\n|    policy_gradient_loss         | 0.000676      |\n|    value_loss                   | 503           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 149           |\n|    action_queue_updates_total   | 156           |\n|    ice_dug                      | 1e+03         |\n|    water_produced               | 215           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 220          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1317         |\n|    time_elapsed                 | 6120         |\n|    total_timesteps              | 5268000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028151139 |\n|    clip_fraction                | 0.0218       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.934       |\n|    explained_variance           | 0.586        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 247          |\n|    n_updates                    | 2632         |\n|    policy_gradient_loss         | 0.00139      |\n|    value_loss                   | 474          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.15e+03     |\n|    water_produced               | 230          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 219          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1318         |\n|    time_elapsed                 | 6124         |\n|    total_timesteps              | 5272000      |\n| train/                          |              |\n|    approx_kl                    | 0.0034495287 |\n|    clip_fraction                | 0.0131       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.988       |\n|    explained_variance           | 0.707        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 208          |\n|    n_updates                    | 2634         |\n|    policy_gradient_loss         | -0.000682    |\n|    value_loss                   | 395          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 835          |\n|    water_produced               | 187          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 234          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1319         |\n|    time_elapsed                 | 6129         |\n|    total_timesteps              | 5276000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020434868 |\n|    clip_fraction                | 0.0146       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.04        |\n|    explained_variance           | 0.63         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 180          |\n|    n_updates                    | 2636         |\n|    policy_gradient_loss         | -0.00053     |\n|    value_loss                   | 368          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.10e+03     |\n|    water_produced               | 253          |\n--------------------------------------------------\nEval num_timesteps=5280000, episode_reward=1443.40 +/- 239.71\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 1.44e+03     |\n| time/                           |              |\n|    total_timesteps              | 5280000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010502458 |\n|    clip_fraction                | 0.00363      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.997       |\n|    explained_variance           | 0.566        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 2638         |\n|    policy_gradient_loss         | -7.55e-05    |\n|    value_loss                   | 404          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 940          |\n|    water_produced               | 206          |\n--------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 228      |\n| time/              |          |\n|    fps             | 859      |\n|    iterations      | 1320     |\n|    time_elapsed    | 6142     |\n|    total_timesteps | 5280000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 225          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1321         |\n|    time_elapsed                 | 6147         |\n|    total_timesteps              | 5284000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011049416 |\n|    clip_fraction                | 0.00225      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.979       |\n|    explained_variance           | 0.579        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 2640         |\n|    policy_gradient_loss         | 0.000506     |\n|    value_loss                   | 424          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 978          |\n|    water_produced               | 199          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 229          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1322         |\n|    time_elapsed                 | 6151         |\n|    total_timesteps              | 5288000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017549123 |\n|    clip_fraction                | 0.0101       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.978       |\n|    explained_variance           | 0.617        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 228          |\n|    n_updates                    | 2642         |\n|    policy_gradient_loss         | -0.00241     |\n|    value_loss                   | 415          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.18e+03     |\n|    water_produced               | 252          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 252         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 1323        |\n|    time_elapsed                 | 6155        |\n|    total_timesteps              | 5292000     |\n| train/                          |             |\n|    approx_kl                    | 0.004878007 |\n|    clip_fraction                | 0.0236      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.891      |\n|    explained_variance           | 0.648       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 201         |\n|    n_updates                    | 2644        |\n|    policy_gradient_loss         | 9.98e-05    |\n|    value_loss                   | 426         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 1.27e+03    |\n|    water_produced               | 294         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 250          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1324         |\n|    time_elapsed                 | 6160         |\n|    total_timesteps              | 5296000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014959505 |\n|    clip_fraction                | 0.00362      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.88        |\n|    explained_variance           | 0.606        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 2646         |\n|    policy_gradient_loss         | 0.00106      |\n|    value_loss                   | 441          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 1.07e+03     |\n|    water_produced               | 247          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 253         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 1325        |\n|    time_elapsed                 | 6164        |\n|    total_timesteps              | 5300000     |\n| train/                          |             |\n|    approx_kl                    | 0.002247894 |\n|    clip_fraction                | 0.0116      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.894      |\n|    explained_variance           | 0.601       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 198         |\n|    n_updates                    | 2648        |\n|    policy_gradient_loss         | 0.000572    |\n|    value_loss                   | 443         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 909         |\n|    water_produced               | 219         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 261          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1326         |\n|    time_elapsed                 | 6169         |\n|    total_timesteps              | 5304000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050612567 |\n|    clip_fraction                | 0.0268       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.915       |\n|    explained_variance           | 0.612        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 196          |\n|    n_updates                    | 2650         |\n|    policy_gradient_loss         | -0.00065     |\n|    value_loss                   | 395          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.17e+03     |\n|    water_produced               | 236          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 250          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1327         |\n|    time_elapsed                 | 6174         |\n|    total_timesteps              | 5308000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012395179 |\n|    clip_fraction                | 0.0025       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.891       |\n|    explained_variance           | 0.56         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 2652         |\n|    policy_gradient_loss         | 0.000478     |\n|    value_loss                   | 452          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 978          |\n|    water_produced               | 202          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 242           |\n| time/                           |               |\n|    fps                          | 859           |\n|    iterations                   | 1328          |\n|    time_elapsed                 | 6178          |\n|    total_timesteps              | 5312000       |\n| train/                          |               |\n|    approx_kl                    | 0.00093815953 |\n|    clip_fraction                | 0.0025        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.903        |\n|    explained_variance           | 0.555         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 267           |\n|    n_updates                    | 2654          |\n|    policy_gradient_loss         | 0.000381      |\n|    value_loss                   | 520           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 158           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 1.1e+03       |\n|    water_produced               | 257           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 237          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1329         |\n|    time_elapsed                 | 6182         |\n|    total_timesteps              | 5316000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010275973 |\n|    clip_fraction                | 0.0035       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.915       |\n|    explained_variance           | 0.65         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 2656         |\n|    policy_gradient_loss         | 0.000752     |\n|    value_loss                   | 410          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1e+03        |\n|    water_produced               | 221          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 250          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1330         |\n|    time_elapsed                 | 6187         |\n|    total_timesteps              | 5320000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013559178 |\n|    clip_fraction                | 0.0109       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.942       |\n|    explained_variance           | 0.68         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 213          |\n|    n_updates                    | 2658         |\n|    policy_gradient_loss         | -0.000878    |\n|    value_loss                   | 464          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.24e+03     |\n|    water_produced               | 279          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 250          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1331         |\n|    time_elapsed                 | 6192         |\n|    total_timesteps              | 5324000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008517912 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.913       |\n|    explained_variance           | 0.658        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 248          |\n|    n_updates                    | 2660         |\n|    policy_gradient_loss         | 0.000597     |\n|    value_loss                   | 526          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.13e+03     |\n|    water_produced               | 239          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 242          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1332         |\n|    time_elapsed                 | 6196         |\n|    total_timesteps              | 5328000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004667275 |\n|    clip_fraction                | 0.0025       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.889       |\n|    explained_variance           | 0.594        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 234          |\n|    n_updates                    | 2662         |\n|    policy_gradient_loss         | 0.000202     |\n|    value_loss                   | 466          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 769          |\n|    water_produced               | 162          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 241          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1333         |\n|    time_elapsed                 | 6201         |\n|    total_timesteps              | 5332000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033584852 |\n|    clip_fraction                | 0.0235       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.955       |\n|    explained_variance           | 0.576        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 2664         |\n|    policy_gradient_loss         | -0.000544    |\n|    value_loss                   | 440          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 252          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 229          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1334         |\n|    time_elapsed                 | 6205         |\n|    total_timesteps              | 5336000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025250134 |\n|    clip_fraction                | 0.0139       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.878       |\n|    explained_variance           | 0.533        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 2666         |\n|    policy_gradient_loss         | 0.000947     |\n|    value_loss                   | 428          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 142          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 914          |\n|    water_produced               | 161          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 222          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1335         |\n|    time_elapsed                 | 6210         |\n|    total_timesteps              | 5340000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018797854 |\n|    clip_fraction                | 0.0104       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.942       |\n|    explained_variance           | 0.716        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 220          |\n|    n_updates                    | 2668         |\n|    policy_gradient_loss         | 0.000813     |\n|    value_loss                   | 451          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.07e+03     |\n|    water_produced               | 242          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 216         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 1336        |\n|    time_elapsed                 | 6214        |\n|    total_timesteps              | 5344000     |\n| train/                          |             |\n|    approx_kl                    | 0.001388008 |\n|    clip_fraction                | 0.00075     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.86       |\n|    explained_variance           | 0.606       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 206         |\n|    n_updates                    | 2670        |\n|    policy_gradient_loss         | -0.00216    |\n|    value_loss                   | 412         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 147         |\n|    action_queue_updates_total   | 151         |\n|    ice_dug                      | 1.12e+03    |\n|    water_produced               | 214         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 212         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 1337        |\n|    time_elapsed                 | 6218        |\n|    total_timesteps              | 5348000     |\n| train/                          |             |\n|    approx_kl                    | 0.004256136 |\n|    clip_fraction                | 0.0175      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.805      |\n|    explained_variance           | 0.541       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 254         |\n|    n_updates                    | 2672        |\n|    policy_gradient_loss         | 0.000618    |\n|    value_loss                   | 501         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 134         |\n|    action_queue_updates_total   | 143         |\n|    ice_dug                      | 759         |\n|    water_produced               | 139         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 216          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1338         |\n|    time_elapsed                 | 6223         |\n|    total_timesteps              | 5352000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033108927 |\n|    clip_fraction                | 0.0242       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.945       |\n|    explained_variance           | 0.776        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 208          |\n|    n_updates                    | 2674         |\n|    policy_gradient_loss         | -0.000551    |\n|    value_loss                   | 457          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 1.26e+03     |\n|    water_produced               | 274          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 230          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1339         |\n|    time_elapsed                 | 6228         |\n|    total_timesteps              | 5356000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011737552 |\n|    clip_fraction                | 0.00387      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.848       |\n|    explained_variance           | 0.583        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 273          |\n|    n_updates                    | 2676         |\n|    policy_gradient_loss         | 0.000393     |\n|    value_loss                   | 534          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 1.02e+03     |\n|    water_produced               | 229          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 224          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1340         |\n|    time_elapsed                 | 6232         |\n|    total_timesteps              | 5360000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015746348 |\n|    clip_fraction                | 0.00512      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.872       |\n|    explained_variance           | 0.718        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 186          |\n|    n_updates                    | 2678         |\n|    policy_gradient_loss         | 0.00103      |\n|    value_loss                   | 391          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.01e+03     |\n|    water_produced               | 214          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 230          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1341         |\n|    time_elapsed                 | 6237         |\n|    total_timesteps              | 5364000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005892773 |\n|    clip_fraction                | 0.002        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.853       |\n|    explained_variance           | 0.552        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 223          |\n|    n_updates                    | 2680         |\n|    policy_gradient_loss         | -0.000331    |\n|    value_loss                   | 424          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.17e+03     |\n|    water_produced               | 240          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 252          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1342         |\n|    time_elapsed                 | 6241         |\n|    total_timesteps              | 5368000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012742413 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.835       |\n|    explained_variance           | 0.594        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 210          |\n|    n_updates                    | 2682         |\n|    policy_gradient_loss         | -0.00112     |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.15e+03     |\n|    water_produced               | 246          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 252          |\n| time/                           |              |\n|    fps                          | 860          |\n|    iterations                   | 1343         |\n|    time_elapsed                 | 6246         |\n|    total_timesteps              | 5372000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020770165 |\n|    clip_fraction                | 0.0137       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.892       |\n|    explained_variance           | 0.705        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 260          |\n|    n_updates                    | 2684         |\n|    policy_gradient_loss         | 0.000118     |\n|    value_loss                   | 494          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 275          |\n--------------------------------------------------\nEval num_timesteps=5376000, episode_reward=1219.16 +/- 475.79\nEpisode length: 931.20 +/- 137.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 931          |\n|    mean_reward                  | 1.22e+03     |\n| time/                           |              |\n|    total_timesteps              | 5376000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024510014 |\n|    clip_fraction                | 0.0152       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.898       |\n|    explained_variance           | 0.692        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 2686         |\n|    policy_gradient_loss         | 0.00226      |\n|    value_loss                   | 431          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 905          |\n|    water_produced               | 193          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 245      |\n| time/              |          |\n|    fps             | 859      |\n|    iterations      | 1344     |\n|    time_elapsed    | 6258     |\n|    total_timesteps | 5376000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 238          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1345         |\n|    time_elapsed                 | 6262         |\n|    total_timesteps              | 5380000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020258527 |\n|    clip_fraction                | 0.0111       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.897       |\n|    explained_variance           | 0.595        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 2688         |\n|    policy_gradient_loss         | -0.000258    |\n|    value_loss                   | 416          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 844          |\n|    water_produced               | 181          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 238          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1346         |\n|    time_elapsed                 | 6267         |\n|    total_timesteps              | 5384000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018960169 |\n|    clip_fraction                | 0.0108       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.925       |\n|    explained_variance           | 0.483        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 2690         |\n|    policy_gradient_loss         | -0.00203     |\n|    value_loss                   | 454          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.13e+03     |\n|    water_produced               | 244          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 232          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1347         |\n|    time_elapsed                 | 6271         |\n|    total_timesteps              | 5388000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028401539 |\n|    clip_fraction                | 0.0136       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.857       |\n|    explained_variance           | 0.556        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 220          |\n|    n_updates                    | 2692         |\n|    policy_gradient_loss         | 0.000563     |\n|    value_loss                   | 435          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 955          |\n|    water_produced               | 216          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 226          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1348         |\n|    time_elapsed                 | 6276         |\n|    total_timesteps              | 5392000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021114312 |\n|    clip_fraction                | 0.01         |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.876       |\n|    explained_variance           | 0.59         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 2694         |\n|    policy_gradient_loss         | -0.000451    |\n|    value_loss                   | 460          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 248          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 240          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1349         |\n|    time_elapsed                 | 6280         |\n|    total_timesteps              | 5396000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005255073 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.86        |\n|    explained_variance           | 0.646        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 253          |\n|    n_updates                    | 2696         |\n|    policy_gradient_loss         | 0.000202     |\n|    value_loss                   | 513          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 1.34e+03     |\n|    water_produced               | 256          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 231         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 1350        |\n|    time_elapsed                 | 6285        |\n|    total_timesteps              | 5400000     |\n| train/                          |             |\n|    approx_kl                    | 0.004919725 |\n|    clip_fraction                | 0.0237      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.836      |\n|    explained_variance           | 0.572       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 240         |\n|    n_updates                    | 2698        |\n|    policy_gradient_loss         | 0.0028      |\n|    value_loss                   | 513         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 149         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 685         |\n|    water_produced               | 136         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 228          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1351         |\n|    time_elapsed                 | 6290         |\n|    total_timesteps              | 5404000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021425544 |\n|    clip_fraction                | 0.00975      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.888       |\n|    explained_variance           | 0.574        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 2700         |\n|    policy_gradient_loss         | -6.08e-05    |\n|    value_loss                   | 427          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.16e+03     |\n|    water_produced               | 232          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 231          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1352         |\n|    time_elapsed                 | 6294         |\n|    total_timesteps              | 5408000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025898316 |\n|    clip_fraction                | 0.018        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.878       |\n|    explained_variance           | 0.658        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 227          |\n|    n_updates                    | 2702         |\n|    policy_gradient_loss         | -0.00284     |\n|    value_loss                   | 434          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.09e+03     |\n|    water_produced               | 229          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 222          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1353         |\n|    time_elapsed                 | 6299         |\n|    total_timesteps              | 5412000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005267274 |\n|    clip_fraction                | 0.00125      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.875       |\n|    explained_variance           | 0.559        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 217          |\n|    n_updates                    | 2704         |\n|    policy_gradient_loss         | 0.000331     |\n|    value_loss                   | 487          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 882          |\n|    water_produced               | 203          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 216          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1354         |\n|    time_elapsed                 | 6303         |\n|    total_timesteps              | 5416000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022702236 |\n|    clip_fraction                | 0.0103       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.908       |\n|    explained_variance           | 0.59         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 236          |\n|    n_updates                    | 2706         |\n|    policy_gradient_loss         | -0.00073     |\n|    value_loss                   | 450          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.12e+03     |\n|    water_produced               | 231          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 243          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1355         |\n|    time_elapsed                 | 6308         |\n|    total_timesteps              | 5420000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019374415 |\n|    clip_fraction                | 0.0101       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.935       |\n|    explained_variance           | 0.695        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 249          |\n|    n_updates                    | 2708         |\n|    policy_gradient_loss         | -0.00053     |\n|    value_loss                   | 476          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.28e+03     |\n|    water_produced               | 266          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 245         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 1356        |\n|    time_elapsed                 | 6312        |\n|    total_timesteps              | 5424000     |\n| train/                          |             |\n|    approx_kl                    | 0.003419736 |\n|    clip_fraction                | 0.0164      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.865      |\n|    explained_variance           | 0.545       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 243         |\n|    n_updates                    | 2710        |\n|    policy_gradient_loss         | 0.00159     |\n|    value_loss                   | 477         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 1.24e+03    |\n|    water_produced               | 240         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 230          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1357         |\n|    time_elapsed                 | 6317         |\n|    total_timesteps              | 5428000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007685673 |\n|    clip_fraction                | 0.00262      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.862       |\n|    explained_variance           | 0.506        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 2712         |\n|    policy_gradient_loss         | 0.00164      |\n|    value_loss                   | 410          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 810          |\n|    water_produced               | 157          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 245          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1358         |\n|    time_elapsed                 | 6322         |\n|    total_timesteps              | 5432000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036957879 |\n|    clip_fraction                | 0.0244       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.926       |\n|    explained_variance           | 0.627        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 184          |\n|    n_updates                    | 2714         |\n|    policy_gradient_loss         | -0.00144     |\n|    value_loss                   | 410          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.28e+03     |\n|    water_produced               | 275          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 259          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1359         |\n|    time_elapsed                 | 6326         |\n|    total_timesteps              | 5436000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007119463 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.9         |\n|    explained_variance           | 0.535        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 2716         |\n|    policy_gradient_loss         | -0.00112     |\n|    value_loss                   | 438          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.36e+03     |\n|    water_produced               | 297          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 251         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 1360        |\n|    time_elapsed                 | 6331        |\n|    total_timesteps              | 5440000     |\n| train/                          |             |\n|    approx_kl                    | 0.004254191 |\n|    clip_fraction                | 0.0269      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.851      |\n|    explained_variance           | 0.591       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 190         |\n|    n_updates                    | 2718        |\n|    policy_gradient_loss         | 0.00335     |\n|    value_loss                   | 437         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.08e+03    |\n|    water_produced               | 230         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 229          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1361         |\n|    time_elapsed                 | 6335         |\n|    total_timesteps              | 5444000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014996275 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.888       |\n|    explained_variance           | 0.578        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 192          |\n|    n_updates                    | 2720         |\n|    policy_gradient_loss         | -0.00111     |\n|    value_loss                   | 348          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 616          |\n|    water_produced               | 136          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 252          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1362         |\n|    time_elapsed                 | 6339         |\n|    total_timesteps              | 5448000      |\n| train/                          |              |\n|    approx_kl                    | 0.0067109196 |\n|    clip_fraction                | 0.0382       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.981       |\n|    explained_variance           | 0.62         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 2722         |\n|    policy_gradient_loss         | -0.000967    |\n|    value_loss                   | 430          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.14e+03     |\n|    water_produced               | 266          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 261          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1363         |\n|    time_elapsed                 | 6344         |\n|    total_timesteps              | 5452000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004521103 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.937       |\n|    explained_variance           | 0.609        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 2724         |\n|    policy_gradient_loss         | -0.00116     |\n|    value_loss                   | 491          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 320          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 248          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1364         |\n|    time_elapsed                 | 6348         |\n|    total_timesteps              | 5456000      |\n| train/                          |              |\n|    approx_kl                    | 0.0048811017 |\n|    clip_fraction                | 0.0289       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.887       |\n|    explained_variance           | 0.704        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 233          |\n|    n_updates                    | 2726         |\n|    policy_gradient_loss         | 0.00371      |\n|    value_loss                   | 468          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.04e+03     |\n|    water_produced               | 235          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 247          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1365         |\n|    time_elapsed                 | 6353         |\n|    total_timesteps              | 5460000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005646118 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.91        |\n|    explained_variance           | 0.713        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 188          |\n|    n_updates                    | 2728         |\n|    policy_gradient_loss         | -9.54e-05    |\n|    value_loss                   | 377          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.08e+03     |\n|    water_produced               | 226          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 270         |\n| time/                           |             |\n|    fps                          | 859         |\n|    iterations                   | 1366        |\n|    time_elapsed                 | 6358        |\n|    total_timesteps              | 5464000     |\n| train/                          |             |\n|    approx_kl                    | 0.001460929 |\n|    clip_fraction                | 0.00325     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.937      |\n|    explained_variance           | 0.591       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 181         |\n|    n_updates                    | 2730        |\n|    policy_gradient_loss         | -0.00053    |\n|    value_loss                   | 399         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 1.14e+03    |\n|    water_produced               | 245         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 257          |\n| time/                           |              |\n|    fps                          | 859          |\n|    iterations                   | 1367         |\n|    time_elapsed                 | 6362         |\n|    total_timesteps              | 5468000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013698044 |\n|    clip_fraction                | 0.00737      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.94        |\n|    explained_variance           | 0.721        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 195          |\n|    n_updates                    | 2732         |\n|    policy_gradient_loss         | 0.000735     |\n|    value_loss                   | 397          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.14e+03     |\n|    water_produced               | 202          |\n--------------------------------------------------\nEval num_timesteps=5472000, episode_reward=1057.28 +/- 799.01\nEpisode length: 786.40 +/- 281.65\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 786          |\n|    mean_reward                  | 1.06e+03     |\n| time/                           |              |\n|    total_timesteps              | 5472000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016081957 |\n|    clip_fraction                | 0.00487      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.954       |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 237          |\n|    n_updates                    | 2734         |\n|    policy_gradient_loss         | -0.000977    |\n|    value_loss                   | 455          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 762          |\n|    water_produced               | 170          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 226      |\n| time/              |          |\n|    fps             | 858      |\n|    iterations      | 1368     |\n|    time_elapsed    | 6374     |\n|    total_timesteps | 5472000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 225          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1369         |\n|    time_elapsed                 | 6378         |\n|    total_timesteps              | 5476000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017310481 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.921       |\n|    explained_variance           | 0.688        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 182          |\n|    n_updates                    | 2736         |\n|    policy_gradient_loss         | 0.000321     |\n|    value_loss                   | 379          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.13e+03     |\n|    water_produced               | 232          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 238          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1370         |\n|    time_elapsed                 | 6383         |\n|    total_timesteps              | 5480000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016161941 |\n|    clip_fraction                | 0.0085       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.901       |\n|    explained_variance           | 0.527        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 240          |\n|    n_updates                    | 2738         |\n|    policy_gradient_loss         | 6.12e-05     |\n|    value_loss                   | 476          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.28e+03     |\n|    water_produced               | 288          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 227         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1371        |\n|    time_elapsed                 | 6387        |\n|    total_timesteps              | 5484000     |\n| train/                          |             |\n|    approx_kl                    | 0.002623889 |\n|    clip_fraction                | 0.0141      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.856      |\n|    explained_variance           | 0.584       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 209         |\n|    n_updates                    | 2740        |\n|    policy_gradient_loss         | 0.00421     |\n|    value_loss                   | 401         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 944         |\n|    water_produced               | 193         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 236          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1372         |\n|    time_elapsed                 | 6391         |\n|    total_timesteps              | 5488000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013476893 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.909       |\n|    explained_variance           | 0.59         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 2742         |\n|    policy_gradient_loss         | -0.00129     |\n|    value_loss                   | 425          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.06e+03     |\n|    water_produced               | 245          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 256          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1373         |\n|    time_elapsed                 | 6396         |\n|    total_timesteps              | 5492000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029842325 |\n|    clip_fraction                | 0.0151       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.936       |\n|    explained_variance           | 0.604        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 190          |\n|    n_updates                    | 2744         |\n|    policy_gradient_loss         | -0.00306     |\n|    value_loss                   | 379          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 265          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 244          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1374         |\n|    time_elapsed                 | 6400         |\n|    total_timesteps              | 5496000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017587546 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.942       |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 230          |\n|    n_updates                    | 2746         |\n|    policy_gradient_loss         | 0.0016       |\n|    value_loss                   | 453          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 992          |\n|    water_produced               | 174          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 227          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1375         |\n|    time_elapsed                 | 6405         |\n|    total_timesteps              | 5500000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027974076 |\n|    clip_fraction                | 0.0171       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.98        |\n|    explained_variance           | 0.523        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 2748         |\n|    policy_gradient_loss         | -0.00172     |\n|    value_loss                   | 425          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 992          |\n|    water_produced               | 208          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 255         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1376        |\n|    time_elapsed                 | 6410        |\n|    total_timesteps              | 5504000     |\n| train/                          |             |\n|    approx_kl                    | 0.001926251 |\n|    clip_fraction                | 0.0065      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.933      |\n|    explained_variance           | 0.523       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 239         |\n|    n_updates                    | 2750        |\n|    policy_gradient_loss         | -2.16e-05   |\n|    value_loss                   | 470         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 162         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.48e+03    |\n|    water_produced               | 327         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 256         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1377        |\n|    time_elapsed                 | 6415        |\n|    total_timesteps              | 5508000     |\n| train/                          |             |\n|    approx_kl                    | 0.004334718 |\n|    clip_fraction                | 0.0212      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.848      |\n|    explained_variance           | 0.596       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 225         |\n|    n_updates                    | 2752        |\n|    policy_gradient_loss         | 0.00361     |\n|    value_loss                   | 482         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 157         |\n|    ice_dug                      | 1.13e+03    |\n|    water_produced               | 247         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 253           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 1378          |\n|    time_elapsed                 | 6419          |\n|    total_timesteps              | 5512000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046585835 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.854        |\n|    explained_variance           | 0.589         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 227           |\n|    n_updates                    | 2754          |\n|    policy_gradient_loss         | 0.000971      |\n|    value_loss                   | 441           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 1.17e+03      |\n|    water_produced               | 250           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 256          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1379         |\n|    time_elapsed                 | 6424         |\n|    total_timesteps              | 5516000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011861443 |\n|    clip_fraction                | 0.003        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.877       |\n|    explained_variance           | 0.556        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 2756         |\n|    policy_gradient_loss         | -0.00117     |\n|    value_loss                   | 422          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 926          |\n|    water_produced               | 190          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 269          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1380         |\n|    time_elapsed                 | 6428         |\n|    total_timesteps              | 5520000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032099683 |\n|    clip_fraction                | 0.0119       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.968       |\n|    explained_variance           | 0.78         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 164          |\n|    n_updates                    | 2758         |\n|    policy_gradient_loss         | -0.000804    |\n|    value_loss                   | 340          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 272          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 262           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 1381          |\n|    time_elapsed                 | 6433          |\n|    total_timesteps              | 5524000       |\n| train/                          |               |\n|    approx_kl                    | 0.00021581855 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.986        |\n|    explained_variance           | 0.824         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 160           |\n|    n_updates                    | 2760          |\n|    policy_gradient_loss         | -0.000237     |\n|    value_loss                   | 334           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 166           |\n|    action_queue_updates_total   | 169           |\n|    ice_dug                      | 1.28e+03      |\n|    water_produced               | 294           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 258         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1382        |\n|    time_elapsed                 | 6437        |\n|    total_timesteps              | 5528000     |\n| train/                          |             |\n|    approx_kl                    | 0.004097783 |\n|    clip_fraction                | 0.0174      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.909      |\n|    explained_variance           | 0.522       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 212         |\n|    n_updates                    | 2762        |\n|    policy_gradient_loss         | 0.00269     |\n|    value_loss                   | 421         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.03e+03    |\n|    water_produced               | 227         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 250          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1383         |\n|    time_elapsed                 | 6442         |\n|    total_timesteps              | 5532000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018015373 |\n|    clip_fraction                | 0.0125       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.888       |\n|    explained_variance           | 0.52         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 193          |\n|    n_updates                    | 2764         |\n|    policy_gradient_loss         | -0.000648    |\n|    value_loss                   | 410          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 938          |\n|    water_produced               | 213          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 272        |\n| time/                           |            |\n|    fps                          | 858        |\n|    iterations                   | 1384       |\n|    time_elapsed                 | 6447       |\n|    total_timesteps              | 5536000    |\n| train/                          |            |\n|    approx_kl                    | 0.00585689 |\n|    clip_fraction                | 0.0238     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.927     |\n|    explained_variance           | 0.593      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 180        |\n|    n_updates                    | 2766       |\n|    policy_gradient_loss         | -0.000313  |\n|    value_loss                   | 388        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 162        |\n|    action_queue_updates_total   | 166        |\n|    ice_dug                      | 1.35e+03   |\n|    water_produced               | 298        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 270          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1385         |\n|    time_elapsed                 | 6451         |\n|    total_timesteps              | 5540000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028337357 |\n|    clip_fraction                | 0.0145       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.897       |\n|    explained_variance           | 0.555        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 2768         |\n|    policy_gradient_loss         | 0.000921     |\n|    value_loss                   | 486          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 1.1e+03      |\n|    water_produced               | 259          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 264           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 1386          |\n|    time_elapsed                 | 6456          |\n|    total_timesteps              | 5544000       |\n| train/                          |               |\n|    approx_kl                    | 0.00075405306 |\n|    clip_fraction                | 0.00112       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.868        |\n|    explained_variance           | 0.62          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 171           |\n|    n_updates                    | 2770          |\n|    policy_gradient_loss         | 0.00109       |\n|    value_loss                   | 355           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 1.25e+03      |\n|    water_produced               | 268           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 249           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 1387          |\n|    time_elapsed                 | 6460          |\n|    total_timesteps              | 5548000       |\n| train/                          |               |\n|    approx_kl                    | 0.00043926443 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.883        |\n|    explained_variance           | 0.674         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 201           |\n|    n_updates                    | 2772          |\n|    policy_gradient_loss         | -0.000809     |\n|    value_loss                   | 416           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 160           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 709           |\n|    water_produced               | 155           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 239         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1388        |\n|    time_elapsed                 | 6465        |\n|    total_timesteps              | 5552000     |\n| train/                          |             |\n|    approx_kl                    | 0.003433186 |\n|    clip_fraction                | 0.0149      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.958      |\n|    explained_variance           | 0.569       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 205         |\n|    n_updates                    | 2774        |\n|    policy_gradient_loss         | -0.00121    |\n|    value_loss                   | 410         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 729         |\n|    water_produced               | 162         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 230         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1389        |\n|    time_elapsed                 | 6469        |\n|    total_timesteps              | 5556000     |\n| train/                          |             |\n|    approx_kl                    | 0.009608557 |\n|    clip_fraction                | 0.0627      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.986      |\n|    explained_variance           | 0.536       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 230         |\n|    n_updates                    | 2776        |\n|    policy_gradient_loss         | 0.00127     |\n|    value_loss                   | 411         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.15e+03    |\n|    water_produced               | 256         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 236          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1390         |\n|    time_elapsed                 | 6473         |\n|    total_timesteps              | 5560000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019867523 |\n|    clip_fraction                | 0.00925      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.951       |\n|    explained_variance           | 0.71         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 247          |\n|    n_updates                    | 2778         |\n|    policy_gradient_loss         | 0.000176     |\n|    value_loss                   | 482          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.32e+03     |\n|    water_produced               | 286          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 228         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1391        |\n|    time_elapsed                 | 6478        |\n|    total_timesteps              | 5564000     |\n| train/                          |             |\n|    approx_kl                    | 0.004125569 |\n|    clip_fraction                | 0.0194      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.905      |\n|    explained_variance           | 0.705       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 212         |\n|    n_updates                    | 2780        |\n|    policy_gradient_loss         | 0.00208     |\n|    value_loss                   | 434         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.01e+03    |\n|    water_produced               | 234         |\n-------------------------------------------------\nEval num_timesteps=5568000, episode_reward=569.32 +/- 792.05\nEpisode length: 580.60 +/- 342.44\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 581          |\n|    mean_reward                  | 569          |\n| time/                           |              |\n|    total_timesteps              | 5568000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015306013 |\n|    clip_fraction                | 0.002        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.858       |\n|    explained_variance           | 0.578        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 206          |\n|    n_updates                    | 2782         |\n|    policy_gradient_loss         | 9.68e-05     |\n|    value_loss                   | 415          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 809          |\n|    water_produced               | 170          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 231      |\n| time/              |          |\n|    fps             | 858      |\n|    iterations      | 1392     |\n|    time_elapsed    | 6488     |\n|    total_timesteps | 5568000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 244         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1393        |\n|    time_elapsed                 | 6492        |\n|    total_timesteps              | 5572000     |\n| train/                          |             |\n|    approx_kl                    | 0.007686644 |\n|    clip_fraction                | 0.0395      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.884      |\n|    explained_variance           | 0.537       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 243         |\n|    n_updates                    | 2784        |\n|    policy_gradient_loss         | -0.00153    |\n|    value_loss                   | 487         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.03e+03    |\n|    water_produced               | 220         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 241           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 1394          |\n|    time_elapsed                 | 6497          |\n|    total_timesteps              | 5576000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046321267 |\n|    clip_fraction                | 0.00137       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.866        |\n|    explained_variance           | 0.552         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 233           |\n|    n_updates                    | 2786          |\n|    policy_gradient_loss         | -0.000467     |\n|    value_loss                   | 517           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 168           |\n|    action_queue_updates_total   | 170           |\n|    ice_dug                      | 1.1e+03       |\n|    water_produced               | 242           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 260         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1395        |\n|    time_elapsed                 | 6501        |\n|    total_timesteps              | 5580000     |\n| train/                          |             |\n|    approx_kl                    | 0.003727092 |\n|    clip_fraction                | 0.0178      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.901      |\n|    explained_variance           | 0.6         |\n|    learning_rate                | 0.0003      |\n|    loss                         | 301         |\n|    n_updates                    | 2788        |\n|    policy_gradient_loss         | -0.000746   |\n|    value_loss                   | 603         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.67e+03    |\n|    water_produced               | 378         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 264          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1396         |\n|    time_elapsed                 | 6506         |\n|    total_timesteps              | 5584000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026000808 |\n|    clip_fraction                | 0.0146       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.834       |\n|    explained_variance           | 0.585        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 273          |\n|    n_updates                    | 2790         |\n|    policy_gradient_loss         | 0.00196      |\n|    value_loss                   | 598          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 251          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 267          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1397         |\n|    time_elapsed                 | 6510         |\n|    total_timesteps              | 5588000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018736277 |\n|    clip_fraction                | 0.0108       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.857       |\n|    explained_variance           | 0.711        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 255          |\n|    n_updates                    | 2792         |\n|    policy_gradient_loss         | 0.00218      |\n|    value_loss                   | 511          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 933          |\n|    water_produced               | 182          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 268        |\n| time/                           |            |\n|    fps                          | 858        |\n|    iterations                   | 1398       |\n|    time_elapsed                 | 6515       |\n|    total_timesteps              | 5592000    |\n| train/                          |            |\n|    approx_kl                    | 0.00675184 |\n|    clip_fraction                | 0.0296     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.877     |\n|    explained_variance           | 0.558      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 210        |\n|    n_updates                    | 2794       |\n|    policy_gradient_loss         | -0.0025    |\n|    value_loss                   | 444        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 154        |\n|    action_queue_updates_total   | 158        |\n|    ice_dug                      | 1.05e+03   |\n|    water_produced               | 228        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 262          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1399         |\n|    time_elapsed                 | 6519         |\n|    total_timesteps              | 5596000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020679925 |\n|    clip_fraction                | 0.0105       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.89        |\n|    explained_variance           | 0.621        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 227          |\n|    n_updates                    | 2796         |\n|    policy_gradient_loss         | -0.000889    |\n|    value_loss                   | 461          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.01e+03     |\n|    water_produced               | 214          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 246           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 1400          |\n|    time_elapsed                 | 6524          |\n|    total_timesteps              | 5600000       |\n| train/                          |               |\n|    approx_kl                    | 0.00072855374 |\n|    clip_fraction                | 0.00212       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.904        |\n|    explained_variance           | 0.594         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 257           |\n|    n_updates                    | 2798          |\n|    policy_gradient_loss         | -0.000434     |\n|    value_loss                   | 523           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 160           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 1.41e+03      |\n|    water_produced               | 298           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 229           |\n| time/                           |               |\n|    fps                          | 858           |\n|    iterations                   | 1401          |\n|    time_elapsed                 | 6528          |\n|    total_timesteps              | 5604000       |\n| train/                          |               |\n|    approx_kl                    | 0.00060937006 |\n|    clip_fraction                | 0.0025        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.842        |\n|    explained_variance           | 0.545         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 268           |\n|    n_updates                    | 2800          |\n|    policy_gradient_loss         | -0.000349     |\n|    value_loss                   | 570           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 162           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 877           |\n|    water_produced               | 169           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 256          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1402         |\n|    time_elapsed                 | 6532         |\n|    total_timesteps              | 5608000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007890308 |\n|    clip_fraction                | 0.002        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.941       |\n|    explained_variance           | 0.629        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 2802         |\n|    policy_gradient_loss         | 0.000282     |\n|    value_loss                   | 512          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.34e+03     |\n|    water_produced               | 311          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 269          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1403         |\n|    time_elapsed                 | 6537         |\n|    total_timesteps              | 5612000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002058144 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.907       |\n|    explained_variance           | 0.758        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 242          |\n|    n_updates                    | 2804         |\n|    policy_gradient_loss         | -0.000741    |\n|    value_loss                   | 522          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.33e+03     |\n|    water_produced               | 292          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 278         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1404        |\n|    time_elapsed                 | 6542        |\n|    total_timesteps              | 5616000     |\n| train/                          |             |\n|    approx_kl                    | 0.003217686 |\n|    clip_fraction                | 0.0164      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.852      |\n|    explained_variance           | 0.618       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 223         |\n|    n_updates                    | 2806        |\n|    policy_gradient_loss         | 0.00444     |\n|    value_loss                   | 431         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 157         |\n|    ice_dug                      | 1.23e+03    |\n|    water_produced               | 258         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 282          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1405         |\n|    time_elapsed                 | 6546         |\n|    total_timesteps              | 5620000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008723736 |\n|    clip_fraction                | 0.003        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.881       |\n|    explained_variance           | 0.549        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 217          |\n|    n_updates                    | 2808         |\n|    policy_gradient_loss         | 0.000233     |\n|    value_loss                   | 434          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.42e+03     |\n|    water_produced               | 318          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 289          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1406         |\n|    time_elapsed                 | 6551         |\n|    total_timesteps              | 5624000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011072101 |\n|    clip_fraction                | 0.004        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.841       |\n|    explained_variance           | 0.598        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 185          |\n|    n_updates                    | 2810         |\n|    policy_gradient_loss         | 0.00175      |\n|    value_loss                   | 397          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 925          |\n|    water_produced               | 205          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 273          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1407         |\n|    time_elapsed                 | 6555         |\n|    total_timesteps              | 5628000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028779681 |\n|    clip_fraction                | 0.0143       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.926       |\n|    explained_variance           | 0.547        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 173          |\n|    n_updates                    | 2812         |\n|    policy_gradient_loss         | -0.000259    |\n|    value_loss                   | 394          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.17e+03     |\n|    water_produced               | 229          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 259          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1408         |\n|    time_elapsed                 | 6560         |\n|    total_timesteps              | 5632000      |\n| train/                          |              |\n|    approx_kl                    | 0.0045206645 |\n|    clip_fraction                | 0.033        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.962       |\n|    explained_variance           | 0.537        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 220          |\n|    n_updates                    | 2814         |\n|    policy_gradient_loss         | -0.000642    |\n|    value_loss                   | 469          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.03e+03     |\n|    water_produced               | 226          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 252          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1409         |\n|    time_elapsed                 | 6565         |\n|    total_timesteps              | 5636000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015448232 |\n|    clip_fraction                | 0.00713      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.62         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 2816         |\n|    policy_gradient_loss         | -0.00167     |\n|    value_loss                   | 456          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 178          |\n|    ice_dug                      | 1.12e+03     |\n|    water_produced               | 223          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 238          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1410         |\n|    time_elapsed                 | 6569         |\n|    total_timesteps              | 5640000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013786902 |\n|    clip_fraction                | 0.00175      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.987       |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 255          |\n|    n_updates                    | 2818         |\n|    policy_gradient_loss         | -0.000678    |\n|    value_loss                   | 517          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.22e+03     |\n|    water_produced               | 253          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 236         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1411        |\n|    time_elapsed                 | 6574        |\n|    total_timesteps              | 5644000     |\n| train/                          |             |\n|    approx_kl                    | 0.003797268 |\n|    clip_fraction                | 0.0277      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.931      |\n|    explained_variance           | 0.665       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 208         |\n|    n_updates                    | 2820        |\n|    policy_gradient_loss         | 0.00196     |\n|    value_loss                   | 442         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 871         |\n|    water_produced               | 196         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 234         |\n| time/                           |             |\n|    fps                          | 858         |\n|    iterations                   | 1412        |\n|    time_elapsed                 | 6579        |\n|    total_timesteps              | 5648000     |\n| train/                          |             |\n|    approx_kl                    | 0.003453844 |\n|    clip_fraction                | 0.0185      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.02       |\n|    explained_variance           | 0.758       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 180         |\n|    n_updates                    | 2822        |\n|    policy_gradient_loss         | -0.00157    |\n|    value_loss                   | 382         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.02e+03    |\n|    water_produced               | 222         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 227          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1413         |\n|    time_elapsed                 | 6583         |\n|    total_timesteps              | 5652000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015830889 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.01        |\n|    explained_variance           | 0.623        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 223          |\n|    n_updates                    | 2824         |\n|    policy_gradient_loss         | -0.00143     |\n|    value_loss                   | 432          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 975          |\n|    water_produced               | 188          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 252          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1414         |\n|    time_elapsed                 | 6587         |\n|    total_timesteps              | 5656000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011698386 |\n|    clip_fraction                | 0.00388      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.04        |\n|    explained_variance           | 0.69         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 2826         |\n|    policy_gradient_loss         | 0.000223     |\n|    value_loss                   | 447          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 1.51e+03     |\n|    water_produced               | 348          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 256          |\n| time/                           |              |\n|    fps                          | 858          |\n|    iterations                   | 1415         |\n|    time_elapsed                 | 6592         |\n|    total_timesteps              | 5660000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030993752 |\n|    clip_fraction                | 0.0085       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.937       |\n|    explained_variance           | 0.57         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 233          |\n|    n_updates                    | 2828         |\n|    policy_gradient_loss         | 0.000793     |\n|    value_loss                   | 470          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 269          |\n--------------------------------------------------\nEval num_timesteps=5664000, episode_reward=1152.48 +/- 893.67\nEpisode length: 779.40 +/- 285.83\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 779          |\n|    mean_reward                  | 1.15e+03     |\n| time/                           |              |\n|    total_timesteps              | 5664000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031869602 |\n|    clip_fraction                | 0.00763      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.908       |\n|    explained_variance           | 0.634        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 2830         |\n|    policy_gradient_loss         | 0.000235     |\n|    value_loss                   | 406          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.01e+03     |\n|    water_produced               | 230          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 263      |\n| time/              |          |\n|    fps             | 857      |\n|    iterations      | 1416     |\n|    time_elapsed    | 6603     |\n|    total_timesteps | 5664000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 268         |\n| time/                           |             |\n|    fps                          | 857         |\n|    iterations                   | 1417        |\n|    time_elapsed                 | 6608        |\n|    total_timesteps              | 5668000     |\n| train/                          |             |\n|    approx_kl                    | 0.004516565 |\n|    clip_fraction                | 0.0281      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.962      |\n|    explained_variance           | 0.764       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 198         |\n|    n_updates                    | 2832        |\n|    policy_gradient_loss         | -0.00415    |\n|    value_loss                   | 350         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.14e+03    |\n|    water_produced               | 247         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 283           |\n| time/                           |               |\n|    fps                          | 857           |\n|    iterations                   | 1418          |\n|    time_elapsed                 | 6612          |\n|    total_timesteps              | 5672000       |\n| train/                          |               |\n|    approx_kl                    | 0.00086272386 |\n|    clip_fraction                | 0.0025        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.916        |\n|    explained_variance           | 0.61          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 241           |\n|    n_updates                    | 2834          |\n|    policy_gradient_loss         | 0.000822      |\n|    value_loss                   | 501           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 163           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 1.26e+03      |\n|    water_produced               | 261           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 255          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1419         |\n|    time_elapsed                 | 6617         |\n|    total_timesteps              | 5676000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018221668 |\n|    clip_fraction                | 0.00875      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.916       |\n|    explained_variance           | 0.515        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 2836         |\n|    policy_gradient_loss         | 0.00107      |\n|    value_loss                   | 509          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 920          |\n|    water_produced               | 215          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 262         |\n| time/                           |             |\n|    fps                          | 857         |\n|    iterations                   | 1420        |\n|    time_elapsed                 | 6621        |\n|    total_timesteps              | 5680000     |\n| train/                          |             |\n|    approx_kl                    | 0.002847487 |\n|    clip_fraction                | 0.0134      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.947      |\n|    explained_variance           | 0.591       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 236         |\n|    n_updates                    | 2838        |\n|    policy_gradient_loss         | -0.000691   |\n|    value_loss                   | 473         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 1.34e+03    |\n|    water_produced               | 301         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 267          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1421         |\n|    time_elapsed                 | 6626         |\n|    total_timesteps              | 5684000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005660095 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.899       |\n|    explained_variance           | 0.599        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 2840         |\n|    policy_gradient_loss         | -0.00102     |\n|    value_loss                   | 459          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.12e+03     |\n|    water_produced               | 254          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 273          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1422         |\n|    time_elapsed                 | 6630         |\n|    total_timesteps              | 5688000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008402726 |\n|    clip_fraction                | 0.00312      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.91        |\n|    explained_variance           | 0.658        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 2842         |\n|    policy_gradient_loss         | 0.000102     |\n|    value_loss                   | 409          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.41e+03     |\n|    water_produced               | 272          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 265          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1423         |\n|    time_elapsed                 | 6635         |\n|    total_timesteps              | 5692000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008171364 |\n|    clip_fraction                | 0.00137      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.886       |\n|    explained_variance           | 0.527        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 293          |\n|    n_updates                    | 2844         |\n|    policy_gradient_loss         | -0.000478    |\n|    value_loss                   | 563          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.1e+03      |\n|    water_produced               | 225          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 265          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1424         |\n|    time_elapsed                 | 6640         |\n|    total_timesteps              | 5696000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027854694 |\n|    clip_fraction                | 0.0114       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.86        |\n|    explained_variance           | 0.552        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 251          |\n|    n_updates                    | 2846         |\n|    policy_gradient_loss         | -0.000332    |\n|    value_loss                   | 507          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.09e+03     |\n|    water_produced               | 213          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 266          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1425         |\n|    time_elapsed                 | 6644         |\n|    total_timesteps              | 5700000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023504246 |\n|    clip_fraction                | 0.0182       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.924       |\n|    explained_variance           | 0.565        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 2848         |\n|    policy_gradient_loss         | -0.000474    |\n|    value_loss                   | 526          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 304          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 265          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1426         |\n|    time_elapsed                 | 6649         |\n|    total_timesteps              | 5704000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032690242 |\n|    clip_fraction                | 0.019        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.881       |\n|    explained_variance           | 0.647        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 271          |\n|    n_updates                    | 2850         |\n|    policy_gradient_loss         | 0.000746     |\n|    value_loss                   | 602          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.19e+03     |\n|    water_produced               | 249          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 268        |\n| time/                           |            |\n|    fps                          | 857        |\n|    iterations                   | 1427       |\n|    time_elapsed                 | 6653       |\n|    total_timesteps              | 5708000    |\n| train/                          |            |\n|    approx_kl                    | 0.00485998 |\n|    clip_fraction                | 0.0335     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.918     |\n|    explained_variance           | 0.552      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 228        |\n|    n_updates                    | 2852       |\n|    policy_gradient_loss         | -0.000159  |\n|    value_loss                   | 485        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 163        |\n|    action_queue_updates_total   | 167        |\n|    ice_dug                      | 1.37e+03   |\n|    water_produced               | 288        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 264          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1428         |\n|    time_elapsed                 | 6658         |\n|    total_timesteps              | 5712000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021490606 |\n|    clip_fraction                | 0.00838      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.862       |\n|    explained_variance           | 0.605        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 2854         |\n|    policy_gradient_loss         | 0.00155      |\n|    value_loss                   | 417          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.05e+03     |\n|    water_produced               | 207          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 273          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1429         |\n|    time_elapsed                 | 6663         |\n|    total_timesteps              | 5716000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021361043 |\n|    clip_fraction                | 0.0095       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.858       |\n|    explained_variance           | 0.516        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 2856         |\n|    policy_gradient_loss         | -0.000276    |\n|    value_loss                   | 450          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.26e+03     |\n|    water_produced               | 253          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 253          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1430         |\n|    time_elapsed                 | 6668         |\n|    total_timesteps              | 5720000      |\n| train/                          |              |\n|    approx_kl                    | 0.0071774246 |\n|    clip_fraction                | 0.0281       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.85        |\n|    explained_variance           | 0.565        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 239          |\n|    n_updates                    | 2858         |\n|    policy_gradient_loss         | -0.00257     |\n|    value_loss                   | 458          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 931          |\n|    water_produced               | 211          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 226          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1431         |\n|    time_elapsed                 | 6672         |\n|    total_timesteps              | 5724000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021525691 |\n|    clip_fraction                | 0.0128       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.917       |\n|    explained_variance           | 0.648        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 2860         |\n|    policy_gradient_loss         | -0.000106    |\n|    value_loss                   | 421          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 576          |\n|    water_produced               | 118          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 217        |\n| time/                           |            |\n|    fps                          | 857        |\n|    iterations                   | 1432       |\n|    time_elapsed                 | 6677       |\n|    total_timesteps              | 5728000    |\n| train/                          |            |\n|    approx_kl                    | 0.01583097 |\n|    clip_fraction                | 0.104      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.05      |\n|    explained_variance           | 0.674      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 170        |\n|    n_updates                    | 2862       |\n|    policy_gradient_loss         | 0.00208    |\n|    value_loss                   | 375        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 167        |\n|    action_queue_updates_total   | 169        |\n|    ice_dug                      | 1.14e+03   |\n|    water_produced               | 248        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 223          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1433         |\n|    time_elapsed                 | 6681         |\n|    total_timesteps              | 5732000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014823459 |\n|    clip_fraction                | 0.00775      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.95        |\n|    explained_variance           | 0.547        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 266          |\n|    n_updates                    | 2864         |\n|    policy_gradient_loss         | -0.00154     |\n|    value_loss                   | 562          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.09e+03     |\n|    water_produced               | 235          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 220         |\n| time/                           |             |\n|    fps                          | 857         |\n|    iterations                   | 1434        |\n|    time_elapsed                 | 6686        |\n|    total_timesteps              | 5736000     |\n| train/                          |             |\n|    approx_kl                    | 0.002791911 |\n|    clip_fraction                | 0.0135      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.923      |\n|    explained_variance           | 0.621       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 257         |\n|    n_updates                    | 2866        |\n|    policy_gradient_loss         | 0.00143     |\n|    value_loss                   | 557         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.04e+03    |\n|    water_produced               | 239         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 234          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1435         |\n|    time_elapsed                 | 6690         |\n|    total_timesteps              | 5740000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014985586 |\n|    clip_fraction                | 0.00437      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.906       |\n|    explained_variance           | 0.64         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 2868         |\n|    policy_gradient_loss         | -0.000568    |\n|    value_loss                   | 524          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 276          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 267          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1436         |\n|    time_elapsed                 | 6694         |\n|    total_timesteps              | 5744000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033183624 |\n|    clip_fraction                | 0.0171       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.816       |\n|    explained_variance           | 0.495        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 267          |\n|    n_updates                    | 2870         |\n|    policy_gradient_loss         | 0.00224      |\n|    value_loss                   | 525          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.26e+03     |\n|    water_produced               | 280          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 250         |\n| time/                           |             |\n|    fps                          | 857         |\n|    iterations                   | 1437        |\n|    time_elapsed                 | 6699        |\n|    total_timesteps              | 5748000     |\n| train/                          |             |\n|    approx_kl                    | 0.003408663 |\n|    clip_fraction                | 0.0252      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.801      |\n|    explained_variance           | 0.646       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 248         |\n|    n_updates                    | 2872        |\n|    policy_gradient_loss         | 0.00231     |\n|    value_loss                   | 471         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 875         |\n|    water_produced               | 162         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 272         |\n| time/                           |             |\n|    fps                          | 857         |\n|    iterations                   | 1438        |\n|    time_elapsed                 | 6704        |\n|    total_timesteps              | 5752000     |\n| train/                          |             |\n|    approx_kl                    | 0.004642614 |\n|    clip_fraction                | 0.0306      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.866      |\n|    explained_variance           | 0.639       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 230         |\n|    n_updates                    | 2874        |\n|    policy_gradient_loss         | -0.00208    |\n|    value_loss                   | 473         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.59e+03    |\n|    water_produced               | 343         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 298           |\n| time/                           |               |\n|    fps                          | 857           |\n|    iterations                   | 1439          |\n|    time_elapsed                 | 6709          |\n|    total_timesteps              | 5756000       |\n| train/                          |               |\n|    approx_kl                    | 0.00085553044 |\n|    clip_fraction                | 0.00412       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.785        |\n|    explained_variance           | 0.517         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 330           |\n|    n_updates                    | 2876          |\n|    policy_gradient_loss         | 0.00011       |\n|    value_loss                   | 656           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 153           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 1.54e+03      |\n|    water_produced               | 360           |\n---------------------------------------------------\nEval num_timesteps=5760000, episode_reward=2026.28 +/- 277.59\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.03e+03     |\n| time/                           |              |\n|    total_timesteps              | 5760000      |\n| train/                          |              |\n|    approx_kl                    | 0.0045903833 |\n|    clip_fraction                | 0.0305       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.727       |\n|    explained_variance           | 0.62         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 2878         |\n|    policy_gradient_loss         | 0.00499      |\n|    value_loss                   | 506          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 151          |\n|    ice_dug                      | 910          |\n|    water_produced               | 201          |\n--------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 282      |\n| time/              |          |\n|    fps             | 856      |\n|    iterations      | 1440     |\n|    time_elapsed    | 6722     |\n|    total_timesteps | 5760000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 256          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1441         |\n|    time_elapsed                 | 6726         |\n|    total_timesteps              | 5764000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029549957 |\n|    clip_fraction                | 0.015        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.815       |\n|    explained_variance           | 0.585        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 245          |\n|    n_updates                    | 2880         |\n|    policy_gradient_loss         | -0.000228    |\n|    value_loss                   | 481          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 842          |\n|    water_produced               | 155          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 275         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1442        |\n|    time_elapsed                 | 6731        |\n|    total_timesteps              | 5768000     |\n| train/                          |             |\n|    approx_kl                    | 0.010714568 |\n|    clip_fraction                | 0.0535      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.865      |\n|    explained_variance           | 0.564       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 233         |\n|    n_updates                    | 2882        |\n|    policy_gradient_loss         | 0.00151     |\n|    value_loss                   | 458         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 1.18e+03    |\n|    water_produced               | 256         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 260         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1443        |\n|    time_elapsed                 | 6736        |\n|    total_timesteps              | 5772000     |\n| train/                          |             |\n|    approx_kl                    | 0.001748815 |\n|    clip_fraction                | 0.00262     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.872      |\n|    explained_variance           | 0.635       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 266         |\n|    n_updates                    | 2884        |\n|    policy_gradient_loss         | -0.00116    |\n|    value_loss                   | 546         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.29e+03    |\n|    water_produced               | 269         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 252        |\n| time/                           |            |\n|    fps                          | 856        |\n|    iterations                   | 1444       |\n|    time_elapsed                 | 6740       |\n|    total_timesteps              | 5776000    |\n| train/                          |            |\n|    approx_kl                    | 0.00240918 |\n|    clip_fraction                | 0.013      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.869     |\n|    explained_variance           | 0.586      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 250        |\n|    n_updates                    | 2886       |\n|    policy_gradient_loss         | 1.85e-05   |\n|    value_loss                   | 561        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 162        |\n|    action_queue_updates_total   | 166        |\n|    ice_dug                      | 1.41e+03   |\n|    water_produced               | 322        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 267         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1445        |\n|    time_elapsed                 | 6745        |\n|    total_timesteps              | 5780000     |\n| train/                          |             |\n|    approx_kl                    | 0.002093093 |\n|    clip_fraction                | 0.00938     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.84       |\n|    explained_variance           | 0.596       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 249         |\n|    n_updates                    | 2888        |\n|    policy_gradient_loss         | 0.00142     |\n|    value_loss                   | 472         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.19e+03    |\n|    water_produced               | 272         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 295           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1446          |\n|    time_elapsed                 | 6750          |\n|    total_timesteps              | 5784000       |\n| train/                          |               |\n|    approx_kl                    | 0.00037017415 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.805        |\n|    explained_variance           | 0.638         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 236           |\n|    n_updates                    | 2890          |\n|    policy_gradient_loss         | 0.00099       |\n|    value_loss                   | 468           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 1.38e+03      |\n|    water_produced               | 293           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 297           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1447          |\n|    time_elapsed                 | 6754          |\n|    total_timesteps              | 5788000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046003642 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.831        |\n|    explained_variance           | 0.495         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 247           |\n|    n_updates                    | 2892          |\n|    policy_gradient_loss         | -9.73e-05     |\n|    value_loss                   | 489           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 156           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 1.33e+03      |\n|    water_produced               | 265           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 272         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1448        |\n|    time_elapsed                 | 6758        |\n|    total_timesteps              | 5792000     |\n| train/                          |             |\n|    approx_kl                    | 0.001386242 |\n|    clip_fraction                | 0.00563     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.857      |\n|    explained_variance           | 0.616       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 198         |\n|    n_updates                    | 2894        |\n|    policy_gradient_loss         | 0.00185     |\n|    value_loss                   | 426         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 655         |\n|    water_produced               | 150         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 262         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1449        |\n|    time_elapsed                 | 6763        |\n|    total_timesteps              | 5796000     |\n| train/                          |             |\n|    approx_kl                    | 0.008235859 |\n|    clip_fraction                | 0.0445      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.932      |\n|    explained_variance           | 0.577       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 185         |\n|    n_updates                    | 2896        |\n|    policy_gradient_loss         | -0.000235   |\n|    value_loss                   | 442         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.17e+03    |\n|    water_produced               | 272         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 265          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1450         |\n|    time_elapsed                 | 6768         |\n|    total_timesteps              | 5800000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010072713 |\n|    clip_fraction                | 0.002        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.957       |\n|    explained_variance           | 0.636        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 224          |\n|    n_updates                    | 2898         |\n|    policy_gradient_loss         | -0.00132     |\n|    value_loss                   | 471          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.34e+03     |\n|    water_produced               | 284          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 246          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1451         |\n|    time_elapsed                 | 6772         |\n|    total_timesteps              | 5804000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029148678 |\n|    clip_fraction                | 0.00987      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.87        |\n|    explained_variance           | 0.554        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 252          |\n|    n_updates                    | 2900         |\n|    policy_gradient_loss         | 1.82e-05     |\n|    value_loss                   | 463          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.07e+03     |\n|    water_produced               | 201          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 240         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1452        |\n|    time_elapsed                 | 6777        |\n|    total_timesteps              | 5808000     |\n| train/                          |             |\n|    approx_kl                    | 0.004324947 |\n|    clip_fraction                | 0.024       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.936      |\n|    explained_variance           | 0.7         |\n|    learning_rate                | 0.0003      |\n|    loss                         | 238         |\n|    n_updates                    | 2902        |\n|    policy_gradient_loss         | -7.22e-05   |\n|    value_loss                   | 489         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.12e+03    |\n|    water_produced               | 239         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 278          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1453         |\n|    time_elapsed                 | 6782         |\n|    total_timesteps              | 5812000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013285497 |\n|    clip_fraction                | 0.00562      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.833       |\n|    explained_variance           | 0.622        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 2904         |\n|    policy_gradient_loss         | -0.0013      |\n|    value_loss                   | 403          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.49e+03     |\n|    water_produced               | 333          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 279         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1454        |\n|    time_elapsed                 | 6786        |\n|    total_timesteps              | 5816000     |\n| train/                          |             |\n|    approx_kl                    | 0.004163718 |\n|    clip_fraction                | 0.0239      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.801      |\n|    explained_variance           | 0.639       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 275         |\n|    n_updates                    | 2906        |\n|    policy_gradient_loss         | 0.00168     |\n|    value_loss                   | 549         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 1.26e+03    |\n|    water_produced               | 277         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 273          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1455         |\n|    time_elapsed                 | 6791         |\n|    total_timesteps              | 5820000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036918507 |\n|    clip_fraction                | 0.027        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.818       |\n|    explained_variance           | 0.576        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 280          |\n|    n_updates                    | 2908         |\n|    policy_gradient_loss         | -6.09e-05    |\n|    value_loss                   | 570          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.23e+03     |\n|    water_produced               | 254          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 302         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1456        |\n|    time_elapsed                 | 6796        |\n|    total_timesteps              | 5824000     |\n| train/                          |             |\n|    approx_kl                    | 0.001303304 |\n|    clip_fraction                | 0.00288     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.854      |\n|    explained_variance           | 0.564       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 271         |\n|    n_updates                    | 2910        |\n|    policy_gradient_loss         | -0.00177    |\n|    value_loss                   | 541         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.48e+03    |\n|    water_produced               | 340         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 308         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1457        |\n|    time_elapsed                 | 6800        |\n|    total_timesteps              | 5828000     |\n| train/                          |             |\n|    approx_kl                    | 0.002507503 |\n|    clip_fraction                | 0.0111      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.856      |\n|    explained_variance           | 0.552       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 277         |\n|    n_updates                    | 2912        |\n|    policy_gradient_loss         | 0.00187     |\n|    value_loss                   | 571         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.23e+03    |\n|    water_produced               | 271         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 286          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1458         |\n|    time_elapsed                 | 6805         |\n|    total_timesteps              | 5832000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006001437 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.823       |\n|    explained_variance           | 0.596        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 195          |\n|    n_updates                    | 2914         |\n|    policy_gradient_loss         | 0.000288     |\n|    value_loss                   | 406          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 997          |\n|    water_produced               | 224          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 302          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1459         |\n|    time_elapsed                 | 6809         |\n|    total_timesteps              | 5836000      |\n| train/                          |              |\n|    approx_kl                    | 0.0055095055 |\n|    clip_fraction                | 0.0367       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.975       |\n|    explained_variance           | 0.745        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 223          |\n|    n_updates                    | 2916         |\n|    policy_gradient_loss         | -0.00198     |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.55e+03     |\n|    water_produced               | 354          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 288          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1460         |\n|    time_elapsed                 | 6814         |\n|    total_timesteps              | 5840000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026470418 |\n|    clip_fraction                | 0.0135       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.828       |\n|    explained_variance           | 0.601        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 212          |\n|    n_updates                    | 2918         |\n|    policy_gradient_loss         | 0.00176      |\n|    value_loss                   | 441          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 974          |\n|    water_produced               | 188          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 267           |\n| time/                           |               |\n|    fps                          | 857           |\n|    iterations                   | 1461          |\n|    time_elapsed                 | 6818          |\n|    total_timesteps              | 5844000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032213714 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.873        |\n|    explained_variance           | 0.592         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 221           |\n|    n_updates                    | 2920          |\n|    policy_gradient_loss         | 0.000334      |\n|    value_loss                   | 444           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 169           |\n|    action_queue_updates_total   | 171           |\n|    ice_dug                      | 1.20e+03      |\n|    water_produced               | 238           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 269          |\n| time/                           |              |\n|    fps                          | 857          |\n|    iterations                   | 1462         |\n|    time_elapsed                 | 6823         |\n|    total_timesteps              | 5848000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012443236 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.894       |\n|    explained_variance           | 0.553        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 266          |\n|    n_updates                    | 2922         |\n|    policy_gradient_loss         | -0.00149     |\n|    value_loss                   | 511          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 282          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 279         |\n| time/                           |             |\n|    fps                          | 857         |\n|    iterations                   | 1463        |\n|    time_elapsed                 | 6828        |\n|    total_timesteps              | 5852000     |\n| train/                          |             |\n|    approx_kl                    | 0.001825739 |\n|    clip_fraction                | 0.0102      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.886      |\n|    explained_variance           | 0.664       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 255         |\n|    n_updates                    | 2924        |\n|    policy_gradient_loss         | 0.00018     |\n|    value_loss                   | 503         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.26e+03    |\n|    water_produced               | 269         |\n-------------------------------------------------\nEval num_timesteps=5856000, episode_reward=1256.68 +/- 685.75\nEpisode length: 860.20 +/- 279.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 860          |\n|    mean_reward                  | 1.26e+03     |\n| time/                           |              |\n|    total_timesteps              | 5856000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008344788 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.889       |\n|    explained_variance           | 0.589        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 226          |\n|    n_updates                    | 2926         |\n|    policy_gradient_loss         | -0.000698    |\n|    value_loss                   | 466          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.09e+03     |\n|    water_produced               | 249          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 257      |\n| time/              |          |\n|    fps             | 856      |\n|    iterations      | 1464     |\n|    time_elapsed    | 6838     |\n|    total_timesteps | 5856000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 268          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1465         |\n|    time_elapsed                 | 6843         |\n|    total_timesteps              | 5860000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036688596 |\n|    clip_fraction                | 0.0168       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.905       |\n|    explained_variance           | 0.635        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 2928         |\n|    policy_gradient_loss         | -0.00091     |\n|    value_loss                   | 428          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.09e+03     |\n|    water_produced               | 242          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 300          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1466         |\n|    time_elapsed                 | 6847         |\n|    total_timesteps              | 5864000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021199821 |\n|    clip_fraction                | 0.0114       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.89        |\n|    explained_variance           | 0.585        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 252          |\n|    n_updates                    | 2930         |\n|    policy_gradient_loss         | -0.00106     |\n|    value_loss                   | 524          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.74e+03     |\n|    water_produced               | 396          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 288          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1467         |\n|    time_elapsed                 | 6852         |\n|    total_timesteps              | 5868000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026157622 |\n|    clip_fraction                | 0.0149       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.817       |\n|    explained_variance           | 0.578        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 241          |\n|    n_updates                    | 2932         |\n|    policy_gradient_loss         | 0.00123      |\n|    value_loss                   | 573          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 997          |\n|    water_produced               | 221          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 299          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1468         |\n|    time_elapsed                 | 6857         |\n|    total_timesteps              | 5872000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003420056 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.862       |\n|    explained_variance           | 0.601        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 271          |\n|    n_updates                    | 2934         |\n|    policy_gradient_loss         | 0.00158      |\n|    value_loss                   | 506          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.43e+03     |\n|    water_produced               | 324          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 298           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1469          |\n|    time_elapsed                 | 6861          |\n|    total_timesteps              | 5876000       |\n| train/                          |               |\n|    approx_kl                    | 0.00043832877 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.874        |\n|    explained_variance           | 0.688         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 216           |\n|    n_updates                    | 2936          |\n|    policy_gradient_loss         | -0.000523     |\n|    value_loss                   | 459           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 165           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 1.09e+03      |\n|    water_produced               | 243           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 312          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1470         |\n|    time_elapsed                 | 6866         |\n|    total_timesteps              | 5880000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009792887 |\n|    clip_fraction                | 0.00588      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.864       |\n|    explained_variance           | 0.621        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 264          |\n|    n_updates                    | 2938         |\n|    policy_gradient_loss         | -3.84e-05    |\n|    value_loss                   | 499          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 309          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 284           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1471          |\n|    time_elapsed                 | 6870          |\n|    total_timesteps              | 5884000       |\n| train/                          |               |\n|    approx_kl                    | 0.00030207942 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.854        |\n|    explained_variance           | 0.603         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 228           |\n|    n_updates                    | 2940          |\n|    policy_gradient_loss         | -0.00107      |\n|    value_loss                   | 488           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 156           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 1.17e+03      |\n|    water_produced               | 262           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 303           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1472          |\n|    time_elapsed                 | 6875          |\n|    total_timesteps              | 5888000       |\n| train/                          |               |\n|    approx_kl                    | 0.00046704206 |\n|    clip_fraction                | 0.0015        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.875        |\n|    explained_variance           | 0.721         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 219           |\n|    n_updates                    | 2942          |\n|    policy_gradient_loss         | -0.000542     |\n|    value_loss                   | 445           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 160           |\n|    ice_dug                      | 1.4e+03       |\n|    water_produced               | 309           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 267         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1473        |\n|    time_elapsed                 | 6880        |\n|    total_timesteps              | 5892000     |\n| train/                          |             |\n|    approx_kl                    | 0.000689435 |\n|    clip_fraction                | 0.00025     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.831      |\n|    explained_variance           | 0.554       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 238         |\n|    n_updates                    | 2944        |\n|    policy_gradient_loss         | -0.000954   |\n|    value_loss                   | 488         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 765         |\n|    water_produced               | 154         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 279         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1474        |\n|    time_elapsed                 | 6884        |\n|    total_timesteps              | 5896000     |\n| train/                          |             |\n|    approx_kl                    | 0.001254032 |\n|    clip_fraction                | 0.00712     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.914      |\n|    explained_variance           | 0.666       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 225         |\n|    n_updates                    | 2946        |\n|    policy_gradient_loss         | 0.000522    |\n|    value_loss                   | 469         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 1.5e+03     |\n|    water_produced               | 296         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 257           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1475          |\n|    time_elapsed                 | 6889          |\n|    total_timesteps              | 5900000       |\n| train/                          |               |\n|    approx_kl                    | 0.00023676646 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.78         |\n|    explained_variance           | 0.47          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 288           |\n|    n_updates                    | 2948          |\n|    policy_gradient_loss         | -0.000461     |\n|    value_loss                   | 593           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 163           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 901           |\n|    water_produced               | 205           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 265           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1476          |\n|    time_elapsed                 | 6894          |\n|    total_timesteps              | 5904000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029123932 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.906        |\n|    explained_variance           | 0.656         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 236           |\n|    n_updates                    | 2950          |\n|    policy_gradient_loss         | -0.000577     |\n|    value_loss                   | 501           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 161           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 1.36e+03      |\n|    water_produced               | 304           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 260           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1477          |\n|    time_elapsed                 | 6898          |\n|    total_timesteps              | 5908000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025131568 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.821        |\n|    explained_variance           | 0.588         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 275           |\n|    n_updates                    | 2952          |\n|    policy_gradient_loss         | -0.000417     |\n|    value_loss                   | 529           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 157           |\n|    ice_dug                      | 1.37e+03      |\n|    water_produced               | 285           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 278          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1478         |\n|    time_elapsed                 | 6903         |\n|    total_timesteps              | 5912000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033737316 |\n|    clip_fraction                | 0.0214       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.765       |\n|    explained_variance           | 0.529        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 262          |\n|    n_updates                    | 2954         |\n|    policy_gradient_loss         | 0.0017       |\n|    value_loss                   | 511          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 135          |\n|    action_queue_updates_total   | 144          |\n|    ice_dug                      | 1.12e+03     |\n|    water_produced               | 237          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 276          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1479         |\n|    time_elapsed                 | 6907         |\n|    total_timesteps              | 5916000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037080697 |\n|    clip_fraction                | 0.0189       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.805       |\n|    explained_variance           | 0.697        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 228          |\n|    n_updates                    | 2956         |\n|    policy_gradient_loss         | -0.00214     |\n|    value_loss                   | 462          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.42e+03     |\n|    water_produced               | 290          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 279          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1480         |\n|    time_elapsed                 | 6911         |\n|    total_timesteps              | 5920000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015485253 |\n|    clip_fraction                | 0.00475      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.799       |\n|    explained_variance           | 0.602        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 269          |\n|    n_updates                    | 2958         |\n|    policy_gradient_loss         | -0.000685    |\n|    value_loss                   | 508          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 1e+03        |\n|    water_produced               | 214          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 279          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1481         |\n|    time_elapsed                 | 6916         |\n|    total_timesteps              | 5924000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028543982 |\n|    clip_fraction                | 0.0159       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.848       |\n|    explained_variance           | 0.692        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 2960         |\n|    policy_gradient_loss         | -0.000781    |\n|    value_loss                   | 477          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.53e+03     |\n|    water_produced               | 304          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 285           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1482          |\n|    time_elapsed                 | 6921          |\n|    total_timesteps              | 5928000       |\n| train/                          |               |\n|    approx_kl                    | 0.00032571226 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.836        |\n|    explained_variance           | 0.572         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 250           |\n|    n_updates                    | 2962          |\n|    policy_gradient_loss         | -0.000507     |\n|    value_loss                   | 498           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 163           |\n|    ice_dug                      | 1.5e+03       |\n|    water_produced               | 316           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 289         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1483        |\n|    time_elapsed                 | 6925        |\n|    total_timesteps              | 5932000     |\n| train/                          |             |\n|    approx_kl                    | 0.003842229 |\n|    clip_fraction                | 0.0205      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.823      |\n|    explained_variance           | 0.594       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 196         |\n|    n_updates                    | 2964        |\n|    policy_gradient_loss         | 0.0041      |\n|    value_loss                   | 421         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.09e+03    |\n|    water_produced               | 259         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 279          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1484         |\n|    time_elapsed                 | 6929         |\n|    total_timesteps              | 5936000      |\n| train/                          |              |\n|    approx_kl                    | 0.0059438134 |\n|    clip_fraction                | 0.0327       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.911       |\n|    explained_variance           | 0.644        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 208          |\n|    n_updates                    | 2966         |\n|    policy_gradient_loss         | 0.000225     |\n|    value_loss                   | 450          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.05e+03     |\n|    water_produced               | 242          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 288          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1485         |\n|    time_elapsed                 | 6934         |\n|    total_timesteps              | 5940000      |\n| train/                          |              |\n|    approx_kl                    | 0.0074259466 |\n|    clip_fraction                | 0.0445       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.934       |\n|    explained_variance           | 0.634        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 204          |\n|    n_updates                    | 2968         |\n|    policy_gradient_loss         | 0.0018       |\n|    value_loss                   | 401          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.24e+03     |\n|    water_produced               | 256          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 292          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1486         |\n|    time_elapsed                 | 6938         |\n|    total_timesteps              | 5944000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025897487 |\n|    clip_fraction                | 0.0119       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.94        |\n|    explained_variance           | 0.683        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 255          |\n|    n_updates                    | 2970         |\n|    policy_gradient_loss         | -0.0018      |\n|    value_loss                   | 521          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.55e+03     |\n|    water_produced               | 320          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 286          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1487         |\n|    time_elapsed                 | 6942         |\n|    total_timesteps              | 5948000      |\n| train/                          |              |\n|    approx_kl                    | 0.0062592626 |\n|    clip_fraction                | 0.042        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.812       |\n|    explained_variance           | 0.476        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 224          |\n|    n_updates                    | 2972         |\n|    policy_gradient_loss         | 0.00348      |\n|    value_loss                   | 508          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.26e+03     |\n|    water_produced               | 289          |\n--------------------------------------------------\nEval num_timesteps=5952000, episode_reward=1331.16 +/- 663.42\nEpisode length: 864.20 +/- 271.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 864          |\n|    mean_reward                  | 1.33e+03     |\n| time/                           |              |\n|    total_timesteps              | 5952000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015946378 |\n|    clip_fraction                | 0.0035       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.84        |\n|    explained_variance           | 0.692        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 2974         |\n|    policy_gradient_loss         | 0.00187      |\n|    value_loss                   | 495          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.08e+03     |\n|    water_produced               | 255          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 285      |\n| time/              |          |\n|    fps             | 856      |\n|    iterations      | 1488     |\n|    time_elapsed    | 6952     |\n|    total_timesteps | 5952000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 316          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1489         |\n|    time_elapsed                 | 6957         |\n|    total_timesteps              | 5956000      |\n| train/                          |              |\n|    approx_kl                    | 0.0049760365 |\n|    clip_fraction                | 0.0269       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.872       |\n|    explained_variance           | 0.65         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 2976         |\n|    policy_gradient_loss         | -0.00277     |\n|    value_loss                   | 439          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.66e+03     |\n|    water_produced               | 393          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 324          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1490         |\n|    time_elapsed                 | 6961         |\n|    total_timesteps              | 5960000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019137919 |\n|    clip_fraction                | 0.0102       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.805       |\n|    explained_variance           | 0.606        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 2978         |\n|    policy_gradient_loss         | 0.00171      |\n|    value_loss                   | 467          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.29e+03     |\n|    water_produced               | 295          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 311          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1491         |\n|    time_elapsed                 | 6965         |\n|    total_timesteps              | 5964000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013066919 |\n|    clip_fraction                | 0.00262      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.869       |\n|    explained_variance           | 0.617        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 2980         |\n|    policy_gradient_loss         | 0.000707     |\n|    value_loss                   | 467          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.13e+03     |\n|    water_produced               | 259          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 318          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1492         |\n|    time_elapsed                 | 6970         |\n|    total_timesteps              | 5968000      |\n| train/                          |              |\n|    approx_kl                    | 0.0059941597 |\n|    clip_fraction                | 0.041        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.938       |\n|    explained_variance           | 0.67         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 2982         |\n|    policy_gradient_loss         | 0.000233     |\n|    value_loss                   | 400          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.53e+03     |\n|    water_produced               | 321          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 323         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1493        |\n|    time_elapsed                 | 6974        |\n|    total_timesteps              | 5972000     |\n| train/                          |             |\n|    approx_kl                    | 0.002213717 |\n|    clip_fraction                | 0.0119      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.898      |\n|    explained_variance           | 0.488       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 224         |\n|    n_updates                    | 2984        |\n|    policy_gradient_loss         | 0.000342    |\n|    value_loss                   | 490         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.23e+03    |\n|    water_produced               | 277         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 293          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1494         |\n|    time_elapsed                 | 6978         |\n|    total_timesteps              | 5976000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010897072 |\n|    clip_fraction                | 0.00762      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.887       |\n|    explained_variance           | 0.594        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 247          |\n|    n_updates                    | 2986         |\n|    policy_gradient_loss         | 0.000386     |\n|    value_loss                   | 476          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.15e+03     |\n|    water_produced               | 252          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 289         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1495        |\n|    time_elapsed                 | 6983        |\n|    total_timesteps              | 5980000     |\n| train/                          |             |\n|    approx_kl                    | 0.005685027 |\n|    clip_fraction                | 0.0416      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.911      |\n|    explained_variance           | 0.607       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 225         |\n|    n_updates                    | 2988        |\n|    policy_gradient_loss         | -0.00131    |\n|    value_loss                   | 453         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 162         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.21e+03    |\n|    water_produced               | 275         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 297          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1496         |\n|    time_elapsed                 | 6987         |\n|    total_timesteps              | 5984000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024490668 |\n|    clip_fraction                | 0.0111       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.908       |\n|    explained_variance           | 0.771        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 212          |\n|    n_updates                    | 2990         |\n|    policy_gradient_loss         | -0.00111     |\n|    value_loss                   | 450          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.27e+03     |\n|    water_produced               | 296          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 287          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1497         |\n|    time_elapsed                 | 6992         |\n|    total_timesteps              | 5988000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013329686 |\n|    clip_fraction                | 0.0065       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.905       |\n|    explained_variance           | 0.715        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 283          |\n|    n_updates                    | 2992         |\n|    policy_gradient_loss         | 0.000617     |\n|    value_loss                   | 526          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.26e+03     |\n|    water_produced               | 274          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 273          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1498         |\n|    time_elapsed                 | 6996         |\n|    total_timesteps              | 5992000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012838461 |\n|    clip_fraction                | 0.00762      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.876       |\n|    explained_variance           | 0.621        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 249          |\n|    n_updates                    | 2994         |\n|    policy_gradient_loss         | 0.000408     |\n|    value_loss                   | 501          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 953          |\n|    water_produced               | 209          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 291          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1499         |\n|    time_elapsed                 | 7000         |\n|    total_timesteps              | 5996000      |\n| train/                          |              |\n|    approx_kl                    | 0.0041155554 |\n|    clip_fraction                | 0.0291       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.957       |\n|    explained_variance           | 0.853        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 213          |\n|    n_updates                    | 2996         |\n|    policy_gradient_loss         | -0.00121     |\n|    value_loss                   | 421          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.59e+03     |\n|    water_produced               | 336          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 306          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1500         |\n|    time_elapsed                 | 7005         |\n|    total_timesteps              | 6000000      |\n| train/                          |              |\n|    approx_kl                    | 0.0048851063 |\n|    clip_fraction                | 0.023        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.822       |\n|    explained_variance           | 0.445        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 263          |\n|    n_updates                    | 2998         |\n|    policy_gradient_loss         | 0.00214      |\n|    value_loss                   | 552          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.52e+03     |\n|    water_produced               | 350          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 298         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1501        |\n|    time_elapsed                 | 7009        |\n|    total_timesteps              | 6004000     |\n| train/                          |             |\n|    approx_kl                    | 0.006276534 |\n|    clip_fraction                | 0.035       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.79       |\n|    explained_variance           | 0.63        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 193         |\n|    n_updates                    | 3000        |\n|    policy_gradient_loss         | 0.00499     |\n|    value_loss                   | 373         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.2e+03     |\n|    water_produced               | 254         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 287          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1502         |\n|    time_elapsed                 | 7014         |\n|    total_timesteps              | 6008000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019225419 |\n|    clip_fraction                | 0.007        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.868       |\n|    explained_variance           | 0.573        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 244          |\n|    n_updates                    | 3002         |\n|    policy_gradient_loss         | 0.000112     |\n|    value_loss                   | 453          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.08e+03     |\n|    water_produced               | 224          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 292          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1503         |\n|    time_elapsed                 | 7018         |\n|    total_timesteps              | 6012000      |\n| train/                          |              |\n|    approx_kl                    | 0.0078736525 |\n|    clip_fraction                | 0.0508       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.933       |\n|    explained_variance           | 0.53         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 3004         |\n|    policy_gradient_loss         | -0.000202    |\n|    value_loss                   | 473          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.07e+03     |\n|    water_produced               | 233          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 272          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1504         |\n|    time_elapsed                 | 7022         |\n|    total_timesteps              | 6016000      |\n| train/                          |              |\n|    approx_kl                    | 0.0074783145 |\n|    clip_fraction                | 0.0496       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.927       |\n|    explained_variance           | 0.61         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 3006         |\n|    policy_gradient_loss         | -0.00167     |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.1e+03      |\n|    water_produced               | 240          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 261         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1505        |\n|    time_elapsed                 | 7027        |\n|    total_timesteps              | 6020000     |\n| train/                          |             |\n|    approx_kl                    | 0.003733533 |\n|    clip_fraction                | 0.0177      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.963      |\n|    explained_variance           | 0.675       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 237         |\n|    n_updates                    | 3008        |\n|    policy_gradient_loss         | -0.0023     |\n|    value_loss                   | 503         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.26e+03    |\n|    water_produced               | 298         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 265         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1506        |\n|    time_elapsed                 | 7031        |\n|    total_timesteps              | 6024000     |\n| train/                          |             |\n|    approx_kl                    | 0.003264622 |\n|    clip_fraction                | 0.01        |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.879      |\n|    explained_variance           | 0.706       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 256         |\n|    n_updates                    | 3010        |\n|    policy_gradient_loss         | 0.00194     |\n|    value_loss                   | 516         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.23e+03    |\n|    water_produced               | 276         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 280         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1507        |\n|    time_elapsed                 | 7035        |\n|    total_timesteps              | 6028000     |\n| train/                          |             |\n|    approx_kl                    | 0.001877921 |\n|    clip_fraction                | 0.00788     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.857      |\n|    explained_variance           | 0.643       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 257         |\n|    n_updates                    | 3012        |\n|    policy_gradient_loss         | -0.000381   |\n|    value_loss                   | 519         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.27e+03    |\n|    water_produced               | 296         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 304           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1508          |\n|    time_elapsed                 | 7040          |\n|    total_timesteps              | 6032000       |\n| train/                          |               |\n|    approx_kl                    | 0.00067333924 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.841        |\n|    explained_variance           | 0.752         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 296           |\n|    n_updates                    | 3014          |\n|    policy_gradient_loss         | 0.000608      |\n|    value_loss                   | 589           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 158           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 1.55e+03      |\n|    water_produced               | 344           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 298          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1509         |\n|    time_elapsed                 | 7044         |\n|    total_timesteps              | 6036000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030171433 |\n|    clip_fraction                | 0.0149       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.781       |\n|    explained_variance           | 0.59         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 248          |\n|    n_updates                    | 3016         |\n|    policy_gradient_loss         | 0.00223      |\n|    value_loss                   | 565          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.03e+03     |\n|    water_produced               | 211          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 298          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1510         |\n|    time_elapsed                 | 7048         |\n|    total_timesteps              | 6040000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005983143 |\n|    clip_fraction                | 0.0025       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.878       |\n|    explained_variance           | 0.61         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 305          |\n|    n_updates                    | 3018         |\n|    policy_gradient_loss         | -9.76e-05    |\n|    value_loss                   | 612          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.36e+03     |\n|    water_produced               | 298          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 313          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1511         |\n|    time_elapsed                 | 7053         |\n|    total_timesteps              | 6044000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010289608 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.846       |\n|    explained_variance           | 0.674        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 264          |\n|    n_updates                    | 3020         |\n|    policy_gradient_loss         | -0.00158     |\n|    value_loss                   | 575          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.54e+03     |\n|    water_produced               | 351          |\n--------------------------------------------------\nEval num_timesteps=6048000, episode_reward=1968.08 +/- 302.22\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 1.97e+03     |\n| time/                           |              |\n|    total_timesteps              | 6048000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027510435 |\n|    clip_fraction                | 0.0185       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.787       |\n|    explained_variance           | 0.629        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 235          |\n|    n_updates                    | 3022         |\n|    policy_gradient_loss         | 0.00406      |\n|    value_loss                   | 513          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.17e+03     |\n|    water_produced               | 234          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 301      |\n| time/              |          |\n|    fps             | 856      |\n|    iterations      | 1512     |\n|    time_elapsed    | 7065     |\n|    total_timesteps | 6048000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 261          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1513         |\n|    time_elapsed                 | 7069         |\n|    total_timesteps              | 6052000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037845112 |\n|    clip_fraction                | 0.0184       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.889       |\n|    explained_variance           | 0.609        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 252          |\n|    n_updates                    | 3024         |\n|    policy_gradient_loss         | -0.00115     |\n|    value_loss                   | 521          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 750          |\n|    water_produced               | 152          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 284        |\n| time/                           |            |\n|    fps                          | 856        |\n|    iterations                   | 1514       |\n|    time_elapsed                 | 7073       |\n|    total_timesteps              | 6056000    |\n| train/                          |            |\n|    approx_kl                    | 0.02534542 |\n|    clip_fraction                | 0.15       |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.04      |\n|    explained_variance           | 0.645      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 230        |\n|    n_updates                    | 3026       |\n|    policy_gradient_loss         | 0.00758    |\n|    value_loss                   | 483        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 176        |\n|    action_queue_updates_total   | 177        |\n|    ice_dug                      | 1.65e+03   |\n|    water_produced               | 323        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 283          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1515         |\n|    time_elapsed                 | 7078         |\n|    total_timesteps              | 6060000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008501735 |\n|    clip_fraction                | 0.00288      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.895       |\n|    explained_variance           | 0.381        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 287          |\n|    n_updates                    | 3028         |\n|    policy_gradient_loss         | -0.00105     |\n|    value_loss                   | 620          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.29e+03     |\n|    water_produced               | 289          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 261          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1516         |\n|    time_elapsed                 | 7082         |\n|    total_timesteps              | 6064000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032142946 |\n|    clip_fraction                | 0.0187       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.926       |\n|    explained_variance           | 0.723        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 255          |\n|    n_updates                    | 3030         |\n|    policy_gradient_loss         | 0.00226      |\n|    value_loss                   | 504          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.1e+03      |\n|    water_produced               | 246          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 283          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1517         |\n|    time_elapsed                 | 7087         |\n|    total_timesteps              | 6068000      |\n| train/                          |              |\n|    approx_kl                    | 0.0043731863 |\n|    clip_fraction                | 0.0265       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.934       |\n|    explained_variance           | 0.735        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 3032         |\n|    policy_gradient_loss         | 0.000408     |\n|    value_loss                   | 457          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.48e+03     |\n|    water_produced               | 341          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 323          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1518         |\n|    time_elapsed                 | 7091         |\n|    total_timesteps              | 6072000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025917564 |\n|    clip_fraction                | 0.011        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.828       |\n|    explained_variance           | 0.615        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 234          |\n|    n_updates                    | 3034         |\n|    policy_gradient_loss         | 0.000243     |\n|    value_loss                   | 505          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.6e+03      |\n|    water_produced               | 346          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 282         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1519        |\n|    time_elapsed                 | 7095        |\n|    total_timesteps              | 6076000     |\n| train/                          |             |\n|    approx_kl                    | 0.009251693 |\n|    clip_fraction                | 0.0543      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.792      |\n|    explained_variance           | 0.703       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 243         |\n|    n_updates                    | 3036        |\n|    policy_gradient_loss         | 0.00647     |\n|    value_loss                   | 498         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 574         |\n|    water_produced               | 125         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 269         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1520        |\n|    time_elapsed                 | 7100        |\n|    total_timesteps              | 6080000     |\n| train/                          |             |\n|    approx_kl                    | 0.002379307 |\n|    clip_fraction                | 0.0125      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.931      |\n|    explained_variance           | 0.692       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 185         |\n|    n_updates                    | 3038        |\n|    policy_gradient_loss         | -0.000367   |\n|    value_loss                   | 491         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 979         |\n|    water_produced               | 229         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 287         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1521        |\n|    time_elapsed                 | 7104        |\n|    total_timesteps              | 6084000     |\n| train/                          |             |\n|    approx_kl                    | 0.017774511 |\n|    clip_fraction                | 0.0816      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.9        |\n|    explained_variance           | 0.647       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 176         |\n|    n_updates                    | 3040        |\n|    policy_gradient_loss         | 0.000471    |\n|    value_loss                   | 394         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.39e+03    |\n|    water_produced               | 331         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 275          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1522         |\n|    time_elapsed                 | 7109         |\n|    total_timesteps              | 6088000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021776329 |\n|    clip_fraction                | 0.00513      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.872       |\n|    explained_variance           | 0.74         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 3042         |\n|    policy_gradient_loss         | 0.00018      |\n|    value_loss                   | 548          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.2e+03      |\n|    water_produced               | 285          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 256          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1523         |\n|    time_elapsed                 | 7113         |\n|    total_timesteps              | 6092000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023268647 |\n|    clip_fraction                | 0.012        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.901       |\n|    explained_variance           | 0.732        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 229          |\n|    n_updates                    | 3044         |\n|    policy_gradient_loss         | 0.000295     |\n|    value_loss                   | 507          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 1.11e+03     |\n|    water_produced               | 258          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 309          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1524         |\n|    time_elapsed                 | 7117         |\n|    total_timesteps              | 6096000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016342048 |\n|    clip_fraction                | 0.0085       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.884       |\n|    explained_variance           | 0.651        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 270          |\n|    n_updates                    | 3046         |\n|    policy_gradient_loss         | -0.00157     |\n|    value_loss                   | 499          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.65e+03     |\n|    water_produced               | 377          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 313         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1525        |\n|    time_elapsed                 | 7122        |\n|    total_timesteps              | 6100000     |\n| train/                          |             |\n|    approx_kl                    | 0.005353457 |\n|    clip_fraction                | 0.0279      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.764      |\n|    explained_variance           | 0.5         |\n|    learning_rate                | 0.0003      |\n|    loss                         | 264         |\n|    n_updates                    | 3048        |\n|    policy_gradient_loss         | 0.00342     |\n|    value_loss                   | 579         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 1.04e+03    |\n|    water_produced               | 252         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 308          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1526         |\n|    time_elapsed                 | 7126         |\n|    total_timesteps              | 6104000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007323545 |\n|    clip_fraction                | 0.00125      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.79        |\n|    explained_variance           | 0.673        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 270          |\n|    n_updates                    | 3050         |\n|    policy_gradient_loss         | 0.000876     |\n|    value_loss                   | 560          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 302          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 283           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1527          |\n|    time_elapsed                 | 7130          |\n|    total_timesteps              | 6108000       |\n| train/                          |               |\n|    approx_kl                    | 0.00091828825 |\n|    clip_fraction                | 0.00312       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.758        |\n|    explained_variance           | 0.58          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 237           |\n|    n_updates                    | 3052          |\n|    policy_gradient_loss         | 0.000147      |\n|    value_loss                   | 470           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 146           |\n|    action_queue_updates_total   | 149           |\n|    ice_dug                      | 851           |\n|    water_produced               | 166           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 284         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1528        |\n|    time_elapsed                 | 7135        |\n|    total_timesteps              | 6112000     |\n| train/                          |             |\n|    approx_kl                    | 0.002818313 |\n|    clip_fraction                | 0.0149      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.759      |\n|    explained_variance           | 0.591       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 223         |\n|    n_updates                    | 3054        |\n|    policy_gradient_loss         | -0.00118    |\n|    value_loss                   | 505         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 1.28e+03    |\n|    water_produced               | 260         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 277          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1529         |\n|    time_elapsed                 | 7139         |\n|    total_timesteps              | 6116000      |\n| train/                          |              |\n|    approx_kl                    | 0.0046028406 |\n|    clip_fraction                | 0.0291       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.792       |\n|    explained_variance           | 0.52         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 310          |\n|    n_updates                    | 3056         |\n|    policy_gradient_loss         | -0.000646    |\n|    value_loss                   | 577          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 152          |\n|    ice_dug                      | 1.49e+03     |\n|    water_produced               | 344          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 270          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1530         |\n|    time_elapsed                 | 7144         |\n|    total_timesteps              | 6120000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023824845 |\n|    clip_fraction                | 0.0154       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.759       |\n|    explained_variance           | 0.671        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 224          |\n|    n_updates                    | 3058         |\n|    policy_gradient_loss         | 0.00225      |\n|    value_loss                   | 507          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 145          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 947          |\n|    water_produced               | 216          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 262          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1531         |\n|    time_elapsed                 | 7148         |\n|    total_timesteps              | 6124000      |\n| train/                          |              |\n|    approx_kl                    | 0.0062953383 |\n|    clip_fraction                | 0.0285       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.88        |\n|    explained_variance           | 0.67         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 3060         |\n|    policy_gradient_loss         | -0.000871    |\n|    value_loss                   | 465          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.18e+03     |\n|    water_produced               | 267          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 306         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1532        |\n|    time_elapsed                 | 7152        |\n|    total_timesteps              | 6128000     |\n| train/                          |             |\n|    approx_kl                    | 0.011536342 |\n|    clip_fraction                | 0.0709      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.899      |\n|    explained_variance           | 0.579       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 222         |\n|    n_updates                    | 3062        |\n|    policy_gradient_loss         | -0.000787   |\n|    value_loss                   | 495         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.8e+03     |\n|    water_produced               | 377         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 320          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1533         |\n|    time_elapsed                 | 7157         |\n|    total_timesteps              | 6132000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032287594 |\n|    clip_fraction                | 0.014        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.847       |\n|    explained_variance           | 0.425        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 268          |\n|    n_updates                    | 3064         |\n|    policy_gradient_loss         | 0.00142      |\n|    value_loss                   | 590          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.55e+03     |\n|    water_produced               | 329          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 319          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1534         |\n|    time_elapsed                 | 7161         |\n|    total_timesteps              | 6136000      |\n| train/                          |              |\n|    approx_kl                    | 0.0054239244 |\n|    clip_fraction                | 0.0345       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.826       |\n|    explained_variance           | 0.524        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 279          |\n|    n_updates                    | 3066         |\n|    policy_gradient_loss         | 0.00413      |\n|    value_loss                   | 513          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.44e+03     |\n|    water_produced               | 338          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 331          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1535         |\n|    time_elapsed                 | 7165         |\n|    total_timesteps              | 6140000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011535004 |\n|    clip_fraction                | 0.00288      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.844       |\n|    explained_variance           | 0.652        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 3068         |\n|    policy_gradient_loss         | 0.00125      |\n|    value_loss                   | 325          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.23e+03     |\n|    water_produced               | 274          |\n--------------------------------------------------\nEval num_timesteps=6144000, episode_reward=1186.56 +/- 970.26\nEpisode length: 720.40 +/- 342.44\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 720         |\n|    mean_reward                  | 1.19e+03    |\n| time/                           |             |\n|    total_timesteps              | 6144000     |\n| train/                          |             |\n|    approx_kl                    | 0.008305174 |\n|    clip_fraction                | 0.0302      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.881      |\n|    explained_variance           | 0.581       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 176         |\n|    n_updates                    | 3070        |\n|    policy_gradient_loss         | -0.00179    |\n|    value_loss                   | 371         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 1.27e+03    |\n|    water_produced               | 267         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 332      |\n| time/              |          |\n|    fps             | 856      |\n|    iterations      | 1536     |\n|    time_elapsed    | 7175     |\n|    total_timesteps | 6144000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 308          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1537         |\n|    time_elapsed                 | 7179         |\n|    total_timesteps              | 6148000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036762885 |\n|    clip_fraction                | 0.0252       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.876       |\n|    explained_variance           | 0.524        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 241          |\n|    n_updates                    | 3072         |\n|    policy_gradient_loss         | -0.00154     |\n|    value_loss                   | 525          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.27e+03     |\n|    water_produced               | 265          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 312         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1538        |\n|    time_elapsed                 | 7184        |\n|    total_timesteps              | 6152000     |\n| train/                          |             |\n|    approx_kl                    | 0.004815765 |\n|    clip_fraction                | 0.0294      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.912      |\n|    explained_variance           | 0.627       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 262         |\n|    n_updates                    | 3074        |\n|    policy_gradient_loss         | -0.00164    |\n|    value_loss                   | 544         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.55e+03    |\n|    water_produced               | 350         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 311          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1539         |\n|    time_elapsed                 | 7188         |\n|    total_timesteps              | 6156000      |\n| train/                          |              |\n|    approx_kl                    | 0.0051384666 |\n|    clip_fraction                | 0.0221       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.819       |\n|    explained_variance           | 0.499        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 309          |\n|    n_updates                    | 3076         |\n|    policy_gradient_loss         | 0.00262      |\n|    value_loss                   | 612          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.4e+03      |\n|    water_produced               | 331          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 321         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1540        |\n|    time_elapsed                 | 7193        |\n|    total_timesteps              | 6160000     |\n| train/                          |             |\n|    approx_kl                    | 0.005276837 |\n|    clip_fraction                | 0.0276      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.792      |\n|    explained_variance           | 0.618       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 225         |\n|    n_updates                    | 3078        |\n|    policy_gradient_loss         | 0.00138     |\n|    value_loss                   | 472         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 1.39e+03    |\n|    water_produced               | 322         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 329           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1541          |\n|    time_elapsed                 | 7197          |\n|    total_timesteps              | 6164000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035912328 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.76         |\n|    explained_variance           | 0.57          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 254           |\n|    n_updates                    | 3080          |\n|    policy_gradient_loss         | 0.000613      |\n|    value_loss                   | 478           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 1.32e+03      |\n|    water_produced               | 308           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 345         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1542        |\n|    time_elapsed                 | 7202        |\n|    total_timesteps              | 6168000     |\n| train/                          |             |\n|    approx_kl                    | 0.007139197 |\n|    clip_fraction                | 0.0339      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.843      |\n|    explained_variance           | 0.707       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 205         |\n|    n_updates                    | 3082        |\n|    policy_gradient_loss         | -0.00484    |\n|    value_loss                   | 459         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.57e+03    |\n|    water_produced               | 343         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 314          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1543         |\n|    time_elapsed                 | 7206         |\n|    total_timesteps              | 6172000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013184345 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.852       |\n|    explained_variance           | 0.528        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 228          |\n|    n_updates                    | 3084         |\n|    policy_gradient_loss         | 0.000691     |\n|    value_loss                   | 478          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 966          |\n|    water_produced               | 199          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 318           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1544          |\n|    time_elapsed                 | 7211          |\n|    total_timesteps              | 6176000       |\n| train/                          |               |\n|    approx_kl                    | 0.00021298253 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.922        |\n|    explained_variance           | 0.636         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 230           |\n|    n_updates                    | 3086          |\n|    policy_gradient_loss         | 0.000208      |\n|    value_loss                   | 517           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 166           |\n|    action_queue_updates_total   | 170           |\n|    ice_dug                      | 1.5e+03       |\n|    water_produced               | 351           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 319           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1545          |\n|    time_elapsed                 | 7215          |\n|    total_timesteps              | 6180000       |\n| train/                          |               |\n|    approx_kl                    | 0.00041025685 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.866        |\n|    explained_variance           | 0.6           |\n|    learning_rate                | 0.0003        |\n|    loss                         | 209           |\n|    n_updates                    | 3088          |\n|    policy_gradient_loss         | -0.00043      |\n|    value_loss                   | 452           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 164           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 1.48e+03      |\n|    water_produced               | 328           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 307         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1546        |\n|    time_elapsed                 | 7219        |\n|    total_timesteps              | 6184000     |\n| train/                          |             |\n|    approx_kl                    | 0.003874553 |\n|    clip_fraction                | 0.0259      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.836      |\n|    explained_variance           | 0.548       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 218         |\n|    n_updates                    | 3090        |\n|    policy_gradient_loss         | 0.005       |\n|    value_loss                   | 472         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.21e+03    |\n|    water_produced               | 249         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 286          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1547         |\n|    time_elapsed                 | 7224         |\n|    total_timesteps              | 6188000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021392028 |\n|    clip_fraction                | 0.0126       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.891       |\n|    explained_variance           | 0.509        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 247          |\n|    n_updates                    | 3092         |\n|    policy_gradient_loss         | -0.000829    |\n|    value_loss                   | 526          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.04e+03     |\n|    water_produced               | 241          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 318         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1548        |\n|    time_elapsed                 | 7228        |\n|    total_timesteps              | 6192000     |\n| train/                          |             |\n|    approx_kl                    | 0.005350049 |\n|    clip_fraction                | 0.0336      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.943      |\n|    explained_variance           | 0.643       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 195         |\n|    n_updates                    | 3094        |\n|    policy_gradient_loss         | 0.000338    |\n|    value_loss                   | 425         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.56e+03    |\n|    water_produced               | 355         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 302           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1549          |\n|    time_elapsed                 | 7233          |\n|    total_timesteps              | 6196000       |\n| train/                          |               |\n|    approx_kl                    | 0.00079160725 |\n|    clip_fraction                | 0.0015        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.865        |\n|    explained_variance           | 0.474         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 181           |\n|    n_updates                    | 3096          |\n|    policy_gradient_loss         | -0.000434     |\n|    value_loss                   | 383           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 164           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 1.19e+03      |\n|    water_produced               | 272           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 299          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1550         |\n|    time_elapsed                 | 7238         |\n|    total_timesteps              | 6200000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011608151 |\n|    clip_fraction                | 0.00462      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.875       |\n|    explained_variance           | 0.587        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 3098         |\n|    policy_gradient_loss         | 0.000706     |\n|    value_loss                   | 417          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.45e+03     |\n|    water_produced               | 311          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 306          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1551         |\n|    time_elapsed                 | 7242         |\n|    total_timesteps              | 6204000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017260276 |\n|    clip_fraction                | 0.005        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.824       |\n|    explained_variance           | 0.602        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 3100         |\n|    policy_gradient_loss         | -0.00195     |\n|    value_loss                   | 382          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.5e+03      |\n|    water_produced               | 282          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 320          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1552         |\n|    time_elapsed                 | 7246         |\n|    total_timesteps              | 6208000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004687871 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.802       |\n|    explained_variance           | 0.611        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 3102         |\n|    policy_gradient_loss         | 0.00154      |\n|    value_loss                   | 481          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.36e+03     |\n|    water_produced               | 309          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 306         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1553        |\n|    time_elapsed                 | 7251        |\n|    total_timesteps              | 6212000     |\n| train/                          |             |\n|    approx_kl                    | 0.005989606 |\n|    clip_fraction                | 0.0411      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.876      |\n|    explained_variance           | 0.695       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 199         |\n|    n_updates                    | 3104        |\n|    policy_gradient_loss         | -0.00242    |\n|    value_loss                   | 432         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.26e+03    |\n|    water_produced               | 289         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 315        |\n| time/                           |            |\n|    fps                          | 856        |\n|    iterations                   | 1554       |\n|    time_elapsed                 | 7255       |\n|    total_timesteps              | 6216000    |\n| train/                          |            |\n|    approx_kl                    | 0.00077932 |\n|    clip_fraction                | 0.00275    |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.877     |\n|    explained_variance           | 0.67       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 220        |\n|    n_updates                    | 3106       |\n|    policy_gradient_loss         | -0.000342  |\n|    value_loss                   | 432        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 162        |\n|    action_queue_updates_total   | 167        |\n|    ice_dug                      | 1.41e+03   |\n|    water_produced               | 312        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 320          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1555         |\n|    time_elapsed                 | 7259         |\n|    total_timesteps              | 6220000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014520499 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.865       |\n|    explained_variance           | 0.642        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 212          |\n|    n_updates                    | 3108         |\n|    policy_gradient_loss         | 0.000353     |\n|    value_loss                   | 453          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 339          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 330          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1556         |\n|    time_elapsed                 | 7264         |\n|    total_timesteps              | 6224000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006256222 |\n|    clip_fraction                | 0.000875     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.8         |\n|    explained_variance           | 0.567        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 3110         |\n|    policy_gradient_loss         | 0.00213      |\n|    value_loss                   | 451          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.44e+03     |\n|    water_produced               | 332          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 332          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1557         |\n|    time_elapsed                 | 7268         |\n|    total_timesteps              | 6228000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022018503 |\n|    clip_fraction                | 0.0145       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.824       |\n|    explained_variance           | 0.617        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 3112         |\n|    policy_gradient_loss         | 0.00158      |\n|    value_loss                   | 455          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.36e+03     |\n|    water_produced               | 318          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 340         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1558        |\n|    time_elapsed                 | 7273        |\n|    total_timesteps              | 6232000     |\n| train/                          |             |\n|    approx_kl                    | 0.003573265 |\n|    clip_fraction                | 0.015       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.873      |\n|    explained_variance           | 0.555       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 193         |\n|    n_updates                    | 3114        |\n|    policy_gradient_loss         | -0.0015     |\n|    value_loss                   | 422         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.44e+03    |\n|    water_produced               | 328         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 319          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1559         |\n|    time_elapsed                 | 7277         |\n|    total_timesteps              | 6236000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012093403 |\n|    clip_fraction                | 0.00462      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.896       |\n|    explained_variance           | 0.656        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 178          |\n|    n_updates                    | 3116         |\n|    policy_gradient_loss         | -0.00036     |\n|    value_loss                   | 355          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.02e+03     |\n|    water_produced               | 212          |\n--------------------------------------------------\nEval num_timesteps=6240000, episode_reward=1333.92 +/- 1014.45\nEpisode length: 793.40 +/- 278.11\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 793          |\n|    mean_reward                  | 1.33e+03     |\n| time/                           |              |\n|    total_timesteps              | 6240000      |\n| train/                          |              |\n|    approx_kl                    | 0.0053451117 |\n|    clip_fraction                | 0.0254       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.938       |\n|    explained_variance           | 0.619        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 251          |\n|    n_updates                    | 3118         |\n|    policy_gradient_loss         | 7.78e-05     |\n|    value_loss                   | 517          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.19e+03     |\n|    water_produced               | 239          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 299      |\n| time/              |          |\n|    fps             | 856      |\n|    iterations      | 1560     |\n|    time_elapsed    | 7289     |\n|    total_timesteps | 6240000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 294         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1561        |\n|    time_elapsed                 | 7293        |\n|    total_timesteps              | 6244000     |\n| train/                          |             |\n|    approx_kl                    | 0.009448283 |\n|    clip_fraction                | 0.0591      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.927      |\n|    explained_variance           | 0.613       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 221         |\n|    n_updates                    | 3120        |\n|    policy_gradient_loss         | 0.00146     |\n|    value_loss                   | 473         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.44e+03    |\n|    water_produced               | 309         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 305          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1562         |\n|    time_elapsed                 | 7298         |\n|    total_timesteps              | 6248000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032806545 |\n|    clip_fraction                | 0.0221       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.887       |\n|    explained_variance           | 0.475        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 3122         |\n|    policy_gradient_loss         | 0.00024      |\n|    value_loss                   | 541          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.59e+03     |\n|    water_produced               | 370          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 279          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1563         |\n|    time_elapsed                 | 7302         |\n|    total_timesteps              | 6252000      |\n| train/                          |              |\n|    approx_kl                    | 0.0070988936 |\n|    clip_fraction                | 0.0356       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.838       |\n|    explained_variance           | 0.612        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 3124         |\n|    policy_gradient_loss         | 0.00343      |\n|    value_loss                   | 469          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 913          |\n|    water_produced               | 203          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 296          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1564         |\n|    time_elapsed                 | 7306         |\n|    total_timesteps              | 6256000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015177128 |\n|    clip_fraction                | 0.00863      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.9         |\n|    explained_variance           | 0.671        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 227          |\n|    n_updates                    | 3126         |\n|    policy_gradient_loss         | -0.000557    |\n|    value_loss                   | 486          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.34e+03     |\n|    water_produced               | 292          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 311           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1565          |\n|    time_elapsed                 | 7311          |\n|    total_timesteps              | 6260000       |\n| train/                          |               |\n|    approx_kl                    | 0.00028081052 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.825        |\n|    explained_variance           | 0.47          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 227           |\n|    n_updates                    | 3128          |\n|    policy_gradient_loss         | -0.000609     |\n|    value_loss                   | 466           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 156           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 1.4e+03       |\n|    water_produced               | 315           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 314          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1566         |\n|    time_elapsed                 | 7315         |\n|    total_timesteps              | 6264000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026245061 |\n|    clip_fraction                | 0.0117       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.816       |\n|    explained_variance           | 0.614        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 3130         |\n|    policy_gradient_loss         | 0.00162      |\n|    value_loss                   | 441          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 324          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 293          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1567         |\n|    time_elapsed                 | 7320         |\n|    total_timesteps              | 6268000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021392927 |\n|    clip_fraction                | 0.008        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.782       |\n|    explained_variance           | 0.55         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 3132         |\n|    policy_gradient_loss         | 0.000988     |\n|    value_loss                   | 404          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.15e+03     |\n|    water_produced               | 268          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 315          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1568         |\n|    time_elapsed                 | 7324         |\n|    total_timesteps              | 6272000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017624861 |\n|    clip_fraction                | 0.0065       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.836       |\n|    explained_variance           | 0.685        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 3134         |\n|    policy_gradient_loss         | -0.000243    |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 310          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 323           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1569          |\n|    time_elapsed                 | 7329          |\n|    total_timesteps              | 6276000       |\n| train/                          |               |\n|    approx_kl                    | 0.00044656807 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.837        |\n|    explained_variance           | 0.595         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 243           |\n|    n_updates                    | 3136          |\n|    policy_gradient_loss         | -0.00128      |\n|    value_loss                   | 493           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 160           |\n|    action_queue_updates_total   | 164           |\n|    ice_dug                      | 1.54e+03      |\n|    water_produced               | 326           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 296          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1570         |\n|    time_elapsed                 | 7334         |\n|    total_timesteps              | 6280000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022460825 |\n|    clip_fraction                | 0.0155       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.811       |\n|    explained_variance           | 0.582        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 210          |\n|    n_updates                    | 3138         |\n|    policy_gradient_loss         | 0.0036       |\n|    value_loss                   | 405          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.03e+03     |\n|    water_produced               | 187          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 295         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1571        |\n|    time_elapsed                 | 7338        |\n|    total_timesteps              | 6284000     |\n| train/                          |             |\n|    approx_kl                    | 0.005729138 |\n|    clip_fraction                | 0.035       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.876      |\n|    explained_variance           | 0.674       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 194         |\n|    n_updates                    | 3140        |\n|    policy_gradient_loss         | -9.53e-05   |\n|    value_loss                   | 435         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.38e+03    |\n|    water_produced               | 320         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 298          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1572         |\n|    time_elapsed                 | 7342         |\n|    total_timesteps              | 6288000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013157928 |\n|    clip_fraction                | 0.0102       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.892       |\n|    explained_variance           | 0.643        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 180          |\n|    n_updates                    | 3142         |\n|    policy_gradient_loss         | -0.00107     |\n|    value_loss                   | 390          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 280          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 297           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1573          |\n|    time_elapsed                 | 7347          |\n|    total_timesteps              | 6292000       |\n| train/                          |               |\n|    approx_kl                    | 0.00083869265 |\n|    clip_fraction                | 0.00337       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.902        |\n|    explained_variance           | 0.654         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 220           |\n|    n_updates                    | 3144          |\n|    policy_gradient_loss         | -0.000787     |\n|    value_loss                   | 466           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 167           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 1.42e+03      |\n|    water_produced               | 307           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 300          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1574         |\n|    time_elapsed                 | 7351         |\n|    total_timesteps              | 6296000      |\n| train/                          |              |\n|    approx_kl                    | 0.0060895868 |\n|    clip_fraction                | 0.0347       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.871       |\n|    explained_variance           | 0.676        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 246          |\n|    n_updates                    | 3146         |\n|    policy_gradient_loss         | -0.000737    |\n|    value_loss                   | 455          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.5e+03      |\n|    water_produced               | 343          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 338          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1575         |\n|    time_elapsed                 | 7355         |\n|    total_timesteps              | 6300000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026182663 |\n|    clip_fraction                | 0.00938      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.83        |\n|    explained_variance           | 0.7          |\n|    learning_rate                | 0.0003       |\n|    loss                         | 286          |\n|    n_updates                    | 3148         |\n|    policy_gradient_loss         | 0.00156      |\n|    value_loss                   | 543          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.77e+03     |\n|    water_produced               | 369          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 346          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1576         |\n|    time_elapsed                 | 7360         |\n|    total_timesteps              | 6304000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033403758 |\n|    clip_fraction                | 0.0174       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.756       |\n|    explained_variance           | 0.476        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 248          |\n|    n_updates                    | 3150         |\n|    policy_gradient_loss         | 0.00192      |\n|    value_loss                   | 511          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.57e+03     |\n|    water_produced               | 356          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 346         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1577        |\n|    time_elapsed                 | 7365        |\n|    total_timesteps              | 6308000     |\n| train/                          |             |\n|    approx_kl                    | 0.008456593 |\n|    clip_fraction                | 0.0415      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.76       |\n|    explained_variance           | 0.631       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 216         |\n|    n_updates                    | 3152        |\n|    policy_gradient_loss         | 0.00654     |\n|    value_loss                   | 456         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 151         |\n|    ice_dug                      | 1.33e+03    |\n|    water_produced               | 279         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 346         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1578        |\n|    time_elapsed                 | 7369        |\n|    total_timesteps              | 6312000     |\n| train/                          |             |\n|    approx_kl                    | 0.004352647 |\n|    clip_fraction                | 0.031       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.779      |\n|    explained_variance           | 0.555       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 222         |\n|    n_updates                    | 3154        |\n|    policy_gradient_loss         | -0.00225    |\n|    value_loss                   | 413         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.49e+03    |\n|    water_produced               | 307         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 347          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1579         |\n|    time_elapsed                 | 7373         |\n|    total_timesteps              | 6316000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035271153 |\n|    clip_fraction                | 0.0216       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.844       |\n|    explained_variance           | 0.553        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 224          |\n|    n_updates                    | 3156         |\n|    policy_gradient_loss         | -0.00198     |\n|    value_loss                   | 458          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.57e+03     |\n|    water_produced               | 348          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 312          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1580         |\n|    time_elapsed                 | 7378         |\n|    total_timesteps              | 6320000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031542536 |\n|    clip_fraction                | 0.017        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.878       |\n|    explained_variance           | 0.605        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 186          |\n|    n_updates                    | 3158         |\n|    policy_gradient_loss         | 0.00192      |\n|    value_loss                   | 394          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 896          |\n|    water_produced               | 203          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 275          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1581         |\n|    time_elapsed                 | 7382         |\n|    total_timesteps              | 6324000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021034125 |\n|    clip_fraction                | 0.011        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.926       |\n|    explained_variance           | 0.654        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 192          |\n|    n_updates                    | 3160         |\n|    policy_gradient_loss         | -0.000873    |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 873          |\n|    water_produced               | 177          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 279         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1582        |\n|    time_elapsed                 | 7387        |\n|    total_timesteps              | 6328000     |\n| train/                          |             |\n|    approx_kl                    | 0.017962033 |\n|    clip_fraction                | 0.0824      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.983      |\n|    explained_variance           | 0.631       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 194         |\n|    n_updates                    | 3162        |\n|    policy_gradient_loss         | 0.00172     |\n|    value_loss                   | 424         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.38e+03    |\n|    water_produced               | 297         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 292          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1583         |\n|    time_elapsed                 | 7391         |\n|    total_timesteps              | 6332000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005906698 |\n|    clip_fraction                | 0.00125      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.939       |\n|    explained_variance           | 0.546        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 233          |\n|    n_updates                    | 3164         |\n|    policy_gradient_loss         | -0.00214     |\n|    value_loss                   | 470          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.66e+03     |\n|    water_produced               | 369          |\n--------------------------------------------------\nEval num_timesteps=6336000, episode_reward=1495.64 +/- 794.42\nEpisode length: 860.20 +/- 279.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 860          |\n|    mean_reward                  | 1.5e+03      |\n| time/                           |              |\n|    total_timesteps              | 6336000      |\n| train/                          |              |\n|    approx_kl                    | 0.0069238283 |\n|    clip_fraction                | 0.0397       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.876       |\n|    explained_variance           | 0.509        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 3166         |\n|    policy_gradient_loss         | 0.00362      |\n|    value_loss                   | 426          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.57e+03     |\n|    water_produced               | 343          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 291      |\n| time/              |          |\n|    fps             | 856      |\n|    iterations      | 1584     |\n|    time_elapsed    | 7401     |\n|    total_timesteps | 6336000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 308          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1585         |\n|    time_elapsed                 | 7406         |\n|    total_timesteps              | 6340000      |\n| train/                          |              |\n|    approx_kl                    | 0.0048372773 |\n|    clip_fraction                | 0.0262       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.835       |\n|    explained_variance           | 0.518        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 3168         |\n|    policy_gradient_loss         | 0.00464      |\n|    value_loss                   | 376          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.3e+03      |\n|    water_produced               | 285          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 336          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1586         |\n|    time_elapsed                 | 7410         |\n|    total_timesteps              | 6344000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038467508 |\n|    clip_fraction                | 0.0165       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.907       |\n|    explained_variance           | 0.627        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 3170         |\n|    policy_gradient_loss         | -0.00305     |\n|    value_loss                   | 400          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.4e+03      |\n|    water_produced               | 310          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 346          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1587         |\n|    time_elapsed                 | 7414         |\n|    total_timesteps              | 6348000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012277435 |\n|    clip_fraction                | 0.00575      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.931       |\n|    explained_variance           | 0.57         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 189          |\n|    n_updates                    | 3172         |\n|    policy_gradient_loss         | -0.0013      |\n|    value_loss                   | 384          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.5e+03      |\n|    water_produced               | 350          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 322        |\n| time/                           |            |\n|    fps                          | 856        |\n|    iterations                   | 1588       |\n|    time_elapsed                 | 7419       |\n|    total_timesteps              | 6352000    |\n| train/                          |            |\n|    approx_kl                    | 0.00435258 |\n|    clip_fraction                | 0.0165     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.877     |\n|    explained_variance           | 0.602      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 177        |\n|    n_updates                    | 3174       |\n|    policy_gradient_loss         | 0.00226    |\n|    value_loss                   | 363        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 166        |\n|    action_queue_updates_total   | 168        |\n|    ice_dug                      | 1.26e+03   |\n|    water_produced               | 250        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 315         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1589        |\n|    time_elapsed                 | 7423        |\n|    total_timesteps              | 6356000     |\n| train/                          |             |\n|    approx_kl                    | 0.005206178 |\n|    clip_fraction                | 0.0186      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.846      |\n|    explained_variance           | 0.598       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 189         |\n|    n_updates                    | 3176        |\n|    policy_gradient_loss         | -0.000963   |\n|    value_loss                   | 420         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.38e+03    |\n|    water_produced               | 312         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 314         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1590        |\n|    time_elapsed                 | 7428        |\n|    total_timesteps              | 6360000     |\n| train/                          |             |\n|    approx_kl                    | 0.003848588 |\n|    clip_fraction                | 0.0159      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.853      |\n|    explained_variance           | 0.614       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 208         |\n|    n_updates                    | 3178        |\n|    policy_gradient_loss         | -0.000803   |\n|    value_loss                   | 453         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 162         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.26e+03    |\n|    water_produced               | 281         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 298           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1591          |\n|    time_elapsed                 | 7432          |\n|    total_timesteps              | 6364000       |\n| train/                          |               |\n|    approx_kl                    | 0.00082126504 |\n|    clip_fraction                | 0.0065        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.863        |\n|    explained_variance           | 0.664         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 215           |\n|    n_updates                    | 3180          |\n|    policy_gradient_loss         | 2.31e-06      |\n|    value_loss                   | 462           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 172           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 1e+03         |\n|    water_produced               | 233           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 274         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1592        |\n|    time_elapsed                 | 7437        |\n|    total_timesteps              | 6368000     |\n| train/                          |             |\n|    approx_kl                    | 0.017679166 |\n|    clip_fraction                | 0.11        |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.973      |\n|    explained_variance           | 0.698       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 243         |\n|    n_updates                    | 3182        |\n|    policy_gradient_loss         | 0.00317     |\n|    value_loss                   | 491         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 173         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.03e+03    |\n|    water_produced               | 236         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 291         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1593        |\n|    time_elapsed                 | 7441        |\n|    total_timesteps              | 6372000     |\n| train/                          |             |\n|    approx_kl                    | 0.012540256 |\n|    clip_fraction                | 0.082       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.977      |\n|    explained_variance           | 0.675       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 250         |\n|    n_updates                    | 3184        |\n|    policy_gradient_loss         | 0.00312     |\n|    value_loss                   | 523         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.55e+03    |\n|    water_produced               | 332         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 312          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1594         |\n|    time_elapsed                 | 7446         |\n|    total_timesteps              | 6376000      |\n| train/                          |              |\n|    approx_kl                    | 0.0045145047 |\n|    clip_fraction                | 0.0249       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.853       |\n|    explained_variance           | 0.427        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 261          |\n|    n_updates                    | 3186         |\n|    policy_gradient_loss         | 0.000513     |\n|    value_loss                   | 568          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 1.82e+03     |\n|    water_produced               | 411          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 295         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1595        |\n|    time_elapsed                 | 7450        |\n|    total_timesteps              | 6380000     |\n| train/                          |             |\n|    approx_kl                    | 0.015171869 |\n|    clip_fraction                | 0.078       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.797      |\n|    explained_variance           | 0.57        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 227         |\n|    n_updates                    | 3188        |\n|    policy_gradient_loss         | 0.00787     |\n|    value_loss                   | 508         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 868         |\n|    water_produced               | 200         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 301          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1596         |\n|    time_elapsed                 | 7454         |\n|    total_timesteps              | 6384000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011599293 |\n|    clip_fraction                | 0.00387      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.88        |\n|    explained_variance           | 0.667        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 274          |\n|    n_updates                    | 3190         |\n|    policy_gradient_loss         | 0.0019       |\n|    value_loss                   | 560          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.17e+03     |\n|    water_produced               | 261          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 315         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1597        |\n|    time_elapsed                 | 7459        |\n|    total_timesteps              | 6388000     |\n| train/                          |             |\n|    approx_kl                    | 0.010483402 |\n|    clip_fraction                | 0.0575      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.875      |\n|    explained_variance           | 0.642       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 198         |\n|    n_updates                    | 3192        |\n|    policy_gradient_loss         | 0.000488    |\n|    value_loss                   | 402         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.32e+03    |\n|    water_produced               | 301         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 320          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1598         |\n|    time_elapsed                 | 7464         |\n|    total_timesteps              | 6392000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012977149 |\n|    clip_fraction                | 0.00562      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.873       |\n|    explained_variance           | 0.645        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 267          |\n|    n_updates                    | 3194         |\n|    policy_gradient_loss         | -0.000934    |\n|    value_loss                   | 552          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.65e+03     |\n|    water_produced               | 356          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 305         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1599        |\n|    time_elapsed                 | 7468        |\n|    total_timesteps              | 6396000     |\n| train/                          |             |\n|    approx_kl                    | 0.006124263 |\n|    clip_fraction                | 0.031       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.772      |\n|    explained_variance           | 0.524       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 234         |\n|    n_updates                    | 3196        |\n|    policy_gradient_loss         | 0.00163     |\n|    value_loss                   | 507         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 1.53e+03    |\n|    water_produced               | 341         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 308          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1600         |\n|    time_elapsed                 | 7473         |\n|    total_timesteps              | 6400000      |\n| train/                          |              |\n|    approx_kl                    | 0.0064821593 |\n|    clip_fraction                | 0.0284       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.743       |\n|    explained_variance           | 0.559        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 197          |\n|    n_updates                    | 3198         |\n|    policy_gradient_loss         | 0.00519      |\n|    value_loss                   | 430          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 141          |\n|    action_queue_updates_total   | 147          |\n|    ice_dug                      | 1.06e+03     |\n|    water_produced               | 212          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 320         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1601        |\n|    time_elapsed                 | 7477        |\n|    total_timesteps              | 6404000     |\n| train/                          |             |\n|    approx_kl                    | 0.003646969 |\n|    clip_fraction                | 0.0188      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.823      |\n|    explained_variance           | 0.688       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 185         |\n|    n_updates                    | 3200        |\n|    policy_gradient_loss         | -0.00265    |\n|    value_loss                   | 416         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 152         |\n|    action_queue_updates_total   | 155         |\n|    ice_dug                      | 1.37e+03    |\n|    water_produced               | 322         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 340          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1602         |\n|    time_elapsed                 | 7481         |\n|    total_timesteps              | 6408000      |\n| train/                          |              |\n|    approx_kl                    | 0.0076207295 |\n|    clip_fraction                | 0.0422       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.836       |\n|    explained_variance           | 0.665        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 3202         |\n|    policy_gradient_loss         | -0.00278     |\n|    value_loss                   | 375          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.73e+03     |\n|    water_produced               | 395          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 330         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1603        |\n|    time_elapsed                 | 7486        |\n|    total_timesteps              | 6412000     |\n| train/                          |             |\n|    approx_kl                    | 0.004330109 |\n|    clip_fraction                | 0.0262      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.795      |\n|    explained_variance           | 0.63        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 214         |\n|    n_updates                    | 3204        |\n|    policy_gradient_loss         | 0.00278     |\n|    value_loss                   | 410         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 1.42e+03    |\n|    water_produced               | 307         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 311          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1604         |\n|    time_elapsed                 | 7491         |\n|    total_timesteps              | 6416000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020479304 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.788       |\n|    explained_variance           | 0.669        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 158          |\n|    n_updates                    | 3206         |\n|    policy_gradient_loss         | 0.000714     |\n|    value_loss                   | 376          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.28e+03     |\n|    water_produced               | 250          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 307         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1605        |\n|    time_elapsed                 | 7495        |\n|    total_timesteps              | 6420000     |\n| train/                          |             |\n|    approx_kl                    | 0.009133693 |\n|    clip_fraction                | 0.0428      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.833      |\n|    explained_variance           | 0.588       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 224         |\n|    n_updates                    | 3208        |\n|    policy_gradient_loss         | -0.0012     |\n|    value_loss                   | 486         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.01e+03    |\n|    water_produced               | 191         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 303         |\n| time/                           |             |\n|    fps                          | 856         |\n|    iterations                   | 1606        |\n|    time_elapsed                 | 7499        |\n|    total_timesteps              | 6424000     |\n| train/                          |             |\n|    approx_kl                    | 0.009790641 |\n|    clip_fraction                | 0.0679      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.914      |\n|    explained_variance           | 0.645       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 215         |\n|    n_updates                    | 3210        |\n|    policy_gradient_loss         | 0.000262    |\n|    value_loss                   | 491         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.34e+03    |\n|    water_produced               | 303         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 309          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1607         |\n|    time_elapsed                 | 7504         |\n|    total_timesteps              | 6428000      |\n| train/                          |              |\n|    approx_kl                    | 0.0052713514 |\n|    clip_fraction                | 0.0386       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.899       |\n|    explained_variance           | 0.709        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 3212         |\n|    policy_gradient_loss         | -0.000473    |\n|    value_loss                   | 449          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.79e+03     |\n|    water_produced               | 424          |\n--------------------------------------------------\nEval num_timesteps=6432000, episode_reward=1569.92 +/- 848.27\nEpisode length: 860.20 +/- 279.60\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 860         |\n|    mean_reward                  | 1.57e+03    |\n| time/                           |             |\n|    total_timesteps              | 6432000     |\n| train/                          |             |\n|    approx_kl                    | 0.006602999 |\n|    clip_fraction                | 0.0423      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.801      |\n|    explained_variance           | 0.577       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 236         |\n|    n_updates                    | 3214        |\n|    policy_gradient_loss         | 0.00251     |\n|    value_loss                   | 498         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 1.7e+03     |\n|    water_produced               | 393         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 326      |\n| time/              |          |\n|    fps             | 855      |\n|    iterations      | 1608     |\n|    time_elapsed    | 7516     |\n|    total_timesteps | 6432000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 339         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1609        |\n|    time_elapsed                 | 7521        |\n|    total_timesteps              | 6436000     |\n| train/                          |             |\n|    approx_kl                    | 0.015396853 |\n|    clip_fraction                | 0.0755      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.772      |\n|    explained_variance           | 0.612       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 232         |\n|    n_updates                    | 3216        |\n|    policy_gradient_loss         | 0.00701     |\n|    value_loss                   | 495         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 154         |\n|    ice_dug                      | 1.48e+03    |\n|    water_produced               | 311         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 342          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1610         |\n|    time_elapsed                 | 7526         |\n|    total_timesteps              | 6440000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010199674 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.788       |\n|    explained_variance           | 0.572        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 226          |\n|    n_updates                    | 3218         |\n|    policy_gradient_loss         | 0.0013       |\n|    value_loss                   | 437          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 937          |\n|    water_produced               | 209          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 354          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1611         |\n|    time_elapsed                 | 7530         |\n|    total_timesteps              | 6444000      |\n| train/                          |              |\n|    approx_kl                    | 0.0144384755 |\n|    clip_fraction                | 0.073        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.897       |\n|    explained_variance           | 0.716        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 179          |\n|    n_updates                    | 3220         |\n|    policy_gradient_loss         | -0.000943    |\n|    value_loss                   | 421          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.62e+03     |\n|    water_produced               | 357          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 325          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1612         |\n|    time_elapsed                 | 7534         |\n|    total_timesteps              | 6448000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008563137 |\n|    clip_fraction                | 0.00837      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.822       |\n|    explained_variance           | 0.54         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 187          |\n|    n_updates                    | 3222         |\n|    policy_gradient_loss         | -0.00146     |\n|    value_loss                   | 414          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.24e+03     |\n|    water_produced               | 283          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 318           |\n| time/                           |               |\n|    fps                          | 855           |\n|    iterations                   | 1613          |\n|    time_elapsed                 | 7539          |\n|    total_timesteps              | 6452000       |\n| train/                          |               |\n|    approx_kl                    | 0.00072026823 |\n|    clip_fraction                | 0.00287       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.873        |\n|    explained_variance           | 0.694         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 239           |\n|    n_updates                    | 3224          |\n|    policy_gradient_loss         | -0.000652     |\n|    value_loss                   | 476           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 165           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 1.7e+03       |\n|    water_produced               | 358           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 317           |\n| time/                           |               |\n|    fps                          | 855           |\n|    iterations                   | 1614          |\n|    time_elapsed                 | 7543          |\n|    total_timesteps              | 6456000       |\n| train/                          |               |\n|    approx_kl                    | 0.00025978746 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.826        |\n|    explained_variance           | 0.55          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 212           |\n|    n_updates                    | 3226          |\n|    policy_gradient_loss         | 0.000203      |\n|    value_loss                   | 433           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 172           |\n|    action_queue_updates_total   | 174           |\n|    ice_dug                      | 1.49e+03      |\n|    water_produced               | 310           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 332          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1615         |\n|    time_elapsed                 | 7548         |\n|    total_timesteps              | 6460000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006176907 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.86        |\n|    explained_variance           | 0.613        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 275          |\n|    n_updates                    | 3228         |\n|    policy_gradient_loss         | 0.000505     |\n|    value_loss                   | 588          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.25e+03     |\n|    water_produced               | 278          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 300          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1616         |\n|    time_elapsed                 | 7553         |\n|    total_timesteps              | 6464000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025897615 |\n|    clip_fraction                | 0.0131       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.879       |\n|    explained_variance           | 0.559        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 3230         |\n|    policy_gradient_loss         | -0.00189     |\n|    value_loss                   | 474          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 897          |\n|    water_produced               | 203          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 308         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1617        |\n|    time_elapsed                 | 7557        |\n|    total_timesteps              | 6468000     |\n| train/                          |             |\n|    approx_kl                    | 0.005246006 |\n|    clip_fraction                | 0.0296      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.929      |\n|    explained_variance           | 0.695       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 246         |\n|    n_updates                    | 3232        |\n|    policy_gradient_loss         | 0.00117     |\n|    value_loss                   | 496         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.49e+03    |\n|    water_produced               | 322         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 302          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1618         |\n|    time_elapsed                 | 7562         |\n|    total_timesteps              | 6472000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021262544 |\n|    clip_fraction                | 0.0146       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.892       |\n|    explained_variance           | 0.672        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 3234         |\n|    policy_gradient_loss         | -0.00195     |\n|    value_loss                   | 544          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.54e+03     |\n|    water_produced               | 329          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 303         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1619        |\n|    time_elapsed                 | 7566        |\n|    total_timesteps              | 6476000     |\n| train/                          |             |\n|    approx_kl                    | 0.005062664 |\n|    clip_fraction                | 0.0329      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.847      |\n|    explained_variance           | 0.563       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 226         |\n|    n_updates                    | 3236        |\n|    policy_gradient_loss         | 0.00115     |\n|    value_loss                   | 465         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.34e+03    |\n|    water_produced               | 316         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 319         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1620        |\n|    time_elapsed                 | 7571        |\n|    total_timesteps              | 6480000     |\n| train/                          |             |\n|    approx_kl                    | 0.008740825 |\n|    clip_fraction                | 0.0421      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.898      |\n|    explained_variance           | 0.678       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 229         |\n|    n_updates                    | 3238        |\n|    policy_gradient_loss         | 0.00274     |\n|    value_loss                   | 520         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 1.56e+03    |\n|    water_produced               | 357         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 309          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1621         |\n|    time_elapsed                 | 7575         |\n|    total_timesteps              | 6484000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031724037 |\n|    clip_fraction                | 0.016        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.783       |\n|    explained_variance           | 0.627        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 179          |\n|    n_updates                    | 3240         |\n|    policy_gradient_loss         | 0.0031       |\n|    value_loss                   | 377          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 690          |\n|    water_produced               | 156          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 306        |\n| time/                           |            |\n|    fps                          | 855        |\n|    iterations                   | 1622       |\n|    time_elapsed                 | 7579       |\n|    total_timesteps              | 6488000    |\n| train/                          |            |\n|    approx_kl                    | 0.00550433 |\n|    clip_fraction                | 0.0312     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.972     |\n|    explained_variance           | 0.672      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 276        |\n|    n_updates                    | 3242       |\n|    policy_gradient_loss         | 0.00018    |\n|    value_loss                   | 585        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 168        |\n|    action_queue_updates_total   | 170        |\n|    ice_dug                      | 1.31e+03   |\n|    water_produced               | 309        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 292         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1623        |\n|    time_elapsed                 | 7584        |\n|    total_timesteps              | 6492000     |\n| train/                          |             |\n|    approx_kl                    | 0.010745266 |\n|    clip_fraction                | 0.0794      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.905      |\n|    explained_variance           | 0.715       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 218         |\n|    n_updates                    | 3244        |\n|    policy_gradient_loss         | 0.002       |\n|    value_loss                   | 462         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.14e+03    |\n|    water_produced               | 263         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 297          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1624         |\n|    time_elapsed                 | 7589         |\n|    total_timesteps              | 6496000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029740632 |\n|    clip_fraction                | 0.0189       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.925       |\n|    explained_variance           | 0.604        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 270          |\n|    n_updates                    | 3246         |\n|    policy_gradient_loss         | -0.00207     |\n|    value_loss                   | 601          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 338          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 298          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1625         |\n|    time_elapsed                 | 7593         |\n|    total_timesteps              | 6500000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020112689 |\n|    clip_fraction                | 0.00337      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.877       |\n|    explained_variance           | 0.725        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 277          |\n|    n_updates                    | 3248         |\n|    policy_gradient_loss         | -7.1e-05     |\n|    value_loss                   | 529          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.68e+03     |\n|    water_produced               | 362          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 306          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1626         |\n|    time_elapsed                 | 7598         |\n|    total_timesteps              | 6504000      |\n| train/                          |              |\n|    approx_kl                    | 0.0067713098 |\n|    clip_fraction                | 0.0428       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.777       |\n|    explained_variance           | 0.539        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 292          |\n|    n_updates                    | 3250         |\n|    policy_gradient_loss         | 0.00289      |\n|    value_loss                   | 613          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 893          |\n|    water_produced               | 191          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 314          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1627         |\n|    time_elapsed                 | 7602         |\n|    total_timesteps              | 6508000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007348376 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.868       |\n|    explained_variance           | 0.588        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 290          |\n|    n_updates                    | 3252         |\n|    policy_gradient_loss         | 0.000446     |\n|    value_loss                   | 626          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.5e+03      |\n|    water_produced               | 349          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 322           |\n| time/                           |               |\n|    fps                          | 856           |\n|    iterations                   | 1628          |\n|    time_elapsed                 | 7607          |\n|    total_timesteps              | 6512000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031473621 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.787        |\n|    explained_variance           | 0.589         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 205           |\n|    n_updates                    | 3254          |\n|    policy_gradient_loss         | -0.000315     |\n|    value_loss                   | 422           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 159           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 1.34e+03      |\n|    water_produced               | 302           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 323          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1629         |\n|    time_elapsed                 | 7611         |\n|    total_timesteps              | 6516000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010049578 |\n|    clip_fraction                | 0.00388      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.823       |\n|    explained_variance           | 0.687        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 3256         |\n|    policy_gradient_loss         | 0.000229     |\n|    value_loss                   | 470          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.47e+03     |\n|    water_produced               | 342          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 315          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1630         |\n|    time_elapsed                 | 7616         |\n|    total_timesteps              | 6520000      |\n| train/                          |              |\n|    approx_kl                    | 0.0039284853 |\n|    clip_fraction                | 0.0301       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.849       |\n|    explained_variance           | 0.75         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 3258         |\n|    policy_gradient_loss         | -0.000937    |\n|    value_loss                   | 459          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.43e+03     |\n|    water_produced               | 324          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 341          |\n| time/                           |              |\n|    fps                          | 856          |\n|    iterations                   | 1631         |\n|    time_elapsed                 | 7620         |\n|    total_timesteps              | 6524000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036961022 |\n|    clip_fraction                | 0.0234       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.794       |\n|    explained_variance           | 0.619        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 3260         |\n|    policy_gradient_loss         | 0.00178      |\n|    value_loss                   | 493          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.5e+03      |\n|    water_produced               | 318          |\n--------------------------------------------------\nEval num_timesteps=6528000, episode_reward=1656.08 +/- 794.94\nEpisode length: 870.20 +/- 259.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 870          |\n|    mean_reward                  | 1.66e+03     |\n| time/                           |              |\n|    total_timesteps              | 6528000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018948268 |\n|    clip_fraction                | 0.0134       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.807       |\n|    explained_variance           | 0.568        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 245          |\n|    n_updates                    | 3262         |\n|    policy_gradient_loss         | 0.00196      |\n|    value_loss                   | 529          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.29e+03     |\n|    water_produced               | 251          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 321      |\n| time/              |          |\n|    fps             | 855      |\n|    iterations      | 1632     |\n|    time_elapsed    | 7633     |\n|    total_timesteps | 6528000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 311          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1633         |\n|    time_elapsed                 | 7638         |\n|    total_timesteps              | 6532000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042252326 |\n|    clip_fraction                | 0.0219       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.861       |\n|    explained_variance           | 0.623        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 258          |\n|    n_updates                    | 3264         |\n|    policy_gradient_loss         | 0.00088      |\n|    value_loss                   | 544          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.26e+03     |\n|    water_produced               | 250          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 304        |\n| time/                           |            |\n|    fps                          | 855        |\n|    iterations                   | 1634       |\n|    time_elapsed                 | 7642       |\n|    total_timesteps              | 6536000    |\n| train/                          |            |\n|    approx_kl                    | 0.01068338 |\n|    clip_fraction                | 0.0524     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.894     |\n|    explained_variance           | 0.692      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 218        |\n|    n_updates                    | 3266       |\n|    policy_gradient_loss         | 0.00468    |\n|    value_loss                   | 456        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 167        |\n|    action_queue_updates_total   | 168        |\n|    ice_dug                      | 1.38e+03   |\n|    water_produced               | 311        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 316          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1635         |\n|    time_elapsed                 | 7647         |\n|    total_timesteps              | 6540000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007914191 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.875       |\n|    explained_variance           | 0.723        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 246          |\n|    n_updates                    | 3268         |\n|    policy_gradient_loss         | 0.000289     |\n|    value_loss                   | 501          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.65e+03     |\n|    water_produced               | 382          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 323          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1636         |\n|    time_elapsed                 | 7651         |\n|    total_timesteps              | 6544000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031446293 |\n|    clip_fraction                | 0.0155       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.774       |\n|    explained_variance           | 0.581        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 272          |\n|    n_updates                    | 3270         |\n|    policy_gradient_loss         | 0.00268      |\n|    value_loss                   | 496          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 150          |\n|    ice_dug                      | 1.49e+03     |\n|    water_produced               | 350          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 315          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1637         |\n|    time_elapsed                 | 7656         |\n|    total_timesteps              | 6548000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016252592 |\n|    clip_fraction                | 0.00775      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.754       |\n|    explained_variance           | 0.599        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 3272         |\n|    policy_gradient_loss         | 0.00295      |\n|    value_loss                   | 425          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 151          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 966          |\n|    water_produced               | 214          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 346         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1638        |\n|    time_elapsed                 | 7660        |\n|    total_timesteps              | 6552000     |\n| train/                          |             |\n|    approx_kl                    | 0.014602385 |\n|    clip_fraction                | 0.0744      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.881      |\n|    explained_variance           | 0.725       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 230         |\n|    n_updates                    | 3274        |\n|    policy_gradient_loss         | 0.000664    |\n|    value_loss                   | 480         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.8e+03     |\n|    water_produced               | 404         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 358           |\n| time/                           |               |\n|    fps                          | 855           |\n|    iterations                   | 1639          |\n|    time_elapsed                 | 7665          |\n|    total_timesteps              | 6556000       |\n| train/                          |               |\n|    approx_kl                    | 0.00054272095 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.774        |\n|    explained_variance           | 0.473         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 270           |\n|    n_updates                    | 3276          |\n|    policy_gradient_loss         | -0.00115      |\n|    value_loss                   | 563           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 161           |\n|    ice_dug                      | 1.66e+03      |\n|    water_produced               | 364           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 334         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1640        |\n|    time_elapsed                 | 7669        |\n|    total_timesteps              | 6560000     |\n| train/                          |             |\n|    approx_kl                    | 0.008133223 |\n|    clip_fraction                | 0.0407      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.738      |\n|    explained_variance           | 0.541       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 228         |\n|    n_updates                    | 3278        |\n|    policy_gradient_loss         | 0.00439     |\n|    value_loss                   | 484         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.21e+03    |\n|    water_produced               | 269         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 327          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1641         |\n|    time_elapsed                 | 7674         |\n|    total_timesteps              | 6564000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026392099 |\n|    clip_fraction                | 0.0125       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.853       |\n|    explained_variance           | 0.734        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 179          |\n|    n_updates                    | 3280         |\n|    policy_gradient_loss         | -0.00149     |\n|    value_loss                   | 406          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.41e+03     |\n|    water_produced               | 312          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 368          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1642         |\n|    time_elapsed                 | 7678         |\n|    total_timesteps              | 6568000      |\n| train/                          |              |\n|    approx_kl                    | 0.0040208865 |\n|    clip_fraction                | 0.0277       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.874       |\n|    explained_variance           | 0.693        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 3282         |\n|    policy_gradient_loss         | -0.00105     |\n|    value_loss                   | 544          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.83e+03     |\n|    water_produced               | 412          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 356         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1643        |\n|    time_elapsed                 | 7683        |\n|    total_timesteps              | 6572000     |\n| train/                          |             |\n|    approx_kl                    | 0.008645101 |\n|    clip_fraction                | 0.0536      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.788      |\n|    explained_variance           | 0.598       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 188         |\n|    n_updates                    | 3284        |\n|    policy_gradient_loss         | 0.00487     |\n|    value_loss                   | 424         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 1.5e+03     |\n|    water_produced               | 348         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 337          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1644         |\n|    time_elapsed                 | 7687         |\n|    total_timesteps              | 6576000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011493921 |\n|    clip_fraction                | 0.00425      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.799       |\n|    explained_variance           | 0.628        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 185          |\n|    n_updates                    | 3286         |\n|    policy_gradient_loss         | 0.00334      |\n|    value_loss                   | 400          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.44e+03     |\n|    water_produced               | 272          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 341          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1645         |\n|    time_elapsed                 | 7692         |\n|    total_timesteps              | 6580000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029622372 |\n|    clip_fraction                | 0.0249       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.825       |\n|    explained_variance           | 0.486        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 3288         |\n|    policy_gradient_loss         | -0.00218     |\n|    value_loss                   | 457          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.45e+03     |\n|    water_produced               | 286          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 328          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1646         |\n|    time_elapsed                 | 7696         |\n|    total_timesteps              | 6584000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022053933 |\n|    clip_fraction                | 0.0101       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.85        |\n|    explained_variance           | 0.619        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 3290         |\n|    policy_gradient_loss         | -0.00198     |\n|    value_loss                   | 496          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.08e+03     |\n|    water_produced               | 247          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 323         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1647        |\n|    time_elapsed                 | 7701        |\n|    total_timesteps              | 6588000     |\n| train/                          |             |\n|    approx_kl                    | 0.005437598 |\n|    clip_fraction                | 0.0289      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.897      |\n|    explained_variance           | 0.658       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 230         |\n|    n_updates                    | 3292        |\n|    policy_gradient_loss         | -0.000168   |\n|    value_loss                   | 471         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.67e+03    |\n|    water_produced               | 390         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 313           |\n| time/                           |               |\n|    fps                          | 855           |\n|    iterations                   | 1648          |\n|    time_elapsed                 | 7705          |\n|    total_timesteps              | 6592000       |\n| train/                          |               |\n|    approx_kl                    | 0.00052821066 |\n|    clip_fraction                | 0.00112       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.852        |\n|    explained_variance           | 0.638         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 226           |\n|    n_updates                    | 3294          |\n|    policy_gradient_loss         | -0.0017       |\n|    value_loss                   | 482           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 157           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 1.4e+03       |\n|    water_produced               | 302           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 311          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1649         |\n|    time_elapsed                 | 7710         |\n|    total_timesteps              | 6596000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012199627 |\n|    clip_fraction                | 0.0025       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.84        |\n|    explained_variance           | 0.68         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 3296         |\n|    policy_gradient_loss         | 0.000825     |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.14e+03     |\n|    water_produced               | 264          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 324         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1650        |\n|    time_elapsed                 | 7714        |\n|    total_timesteps              | 6600000     |\n| train/                          |             |\n|    approx_kl                    | 0.011579059 |\n|    clip_fraction                | 0.0656      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.927      |\n|    explained_variance           | 0.73        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 267         |\n|    n_updates                    | 3298        |\n|    policy_gradient_loss         | 0.00182     |\n|    value_loss                   | 539         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.62e+03    |\n|    water_produced               | 346         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 357          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1651         |\n|    time_elapsed                 | 7718         |\n|    total_timesteps              | 6604000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021836162 |\n|    clip_fraction                | 0.00937      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.818       |\n|    explained_variance           | 0.458        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 3300         |\n|    policy_gradient_loss         | 0.000105     |\n|    value_loss                   | 518          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.73e+03     |\n|    water_produced               | 410          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 335         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1652        |\n|    time_elapsed                 | 7723        |\n|    total_timesteps              | 6608000     |\n| train/                          |             |\n|    approx_kl                    | 0.012279823 |\n|    clip_fraction                | 0.0739      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.754      |\n|    explained_variance           | 0.638       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 198         |\n|    n_updates                    | 3302        |\n|    policy_gradient_loss         | 0.00613     |\n|    value_loss                   | 428         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.23e+03    |\n|    water_produced               | 281         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 353          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1653         |\n|    time_elapsed                 | 7727         |\n|    total_timesteps              | 6612000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024972854 |\n|    clip_fraction                | 0.00963      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.842       |\n|    explained_variance           | 0.69         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 3304         |\n|    policy_gradient_loss         | -0.000641    |\n|    value_loss                   | 468          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.62e+03     |\n|    water_produced               | 390          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 359           |\n| time/                           |               |\n|    fps                          | 855           |\n|    iterations                   | 1654          |\n|    time_elapsed                 | 7732          |\n|    total_timesteps              | 6616000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029498487 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.815        |\n|    explained_variance           | 0.557         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 213           |\n|    n_updates                    | 3306          |\n|    policy_gradient_loss         | -0.000817     |\n|    value_loss                   | 424           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 161           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 1.46e+03      |\n|    water_produced               | 290           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 362          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1655         |\n|    time_elapsed                 | 7736         |\n|    total_timesteps              | 6620000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021526061 |\n|    clip_fraction                | 0.0119       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.813       |\n|    explained_variance           | 0.483        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 3308         |\n|    policy_gradient_loss         | 0.000313     |\n|    value_loss                   | 470          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.55e+03     |\n|    water_produced               | 363          |\n--------------------------------------------------\nEval num_timesteps=6624000, episode_reward=2184.64 +/- 131.29\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.18e+03     |\n| time/                           |              |\n|    total_timesteps              | 6624000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016785752 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.787       |\n|    explained_variance           | 0.658        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 170          |\n|    n_updates                    | 3310         |\n|    policy_gradient_loss         | 0.000656     |\n|    value_loss                   | 384          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.68e+03     |\n|    water_produced               | 391          |\n--------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 358      |\n| time/              |          |\n|    fps             | 854      |\n|    iterations      | 1656     |\n|    time_elapsed    | 7749     |\n|    total_timesteps | 6624000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 359          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1657         |\n|    time_elapsed                 | 7754         |\n|    total_timesteps              | 6628000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036985553 |\n|    clip_fraction                | 0.0235       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.775       |\n|    explained_variance           | 0.747        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 3312         |\n|    policy_gradient_loss         | 0.00369      |\n|    value_loss                   | 432          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.26e+03     |\n|    water_produced               | 284          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 335          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1658         |\n|    time_elapsed                 | 7758         |\n|    total_timesteps              | 6632000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029325578 |\n|    clip_fraction                | 0.0141       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.826       |\n|    explained_variance           | 0.607        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 3314         |\n|    policy_gradient_loss         | -0.000835    |\n|    value_loss                   | 483          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.5e+03      |\n|    water_produced               | 273          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 345         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1659        |\n|    time_elapsed                 | 7762        |\n|    total_timesteps              | 6636000     |\n| train/                          |             |\n|    approx_kl                    | 0.006328898 |\n|    clip_fraction                | 0.0462      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.847      |\n|    explained_variance           | 0.55        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 256         |\n|    n_updates                    | 3316        |\n|    policy_gradient_loss         | -0.00173    |\n|    value_loss                   | 505         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.49e+03    |\n|    water_produced               | 342         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 340          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1660         |\n|    time_elapsed                 | 7767         |\n|    total_timesteps              | 6640000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032919415 |\n|    clip_fraction                | 0.0164       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.796       |\n|    explained_variance           | 0.578        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 3318         |\n|    policy_gradient_loss         | 0.000396     |\n|    value_loss                   | 472          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.45e+03     |\n|    water_produced               | 337          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 335          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1661         |\n|    time_elapsed                 | 7771         |\n|    total_timesteps              | 6644000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020646825 |\n|    clip_fraction                | 0.0115       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.786       |\n|    explained_variance           | 0.607        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 3320         |\n|    policy_gradient_loss         | -0.00152     |\n|    value_loss                   | 407          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.62e+03     |\n|    water_produced               | 365          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 333          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1662         |\n|    time_elapsed                 | 7776         |\n|    total_timesteps              | 6648000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021908854 |\n|    clip_fraction                | 0.0138       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.816       |\n|    explained_variance           | 0.61         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 178          |\n|    n_updates                    | 3322         |\n|    policy_gradient_loss         | -1.3e-06     |\n|    value_loss                   | 382          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.28e+03     |\n|    water_produced               | 272          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 322          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1663         |\n|    time_elapsed                 | 7781         |\n|    total_timesteps              | 6652000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037087668 |\n|    clip_fraction                | 0.014        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.877       |\n|    explained_variance           | 0.715        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 3324         |\n|    policy_gradient_loss         | 0.000674     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.03e+03     |\n|    water_produced               | 227          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 325        |\n| time/                           |            |\n|    fps                          | 854        |\n|    iterations                   | 1664       |\n|    time_elapsed                 | 7785       |\n|    total_timesteps              | 6656000    |\n| train/                          |            |\n|    approx_kl                    | 0.01607706 |\n|    clip_fraction                | 0.092      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.952     |\n|    explained_variance           | 0.698      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 206        |\n|    n_updates                    | 3326       |\n|    policy_gradient_loss         | 0.00585    |\n|    value_loss                   | 485        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 172        |\n|    action_queue_updates_total   | 174        |\n|    ice_dug                      | 1.64e+03   |\n|    water_produced               | 356        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 300          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1665         |\n|    time_elapsed                 | 7789         |\n|    total_timesteps              | 6660000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010409683 |\n|    clip_fraction                | 0.00488      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.848       |\n|    explained_variance           | 0.484        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 308          |\n|    n_updates                    | 3328         |\n|    policy_gradient_loss         | -0.00105     |\n|    value_loss                   | 599          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 936          |\n|    water_produced               | 215          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 293          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1666         |\n|    time_elapsed                 | 7794         |\n|    total_timesteps              | 6664000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012547018 |\n|    clip_fraction                | 0.00487      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.961       |\n|    explained_variance           | 0.778        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 217          |\n|    n_updates                    | 3330         |\n|    policy_gradient_loss         | -0.00119     |\n|    value_loss                   | 486          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 333          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 317        |\n| time/                           |            |\n|    fps                          | 855        |\n|    iterations                   | 1667       |\n|    time_elapsed                 | 7798       |\n|    total_timesteps              | 6668000    |\n| train/                          |            |\n|    approx_kl                    | 0.00236945 |\n|    clip_fraction                | 0.0154     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.876     |\n|    explained_variance           | 0.736      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 256        |\n|    n_updates                    | 3332       |\n|    policy_gradient_loss         | 0.000428   |\n|    value_loss                   | 514        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 169        |\n|    action_queue_updates_total   | 173        |\n|    ice_dug                      | 1.76e+03   |\n|    water_produced               | 387        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 336         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1668        |\n|    time_elapsed                 | 7803        |\n|    total_timesteps              | 6672000     |\n| train/                          |             |\n|    approx_kl                    | 0.011384253 |\n|    clip_fraction                | 0.0726      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.76       |\n|    explained_variance           | 0.409       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 240         |\n|    n_updates                    | 3334        |\n|    policy_gradient_loss         | 0.00387     |\n|    value_loss                   | 530         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 1.44e+03    |\n|    water_produced               | 318         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 338         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1669        |\n|    time_elapsed                 | 7807        |\n|    total_timesteps              | 6676000     |\n| train/                          |             |\n|    approx_kl                    | 0.003917224 |\n|    clip_fraction                | 0.031       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.812      |\n|    explained_variance           | 0.696       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 258         |\n|    n_updates                    | 3336        |\n|    policy_gradient_loss         | 0.00407     |\n|    value_loss                   | 496         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.56e+03    |\n|    water_produced               | 365         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 373          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1670         |\n|    time_elapsed                 | 7812         |\n|    total_timesteps              | 6680000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015324098 |\n|    clip_fraction                | 0.00225      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.821       |\n|    explained_variance           | 0.618        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 3338         |\n|    policy_gradient_loss         | -0.000187    |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.67e+03     |\n|    water_produced               | 384          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 383          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1671         |\n|    time_elapsed                 | 7817         |\n|    total_timesteps              | 6684000      |\n| train/                          |              |\n|    approx_kl                    | 0.0046103406 |\n|    clip_fraction                | 0.0272       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.799       |\n|    explained_variance           | 0.625        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 189          |\n|    n_updates                    | 3340         |\n|    policy_gradient_loss         | 0.00478      |\n|    value_loss                   | 354          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.65e+03     |\n|    water_produced               | 381          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 365          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1672         |\n|    time_elapsed                 | 7821         |\n|    total_timesteps              | 6688000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017243384 |\n|    clip_fraction                | 0.0065       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.783       |\n|    explained_variance           | 0.611        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 3342         |\n|    policy_gradient_loss         | 0.000735     |\n|    value_loss                   | 395          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.38e+03     |\n|    water_produced               | 302          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 366         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1673        |\n|    time_elapsed                 | 7825        |\n|    total_timesteps              | 6692000     |\n| train/                          |             |\n|    approx_kl                    | 0.006257114 |\n|    clip_fraction                | 0.0205      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.804      |\n|    explained_variance           | 0.621       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 170         |\n|    n_updates                    | 3344        |\n|    policy_gradient_loss         | -0.00365    |\n|    value_loss                   | 367         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 1.46e+03    |\n|    water_produced               | 318         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 302          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1674         |\n|    time_elapsed                 | 7830         |\n|    total_timesteps              | 6696000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016062688 |\n|    clip_fraction                | 0.0065       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.839       |\n|    explained_variance           | 0.454        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 3346         |\n|    policy_gradient_loss         | -0.00147     |\n|    value_loss                   | 476          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 332          |\n|    water_produced               | 58.2         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 269         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1675        |\n|    time_elapsed                 | 7834        |\n|    total_timesteps              | 6700000     |\n| train/                          |             |\n|    approx_kl                    | 0.005254554 |\n|    clip_fraction                | 0.0307      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.04       |\n|    explained_variance           | 0.465       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 253         |\n|    n_updates                    | 3348        |\n|    policy_gradient_loss         | -0.000464   |\n|    value_loss                   | 644         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.06e+03    |\n|    water_produced               | 227         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 256         |\n| time/                           |             |\n|    fps                          | 855         |\n|    iterations                   | 1676        |\n|    time_elapsed                 | 7839        |\n|    total_timesteps              | 6704000     |\n| train/                          |             |\n|    approx_kl                    | 0.024104867 |\n|    clip_fraction                | 0.15        |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.987      |\n|    explained_variance           | 0.699       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 247         |\n|    n_updates                    | 3350        |\n|    policy_gradient_loss         | 0.00702     |\n|    value_loss                   | 492         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.43e+03    |\n|    water_produced               | 318         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 253          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1677         |\n|    time_elapsed                 | 7843         |\n|    total_timesteps              | 6708000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017375111 |\n|    clip_fraction                | 0.0065       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.894       |\n|    explained_variance           | 0.683        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 264          |\n|    n_updates                    | 3352         |\n|    policy_gradient_loss         | -0.0012      |\n|    value_loss                   | 512          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.55e+03     |\n|    water_produced               | 284          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 251          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1678         |\n|    time_elapsed                 | 7848         |\n|    total_timesteps              | 6712000      |\n| train/                          |              |\n|    approx_kl                    | 0.0044280495 |\n|    clip_fraction                | 0.0241       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.807       |\n|    explained_variance           | 0.473        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 294          |\n|    n_updates                    | 3354         |\n|    policy_gradient_loss         | 0.000877     |\n|    value_loss                   | 577          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.57e+03     |\n|    water_produced               | 307          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 319          |\n| time/                           |              |\n|    fps                          | 855          |\n|    iterations                   | 1679         |\n|    time_elapsed                 | 7852         |\n|    total_timesteps              | 6716000      |\n| train/                          |              |\n|    approx_kl                    | 0.0060073063 |\n|    clip_fraction                | 0.0369       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.804       |\n|    explained_variance           | 0.508        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 299          |\n|    n_updates                    | 3356         |\n|    policy_gradient_loss         | 0.000698     |\n|    value_loss                   | 621          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.78e+03     |\n|    water_produced               | 386          |\n--------------------------------------------------\nEval num_timesteps=6720000, episode_reward=1401.20 +/- 1193.36\nEpisode length: 721.40 +/- 341.22\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 721         |\n|    mean_reward                  | 1.4e+03     |\n| time/                           |             |\n|    total_timesteps              | 6720000     |\n| train/                          |             |\n|    approx_kl                    | 0.008167973 |\n|    clip_fraction                | 0.038       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.745      |\n|    explained_variance           | 0.536       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 215         |\n|    n_updates                    | 3358        |\n|    policy_gradient_loss         | 0.00456     |\n|    value_loss                   | 481         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 147         |\n|    ice_dug                      | 1.25e+03    |\n|    water_produced               | 290         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 332      |\n| time/              |          |\n|    fps             | 854      |\n|    iterations      | 1680     |\n|    time_elapsed    | 7865     |\n|    total_timesteps | 6720000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 300          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1681         |\n|    time_elapsed                 | 7870         |\n|    total_timesteps              | 6724000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006715537 |\n|    clip_fraction                | 0.000875     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.757       |\n|    explained_variance           | 0.599        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 206          |\n|    n_updates                    | 3360         |\n|    policy_gradient_loss         | 0.00182      |\n|    value_loss                   | 433          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 698          |\n|    water_produced               | 164          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 307         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1682        |\n|    time_elapsed                 | 7874        |\n|    total_timesteps              | 6728000     |\n| train/                          |             |\n|    approx_kl                    | 0.017585931 |\n|    clip_fraction                | 0.0821      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.926      |\n|    explained_variance           | 0.685       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 189         |\n|    n_updates                    | 3362        |\n|    policy_gradient_loss         | 0.00606     |\n|    value_loss                   | 473         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.45e+03    |\n|    water_produced               | 319         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 277         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1683        |\n|    time_elapsed                 | 7879        |\n|    total_timesteps              | 6732000     |\n| train/                          |             |\n|    approx_kl                    | 0.006017481 |\n|    clip_fraction                | 0.0331      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.851      |\n|    explained_variance           | 0.598       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 243         |\n|    n_updates                    | 3364        |\n|    policy_gradient_loss         | -0.00105    |\n|    value_loss                   | 495         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 886         |\n|    water_produced               | 167         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 260          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1684         |\n|    time_elapsed                 | 7883         |\n|    total_timesteps              | 6736000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032537659 |\n|    clip_fraction                | 0.0138       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.974       |\n|    explained_variance           | 0.686        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 244          |\n|    n_updates                    | 3366         |\n|    policy_gradient_loss         | -0.000504    |\n|    value_loss                   | 568          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.41e+03     |\n|    water_produced               | 303          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 232          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1685         |\n|    time_elapsed                 | 7888         |\n|    total_timesteps              | 6740000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020424877 |\n|    clip_fraction                | 0.0105       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.906       |\n|    explained_variance           | 0.63         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 282          |\n|    n_updates                    | 3368         |\n|    policy_gradient_loss         | -0.00172     |\n|    value_loss                   | 573          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 672          |\n|    water_produced               | 155          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 283          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1686         |\n|    time_elapsed                 | 7892         |\n|    total_timesteps              | 6744000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011374217 |\n|    clip_fraction                | 0.00238      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -1.05        |\n|    explained_variance           | 0.782        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 3370         |\n|    policy_gradient_loss         | -0.000187    |\n|    value_loss                   | 503          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 407          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 298           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1687          |\n|    time_elapsed                 | 7896          |\n|    total_timesteps              | 6748000       |\n| train/                          |               |\n|    approx_kl                    | 0.00036465173 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.824        |\n|    explained_variance           | 0.502         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 254           |\n|    n_updates                    | 3372          |\n|    policy_gradient_loss         | 0.000118      |\n|    value_loss                   | 514           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 175           |\n|    action_queue_updates_total   | 176           |\n|    ice_dug                      | 1.76e+03      |\n|    water_produced               | 392           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 335         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1688        |\n|    time_elapsed                 | 7901        |\n|    total_timesteps              | 6752000     |\n| train/                          |             |\n|    approx_kl                    | 0.014952527 |\n|    clip_fraction                | 0.095       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.807      |\n|    explained_variance           | 0.525       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 262         |\n|    n_updates                    | 3374        |\n|    policy_gradient_loss         | 0.00609     |\n|    value_loss                   | 542         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.48e+03    |\n|    water_produced               | 345         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 344          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1689         |\n|    time_elapsed                 | 7905         |\n|    total_timesteps              | 6756000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008070179 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.838       |\n|    explained_variance           | 0.716        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 3376         |\n|    policy_gradient_loss         | 0.000481     |\n|    value_loss                   | 451          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.57e+03     |\n|    water_produced               | 346          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 390           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1690          |\n|    time_elapsed                 | 7910          |\n|    total_timesteps              | 6760000       |\n| train/                          |               |\n|    approx_kl                    | 0.00053107226 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.813        |\n|    explained_variance           | 0.589         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 204           |\n|    n_updates                    | 3378          |\n|    policy_gradient_loss         | 0.00084       |\n|    value_loss                   | 444           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 166           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 1.63e+03      |\n|    water_produced               | 376           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 362          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1691         |\n|    time_elapsed                 | 7914         |\n|    total_timesteps              | 6764000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012349316 |\n|    clip_fraction                | 0.00437      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.792       |\n|    explained_variance           | 0.607        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 190          |\n|    n_updates                    | 3380         |\n|    policy_gradient_loss         | 0.00183      |\n|    value_loss                   | 379          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 273          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 343         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1692        |\n|    time_elapsed                 | 7918        |\n|    total_timesteps              | 6768000     |\n| train/                          |             |\n|    approx_kl                    | 0.008664772 |\n|    clip_fraction                | 0.0299      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.865      |\n|    explained_variance           | 0.676       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 198         |\n|    n_updates                    | 3382        |\n|    policy_gradient_loss         | 0.00146     |\n|    value_loss                   | 436         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.33e+03    |\n|    water_produced               | 306         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 352         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1693        |\n|    time_elapsed                 | 7923        |\n|    total_timesteps              | 6772000     |\n| train/                          |             |\n|    approx_kl                    | 0.014830323 |\n|    clip_fraction                | 0.0794      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.898      |\n|    explained_variance           | 0.696       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 206         |\n|    n_updates                    | 3384        |\n|    policy_gradient_loss         | 0.00361     |\n|    value_loss                   | 455         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.74e+03    |\n|    water_produced               | 387         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 356          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1694         |\n|    time_elapsed                 | 7927         |\n|    total_timesteps              | 6776000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031800761 |\n|    clip_fraction                | 0.0181       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.783       |\n|    explained_variance           | 0.527        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 212          |\n|    n_updates                    | 3386         |\n|    policy_gradient_loss         | 0.000304     |\n|    value_loss                   | 435          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.66e+03     |\n|    water_produced               | 360          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 323         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1695        |\n|    time_elapsed                 | 7932        |\n|    total_timesteps              | 6780000     |\n| train/                          |             |\n|    approx_kl                    | 0.008456408 |\n|    clip_fraction                | 0.0408      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.752      |\n|    explained_variance           | 0.535       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 204         |\n|    n_updates                    | 3388        |\n|    policy_gradient_loss         | 0.00525     |\n|    value_loss                   | 425         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 924         |\n|    water_produced               | 218         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 342         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1696        |\n|    time_elapsed                 | 7936        |\n|    total_timesteps              | 6784000     |\n| train/                          |             |\n|    approx_kl                    | 0.007315831 |\n|    clip_fraction                | 0.0474      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.878      |\n|    explained_variance           | 0.655       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 240         |\n|    n_updates                    | 3390        |\n|    policy_gradient_loss         | -0.00177    |\n|    value_loss                   | 563         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.65e+03    |\n|    water_produced               | 366         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 351          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1697         |\n|    time_elapsed                 | 7940         |\n|    total_timesteps              | 6788000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015197744 |\n|    clip_fraction                | 0.0123       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.792       |\n|    explained_variance           | 0.626        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 196          |\n|    n_updates                    | 3392         |\n|    policy_gradient_loss         | -0.00319     |\n|    value_loss                   | 433          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.59e+03     |\n|    water_produced               | 348          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 329        |\n| time/                           |            |\n|    fps                          | 854        |\n|    iterations                   | 1698       |\n|    time_elapsed                 | 7945       |\n|    total_timesteps              | 6792000    |\n| train/                          |            |\n|    approx_kl                    | 0.00559174 |\n|    clip_fraction                | 0.0305     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.752     |\n|    explained_variance           | 0.619      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 203        |\n|    n_updates                    | 3394       |\n|    policy_gradient_loss         | 0.00241    |\n|    value_loss                   | 454        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 159        |\n|    action_queue_updates_total   | 160        |\n|    ice_dug                      | 1.23e+03   |\n|    water_produced               | 281        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 306         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1699        |\n|    time_elapsed                 | 7949        |\n|    total_timesteps              | 6796000     |\n| train/                          |             |\n|    approx_kl                    | 0.004335175 |\n|    clip_fraction                | 0.0151      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.81       |\n|    explained_variance           | 0.698       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 184         |\n|    n_updates                    | 3396        |\n|    policy_gradient_loss         | -0.00113    |\n|    value_loss                   | 440         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 147         |\n|    action_queue_updates_total   | 153         |\n|    ice_dug                      | 1.11e+03    |\n|    water_produced               | 250         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 326         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1700        |\n|    time_elapsed                 | 7954        |\n|    total_timesteps              | 6800000     |\n| train/                          |             |\n|    approx_kl                    | 0.015937394 |\n|    clip_fraction                | 0.0857      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.875      |\n|    explained_variance           | 0.766       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 202         |\n|    n_updates                    | 3398        |\n|    policy_gradient_loss         | 0.00459     |\n|    value_loss                   | 420         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.37e+03    |\n|    water_produced               | 313         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 315          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1701         |\n|    time_elapsed                 | 7958         |\n|    total_timesteps              | 6804000      |\n| train/                          |              |\n|    approx_kl                    | 0.0044955513 |\n|    clip_fraction                | 0.0253       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.853       |\n|    explained_variance           | 0.664        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 234          |\n|    n_updates                    | 3400         |\n|    policy_gradient_loss         | -0.00198     |\n|    value_loss                   | 516          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.45e+03     |\n|    water_produced               | 314          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 324           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1702          |\n|    time_elapsed                 | 7963          |\n|    total_timesteps              | 6808000       |\n| train/                          |               |\n|    approx_kl                    | 0.00093055225 |\n|    clip_fraction                | 0.001         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.842        |\n|    explained_variance           | 0.73          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 278           |\n|    n_updates                    | 3402          |\n|    policy_gradient_loss         | -0.000495     |\n|    value_loss                   | 527           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 162           |\n|    action_queue_updates_total   | 166           |\n|    ice_dug                      | 1.71e+03      |\n|    water_produced               | 391           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 340          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1703         |\n|    time_elapsed                 | 7967         |\n|    total_timesteps              | 6812000      |\n| train/                          |              |\n|    approx_kl                    | 0.0074528405 |\n|    clip_fraction                | 0.0474       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.727       |\n|    explained_variance           | 0.517        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 282          |\n|    n_updates                    | 3404         |\n|    policy_gradient_loss         | 0.00397      |\n|    value_loss                   | 570          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.61e+03     |\n|    water_produced               | 360          |\n--------------------------------------------------\nEval num_timesteps=6816000, episode_reward=1384.96 +/- 1115.85\nEpisode length: 750.40 +/- 309.35\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 750         |\n|    mean_reward                  | 1.38e+03    |\n| time/                           |             |\n|    total_timesteps              | 6816000     |\n| train/                          |             |\n|    approx_kl                    | 0.007222506 |\n|    clip_fraction                | 0.0427      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.745      |\n|    explained_variance           | 0.619       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 224         |\n|    n_updates                    | 3406        |\n|    policy_gradient_loss         | 0.00464     |\n|    value_loss                   | 460         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.61e+03    |\n|    water_produced               | 363         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 364      |\n| time/              |          |\n|    fps             | 854      |\n|    iterations      | 1704     |\n|    time_elapsed    | 7977     |\n|    total_timesteps | 6816000  |\n---------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 359        |\n| time/                           |            |\n|    fps                          | 854        |\n|    iterations                   | 1705       |\n|    time_elapsed                 | 7981       |\n|    total_timesteps              | 6820000    |\n| train/                          |            |\n|    approx_kl                    | 0.00138089 |\n|    clip_fraction                | 0.00337    |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.801     |\n|    explained_variance           | 0.551      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 204        |\n|    n_updates                    | 3408       |\n|    policy_gradient_loss         | 0.00177    |\n|    value_loss                   | 440        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 149        |\n|    action_queue_updates_total   | 152        |\n|    ice_dug                      | 1.24e+03   |\n|    water_produced               | 289        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 358         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1706        |\n|    time_elapsed                 | 7986        |\n|    total_timesteps              | 6824000     |\n| train/                          |             |\n|    approx_kl                    | 0.004991217 |\n|    clip_fraction                | 0.0223      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.861      |\n|    explained_variance           | 0.701       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 184         |\n|    n_updates                    | 3410        |\n|    policy_gradient_loss         | -0.00162    |\n|    value_loss                   | 403         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.36e+03    |\n|    water_produced               | 309         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 370        |\n| time/                           |            |\n|    fps                          | 854        |\n|    iterations                   | 1707       |\n|    time_elapsed                 | 7990       |\n|    total_timesteps              | 6828000    |\n| train/                          |            |\n|    approx_kl                    | 0.00415833 |\n|    clip_fraction                | 0.0371     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.869     |\n|    explained_variance           | 0.47       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 228        |\n|    n_updates                    | 3412       |\n|    policy_gradient_loss         | -0.000525  |\n|    value_loss                   | 426        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 175        |\n|    action_queue_updates_total   | 175        |\n|    ice_dug                      | 1.91e+03   |\n|    water_produced               | 450        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 366         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1708        |\n|    time_elapsed                 | 7995        |\n|    total_timesteps              | 6832000     |\n| train/                          |             |\n|    approx_kl                    | 0.009069545 |\n|    clip_fraction                | 0.0459      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.765      |\n|    explained_variance           | 0.651       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 165         |\n|    n_updates                    | 3414        |\n|    policy_gradient_loss         | 0.00684     |\n|    value_loss                   | 387         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.54e+03    |\n|    water_produced               | 343         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 332          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1709         |\n|    time_elapsed                 | 7999         |\n|    total_timesteps              | 6836000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042210794 |\n|    clip_fraction                | 0.0243       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.783       |\n|    explained_variance           | 0.531        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 234          |\n|    n_updates                    | 3416         |\n|    policy_gradient_loss         | 0.00129      |\n|    value_loss                   | 483          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 146          |\n|    action_queue_updates_total   | 148          |\n|    ice_dug                      | 864          |\n|    water_produced               | 199          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 320         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1710        |\n|    time_elapsed                 | 8004        |\n|    total_timesteps              | 6840000     |\n| train/                          |             |\n|    approx_kl                    | 0.007573883 |\n|    clip_fraction                | 0.0419      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.843      |\n|    explained_variance           | 0.649       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 188         |\n|    n_updates                    | 3418        |\n|    policy_gradient_loss         | -0.00295    |\n|    value_loss                   | 456         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1e+03       |\n|    water_produced               | 232         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 346         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1711        |\n|    time_elapsed                 | 8008        |\n|    total_timesteps              | 6844000     |\n| train/                          |             |\n|    approx_kl                    | 0.024329599 |\n|    clip_fraction                | 0.176       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.928      |\n|    explained_variance           | 0.718       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 209         |\n|    n_updates                    | 3420        |\n|    policy_gradient_loss         | 0.00707     |\n|    value_loss                   | 481         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.84e+03    |\n|    water_produced               | 432         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 293          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1712         |\n|    time_elapsed                 | 8013         |\n|    total_timesteps              | 6848000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035274369 |\n|    clip_fraction                | 0.0164       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.769       |\n|    explained_variance           | 0.605        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 3422         |\n|    policy_gradient_loss         | 0.000329     |\n|    value_loss                   | 452          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 872          |\n|    water_produced               | 195          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 308          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1713         |\n|    time_elapsed                 | 8017         |\n|    total_timesteps              | 6852000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019139505 |\n|    clip_fraction                | 0.0075       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.871       |\n|    explained_variance           | 0.705        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 264          |\n|    n_updates                    | 3424         |\n|    policy_gradient_loss         | 0.00129      |\n|    value_loss                   | 596          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.76e+03     |\n|    water_produced               | 417          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 340           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1714          |\n|    time_elapsed                 | 8021          |\n|    total_timesteps              | 6856000       |\n| train/                          |               |\n|    approx_kl                    | 0.00077728386 |\n|    clip_fraction                | 0.00237       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.734        |\n|    explained_variance           | 0.638         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 211           |\n|    n_updates                    | 3426          |\n|    policy_gradient_loss         | -0.000244     |\n|    value_loss                   | 420           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 1.52e+03      |\n|    water_produced               | 353           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 368          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1715         |\n|    time_elapsed                 | 8026         |\n|    total_timesteps              | 6860000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010854249 |\n|    clip_fraction                | 0.005        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.73        |\n|    explained_variance           | 0.626        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 207          |\n|    n_updates                    | 3428         |\n|    policy_gradient_loss         | 0.00275      |\n|    value_loss                   | 411          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.56e+03     |\n|    water_produced               | 366          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 347          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1716         |\n|    time_elapsed                 | 8030         |\n|    total_timesteps              | 6864000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018152442 |\n|    clip_fraction                | 0.00462      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.781       |\n|    explained_variance           | 0.628        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 193          |\n|    n_updates                    | 3430         |\n|    policy_gradient_loss         | -0.00134     |\n|    value_loss                   | 423          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.52e+03     |\n|    water_produced               | 330          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 390          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1717         |\n|    time_elapsed                 | 8035         |\n|    total_timesteps              | 6868000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015896106 |\n|    clip_fraction                | 0.00838      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.788       |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 230          |\n|    n_updates                    | 3432         |\n|    policy_gradient_loss         | 8.33e-05     |\n|    value_loss                   | 471          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 401          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 384          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1718         |\n|    time_elapsed                 | 8039         |\n|    total_timesteps              | 6872000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024596616 |\n|    clip_fraction                | 0.00513      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.766       |\n|    explained_variance           | 0.624        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 3434         |\n|    policy_gradient_loss         | -0.000693    |\n|    value_loss                   | 403          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.8e+03      |\n|    water_produced               | 386          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 363         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1719        |\n|    time_elapsed                 | 8044        |\n|    total_timesteps              | 6876000     |\n| train/                          |             |\n|    approx_kl                    | 0.008160926 |\n|    clip_fraction                | 0.055       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.706      |\n|    explained_variance           | 0.565       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 251         |\n|    n_updates                    | 3436        |\n|    policy_gradient_loss         | 0.00489     |\n|    value_loss                   | 522         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 153         |\n|    ice_dug                      | 1.1e+03     |\n|    water_produced               | 253         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 342          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1720         |\n|    time_elapsed                 | 8048         |\n|    total_timesteps              | 6880000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032371874 |\n|    clip_fraction                | 0.0193       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.791       |\n|    explained_variance           | 0.684        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 3438         |\n|    policy_gradient_loss         | -0.000266    |\n|    value_loss                   | 505          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.14e+03     |\n|    water_produced               | 269          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 355         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1721        |\n|    time_elapsed                 | 8052        |\n|    total_timesteps              | 6884000     |\n| train/                          |             |\n|    approx_kl                    | 0.017526444 |\n|    clip_fraction                | 0.094       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.85       |\n|    explained_variance           | 0.67        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 241         |\n|    n_updates                    | 3440        |\n|    policy_gradient_loss         | 0.00374     |\n|    value_loss                   | 465         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 162         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.71e+03    |\n|    water_produced               | 393         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 348          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1722         |\n|    time_elapsed                 | 8057         |\n|    total_timesteps              | 6888000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010525708 |\n|    clip_fraction                | 0.00313      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.778       |\n|    explained_variance           | 0.615        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 3442         |\n|    policy_gradient_loss         | 0.000542     |\n|    value_loss                   | 427          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.62e+03     |\n|    water_produced               | 367          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 337         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1723        |\n|    time_elapsed                 | 8061        |\n|    total_timesteps              | 6892000     |\n| train/                          |             |\n|    approx_kl                    | 0.007251574 |\n|    clip_fraction                | 0.0361      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.74       |\n|    explained_variance           | 0.593       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 178         |\n|    n_updates                    | 3444        |\n|    policy_gradient_loss         | 0.0046      |\n|    value_loss                   | 373         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 150         |\n|    action_queue_updates_total   | 152         |\n|    ice_dug                      | 1.45e+03    |\n|    water_produced               | 333         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 364         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1724        |\n|    time_elapsed                 | 8066        |\n|    total_timesteps              | 6896000     |\n| train/                          |             |\n|    approx_kl                    | 0.006852679 |\n|    clip_fraction                | 0.0395      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.82       |\n|    explained_variance           | 0.656       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 155         |\n|    n_updates                    | 3446        |\n|    policy_gradient_loss         | -0.00389    |\n|    value_loss                   | 340         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.78e+03    |\n|    water_produced               | 382         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 358          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1725         |\n|    time_elapsed                 | 8071         |\n|    total_timesteps              | 6900000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035327703 |\n|    clip_fraction                | 0.0191       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.781       |\n|    explained_variance           | 0.615        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 229          |\n|    n_updates                    | 3448         |\n|    policy_gradient_loss         | -0.000491    |\n|    value_loss                   | 504          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.03e+03     |\n|    water_produced               | 239          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 327           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1726          |\n|    time_elapsed                 | 8075          |\n|    total_timesteps              | 6904000       |\n| train/                          |               |\n|    approx_kl                    | 0.00066881784 |\n|    clip_fraction                | 0.00462       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.826        |\n|    explained_variance           | 0.682         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 224           |\n|    n_updates                    | 3450          |\n|    policy_gradient_loss         | -0.000157     |\n|    value_loss                   | 525           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 159           |\n|    action_queue_updates_total   | 165           |\n|    ice_dug                      | 1.23e+03      |\n|    water_produced               | 245           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 296         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1727        |\n|    time_elapsed                 | 8079        |\n|    total_timesteps              | 6908000     |\n| train/                          |             |\n|    approx_kl                    | 0.013123935 |\n|    clip_fraction                | 0.0706      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.88       |\n|    explained_variance           | 0.624       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 247         |\n|    n_updates                    | 3452        |\n|    policy_gradient_loss         | -0.0013     |\n|    value_loss                   | 547         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.31e+03    |\n|    water_produced               | 213         |\n-------------------------------------------------\nEval num_timesteps=6912000, episode_reward=1294.80 +/- 1078.35\nEpisode length: 720.40 +/- 342.44\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 720         |\n|    mean_reward                  | 1.29e+03    |\n| time/                           |             |\n|    total_timesteps              | 6912000     |\n| train/                          |             |\n|    approx_kl                    | 0.015871756 |\n|    clip_fraction                | 0.113       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.894      |\n|    explained_variance           | 0.564       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 271         |\n|    n_updates                    | 3454        |\n|    policy_gradient_loss         | 0.00373     |\n|    value_loss                   | 571         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 1.86e+03    |\n|    water_produced               | 416         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 313      |\n| time/              |          |\n|    fps             | 854      |\n|    iterations      | 1728     |\n|    time_elapsed    | 8089     |\n|    total_timesteps | 6912000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 310          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1729         |\n|    time_elapsed                 | 8094         |\n|    total_timesteps              | 6916000      |\n| train/                          |              |\n|    approx_kl                    | 0.0060151406 |\n|    clip_fraction                | 0.0305       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.778       |\n|    explained_variance           | 0.441        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 242          |\n|    n_updates                    | 3456         |\n|    policy_gradient_loss         | -0.000566    |\n|    value_loss                   | 530          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.53e+03     |\n|    water_produced               | 369          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 327         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1730        |\n|    time_elapsed                 | 8098        |\n|    total_timesteps              | 6920000     |\n| train/                          |             |\n|    approx_kl                    | 0.007468945 |\n|    clip_fraction                | 0.0534      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.788      |\n|    explained_variance           | 0.72        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 273         |\n|    n_updates                    | 3458        |\n|    policy_gradient_loss         | 0.00185     |\n|    value_loss                   | 550         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.45e+03    |\n|    water_produced               | 320         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 342          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1731         |\n|    time_elapsed                 | 8103         |\n|    total_timesteps              | 6924000      |\n| train/                          |              |\n|    approx_kl                    | 0.0049582366 |\n|    clip_fraction                | 0.0259       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.813       |\n|    explained_variance           | 0.728        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 3460         |\n|    policy_gradient_loss         | -0.000475    |\n|    value_loss                   | 485          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.47e+03     |\n|    water_produced               | 316          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 372          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1732         |\n|    time_elapsed                 | 8107         |\n|    total_timesteps              | 6928000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017121207 |\n|    clip_fraction                | 0.00712      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.752       |\n|    explained_variance           | 0.604        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 260          |\n|    n_updates                    | 3462         |\n|    policy_gradient_loss         | -0.000387    |\n|    value_loss                   | 530          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.54e+03     |\n|    water_produced               | 361          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 332          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1733         |\n|    time_elapsed                 | 8112         |\n|    total_timesteps              | 6932000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021231784 |\n|    clip_fraction                | 0.00763      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.822       |\n|    explained_variance           | 0.705        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 240          |\n|    n_updates                    | 3464         |\n|    policy_gradient_loss         | -0.00136     |\n|    value_loss                   | 547          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.09e+03     |\n|    water_produced               | 223          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 334          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1734         |\n|    time_elapsed                 | 8116         |\n|    total_timesteps              | 6936000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050594076 |\n|    clip_fraction                | 0.0248       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.877       |\n|    explained_variance           | 0.677        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 304          |\n|    n_updates                    | 3466         |\n|    policy_gradient_loss         | -6.69e-05    |\n|    value_loss                   | 641          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.76e+03     |\n|    water_produced               | 376          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 345          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1735         |\n|    time_elapsed                 | 8121         |\n|    total_timesteps              | 6940000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028051992 |\n|    clip_fraction                | 0.0178       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.726       |\n|    explained_variance           | 0.424        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 249          |\n|    n_updates                    | 3468         |\n|    policy_gradient_loss         | -0.000292    |\n|    value_loss                   | 543          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.7e+03      |\n|    water_produced               | 372          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 347         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1736        |\n|    time_elapsed                 | 8125        |\n|    total_timesteps              | 6944000     |\n| train/                          |             |\n|    approx_kl                    | 0.010506945 |\n|    clip_fraction                | 0.0592      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.687      |\n|    explained_variance           | 0.469       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 234         |\n|    n_updates                    | 3470        |\n|    policy_gradient_loss         | 0.00508     |\n|    value_loss                   | 488         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 157         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.44e+03    |\n|    water_produced               | 328         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 330         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1737        |\n|    time_elapsed                 | 8130        |\n|    total_timesteps              | 6948000     |\n| train/                          |             |\n|    approx_kl                    | 0.006857544 |\n|    clip_fraction                | 0.0364      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.766      |\n|    explained_variance           | 0.604       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 247         |\n|    n_updates                    | 3472        |\n|    policy_gradient_loss         | 0.000158    |\n|    value_loss                   | 523         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.16e+03    |\n|    water_produced               | 277         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 332         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1738        |\n|    time_elapsed                 | 8135        |\n|    total_timesteps              | 6952000     |\n| train/                          |             |\n|    approx_kl                    | 0.005770045 |\n|    clip_fraction                | 0.0353      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.812      |\n|    explained_variance           | 0.72        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 225         |\n|    n_updates                    | 3474        |\n|    policy_gradient_loss         | 0.00242     |\n|    value_loss                   | 479         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.27e+03    |\n|    water_produced               | 236         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 274          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1739         |\n|    time_elapsed                 | 8139         |\n|    total_timesteps              | 6956000      |\n| train/                          |              |\n|    approx_kl                    | 0.0117766475 |\n|    clip_fraction                | 0.0779       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.864       |\n|    explained_variance           | 0.68         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 304          |\n|    n_updates                    | 3476         |\n|    policy_gradient_loss         | -0.000172    |\n|    value_loss                   | 597          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 399          |\n|    water_produced               | 98.5         |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 265         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1740        |\n|    time_elapsed                 | 8143        |\n|    total_timesteps              | 6960000     |\n| train/                          |             |\n|    approx_kl                    | 0.008689173 |\n|    clip_fraction                | 0.0425      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.08       |\n|    explained_variance           | 0.717       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 222         |\n|    n_updates                    | 3478        |\n|    policy_gradient_loss         | 0.000241    |\n|    value_loss                   | 547         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.52e+03    |\n|    water_produced               | 331         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 281          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1741         |\n|    time_elapsed                 | 8148         |\n|    total_timesteps              | 6964000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019216433 |\n|    clip_fraction                | 0.013        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.844       |\n|    explained_variance           | 0.726        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 309          |\n|    n_updates                    | 3480         |\n|    policy_gradient_loss         | -0.000409    |\n|    value_loss                   | 687          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.78e+03     |\n|    water_produced               | 404          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 282         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1742        |\n|    time_elapsed                 | 8153        |\n|    total_timesteps              | 6968000     |\n| train/                          |             |\n|    approx_kl                    | 0.015328604 |\n|    clip_fraction                | 0.0891      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.677      |\n|    explained_variance           | 0.49        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 266         |\n|    n_updates                    | 3482        |\n|    policy_gradient_loss         | 0.00487     |\n|    value_loss                   | 595         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.28e+03    |\n|    water_produced               | 276         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 292          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1743         |\n|    time_elapsed                 | 8157         |\n|    total_timesteps              | 6972000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030773918 |\n|    clip_fraction                | 0.0291       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.801       |\n|    explained_variance           | 0.72         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 302          |\n|    n_updates                    | 3484         |\n|    policy_gradient_loss         | 0.00091      |\n|    value_loss                   | 659          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.51e+03     |\n|    water_produced               | 284          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 355          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1744         |\n|    time_elapsed                 | 8162         |\n|    total_timesteps              | 6976000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021546935 |\n|    clip_fraction                | 0.00913      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.755       |\n|    explained_variance           | 0.499        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 321          |\n|    n_updates                    | 3486         |\n|    policy_gradient_loss         | -0.000995    |\n|    value_loss                   | 679          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.8e+03      |\n|    water_produced               | 399          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 357          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1745         |\n|    time_elapsed                 | 8166         |\n|    total_timesteps              | 6980000      |\n| train/                          |              |\n|    approx_kl                    | 0.0069268406 |\n|    clip_fraction                | 0.0341       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.67        |\n|    explained_variance           | 0.576        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 3488         |\n|    policy_gradient_loss         | 0.00473      |\n|    value_loss                   | 475          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 149          |\n|    ice_dug                      | 1.55e+03     |\n|    water_produced               | 343          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 342          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1746         |\n|    time_elapsed                 | 8170         |\n|    total_timesteps              | 6984000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010786306 |\n|    clip_fraction                | 0.00725      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.684       |\n|    explained_variance           | 0.615        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 3490         |\n|    policy_gradient_loss         | 0.0012       |\n|    value_loss                   | 474          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 143          |\n|    action_queue_updates_total   | 145          |\n|    ice_dug                      | 1.44e+03     |\n|    water_produced               | 330          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 364        |\n| time/                           |            |\n|    fps                          | 854        |\n|    iterations                   | 1747       |\n|    time_elapsed                 | 8175       |\n|    total_timesteps              | 6988000    |\n| train/                          |            |\n|    approx_kl                    | 0.01052726 |\n|    clip_fraction                | 0.0498     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.705     |\n|    explained_variance           | 0.601      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 198        |\n|    n_updates                    | 3492       |\n|    policy_gradient_loss         | -0.00347   |\n|    value_loss                   | 409        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 152        |\n|    action_queue_updates_total   | 156        |\n|    ice_dug                      | 1.68e+03   |\n|    water_produced               | 384        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 366          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1748         |\n|    time_elapsed                 | 8179         |\n|    total_timesteps              | 6992000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018410435 |\n|    clip_fraction                | 0.00675      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.716       |\n|    explained_variance           | 0.611        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 207          |\n|    n_updates                    | 3494         |\n|    policy_gradient_loss         | -0.000373    |\n|    value_loss                   | 410          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.35e+03     |\n|    water_produced               | 296          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 349          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1749         |\n|    time_elapsed                 | 8184         |\n|    total_timesteps              | 6996000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015203613 |\n|    clip_fraction                | 0.00463      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.752       |\n|    explained_variance           | 0.687        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 223          |\n|    n_updates                    | 3496         |\n|    policy_gradient_loss         | 0.000356     |\n|    value_loss                   | 457          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.42e+03     |\n|    water_produced               | 317          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 358         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1750        |\n|    time_elapsed                 | 8188        |\n|    total_timesteps              | 7000000     |\n| train/                          |             |\n|    approx_kl                    | 0.011723431 |\n|    clip_fraction                | 0.0566      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.821      |\n|    explained_variance           | 0.745       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 203         |\n|    n_updates                    | 3498        |\n|    policy_gradient_loss         | 0.000389    |\n|    value_loss                   | 399         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.84e+03    |\n|    water_produced               | 383         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 362         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1751        |\n|    time_elapsed                 | 8193        |\n|    total_timesteps              | 7004000     |\n| train/                          |             |\n|    approx_kl                    | 0.005645425 |\n|    clip_fraction                | 0.0346      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.724      |\n|    explained_variance           | 0.477       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 210         |\n|    n_updates                    | 3500        |\n|    policy_gradient_loss         | 0.00273     |\n|    value_loss                   | 441         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 1.55e+03    |\n|    water_produced               | 350         |\n-------------------------------------------------\nEval num_timesteps=7008000, episode_reward=1767.32 +/- 899.85\nEpisode length: 860.20 +/- 279.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 860          |\n|    mean_reward                  | 1.77e+03     |\n| time/                           |              |\n|    total_timesteps              | 7008000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011933817 |\n|    clip_fraction                | 0.00837      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.755       |\n|    explained_variance           | 0.622        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 3502         |\n|    policy_gradient_loss         | 0.00267      |\n|    value_loss                   | 437          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.22e+03     |\n|    water_produced               | 266          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 337      |\n| time/              |          |\n|    fps             | 854      |\n|    iterations      | 1752     |\n|    time_elapsed    | 8205     |\n|    total_timesteps | 7008000  |\n---------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 359        |\n| time/                           |            |\n|    fps                          | 854        |\n|    iterations                   | 1753       |\n|    time_elapsed                 | 8210       |\n|    total_timesteps              | 7012000    |\n| train/                          |            |\n|    approx_kl                    | 0.01377015 |\n|    clip_fraction                | 0.0806     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.872     |\n|    explained_variance           | 0.708      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 246        |\n|    n_updates                    | 3504       |\n|    policy_gradient_loss         | 0.00121    |\n|    value_loss                   | 495        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 167        |\n|    action_queue_updates_total   | 170        |\n|    ice_dug                      | 1.76e+03   |\n|    water_produced               | 400        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 345          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1754         |\n|    time_elapsed                 | 8214         |\n|    total_timesteps              | 7016000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016881961 |\n|    clip_fraction                | 0.00725      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.764       |\n|    explained_variance           | 0.542        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 3506         |\n|    policy_gradient_loss         | -0.000295    |\n|    value_loss                   | 474          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.24e+03     |\n|    water_produced               | 250          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 334           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1755          |\n|    time_elapsed                 | 8219          |\n|    total_timesteps              | 7020000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035483157 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.811        |\n|    explained_variance           | 0.718         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 257           |\n|    n_updates                    | 3508          |\n|    policy_gradient_loss         | 0.000739      |\n|    value_loss                   | 510           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 163           |\n|    action_queue_updates_total   | 169           |\n|    ice_dug                      | 1.4e+03       |\n|    water_produced               | 334           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 349         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1756        |\n|    time_elapsed                 | 8223        |\n|    total_timesteps              | 7024000     |\n| train/                          |             |\n|    approx_kl                    | 0.008024044 |\n|    clip_fraction                | 0.0554      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.814      |\n|    explained_variance           | 0.688       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 218         |\n|    n_updates                    | 3510        |\n|    policy_gradient_loss         | 0.00232     |\n|    value_loss                   | 456         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.88e+03    |\n|    water_produced               | 423         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 363          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1757         |\n|    time_elapsed                 | 8227         |\n|    total_timesteps              | 7028000      |\n| train/                          |              |\n|    approx_kl                    | 0.0048024664 |\n|    clip_fraction                | 0.0299       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.708       |\n|    explained_variance           | 0.398        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 311          |\n|    n_updates                    | 3512         |\n|    policy_gradient_loss         | 0.00172      |\n|    value_loss                   | 614          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.69e+03     |\n|    water_produced               | 332          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 342         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1758        |\n|    time_elapsed                 | 8232        |\n|    total_timesteps              | 7032000     |\n| train/                          |             |\n|    approx_kl                    | 0.008570497 |\n|    clip_fraction                | 0.0502      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.689      |\n|    explained_variance           | 0.545       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 229         |\n|    n_updates                    | 3514        |\n|    policy_gradient_loss         | 0.00247     |\n|    value_loss                   | 482         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 157         |\n|    ice_dug                      | 1.31e+03    |\n|    water_produced               | 298         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 343         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1759        |\n|    time_elapsed                 | 8236        |\n|    total_timesteps              | 7036000     |\n| train/                          |             |\n|    approx_kl                    | 0.008916021 |\n|    clip_fraction                | 0.054       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.769      |\n|    explained_variance           | 0.746       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 164         |\n|    n_updates                    | 3516        |\n|    policy_gradient_loss         | -0.00165    |\n|    value_loss                   | 386         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.42e+03    |\n|    water_produced               | 254         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 341         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1760        |\n|    time_elapsed                 | 8240        |\n|    total_timesteps              | 7040000     |\n| train/                          |             |\n|    approx_kl                    | 0.015358852 |\n|    clip_fraction                | 0.106       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.839      |\n|    explained_variance           | 0.677       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 298         |\n|    n_updates                    | 3518        |\n|    policy_gradient_loss         | 0.00449     |\n|    value_loss                   | 601         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.57e+03    |\n|    water_produced               | 321         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 339          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1761         |\n|    time_elapsed                 | 8245         |\n|    total_timesteps              | 7044000      |\n| train/                          |              |\n|    approx_kl                    | 0.0041353954 |\n|    clip_fraction                | 0.0196       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.764       |\n|    explained_variance           | 0.509        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 352          |\n|    n_updates                    | 3520         |\n|    policy_gradient_loss         | 0.00059      |\n|    value_loss                   | 744          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.8e+03      |\n|    water_produced               | 411          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 326         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1762        |\n|    time_elapsed                 | 8250        |\n|    total_timesteps              | 7048000     |\n| train/                          |             |\n|    approx_kl                    | 0.006463503 |\n|    clip_fraction                | 0.0334      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.66       |\n|    explained_variance           | 0.615       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 198         |\n|    n_updates                    | 3522        |\n|    policy_gradient_loss         | 0.00549     |\n|    value_loss                   | 435         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.17e+03    |\n|    water_produced               | 274         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 342           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1763          |\n|    time_elapsed                 | 8254          |\n|    total_timesteps              | 7052000       |\n| train/                          |               |\n|    approx_kl                    | 0.00060450693 |\n|    clip_fraction                | 0.00075       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.788        |\n|    explained_variance           | 0.819         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 284           |\n|    n_updates                    | 3524          |\n|    policy_gradient_loss         | 0.00158       |\n|    value_loss                   | 592           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 151           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 1.68e+03      |\n|    water_produced               | 372           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 357           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1764          |\n|    time_elapsed                 | 8258          |\n|    total_timesteps              | 7056000       |\n| train/                          |               |\n|    approx_kl                    | 0.00030290088 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.695        |\n|    explained_variance           | 0.598         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 212           |\n|    n_updates                    | 3526          |\n|    policy_gradient_loss         | -0.000831     |\n|    value_loss                   | 413           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 147           |\n|    action_queue_updates_total   | 151           |\n|    ice_dug                      | 1.5e+03       |\n|    water_produced               | 330           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 375         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1765        |\n|    time_elapsed                 | 8263        |\n|    total_timesteps              | 7060000     |\n| train/                          |             |\n|    approx_kl                    | 0.003911563 |\n|    clip_fraction                | 0.0203      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.741      |\n|    explained_variance           | 0.604       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 231         |\n|    n_updates                    | 3528        |\n|    policy_gradient_loss         | -0.00187    |\n|    value_loss                   | 461         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 1.79e+03    |\n|    water_produced               | 411         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 365          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1766         |\n|    time_elapsed                 | 8267         |\n|    total_timesteps              | 7064000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010657224 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.747       |\n|    explained_variance           | 0.589        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 3530         |\n|    policy_gradient_loss         | -0.000272    |\n|    value_loss                   | 409          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.53e+03     |\n|    water_produced               | 362          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 379         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1767        |\n|    time_elapsed                 | 8271        |\n|    total_timesteps              | 7068000     |\n| train/                          |             |\n|    approx_kl                    | 0.002418683 |\n|    clip_fraction                | 0.0148      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.767      |\n|    explained_variance           | 0.632       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 159         |\n|    n_updates                    | 3532        |\n|    policy_gradient_loss         | 0.000716    |\n|    value_loss                   | 344         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.65e+03    |\n|    water_produced               | 340         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 384          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1768         |\n|    time_elapsed                 | 8276         |\n|    total_timesteps              | 7072000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024067042 |\n|    clip_fraction                | 0.0112       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.803       |\n|    explained_variance           | 0.519        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 3534         |\n|    policy_gradient_loss         | -0.000513    |\n|    value_loss                   | 483          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.69e+03     |\n|    water_produced               | 397          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 374          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1769         |\n|    time_elapsed                 | 8280         |\n|    total_timesteps              | 7076000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033794884 |\n|    clip_fraction                | 0.0179       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.81        |\n|    explained_variance           | 0.639        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 157          |\n|    n_updates                    | 3536         |\n|    policy_gradient_loss         | 0.00417      |\n|    value_loss                   | 321          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.25e+03     |\n|    water_produced               | 280          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 362          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1770         |\n|    time_elapsed                 | 8285         |\n|    total_timesteps              | 7080000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032873661 |\n|    clip_fraction                | 0.0116       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.862       |\n|    explained_variance           | 0.594        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 217          |\n|    n_updates                    | 3538         |\n|    policy_gradient_loss         | 0.000416     |\n|    value_loss                   | 492          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.58e+03     |\n|    water_produced               | 352          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 335          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1771         |\n|    time_elapsed                 | 8289         |\n|    total_timesteps              | 7084000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028199058 |\n|    clip_fraction                | 0.0222       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.867       |\n|    explained_variance           | 0.558        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 167          |\n|    n_updates                    | 3540         |\n|    policy_gradient_loss         | -0.00385     |\n|    value_loss                   | 336          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.01e+03     |\n|    water_produced               | 234          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 343          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1772         |\n|    time_elapsed                 | 8293         |\n|    total_timesteps              | 7088000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019619707 |\n|    clip_fraction                | 0.0075       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.895       |\n|    explained_variance           | 0.667        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 227          |\n|    n_updates                    | 3542         |\n|    policy_gradient_loss         | -0.000512    |\n|    value_loss                   | 488          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.7e+03      |\n|    water_produced               | 378          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 331          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1773         |\n|    time_elapsed                 | 8298         |\n|    total_timesteps              | 7092000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012364872 |\n|    clip_fraction                | 0.00662      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.832       |\n|    explained_variance           | 0.586        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 3544         |\n|    policy_gradient_loss         | -0.00129     |\n|    value_loss                   | 403          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.61e+03     |\n|    water_produced               | 337          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 326          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1774         |\n|    time_elapsed                 | 8302         |\n|    total_timesteps              | 7096000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025431528 |\n|    clip_fraction                | 0.0133       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.798       |\n|    explained_variance           | 0.545        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 189          |\n|    n_updates                    | 3546         |\n|    policy_gradient_loss         | -4.71e-05    |\n|    value_loss                   | 439          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.33e+03     |\n|    water_produced               | 256          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 315         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1775        |\n|    time_elapsed                 | 8307        |\n|    total_timesteps              | 7100000     |\n| train/                          |             |\n|    approx_kl                    | 0.009241624 |\n|    clip_fraction                | 0.0601      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.828      |\n|    explained_variance           | 0.495       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 311         |\n|    n_updates                    | 3548        |\n|    policy_gradient_loss         | 0.00373     |\n|    value_loss                   | 629         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 162         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.27e+03    |\n|    water_produced               | 299         |\n-------------------------------------------------\nEval num_timesteps=7104000, episode_reward=2031.60 +/- 1023.95\nEpisode length: 860.20 +/- 279.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 860          |\n|    mean_reward                  | 2.03e+03     |\n| time/                           |              |\n|    total_timesteps              | 7104000      |\n| train/                          |              |\n|    approx_kl                    | 0.0076142894 |\n|    clip_fraction                | 0.0495       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.891       |\n|    explained_variance           | 0.746        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 237          |\n|    n_updates                    | 3550         |\n|    policy_gradient_loss         | 0.00183      |\n|    value_loss                   | 488          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.53e+03     |\n|    water_produced               | 334          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 336      |\n| time/              |          |\n|    fps             | 854      |\n|    iterations      | 1776     |\n|    time_elapsed    | 8317     |\n|    total_timesteps | 7104000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 339          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1777         |\n|    time_elapsed                 | 8321         |\n|    total_timesteps              | 7108000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033666857 |\n|    clip_fraction                | 0.0197       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.843       |\n|    explained_variance           | 0.765        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 272          |\n|    n_updates                    | 3552         |\n|    policy_gradient_loss         | -0.00199     |\n|    value_loss                   | 557          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.77e+03     |\n|    water_produced               | 396          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 358         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1778        |\n|    time_elapsed                 | 8326        |\n|    total_timesteps              | 7112000     |\n| train/                          |             |\n|    approx_kl                    | 0.005865093 |\n|    clip_fraction                | 0.0336      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.743      |\n|    explained_variance           | 0.527       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 273         |\n|    n_updates                    | 3554        |\n|    policy_gradient_loss         | 0.00138     |\n|    value_loss                   | 557         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.87e+03    |\n|    water_produced               | 428         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 372         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1779        |\n|    time_elapsed                 | 8330        |\n|    total_timesteps              | 7116000     |\n| train/                          |             |\n|    approx_kl                    | 0.012194996 |\n|    clip_fraction                | 0.0698      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.681      |\n|    explained_variance           | 0.548       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 213         |\n|    n_updates                    | 3556        |\n|    policy_gradient_loss         | 0.00596     |\n|    value_loss                   | 448         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 147         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 1.54e+03    |\n|    water_produced               | 322         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 349          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1780         |\n|    time_elapsed                 | 8334         |\n|    total_timesteps              | 7120000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029749747 |\n|    clip_fraction                | 0.0174       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.719       |\n|    explained_variance           | 0.612        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 224          |\n|    n_updates                    | 3558         |\n|    policy_gradient_loss         | -0.00123     |\n|    value_loss                   | 452          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 918          |\n|    water_produced               | 190          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 351         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1781        |\n|    time_elapsed                 | 8339        |\n|    total_timesteps              | 7124000     |\n| train/                          |             |\n|    approx_kl                    | 0.021105438 |\n|    clip_fraction                | 0.123       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.934      |\n|    explained_variance           | 0.666       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 242         |\n|    n_updates                    | 3560        |\n|    policy_gradient_loss         | 0.00606     |\n|    value_loss                   | 567         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.51e+03    |\n|    water_produced               | 342         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 334         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1782        |\n|    time_elapsed                 | 8344        |\n|    total_timesteps              | 7128000     |\n| train/                          |             |\n|    approx_kl                    | 0.016270922 |\n|    clip_fraction                | 0.0895      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.873      |\n|    explained_variance           | 0.733       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 251         |\n|    n_updates                    | 3562        |\n|    policy_gradient_loss         | 0.00606     |\n|    value_loss                   | 474         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.42e+03    |\n|    water_produced               | 317         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 297          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1783         |\n|    time_elapsed                 | 8348         |\n|    total_timesteps              | 7132000      |\n| train/                          |              |\n|    approx_kl                    | 0.0040542455 |\n|    clip_fraction                | 0.0175       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.865       |\n|    explained_variance           | 0.775        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 225          |\n|    n_updates                    | 3564         |\n|    policy_gradient_loss         | -0.00082     |\n|    value_loss                   | 466          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.11e+03     |\n|    water_produced               | 250          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 305         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1784        |\n|    time_elapsed                 | 8353        |\n|    total_timesteps              | 7136000     |\n| train/                          |             |\n|    approx_kl                    | 0.006578843 |\n|    clip_fraction                | 0.0366      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.956      |\n|    explained_variance           | 0.806       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 277         |\n|    n_updates                    | 3566        |\n|    policy_gradient_loss         | 0.000886    |\n|    value_loss                   | 532         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.75e+03    |\n|    water_produced               | 360         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 331           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1785          |\n|    time_elapsed                 | 8357          |\n|    total_timesteps              | 7140000       |\n| train/                          |               |\n|    approx_kl                    | 0.00085064955 |\n|    clip_fraction                | 0.001         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.758        |\n|    explained_variance           | 0.417         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 305           |\n|    n_updates                    | 3568          |\n|    policy_gradient_loss         | -0.000166     |\n|    value_loss                   | 648           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 170           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 1.42e+03      |\n|    water_produced               | 311           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 327          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1786         |\n|    time_elapsed                 | 8361         |\n|    total_timesteps              | 7144000      |\n| train/                          |              |\n|    approx_kl                    | 0.0065661324 |\n|    clip_fraction                | 0.0396       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.791       |\n|    explained_variance           | 0.586        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 310          |\n|    n_updates                    | 3570         |\n|    policy_gradient_loss         | 0.00123      |\n|    value_loss                   | 662          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 324          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 352          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1787         |\n|    time_elapsed                 | 8366         |\n|    total_timesteps              | 7148000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016405206 |\n|    clip_fraction                | 0.00663      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.851       |\n|    explained_variance           | 0.818        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 3572         |\n|    policy_gradient_loss         | -0.0011      |\n|    value_loss                   | 456          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.95e+03     |\n|    water_produced               | 436          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 391          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1788         |\n|    time_elapsed                 | 8370         |\n|    total_timesteps              | 7152000      |\n| train/                          |              |\n|    approx_kl                    | 0.0073078037 |\n|    clip_fraction                | 0.0475       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.706       |\n|    explained_variance           | 0.448        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 3574         |\n|    policy_gradient_loss         | 0.00244      |\n|    value_loss                   | 575          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 439          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 368         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1789        |\n|    time_elapsed                 | 8375        |\n|    total_timesteps              | 7156000     |\n| train/                          |             |\n|    approx_kl                    | 0.013382772 |\n|    clip_fraction                | 0.076       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.658      |\n|    explained_variance           | 0.602       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 195         |\n|    n_updates                    | 3576        |\n|    policy_gradient_loss         | 0.00688     |\n|    value_loss                   | 402         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 148         |\n|    ice_dug                      | 1.09e+03    |\n|    water_produced               | 254         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 334          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1790         |\n|    time_elapsed                 | 8379         |\n|    total_timesteps              | 7160000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008469241 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.761       |\n|    explained_variance           | 0.719        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 284          |\n|    n_updates                    | 3578         |\n|    policy_gradient_loss         | 0.000576     |\n|    value_loss                   | 560          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 661          |\n|    water_produced               | 146          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 301         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1791        |\n|    time_elapsed                 | 8383        |\n|    total_timesteps              | 7164000     |\n| train/                          |             |\n|    approx_kl                    | 0.031002874 |\n|    clip_fraction                | 0.167       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.999      |\n|    explained_variance           | 0.817       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 144         |\n|    n_updates                    | 3580        |\n|    policy_gradient_loss         | 0.0133      |\n|    value_loss                   | 402         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 761         |\n|    water_produced               | 166         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 289        |\n| time/                           |            |\n|    fps                          | 854        |\n|    iterations                   | 1792       |\n|    time_elapsed                 | 8388       |\n|    total_timesteps              | 7168000    |\n| train/                          |            |\n|    approx_kl                    | 0.04145104 |\n|    clip_fraction                | 0.191      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -1.01      |\n|    explained_variance           | 0.788      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 191        |\n|    n_updates                    | 3582       |\n|    policy_gradient_loss         | 0.0132     |\n|    value_loss                   | 449        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 166        |\n|    action_queue_updates_total   | 170        |\n|    ice_dug                      | 1.76e+03   |\n|    water_produced               | 380        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 277          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1793         |\n|    time_elapsed                 | 8392         |\n|    total_timesteps              | 7172000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013702672 |\n|    clip_fraction                | 0.00163      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.743       |\n|    explained_variance           | 0.475        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 299          |\n|    n_updates                    | 3584         |\n|    policy_gradient_loss         | -0.00018     |\n|    value_loss                   | 635          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 157          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.68e+03     |\n|    water_produced               | 382          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 313         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1794        |\n|    time_elapsed                 | 8397        |\n|    total_timesteps              | 7176000     |\n| train/                          |             |\n|    approx_kl                    | 0.011647785 |\n|    clip_fraction                | 0.0643      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.679      |\n|    explained_variance           | 0.414       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 248         |\n|    n_updates                    | 3586        |\n|    policy_gradient_loss         | 0.00253     |\n|    value_loss                   | 542         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.82e+03    |\n|    water_produced               | 427         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 350         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1795        |\n|    time_elapsed                 | 8401        |\n|    total_timesteps              | 7180000     |\n| train/                          |             |\n|    approx_kl                    | 0.011298404 |\n|    clip_fraction                | 0.0523      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.67       |\n|    explained_variance           | 0.606       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 218         |\n|    n_updates                    | 3588        |\n|    policy_gradient_loss         | 0.00557     |\n|    value_loss                   | 428         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 144         |\n|    action_queue_updates_total   | 147         |\n|    ice_dug                      | 1.52e+03    |\n|    water_produced               | 320         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 372          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1796         |\n|    time_elapsed                 | 8406         |\n|    total_timesteps              | 7184000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033684957 |\n|    clip_fraction                | 0.022        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.719       |\n|    explained_variance           | 0.546        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 227          |\n|    n_updates                    | 3590         |\n|    policy_gradient_loss         | -0.00136     |\n|    value_loss                   | 449          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.19e+03     |\n|    water_produced               | 271          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 354         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1797        |\n|    time_elapsed                 | 8410        |\n|    total_timesteps              | 7188000     |\n| train/                          |             |\n|    approx_kl                    | 0.021566179 |\n|    clip_fraction                | 0.0996      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.868      |\n|    explained_variance           | 0.763       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 186         |\n|    n_updates                    | 3592        |\n|    policy_gradient_loss         | 0.00348     |\n|    value_loss                   | 402         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.36e+03    |\n|    water_produced               | 294         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 341         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1798        |\n|    time_elapsed                 | 8415        |\n|    total_timesteps              | 7192000     |\n| train/                          |             |\n|    approx_kl                    | 0.007951142 |\n|    clip_fraction                | 0.052       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.85       |\n|    explained_variance           | 0.782       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 232         |\n|    n_updates                    | 3594        |\n|    policy_gradient_loss         | 0.00184     |\n|    value_loss                   | 448         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.39e+03    |\n|    water_produced               | 320         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 322          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1799         |\n|    time_elapsed                 | 8419         |\n|    total_timesteps              | 7196000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017702419 |\n|    clip_fraction                | 0.00787      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.833       |\n|    explained_variance           | 0.788        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 271          |\n|    n_updates                    | 3596         |\n|    policy_gradient_loss         | -0.000503    |\n|    value_loss                   | 537          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.44e+03     |\n|    water_produced               | 336          |\n--------------------------------------------------\nEval num_timesteps=7200000, episode_reward=2052.68 +/- 199.34\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.05e+03    |\n| time/                           |             |\n|    total_timesteps              | 7200000     |\n| train/                          |             |\n|    approx_kl                    | 0.004492572 |\n|    clip_fraction                | 0.0247      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.821      |\n|    explained_variance           | 0.713       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 286         |\n|    n_updates                    | 3598        |\n|    policy_gradient_loss         | -0.00114    |\n|    value_loss                   | 611         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.06e+03    |\n|    water_produced               | 238         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 305      |\n| time/              |          |\n|    fps             | 853      |\n|    iterations      | 1800     |\n|    time_elapsed    | 8432     |\n|    total_timesteps | 7200000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 324          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1801         |\n|    time_elapsed                 | 8437         |\n|    total_timesteps              | 7204000      |\n| train/                          |              |\n|    approx_kl                    | 0.0060331677 |\n|    clip_fraction                | 0.0388       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.823       |\n|    explained_variance           | 0.656        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 374          |\n|    n_updates                    | 3600         |\n|    policy_gradient_loss         | 0.00227      |\n|    value_loss                   | 677          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.59e+03     |\n|    water_produced               | 363          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 358         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1802        |\n|    time_elapsed                 | 8441        |\n|    total_timesteps              | 7208000     |\n| train/                          |             |\n|    approx_kl                    | 0.005749902 |\n|    clip_fraction                | 0.0356      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.777      |\n|    explained_variance           | 0.658       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 296         |\n|    n_updates                    | 3602        |\n|    policy_gradient_loss         | -0.000356   |\n|    value_loss                   | 613         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 162         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.97e+03    |\n|    water_produced               | 460         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 354         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1803        |\n|    time_elapsed                 | 8446        |\n|    total_timesteps              | 7212000     |\n| train/                          |             |\n|    approx_kl                    | 0.015488565 |\n|    clip_fraction                | 0.0671      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.611      |\n|    explained_variance           | 0.536       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 203         |\n|    n_updates                    | 3604        |\n|    policy_gradient_loss         | 0.00899     |\n|    value_loss                   | 455         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 1.5e+03     |\n|    water_produced               | 296         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 338           |\n| time/                           |               |\n|    fps                          | 853           |\n|    iterations                   | 1804          |\n|    time_elapsed                 | 8450          |\n|    total_timesteps              | 7216000       |\n| train/                          |               |\n|    approx_kl                    | 0.00096001837 |\n|    clip_fraction                | 0.0103        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.659        |\n|    explained_variance           | 0.597         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 296           |\n|    n_updates                    | 3606          |\n|    policy_gradient_loss         | 0.00204       |\n|    value_loss                   | 602           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 124           |\n|    action_queue_updates_total   | 126           |\n|    ice_dug                      | 1.19e+03      |\n|    water_produced               | 259           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 375         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1805        |\n|    time_elapsed                 | 8454        |\n|    total_timesteps              | 7220000     |\n| train/                          |             |\n|    approx_kl                    | 0.014064538 |\n|    clip_fraction                | 0.0561      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.681      |\n|    explained_variance           | 0.597       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 212         |\n|    n_updates                    | 3608        |\n|    policy_gradient_loss         | -0.00361    |\n|    value_loss                   | 464         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.82e+03    |\n|    water_produced               | 416         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 390          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1806         |\n|    time_elapsed                 | 8459         |\n|    total_timesteps              | 7224000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012376525 |\n|    clip_fraction                | 0.014        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.678       |\n|    explained_variance           | 0.594        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 234          |\n|    n_updates                    | 3610         |\n|    policy_gradient_loss         | -0.00136     |\n|    value_loss                   | 496          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 2e+03        |\n|    water_produced               | 432          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 355         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1807        |\n|    time_elapsed                 | 8463        |\n|    total_timesteps              | 7228000     |\n| train/                          |             |\n|    approx_kl                    | 0.010728252 |\n|    clip_fraction                | 0.0569      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.647      |\n|    explained_variance           | 0.422       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 279         |\n|    n_updates                    | 3612        |\n|    policy_gradient_loss         | 0.00563     |\n|    value_loss                   | 543         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 1.27e+03    |\n|    water_produced               | 295         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 365          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1808         |\n|    time_elapsed                 | 8468         |\n|    total_timesteps              | 7232000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005859484 |\n|    clip_fraction                | 0.00362      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.744       |\n|    explained_variance           | 0.793        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 3614         |\n|    policy_gradient_loss         | 0.00148      |\n|    value_loss                   | 434          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 150          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 1.58e+03     |\n|    water_produced               | 345          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 370          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1809         |\n|    time_elapsed                 | 8472         |\n|    total_timesteps              | 7236000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010774309 |\n|    clip_fraction                | 0.00637      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.74        |\n|    explained_variance           | 0.668        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 3616         |\n|    policy_gradient_loss         | -0.00133     |\n|    value_loss                   | 475          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 1.26e+03     |\n|    water_produced               | 285          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 359          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1810         |\n|    time_elapsed                 | 8477         |\n|    total_timesteps              | 7240000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020083599 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.778       |\n|    explained_variance           | 0.762        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 219          |\n|    n_updates                    | 3618         |\n|    policy_gradient_loss         | -0.00117     |\n|    value_loss                   | 439          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.59e+03     |\n|    water_produced               | 362          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 325           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1811          |\n|    time_elapsed                 | 8481          |\n|    total_timesteps              | 7244000       |\n| train/                          |               |\n|    approx_kl                    | 0.00083540427 |\n|    clip_fraction                | 0.00538       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.73         |\n|    explained_variance           | 0.542         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 197           |\n|    n_updates                    | 3620          |\n|    policy_gradient_loss         | -0.00127      |\n|    value_loss                   | 430           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 168           |\n|    action_queue_updates_total   | 170           |\n|    ice_dug                      | 1.16e+03      |\n|    water_produced               | 269           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 331         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1812        |\n|    time_elapsed                 | 8486        |\n|    total_timesteps              | 7248000     |\n| train/                          |             |\n|    approx_kl                    | 0.001798201 |\n|    clip_fraction                | 0.00963     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.864      |\n|    explained_variance           | 0.768       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 257         |\n|    n_updates                    | 3622        |\n|    policy_gradient_loss         | -0.000854   |\n|    value_loss                   | 542         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.55e+03    |\n|    water_produced               | 325         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 314         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1813        |\n|    time_elapsed                 | 8490        |\n|    total_timesteps              | 7252000     |\n| train/                          |             |\n|    approx_kl                    | 0.003994117 |\n|    clip_fraction                | 0.0286      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.828      |\n|    explained_variance           | 0.642       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 287         |\n|    n_updates                    | 3624        |\n|    policy_gradient_loss         | -0.000514   |\n|    value_loss                   | 576         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.2e+03     |\n|    water_produced               | 259         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 335         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1814        |\n|    time_elapsed                 | 8495        |\n|    total_timesteps              | 7256000     |\n| train/                          |             |\n|    approx_kl                    | 0.003029632 |\n|    clip_fraction                | 0.0152      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.887      |\n|    explained_variance           | 0.781       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 209         |\n|    n_updates                    | 3626        |\n|    policy_gradient_loss         | -0.00161    |\n|    value_loss                   | 488         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.77e+03    |\n|    water_produced               | 388         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 352           |\n| time/                           |               |\n|    fps                          | 854           |\n|    iterations                   | 1815          |\n|    time_elapsed                 | 8499          |\n|    total_timesteps              | 7260000       |\n| train/                          |               |\n|    approx_kl                    | 0.00034389948 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.753        |\n|    explained_variance           | 0.386         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 244           |\n|    n_updates                    | 3628          |\n|    policy_gradient_loss         | 7.45e-05      |\n|    value_loss                   | 538           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 167           |\n|    action_queue_updates_total   | 169           |\n|    ice_dug                      | 1.86e+03      |\n|    water_produced               | 442           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 363         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1816        |\n|    time_elapsed                 | 8504        |\n|    total_timesteps              | 7264000     |\n| train/                          |             |\n|    approx_kl                    | 0.012369645 |\n|    clip_fraction                | 0.0743      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.72       |\n|    explained_variance           | 0.603       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 204         |\n|    n_updates                    | 3630        |\n|    policy_gradient_loss         | 0.00743     |\n|    value_loss                   | 398         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 148         |\n|    action_queue_updates_total   | 153         |\n|    ice_dug                      | 1.44e+03    |\n|    water_produced               | 323         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 362         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1817        |\n|    time_elapsed                 | 8508        |\n|    total_timesteps              | 7268000     |\n| train/                          |             |\n|    approx_kl                    | 0.002174162 |\n|    clip_fraction                | 0.00862     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.785      |\n|    explained_variance           | 0.587       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 180         |\n|    n_updates                    | 3632        |\n|    policy_gradient_loss         | -0.000262   |\n|    value_loss                   | 371         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.44e+03    |\n|    water_produced               | 322         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 387         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1818        |\n|    time_elapsed                 | 8512        |\n|    total_timesteps              | 7272000     |\n| train/                          |             |\n|    approx_kl                    | 0.010688794 |\n|    clip_fraction                | 0.064       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.869      |\n|    explained_variance           | 0.697       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 230         |\n|    n_updates                    | 3634        |\n|    policy_gradient_loss         | 0.000855    |\n|    value_loss                   | 448         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.64e+03    |\n|    water_produced               | 380         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 381          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1819         |\n|    time_elapsed                 | 8517         |\n|    total_timesteps              | 7276000      |\n| train/                          |              |\n|    approx_kl                    | 0.0054029473 |\n|    clip_fraction                | 0.0275       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.783       |\n|    explained_variance           | 0.555        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 3636         |\n|    policy_gradient_loss         | 0.000607     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.6e+03      |\n|    water_produced               | 358          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 346         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1820        |\n|    time_elapsed                 | 8521        |\n|    total_timesteps              | 7280000     |\n| train/                          |             |\n|    approx_kl                    | 0.001814279 |\n|    clip_fraction                | 0.00988     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.763      |\n|    explained_variance           | 0.569       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 216         |\n|    n_updates                    | 3638        |\n|    policy_gradient_loss         | -0.000296   |\n|    value_loss                   | 432         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.32e+03    |\n|    water_produced               | 274         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 362         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1821        |\n|    time_elapsed                 | 8525        |\n|    total_timesteps              | 7284000     |\n| train/                          |             |\n|    approx_kl                    | 0.008968914 |\n|    clip_fraction                | 0.0516      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.881      |\n|    explained_variance           | 0.733       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 280         |\n|    n_updates                    | 3640        |\n|    policy_gradient_loss         | 0.00236     |\n|    value_loss                   | 595         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.74e+03    |\n|    water_produced               | 400         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 366          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1822         |\n|    time_elapsed                 | 8530         |\n|    total_timesteps              | 7288000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031319414 |\n|    clip_fraction                | 0.014        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.752       |\n|    explained_variance           | 0.663        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 217          |\n|    n_updates                    | 3642         |\n|    policy_gradient_loss         | 1.29e-05     |\n|    value_loss                   | 478          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 1.6e+03      |\n|    water_produced               | 340          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 365          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1823         |\n|    time_elapsed                 | 8535         |\n|    total_timesteps              | 7292000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035873323 |\n|    clip_fraction                | 0.026        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.686       |\n|    explained_variance           | 0.554        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 263          |\n|    n_updates                    | 3644         |\n|    policy_gradient_loss         | 0.00167      |\n|    value_loss                   | 508          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 148          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 1.67e+03     |\n|    water_produced               | 375          |\n--------------------------------------------------\nEval num_timesteps=7296000, episode_reward=2006.36 +/- 705.26\nEpisode length: 984.20 +/- 31.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 984          |\n|    mean_reward                  | 2.01e+03     |\n| time/                           |              |\n|    total_timesteps              | 7296000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020687494 |\n|    clip_fraction                | 0.0142       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.703       |\n|    explained_variance           | 0.597        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 179          |\n|    n_updates                    | 3646         |\n|    policy_gradient_loss         | -0.000505    |\n|    value_loss                   | 397          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.48e+03     |\n|    water_produced               | 337          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 361      |\n| time/              |          |\n|    fps             | 853      |\n|    iterations      | 1824     |\n|    time_elapsed    | 8547     |\n|    total_timesteps | 7296000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 348          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1825         |\n|    time_elapsed                 | 8551         |\n|    total_timesteps              | 7300000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028019845 |\n|    clip_fraction                | 0.0171       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.763       |\n|    explained_variance           | 0.531        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 3648         |\n|    policy_gradient_loss         | -0.000194    |\n|    value_loss                   | 425          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 982          |\n|    water_produced               | 213          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 324         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1826        |\n|    time_elapsed                 | 8556        |\n|    total_timesteps              | 7304000     |\n| train/                          |             |\n|    approx_kl                    | 0.022008784 |\n|    clip_fraction                | 0.137       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.918      |\n|    explained_variance           | 0.788       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 176         |\n|    n_updates                    | 3650        |\n|    policy_gradient_loss         | 0.005       |\n|    value_loss                   | 451         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.26e+03    |\n|    water_produced               | 285         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 310         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1827        |\n|    time_elapsed                 | 8560        |\n|    total_timesteps              | 7308000     |\n| train/                          |             |\n|    approx_kl                    | 0.011412609 |\n|    clip_fraction                | 0.0821      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.921      |\n|    explained_variance           | 0.796       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 294         |\n|    n_updates                    | 3652        |\n|    policy_gradient_loss         | 0.00152     |\n|    value_loss                   | 583         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.31e+03    |\n|    water_produced               | 273         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 327          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1828         |\n|    time_elapsed                 | 8565         |\n|    total_timesteps              | 7312000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033962638 |\n|    clip_fraction                | 0.0233       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.9         |\n|    explained_variance           | 0.774        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 382          |\n|    n_updates                    | 3654         |\n|    policy_gradient_loss         | -0.000859    |\n|    value_loss                   | 688          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 1.92e+03     |\n|    water_produced               | 458          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 338          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1829         |\n|    time_elapsed                 | 8569         |\n|    total_timesteps              | 7316000      |\n| train/                          |              |\n|    approx_kl                    | 0.0044361064 |\n|    clip_fraction                | 0.0254       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.728       |\n|    explained_variance           | 0.479        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 226          |\n|    n_updates                    | 3656         |\n|    policy_gradient_loss         | -0.000474    |\n|    value_loss                   | 536          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.73e+03     |\n|    water_produced               | 389          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 359         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1830        |\n|    time_elapsed                 | 8574        |\n|    total_timesteps              | 7320000     |\n| train/                          |             |\n|    approx_kl                    | 0.016900513 |\n|    clip_fraction                | 0.0924      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.715      |\n|    explained_variance           | 0.562       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 271         |\n|    n_updates                    | 3658        |\n|    policy_gradient_loss         | 0.00774     |\n|    value_loss                   | 547         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.35e+03    |\n|    water_produced               | 315         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 366          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1831         |\n|    time_elapsed                 | 8578         |\n|    total_timesteps              | 7324000      |\n| train/                          |              |\n|    approx_kl                    | 0.0065921703 |\n|    clip_fraction                | 0.0389       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.815       |\n|    explained_variance           | 0.745        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 295          |\n|    n_updates                    | 3660         |\n|    policy_gradient_loss         | 0.00106      |\n|    value_loss                   | 578          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.35e+03     |\n|    water_produced               | 320          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 370         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1832        |\n|    time_elapsed                 | 8582        |\n|    total_timesteps              | 7328000     |\n| train/                          |             |\n|    approx_kl                    | 0.011192235 |\n|    clip_fraction                | 0.0828      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.853      |\n|    explained_variance           | 0.77        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 227         |\n|    n_updates                    | 3662        |\n|    policy_gradient_loss         | 0.00373     |\n|    value_loss                   | 472         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.49e+03    |\n|    water_produced               | 292         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 356          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1833         |\n|    time_elapsed                 | 8587         |\n|    total_timesteps              | 7332000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027978579 |\n|    clip_fraction                | 0.0119       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.85        |\n|    explained_variance           | 0.746        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 3664         |\n|    policy_gradient_loss         | -0.00184     |\n|    value_loss                   | 507          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.73e+03     |\n|    water_produced               | 390          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 367         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1834        |\n|    time_elapsed                 | 8591        |\n|    total_timesteps              | 7336000     |\n| train/                          |             |\n|    approx_kl                    | 0.006330037 |\n|    clip_fraction                | 0.0337      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.73       |\n|    explained_variance           | 0.502       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 231         |\n|    n_updates                    | 3666        |\n|    policy_gradient_loss         | -0.000361   |\n|    value_loss                   | 534         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.93e+03    |\n|    water_produced               | 439         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 364         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1835        |\n|    time_elapsed                 | 8596        |\n|    total_timesteps              | 7340000     |\n| train/                          |             |\n|    approx_kl                    | 0.015564015 |\n|    clip_fraction                | 0.0741      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.667      |\n|    explained_variance           | 0.567       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 267         |\n|    n_updates                    | 3668        |\n|    policy_gradient_loss         | 0.00856     |\n|    value_loss                   | 516         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 1.26e+03    |\n|    water_produced               | 300         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 357         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1836        |\n|    time_elapsed                 | 8600        |\n|    total_timesteps              | 7344000     |\n| train/                          |             |\n|    approx_kl                    | 0.003919444 |\n|    clip_fraction                | 0.0181      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.816      |\n|    explained_variance           | 0.777       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 221         |\n|    n_updates                    | 3670        |\n|    policy_gradient_loss         | 0.00141     |\n|    value_loss                   | 472         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 1.23e+03    |\n|    water_produced               | 288         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 365         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1837        |\n|    time_elapsed                 | 8605        |\n|    total_timesteps              | 7348000     |\n| train/                          |             |\n|    approx_kl                    | 0.021951072 |\n|    clip_fraction                | 0.0892      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.895      |\n|    explained_variance           | 0.807       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 206         |\n|    n_updates                    | 3672        |\n|    policy_gradient_loss         | 0.00558     |\n|    value_loss                   | 384         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.41e+03    |\n|    water_produced               | 332         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 373          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1838         |\n|    time_elapsed                 | 8609         |\n|    total_timesteps              | 7352000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025982335 |\n|    clip_fraction                | 0.0149       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.85        |\n|    explained_variance           | 0.8          |\n|    learning_rate                | 0.0003       |\n|    loss                         | 252          |\n|    n_updates                    | 3674         |\n|    policy_gradient_loss         | 0.000704     |\n|    value_loss                   | 504          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.81e+03     |\n|    water_produced               | 430          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 342         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1839        |\n|    time_elapsed                 | 8613        |\n|    total_timesteps              | 7356000     |\n| train/                          |             |\n|    approx_kl                    | 0.008550893 |\n|    clip_fraction                | 0.0501      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.717      |\n|    explained_variance           | 0.553       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 203         |\n|    n_updates                    | 3676        |\n|    policy_gradient_loss         | 0.00427     |\n|    value_loss                   | 441         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 156         |\n|    ice_dug                      | 1.37e+03    |\n|    water_produced               | 289         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 358          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1840         |\n|    time_elapsed                 | 8618         |\n|    total_timesteps              | 7360000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019573246 |\n|    clip_fraction                | 0.009        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.786       |\n|    explained_variance           | 0.635        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 276          |\n|    n_updates                    | 3678         |\n|    policy_gradient_loss         | -0.00102     |\n|    value_loss                   | 603          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.61e+03     |\n|    water_produced               | 378          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 362          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1841         |\n|    time_elapsed                 | 8622         |\n|    total_timesteps              | 7364000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014700899 |\n|    clip_fraction                | 0.0141       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.752       |\n|    explained_variance           | 0.589        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 195          |\n|    n_updates                    | 3680         |\n|    policy_gradient_loss         | -0.00321     |\n|    value_loss                   | 406          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.4e+03      |\n|    water_produced               | 305          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 372          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1842         |\n|    time_elapsed                 | 8627         |\n|    total_timesteps              | 7368000      |\n| train/                          |              |\n|    approx_kl                    | 0.0055625397 |\n|    clip_fraction                | 0.0183       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.858       |\n|    explained_variance           | 0.718        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 254          |\n|    n_updates                    | 3682         |\n|    policy_gradient_loss         | 0.000826     |\n|    value_loss                   | 523          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.73e+03     |\n|    water_produced               | 379          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 339          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1843         |\n|    time_elapsed                 | 8631         |\n|    total_timesteps              | 7372000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024709902 |\n|    clip_fraction                | 0.0144       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.8         |\n|    explained_variance           | 0.501        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 3684         |\n|    policy_gradient_loss         | 0.00241      |\n|    value_loss                   | 418          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.21e+03     |\n|    water_produced               | 272          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 346          |\n| time/                           |              |\n|    fps                          | 854          |\n|    iterations                   | 1844         |\n|    time_elapsed                 | 8635         |\n|    total_timesteps              | 7376000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022001571 |\n|    clip_fraction                | 0.0174       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.885       |\n|    explained_variance           | 0.82         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 179          |\n|    n_updates                    | 3686         |\n|    policy_gradient_loss         | -0.000342    |\n|    value_loss                   | 435          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 322          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 363         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1845        |\n|    time_elapsed                 | 8640        |\n|    total_timesteps              | 7380000     |\n| train/                          |             |\n|    approx_kl                    | 0.017346947 |\n|    clip_fraction                | 0.0846      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.884      |\n|    explained_variance           | 0.775       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 205         |\n|    n_updates                    | 3688        |\n|    policy_gradient_loss         | 0.00435     |\n|    value_loss                   | 390         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.94e+03    |\n|    water_produced               | 462         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 380         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1846        |\n|    time_elapsed                 | 8644        |\n|    total_timesteps              | 7384000     |\n| train/                          |             |\n|    approx_kl                    | 0.005828592 |\n|    clip_fraction                | 0.0341      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.744      |\n|    explained_variance           | 0.567       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 215         |\n|    n_updates                    | 3690        |\n|    policy_gradient_loss         | 0.00126     |\n|    value_loss                   | 431         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.66e+03    |\n|    water_produced               | 384         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 382         |\n| time/                           |             |\n|    fps                          | 854         |\n|    iterations                   | 1847        |\n|    time_elapsed                 | 8649        |\n|    total_timesteps              | 7388000     |\n| train/                          |             |\n|    approx_kl                    | 0.003542963 |\n|    clip_fraction                | 0.0198      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.712      |\n|    explained_variance           | 0.564       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 229         |\n|    n_updates                    | 3692        |\n|    policy_gradient_loss         | 0.00154     |\n|    value_loss                   | 458         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 157         |\n|    ice_dug                      | 1.8e+03     |\n|    water_produced               | 393         |\n-------------------------------------------------\nEval num_timesteps=7392000, episode_reward=2210.00 +/- 1108.65\nEpisode length: 861.20 +/- 277.60\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 861           |\n|    mean_reward                  | 2.21e+03      |\n| time/                           |               |\n|    total_timesteps              | 7392000       |\n| train/                          |               |\n|    approx_kl                    | 0.00042992382 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.689        |\n|    explained_variance           | 0.594         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 205           |\n|    n_updates                    | 3694          |\n|    policy_gradient_loss         | -0.000242     |\n|    value_loss                   | 413           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 158           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 1.33e+03      |\n|    water_produced               | 310           |\n---------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 390      |\n| time/              |          |\n|    fps             | 853      |\n|    iterations      | 1848     |\n|    time_elapsed    | 8662     |\n|    total_timesteps | 7392000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 412          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1849         |\n|    time_elapsed                 | 8666         |\n|    total_timesteps              | 7396000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011059602 |\n|    clip_fraction                | 0.00613      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.745       |\n|    explained_variance           | 0.677        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 241          |\n|    n_updates                    | 3696         |\n|    policy_gradient_loss         | -0.000143    |\n|    value_loss                   | 520          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.89e+03     |\n|    water_produced               | 423          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 368          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1850         |\n|    time_elapsed                 | 8670         |\n|    total_timesteps              | 7400000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005861137 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.699       |\n|    explained_variance           | 0.622        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 3698         |\n|    policy_gradient_loss         | -0.00158     |\n|    value_loss                   | 416          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.2e+03      |\n|    water_produced               | 251          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 345         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1851        |\n|    time_elapsed                 | 8675        |\n|    total_timesteps              | 7404000     |\n| train/                          |             |\n|    approx_kl                    | 0.000853243 |\n|    clip_fraction                | 0.00388     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.81       |\n|    explained_variance           | 0.752       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 250         |\n|    n_updates                    | 3700        |\n|    policy_gradient_loss         | 3.62e-05    |\n|    value_loss                   | 554         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.25e+03    |\n|    water_produced               | 273         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 288         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1852        |\n|    time_elapsed                 | 8679        |\n|    total_timesteps              | 7408000     |\n| train/                          |             |\n|    approx_kl                    | 0.015654454 |\n|    clip_fraction                | 0.0785      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.864      |\n|    explained_variance           | 0.747       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 206         |\n|    n_updates                    | 3702        |\n|    policy_gradient_loss         | 0.00466     |\n|    value_loss                   | 471         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 601         |\n|    water_produced               | 121         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 289         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1853        |\n|    time_elapsed                 | 8684        |\n|    total_timesteps              | 7412000     |\n| train/                          |             |\n|    approx_kl                    | 0.010869188 |\n|    clip_fraction                | 0.0615      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.02       |\n|    explained_variance           | 0.808       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 219         |\n|    n_updates                    | 3704        |\n|    policy_gradient_loss         | 0.00144     |\n|    value_loss                   | 527         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.5e+03     |\n|    water_produced               | 310         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 267         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1854        |\n|    time_elapsed                 | 8688        |\n|    total_timesteps              | 7416000     |\n| train/                          |             |\n|    approx_kl                    | 0.003997194 |\n|    clip_fraction                | 0.0432      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.833      |\n|    explained_variance           | 0.76        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 296         |\n|    n_updates                    | 3706        |\n|    policy_gradient_loss         | 0.00287     |\n|    value_loss                   | 626         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.4e+03     |\n|    water_produced               | 321         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 296          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1855         |\n|    time_elapsed                 | 8693         |\n|    total_timesteps              | 7420000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011257909 |\n|    clip_fraction                | 0.00313      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.806       |\n|    explained_variance           | 0.826        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 3708         |\n|    policy_gradient_loss         | -0.000259    |\n|    value_loss                   | 528          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 388          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 294         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1856        |\n|    time_elapsed                 | 8698        |\n|    total_timesteps              | 7424000     |\n| train/                          |             |\n|    approx_kl                    | 0.003453759 |\n|    clip_fraction                | 0.0186      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.698      |\n|    explained_variance           | 0.509       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 243         |\n|    n_updates                    | 3710        |\n|    policy_gradient_loss         | 0.00019     |\n|    value_loss                   | 528         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.41e+03    |\n|    water_produced               | 266         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 361          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1857         |\n|    time_elapsed                 | 8702         |\n|    total_timesteps              | 7428000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006647896 |\n|    clip_fraction                | 0.00313      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.807       |\n|    explained_variance           | 0.724        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 372          |\n|    n_updates                    | 3712         |\n|    policy_gradient_loss         | 0.0012       |\n|    value_loss                   | 776          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.94e+03     |\n|    water_produced               | 439          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 369          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1858         |\n|    time_elapsed                 | 8707         |\n|    total_timesteps              | 7432000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008447468 |\n|    clip_fraction                | 0.00488      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.685       |\n|    explained_variance           | 0.528        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 263          |\n|    n_updates                    | 3714         |\n|    policy_gradient_loss         | 0.000553     |\n|    value_loss                   | 522          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.52e+03     |\n|    water_produced               | 350          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 388          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1859         |\n|    time_elapsed                 | 8711         |\n|    total_timesteps              | 7436000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018746965 |\n|    clip_fraction                | 0.00713      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.772       |\n|    explained_variance           | 0.806        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 220          |\n|    n_updates                    | 3716         |\n|    policy_gradient_loss         | 0.000232     |\n|    value_loss                   | 475          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.83e+03     |\n|    water_produced               | 411          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 377          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1860         |\n|    time_elapsed                 | 8716         |\n|    total_timesteps              | 7440000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013111073 |\n|    clip_fraction                | 0.00763      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.673       |\n|    explained_variance           | 0.57         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 240          |\n|    n_updates                    | 3718         |\n|    policy_gradient_loss         | 0.000529     |\n|    value_loss                   | 481          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 155          |\n|    ice_dug                      | 1.45e+03     |\n|    water_produced               | 338          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 372           |\n| time/                           |               |\n|    fps                          | 853           |\n|    iterations                   | 1861          |\n|    time_elapsed                 | 8720          |\n|    total_timesteps              | 7444000       |\n| train/                          |               |\n|    approx_kl                    | 0.00039709103 |\n|    clip_fraction                | 0.000625      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.717        |\n|    explained_variance           | 0.677         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 263           |\n|    n_updates                    | 3720          |\n|    policy_gradient_loss         | 0.000476      |\n|    value_loss                   | 496           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 152           |\n|    action_queue_updates_total   | 154           |\n|    ice_dug                      | 1.05e+03      |\n|    water_produced               | 244           |\n---------------------------------------------------\n-----------------------------------------------\n| rollout/                        |           |\n|    ep_len_mean                  | 200       |\n|    ep_rew_mean                  | 338       |\n| time/                           |           |\n|    fps                          | 853       |\n|    iterations                   | 1862      |\n|    time_elapsed                 | 8725      |\n|    total_timesteps              | 7448000   |\n| train/                          |           |\n|    approx_kl                    | 0.0238549 |\n|    clip_fraction                | 0.13      |\n|    clip_range                   | 0.2       |\n|    entropy_loss                 | -0.875    |\n|    explained_variance           | 0.779     |\n|    learning_rate                | 0.0003    |\n|    loss                         | 230       |\n|    n_updates                    | 3722      |\n|    policy_gradient_loss         | 0.0117    |\n|    value_loss                   | 529       |\n| train_metrics/                  |           |\n|    action_queue_updates_success | 163       |\n|    action_queue_updates_total   | 166       |\n|    ice_dug                      | 1.56e+03  |\n|    water_produced               | 274       |\n-----------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 356          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1863         |\n|    time_elapsed                 | 8730         |\n|    total_timesteps              | 7452000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030061703 |\n|    clip_fraction                | 0.0145       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.76        |\n|    explained_variance           | 0.546        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 412          |\n|    n_updates                    | 3724         |\n|    policy_gradient_loss         | 0.000245     |\n|    value_loss                   | 853          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.86e+03     |\n|    water_produced               | 437          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 331         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1864        |\n|    time_elapsed                 | 8735        |\n|    total_timesteps              | 7456000     |\n| train/                          |             |\n|    approx_kl                    | 0.012011486 |\n|    clip_fraction                | 0.0535      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.648      |\n|    explained_variance           | 0.534       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 222         |\n|    n_updates                    | 3726        |\n|    policy_gradient_loss         | 0.00463     |\n|    value_loss                   | 481         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 1.26e+03    |\n|    water_produced               | 291         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 317          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1865         |\n|    time_elapsed                 | 8739         |\n|    total_timesteps              | 7460000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013465241 |\n|    clip_fraction                | 0.0145       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.741       |\n|    explained_variance           | 0.79         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 271          |\n|    n_updates                    | 3728         |\n|    policy_gradient_loss         | 0.00344      |\n|    value_loss                   | 567          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 1.18e+03     |\n|    water_produced               | 273          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 344         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1866        |\n|    time_elapsed                 | 8744        |\n|    total_timesteps              | 7464000     |\n| train/                          |             |\n|    approx_kl                    | 0.018506609 |\n|    clip_fraction                | 0.0815      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.818      |\n|    explained_variance           | 0.799       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 229         |\n|    n_updates                    | 3730        |\n|    policy_gradient_loss         | 0.00312     |\n|    value_loss                   | 484         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 157         |\n|    ice_dug                      | 1.58e+03    |\n|    water_produced               | 372         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 370          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1867         |\n|    time_elapsed                 | 8748         |\n|    total_timesteps              | 7468000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015214118 |\n|    clip_fraction                | 0.00362      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.704       |\n|    explained_variance           | 0.589        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 362          |\n|    n_updates                    | 3732         |\n|    policy_gradient_loss         | 1.8e-05      |\n|    value_loss                   | 689          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 400          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 356         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1868        |\n|    time_elapsed                 | 8753        |\n|    total_timesteps              | 7472000     |\n| train/                          |             |\n|    approx_kl                    | 0.007383841 |\n|    clip_fraction                | 0.0355      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.655      |\n|    explained_variance           | 0.596       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 222         |\n|    n_updates                    | 3734        |\n|    policy_gradient_loss         | 0.00597     |\n|    value_loss                   | 466         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 145         |\n|    action_queue_updates_total   | 149         |\n|    ice_dug                      | 1.59e+03    |\n|    water_produced               | 371         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 353          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1869         |\n|    time_elapsed                 | 8758         |\n|    total_timesteps              | 7476000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050052614 |\n|    clip_fraction                | 0.0359       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.671       |\n|    explained_variance           | 0.593        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 239          |\n|    n_updates                    | 3736         |\n|    policy_gradient_loss         | 0.000458     |\n|    value_loss                   | 478          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 153          |\n|    action_queue_updates_total   | 156          |\n|    ice_dug                      | 1.23e+03     |\n|    water_produced               | 277          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 363         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1870        |\n|    time_elapsed                 | 8762        |\n|    total_timesteps              | 7480000     |\n| train/                          |             |\n|    approx_kl                    | 0.008880074 |\n|    clip_fraction                | 0.0275      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.823      |\n|    explained_variance           | 0.812       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 168         |\n|    n_updates                    | 3738        |\n|    policy_gradient_loss         | -0.00159    |\n|    value_loss                   | 414         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.41e+03    |\n|    water_produced               | 322         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 384        |\n| time/                           |            |\n|    fps                          | 853        |\n|    iterations                   | 1871       |\n|    time_elapsed                 | 8767       |\n|    total_timesteps              | 7484000    |\n| train/                          |            |\n|    approx_kl                    | 0.01813172 |\n|    clip_fraction                | 0.0835     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.866     |\n|    explained_variance           | 0.829      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 203        |\n|    n_updates                    | 3740       |\n|    policy_gradient_loss         | 0.00463    |\n|    value_loss                   | 410        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 173        |\n|    action_queue_updates_total   | 174        |\n|    ice_dug                      | 1.99e+03   |\n|    water_produced               | 472        |\n------------------------------------------------\nEval num_timesteps=7488000, episode_reward=2088.40 +/- 932.22\nEpisode length: 911.20 +/- 177.60\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 911         |\n|    mean_reward                  | 2.09e+03    |\n| time/                           |             |\n|    total_timesteps              | 7488000     |\n| train/                          |             |\n|    approx_kl                    | 0.007068388 |\n|    clip_fraction                | 0.0458      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.733      |\n|    explained_variance           | 0.591       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 183         |\n|    n_updates                    | 3742        |\n|    policy_gradient_loss         | 0.00545     |\n|    value_loss                   | 392         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 146         |\n|    action_queue_updates_total   | 153         |\n|    ice_dug                      | 1.51e+03    |\n|    water_produced               | 345         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 373      |\n| time/              |          |\n|    fps             | 852      |\n|    iterations      | 1872     |\n|    time_elapsed    | 8780     |\n|    total_timesteps | 7488000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 382          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1873         |\n|    time_elapsed                 | 8784         |\n|    total_timesteps              | 7492000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009378571 |\n|    clip_fraction                | 0.003        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.747       |\n|    explained_variance           | 0.679        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 207          |\n|    n_updates                    | 3744         |\n|    policy_gradient_loss         | 0.002        |\n|    value_loss                   | 430          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.83e+03     |\n|    water_produced               | 417          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 405          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1874         |\n|    time_elapsed                 | 8789         |\n|    total_timesteps              | 7496000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004565632 |\n|    clip_fraction                | 0.000875     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.753       |\n|    explained_variance           | 0.527        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 227          |\n|    n_updates                    | 3746         |\n|    policy_gradient_loss         | -0.000713    |\n|    value_loss                   | 452          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.62e+03     |\n|    water_produced               | 384          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 383          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1875         |\n|    time_elapsed                 | 8793         |\n|    total_timesteps              | 7500000      |\n| train/                          |              |\n|    approx_kl                    | 0.0041083014 |\n|    clip_fraction                | 0.0179       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.772       |\n|    explained_variance           | 0.534        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 182          |\n|    n_updates                    | 3748         |\n|    policy_gradient_loss         | 0.000845     |\n|    value_loss                   | 367          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.02e+03     |\n|    water_produced               | 219          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 357        |\n| time/                           |            |\n|    fps                          | 852        |\n|    iterations                   | 1876       |\n|    time_elapsed                 | 8798       |\n|    total_timesteps              | 7504000    |\n| train/                          |            |\n|    approx_kl                    | 0.03306794 |\n|    clip_fraction                | 0.16       |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.893     |\n|    explained_variance           | 0.735      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 238        |\n|    n_updates                    | 3750       |\n|    policy_gradient_loss         | 0.00849    |\n|    value_loss                   | 538        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 170        |\n|    action_queue_updates_total   | 176        |\n|    ice_dug                      | 1.45e+03   |\n|    water_produced               | 347        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 357         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1877        |\n|    time_elapsed                 | 8802        |\n|    total_timesteps              | 7508000     |\n| train/                          |             |\n|    approx_kl                    | 0.003720406 |\n|    clip_fraction                | 0.0253      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.853      |\n|    explained_variance           | 0.512       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 243         |\n|    n_updates                    | 3752        |\n|    policy_gradient_loss         | 0.00291     |\n|    value_loss                   | 500         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 1.86e+03    |\n|    water_produced               | 341         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 326         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1878        |\n|    time_elapsed                 | 8807        |\n|    total_timesteps              | 7512000     |\n| train/                          |             |\n|    approx_kl                    | 0.008887834 |\n|    clip_fraction                | 0.0377      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.771      |\n|    explained_variance           | 0.362       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 313         |\n|    n_updates                    | 3754        |\n|    policy_gradient_loss         | 9.9e-05     |\n|    value_loss                   | 643         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.19e+03    |\n|    water_produced               | 270         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 319         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1879        |\n|    time_elapsed                 | 8811        |\n|    total_timesteps              | 7516000     |\n| train/                          |             |\n|    approx_kl                    | 0.006077794 |\n|    clip_fraction                | 0.0379      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.841      |\n|    explained_variance           | 0.69        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 255         |\n|    n_updates                    | 3756        |\n|    policy_gradient_loss         | 0.0018      |\n|    value_loss                   | 594         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.63e+03    |\n|    water_produced               | 348         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 342          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1880         |\n|    time_elapsed                 | 8816         |\n|    total_timesteps              | 7520000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023270962 |\n|    clip_fraction                | 0.008        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.764       |\n|    explained_variance           | 0.515        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 260          |\n|    n_updates                    | 3758         |\n|    policy_gradient_loss         | -0.00124     |\n|    value_loss                   | 542          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.6e+03      |\n|    water_produced               | 326          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 337          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1881         |\n|    time_elapsed                 | 8821         |\n|    total_timesteps              | 7524000      |\n| train/                          |              |\n|    approx_kl                    | 0.0065833307 |\n|    clip_fraction                | 0.0386       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.732       |\n|    explained_variance           | 0.461        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 261          |\n|    n_updates                    | 3760         |\n|    policy_gradient_loss         | 0.00146      |\n|    value_loss                   | 561          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 324          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 352          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1882         |\n|    time_elapsed                 | 8825         |\n|    total_timesteps              | 7528000      |\n| train/                          |              |\n|    approx_kl                    | 0.0045523643 |\n|    clip_fraction                | 0.021        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.85        |\n|    explained_variance           | 0.78         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 217          |\n|    n_updates                    | 3762         |\n|    policy_gradient_loss         | -0.000123    |\n|    value_loss                   | 457          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.8e+03      |\n|    water_produced               | 416          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 378         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1883        |\n|    time_elapsed                 | 8829        |\n|    total_timesteps              | 7532000     |\n| train/                          |             |\n|    approx_kl                    | 0.004985839 |\n|    clip_fraction                | 0.0339      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.723      |\n|    explained_variance           | 0.574       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 199         |\n|    n_updates                    | 3764        |\n|    policy_gradient_loss         | 0.000112    |\n|    value_loss                   | 415         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.66e+03    |\n|    water_produced               | 393         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 388         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1884        |\n|    time_elapsed                 | 8834        |\n|    total_timesteps              | 7536000     |\n| train/                          |             |\n|    approx_kl                    | 0.007346508 |\n|    clip_fraction                | 0.0634      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.694      |\n|    explained_variance           | 0.56        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 238         |\n|    n_updates                    | 3766        |\n|    policy_gradient_loss         | 0.00126     |\n|    value_loss                   | 463         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 1.86e+03    |\n|    water_produced               | 397         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 373          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1885         |\n|    time_elapsed                 | 8838         |\n|    total_timesteps              | 7540000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020503323 |\n|    clip_fraction                | 0.0136       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.734       |\n|    explained_variance           | 0.571        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 3768         |\n|    policy_gradient_loss         | 0.000763     |\n|    value_loss                   | 455          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.1e+03      |\n|    water_produced               | 255          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 366          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1886         |\n|    time_elapsed                 | 8843         |\n|    total_timesteps              | 7544000      |\n| train/                          |              |\n|    approx_kl                    | 0.0068190754 |\n|    clip_fraction                | 0.039        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.869       |\n|    explained_variance           | 0.755        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 239          |\n|    n_updates                    | 3770         |\n|    policy_gradient_loss         | 0.00179      |\n|    value_loss                   | 516          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 289          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 358         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1887        |\n|    time_elapsed                 | 8848        |\n|    total_timesteps              | 7548000     |\n| train/                          |             |\n|    approx_kl                    | 0.018455362 |\n|    clip_fraction                | 0.102       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.884      |\n|    explained_variance           | 0.723       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 189         |\n|    n_updates                    | 3772        |\n|    policy_gradient_loss         | 0.00354     |\n|    value_loss                   | 428         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 177         |\n|    ice_dug                      | 1.72e+03    |\n|    water_produced               | 380         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 354         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1888        |\n|    time_elapsed                 | 8852        |\n|    total_timesteps              | 7552000     |\n| train/                          |             |\n|    approx_kl                    | 0.009632942 |\n|    clip_fraction                | 0.0695      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.772      |\n|    explained_variance           | 0.51        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 208         |\n|    n_updates                    | 3774        |\n|    policy_gradient_loss         | -0.00185    |\n|    value_loss                   | 423         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.63e+03    |\n|    water_produced               | 373         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 336         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1889        |\n|    time_elapsed                 | 8857        |\n|    total_timesteps              | 7556000     |\n| train/                          |             |\n|    approx_kl                    | 0.004204045 |\n|    clip_fraction                | 0.0294      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.789      |\n|    explained_variance           | 0.647       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 242         |\n|    n_updates                    | 3776        |\n|    policy_gradient_loss         | 0.00274     |\n|    value_loss                   | 522         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.33e+03    |\n|    water_produced               | 310         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 352         |\n| time/                           |             |\n|    fps                          | 853         |\n|    iterations                   | 1890        |\n|    time_elapsed                 | 8861        |\n|    total_timesteps              | 7560000     |\n| train/                          |             |\n|    approx_kl                    | 0.007130143 |\n|    clip_fraction                | 0.0408      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.838      |\n|    explained_variance           | 0.787       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 219         |\n|    n_updates                    | 3778        |\n|    policy_gradient_loss         | 0.00232     |\n|    value_loss                   | 439         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.61e+03    |\n|    water_produced               | 333         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 375          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1891         |\n|    time_elapsed                 | 8865         |\n|    total_timesteps              | 7564000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009817636 |\n|    clip_fraction                | 0.004        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.787       |\n|    explained_variance           | 0.559        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 3780         |\n|    policy_gradient_loss         | -0.000478    |\n|    value_loss                   | 528          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.7e+03      |\n|    water_produced               | 400          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 373          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1892         |\n|    time_elapsed                 | 8870         |\n|    total_timesteps              | 7568000      |\n| train/                          |              |\n|    approx_kl                    | 0.0052078594 |\n|    clip_fraction                | 0.0291       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.728       |\n|    explained_variance           | 0.511        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 210          |\n|    n_updates                    | 3782         |\n|    policy_gradient_loss         | 0.00136      |\n|    value_loss                   | 410          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.59e+03     |\n|    water_produced               | 373          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 355          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1893         |\n|    time_elapsed                 | 8874         |\n|    total_timesteps              | 7572000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016955526 |\n|    clip_fraction                | 0.0154       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.725       |\n|    explained_variance           | 0.717        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 3784         |\n|    policy_gradient_loss         | 0.000667     |\n|    value_loss                   | 409          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.65e+03     |\n|    water_produced               | 281          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 378          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1894         |\n|    time_elapsed                 | 8879         |\n|    total_timesteps              | 7576000      |\n| train/                          |              |\n|    approx_kl                    | 0.0057761194 |\n|    clip_fraction                | 0.0424       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.761       |\n|    explained_variance           | 0.529        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 283          |\n|    n_updates                    | 3786         |\n|    policy_gradient_loss         | -0.00118     |\n|    value_loss                   | 626          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.87e+03     |\n|    water_produced               | 420          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 374          |\n| time/                           |              |\n|    fps                          | 853          |\n|    iterations                   | 1895         |\n|    time_elapsed                 | 8883         |\n|    total_timesteps              | 7580000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033058662 |\n|    clip_fraction                | 0.0203       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.708       |\n|    explained_variance           | 0.504        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 346          |\n|    n_updates                    | 3788         |\n|    policy_gradient_loss         | 0.00137      |\n|    value_loss                   | 645          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.36e+03     |\n|    water_produced               | 315          |\n--------------------------------------------------\nEval num_timesteps=7584000, episode_reward=2475.44 +/- 242.15\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.48e+03    |\n| time/                           |             |\n|    total_timesteps              | 7584000     |\n| train/                          |             |\n|    approx_kl                    | 0.007672576 |\n|    clip_fraction                | 0.0581      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.824      |\n|    explained_variance           | 0.725       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 229         |\n|    n_updates                    | 3790        |\n|    policy_gradient_loss         | -0.000112   |\n|    value_loss                   | 491         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.39e+03    |\n|    water_produced               | 301         |\n-------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 354      |\n| time/              |          |\n|    fps             | 852      |\n|    iterations      | 1896     |\n|    time_elapsed    | 8895     |\n|    total_timesteps | 7584000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 355         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1897        |\n|    time_elapsed                 | 8900        |\n|    total_timesteps              | 7588000     |\n| train/                          |             |\n|    approx_kl                    | 0.008644991 |\n|    clip_fraction                | 0.0429      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.809      |\n|    explained_variance           | 0.59        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 201         |\n|    n_updates                    | 3792        |\n|    policy_gradient_loss         | 0.00139     |\n|    value_loss                   | 471         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 173         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.72e+03    |\n|    water_produced               | 380         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 356          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1898         |\n|    time_elapsed                 | 8904         |\n|    total_timesteps              | 7592000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042582406 |\n|    clip_fraction                | 0.023        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.787       |\n|    explained_variance           | 0.533        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 204          |\n|    n_updates                    | 3794         |\n|    policy_gradient_loss         | -0.00188     |\n|    value_loss                   | 445          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.31e+03     |\n|    water_produced               | 287          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 357           |\n| time/                           |               |\n|    fps                          | 852           |\n|    iterations                   | 1899          |\n|    time_elapsed                 | 8909          |\n|    total_timesteps              | 7596000       |\n| train/                          |               |\n|    approx_kl                    | 0.00088198774 |\n|    clip_fraction                | 0.00225       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.831        |\n|    explained_variance           | 0.764         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 223           |\n|    n_updates                    | 3796          |\n|    policy_gradient_loss         | -0.000574     |\n|    value_loss                   | 519           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 166           |\n|    action_queue_updates_total   | 169           |\n|    ice_dug                      | 1.88e+03      |\n|    water_produced               | 424           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 361          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1900         |\n|    time_elapsed                 | 8913         |\n|    total_timesteps              | 7600000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003133233 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.731       |\n|    explained_variance           | 0.539        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 3798         |\n|    policy_gradient_loss         | -0.000111    |\n|    value_loss                   | 480          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.5e+03      |\n|    water_produced               | 333          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 369          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1901         |\n|    time_elapsed                 | 8918         |\n|    total_timesteps              | 7604000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008527851 |\n|    clip_fraction                | 0.00175      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.836       |\n|    explained_variance           | 0.775        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 261          |\n|    n_updates                    | 3800         |\n|    policy_gradient_loss         | 0.00053      |\n|    value_loss                   | 547          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.48e+03     |\n|    water_produced               | 342          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 370         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1902        |\n|    time_elapsed                 | 8922        |\n|    total_timesteps              | 7608000     |\n| train/                          |             |\n|    approx_kl                    | 0.004761054 |\n|    clip_fraction                | 0.0314      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.819      |\n|    explained_variance           | 0.673       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 317         |\n|    n_updates                    | 3802        |\n|    policy_gradient_loss         | -0.000172   |\n|    value_loss                   | 596         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.79e+03    |\n|    water_produced               | 384         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 364         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1903        |\n|    time_elapsed                 | 8927        |\n|    total_timesteps              | 7612000     |\n| train/                          |             |\n|    approx_kl                    | 0.005201864 |\n|    clip_fraction                | 0.0279      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.738      |\n|    explained_variance           | 0.459       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 242         |\n|    n_updates                    | 3804        |\n|    policy_gradient_loss         | 0.0018      |\n|    value_loss                   | 481         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 154         |\n|    ice_dug                      | 1.23e+03    |\n|    water_produced               | 260         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 366          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1904         |\n|    time_elapsed                 | 8931         |\n|    total_timesteps              | 7616000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027498745 |\n|    clip_fraction                | 0.0135       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.763       |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 265          |\n|    n_updates                    | 3806         |\n|    policy_gradient_loss         | -0.00141     |\n|    value_loss                   | 584          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.86e+03     |\n|    water_produced               | 434          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 380          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1905         |\n|    time_elapsed                 | 8936         |\n|    total_timesteps              | 7620000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020787457 |\n|    clip_fraction                | 0.0131       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.749       |\n|    explained_variance           | 0.665        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 173          |\n|    n_updates                    | 3808         |\n|    policy_gradient_loss         | -0.000287    |\n|    value_loss                   | 343          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.7e+03      |\n|    water_produced               | 399          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 398          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1906         |\n|    time_elapsed                 | 8940         |\n|    total_timesteps              | 7624000      |\n| train/                          |              |\n|    approx_kl                    | 0.0039339866 |\n|    clip_fraction                | 0.0225       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.765       |\n|    explained_variance           | 0.677        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 140          |\n|    n_updates                    | 3810         |\n|    policy_gradient_loss         | -0.000833    |\n|    value_loss                   | 262          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.81e+03     |\n|    water_produced               | 427          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 361          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1907         |\n|    time_elapsed                 | 8945         |\n|    total_timesteps              | 7628000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012297953 |\n|    clip_fraction                | 0.00888      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.752       |\n|    explained_variance           | 0.704        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 162          |\n|    n_updates                    | 3812         |\n|    policy_gradient_loss         | 0.00064      |\n|    value_loss                   | 327          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.05e+03     |\n|    water_produced               | 206          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 377          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1908         |\n|    time_elapsed                 | 8949         |\n|    total_timesteps              | 7632000      |\n| train/                          |              |\n|    approx_kl                    | 0.0045383833 |\n|    clip_fraction                | 0.022        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.83        |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 320          |\n|    n_updates                    | 3814         |\n|    policy_gradient_loss         | 0.00233      |\n|    value_loss                   | 695          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.69e+03     |\n|    water_produced               | 335          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 371          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1909         |\n|    time_elapsed                 | 8954         |\n|    total_timesteps              | 7636000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027167695 |\n|    clip_fraction                | 0.0148       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.778       |\n|    explained_variance           | 0.458        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 248          |\n|    n_updates                    | 3816         |\n|    policy_gradient_loss         | -0.00172     |\n|    value_loss                   | 545          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.75e+03     |\n|    water_produced               | 408          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 343         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1910        |\n|    time_elapsed                 | 8958        |\n|    total_timesteps              | 7640000     |\n| train/                          |             |\n|    approx_kl                    | 0.006957788 |\n|    clip_fraction                | 0.0314      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.758      |\n|    explained_variance           | 0.629       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 167         |\n|    n_updates                    | 3818        |\n|    policy_gradient_loss         | 0.0024      |\n|    value_loss                   | 340         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 160         |\n|    ice_dug                      | 1.19e+03    |\n|    water_produced               | 264         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 330          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1911         |\n|    time_elapsed                 | 8963         |\n|    total_timesteps              | 7644000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022873108 |\n|    clip_fraction                | 0.0085       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.86        |\n|    explained_variance           | 0.741        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 3820         |\n|    policy_gradient_loss         | -0.000133    |\n|    value_loss                   | 518          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.64e+03     |\n|    water_produced               | 361          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 352          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1912         |\n|    time_elapsed                 | 8967         |\n|    total_timesteps              | 7648000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029661683 |\n|    clip_fraction                | 0.0193       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.833       |\n|    explained_variance           | 0.616        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 233          |\n|    n_updates                    | 3822         |\n|    policy_gradient_loss         | -0.000574    |\n|    value_loss                   | 463          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.38e+03     |\n|    water_produced               | 315          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 361          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1913         |\n|    time_elapsed                 | 8971         |\n|    total_timesteps              | 7652000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036300153 |\n|    clip_fraction                | 0.02         |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.854       |\n|    explained_variance           | 0.717        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 252          |\n|    n_updates                    | 3824         |\n|    policy_gradient_loss         | 0.000565     |\n|    value_loss                   | 496          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.85e+03     |\n|    water_produced               | 379          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 319           |\n| time/                           |               |\n|    fps                          | 852           |\n|    iterations                   | 1914          |\n|    time_elapsed                 | 8976          |\n|    total_timesteps              | 7656000       |\n| train/                          |               |\n|    approx_kl                    | 0.00055075996 |\n|    clip_fraction                | 0.00175       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.763        |\n|    explained_variance           | 0.394         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 289           |\n|    n_updates                    | 3826          |\n|    policy_gradient_loss         | -0.000148     |\n|    value_loss                   | 568           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 165           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 1.17e+03      |\n|    water_produced               | 202           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 328          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1915         |\n|    time_elapsed                 | 8981         |\n|    total_timesteps              | 7660000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004547388 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.821       |\n|    explained_variance           | 0.658        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 294          |\n|    n_updates                    | 3828         |\n|    policy_gradient_loss         | -0.00082     |\n|    value_loss                   | 675          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.32e+03     |\n|    water_produced               | 308          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 296         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1916        |\n|    time_elapsed                 | 8985        |\n|    total_timesteps              | 7664000     |\n| train/                          |             |\n|    approx_kl                    | 0.009346177 |\n|    clip_fraction                | 0.0586      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.861      |\n|    explained_variance           | 0.779       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 249         |\n|    n_updates                    | 3830        |\n|    policy_gradient_loss         | 0.00231     |\n|    value_loss                   | 458         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.1e+03     |\n|    water_produced               | 207         |\n-------------------------------------------------\n-----------------------------------------------\n| rollout/                        |           |\n|    ep_len_mean                  | 200       |\n|    ep_rew_mean                  | 316       |\n| time/                           |           |\n|    fps                          | 852       |\n|    iterations                   | 1917      |\n|    time_elapsed                 | 8989      |\n|    total_timesteps              | 7668000   |\n| train/                          |           |\n|    approx_kl                    | 0.0086782 |\n|    clip_fraction                | 0.0488    |\n|    clip_range                   | 0.2       |\n|    entropy_loss                 | -0.844    |\n|    explained_variance           | 0.71      |\n|    learning_rate                | 0.0003    |\n|    loss                         | 312       |\n|    n_updates                    | 3832      |\n|    policy_gradient_loss         | 0.00174   |\n|    value_loss                   | 647       |\n| train_metrics/                  |           |\n|    action_queue_updates_success | 177       |\n|    action_queue_updates_total   | 180       |\n|    ice_dug                      | 1.91e+03  |\n|    water_produced               | 413       |\n-----------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 323          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1918         |\n|    time_elapsed                 | 8994         |\n|    total_timesteps              | 7672000      |\n| train/                          |              |\n|    approx_kl                    | 0.0040014186 |\n|    clip_fraction                | 0.0209       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.779       |\n|    explained_variance           | 0.426        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 284          |\n|    n_updates                    | 3834         |\n|    policy_gradient_loss         | -0.000206    |\n|    value_loss                   | 586          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 2.02e+03     |\n|    water_produced               | 409          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 331        |\n| time/                           |            |\n|    fps                          | 852        |\n|    iterations                   | 1919       |\n|    time_elapsed                 | 8998       |\n|    total_timesteps              | 7676000    |\n| train/                          |            |\n|    approx_kl                    | 0.02037349 |\n|    clip_fraction                | 0.0915     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.674     |\n|    explained_variance           | 0.534      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 238        |\n|    n_updates                    | 3836       |\n|    policy_gradient_loss         | 0.00773    |\n|    value_loss                   | 459        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 159        |\n|    action_queue_updates_total   | 160        |\n|    ice_dug                      | 1.14e+03   |\n|    water_produced               | 246        |\n------------------------------------------------\nEval num_timesteps=7680000, episode_reward=2606.48 +/- 456.50\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.61e+03    |\n| time/                           |             |\n|    total_timesteps              | 7680000     |\n| train/                          |             |\n|    approx_kl                    | 0.004060439 |\n|    clip_fraction                | 0.0184      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.849      |\n|    explained_variance           | 0.755       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 268         |\n|    n_updates                    | 3838        |\n|    policy_gradient_loss         | -7.77e-05   |\n|    value_loss                   | 590         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.45e+03    |\n|    water_produced               | 326         |\n-------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 335      |\n| time/              |          |\n|    fps             | 852      |\n|    iterations      | 1920     |\n|    time_elapsed    | 9011     |\n|    total_timesteps | 7680000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 359         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1921        |\n|    time_elapsed                 | 9016        |\n|    total_timesteps              | 7684000     |\n| train/                          |             |\n|    approx_kl                    | 0.013103609 |\n|    clip_fraction                | 0.0922      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.852      |\n|    explained_variance           | 0.657       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 305         |\n|    n_updates                    | 3840        |\n|    policy_gradient_loss         | 0.00241     |\n|    value_loss                   | 588         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.55e+03    |\n|    water_produced               | 318         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 360          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1922         |\n|    time_elapsed                 | 9020         |\n|    total_timesteps              | 7688000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037845238 |\n|    clip_fraction                | 0.0187       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.831       |\n|    explained_variance           | 0.697        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 278          |\n|    n_updates                    | 3842         |\n|    policy_gradient_loss         | 0.000168     |\n|    value_loss                   | 610          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.91e+03     |\n|    water_produced               | 423          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 338        |\n| time/                           |            |\n|    fps                          | 852        |\n|    iterations                   | 1923       |\n|    time_elapsed                 | 9025       |\n|    total_timesteps              | 7692000    |\n| train/                          |            |\n|    approx_kl                    | 0.00476418 |\n|    clip_fraction                | 0.027      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.777     |\n|    explained_variance           | 0.53       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 237        |\n|    n_updates                    | 3844       |\n|    policy_gradient_loss         | 0.00155    |\n|    value_loss                   | 488        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 166        |\n|    action_queue_updates_total   | 167        |\n|    ice_dug                      | 1.39e+03   |\n|    water_produced               | 302        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 369          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1924         |\n|    time_elapsed                 | 9030         |\n|    total_timesteps              | 7696000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011959972 |\n|    clip_fraction                | 0.00225      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.845       |\n|    explained_variance           | 0.768        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 245          |\n|    n_updates                    | 3846         |\n|    policy_gradient_loss         | -0.000666    |\n|    value_loss                   | 499          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.72e+03     |\n|    water_produced               | 394          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 374          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1925         |\n|    time_elapsed                 | 9034         |\n|    total_timesteps              | 7700000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009859271 |\n|    clip_fraction                | 0.0015       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.806       |\n|    explained_variance           | 0.721        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 3848         |\n|    policy_gradient_loss         | -0.000217    |\n|    value_loss                   | 483          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 347          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 373          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1926         |\n|    time_elapsed                 | 9039         |\n|    total_timesteps              | 7704000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016949748 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.759       |\n|    explained_variance           | 0.555        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 245          |\n|    n_updates                    | 3850         |\n|    policy_gradient_loss         | 0.00134      |\n|    value_loss                   | 506          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.4e+03      |\n|    water_produced               | 317          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 333         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1927        |\n|    time_elapsed                 | 9044        |\n|    total_timesteps              | 7708000     |\n| train/                          |             |\n|    approx_kl                    | 0.008354526 |\n|    clip_fraction                | 0.0264      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.811      |\n|    explained_variance           | 0.745       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 203         |\n|    n_updates                    | 3852        |\n|    policy_gradient_loss         | -0.00192    |\n|    value_loss                   | 409         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.17e+03    |\n|    water_produced               | 231         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 365         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1928        |\n|    time_elapsed                 | 9048        |\n|    total_timesteps              | 7712000     |\n| train/                          |             |\n|    approx_kl                    | 0.012944216 |\n|    clip_fraction                | 0.057       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.91       |\n|    explained_variance           | 0.758       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 323         |\n|    n_updates                    | 3854        |\n|    policy_gradient_loss         | 0.00314     |\n|    value_loss                   | 699         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.94e+03    |\n|    water_produced               | 457         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 368         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1929        |\n|    time_elapsed                 | 9053        |\n|    total_timesteps              | 7716000     |\n| train/                          |             |\n|    approx_kl                    | 0.002165608 |\n|    clip_fraction                | 0.0104      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.746      |\n|    explained_variance           | 0.616       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 195         |\n|    n_updates                    | 3856        |\n|    policy_gradient_loss         | -0.000132   |\n|    value_loss                   | 427         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.76e+03    |\n|    water_produced               | 408         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 371         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1930        |\n|    time_elapsed                 | 9057        |\n|    total_timesteps              | 7720000     |\n| train/                          |             |\n|    approx_kl                    | 0.008796674 |\n|    clip_fraction                | 0.0601      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.696      |\n|    explained_variance           | 0.689       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 193         |\n|    n_updates                    | 3858        |\n|    policy_gradient_loss         | 0.00634     |\n|    value_loss                   | 384         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.63e+03    |\n|    water_produced               | 361         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 364          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1931         |\n|    time_elapsed                 | 9062         |\n|    total_timesteps              | 7724000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026227206 |\n|    clip_fraction                | 0.0126       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.77        |\n|    explained_variance           | 0.568        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 305          |\n|    n_updates                    | 3860         |\n|    policy_gradient_loss         | 3.84e-07     |\n|    value_loss                   | 587          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.32e+03     |\n|    water_produced               | 286          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 393         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1932        |\n|    time_elapsed                 | 9066        |\n|    total_timesteps              | 7728000     |\n| train/                          |             |\n|    approx_kl                    | 0.011015119 |\n|    clip_fraction                | 0.0607      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.792      |\n|    explained_variance           | 0.714       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 213         |\n|    n_updates                    | 3862        |\n|    policy_gradient_loss         | -0.000979   |\n|    value_loss                   | 455         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.55e+03    |\n|    water_produced               | 370         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 380          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1933         |\n|    time_elapsed                 | 9071         |\n|    total_timesteps              | 7732000      |\n| train/                          |              |\n|    approx_kl                    | 0.0122931935 |\n|    clip_fraction                | 0.069        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.823       |\n|    explained_variance           | 0.732        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 246          |\n|    n_updates                    | 3864         |\n|    policy_gradient_loss         | 0.0047       |\n|    value_loss                   | 463          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.72e+03     |\n|    water_produced               | 396          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 347         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1934        |\n|    time_elapsed                 | 9076        |\n|    total_timesteps              | 7736000     |\n| train/                          |             |\n|    approx_kl                    | 0.007733817 |\n|    clip_fraction                | 0.0446      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.729      |\n|    explained_variance           | 0.518       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 205         |\n|    n_updates                    | 3866        |\n|    policy_gradient_loss         | -0.000366   |\n|    value_loss                   | 443         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.21e+03    |\n|    water_produced               | 249         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 362          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1935         |\n|    time_elapsed                 | 9080         |\n|    total_timesteps              | 7740000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014586212 |\n|    clip_fraction                | 0.0124       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.855       |\n|    explained_variance           | 0.743        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 311          |\n|    n_updates                    | 3868         |\n|    policy_gradient_loss         | -0.000125    |\n|    value_loss                   | 691          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.92e+03     |\n|    water_produced               | 430          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 348          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1936         |\n|    time_elapsed                 | 9085         |\n|    total_timesteps              | 7744000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007599108 |\n|    clip_fraction                | 0.00387      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.75        |\n|    explained_variance           | 0.502        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 242          |\n|    n_updates                    | 3870         |\n|    policy_gradient_loss         | -0.000144    |\n|    value_loss                   | 529          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.06e+03     |\n|    water_produced               | 222          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 353          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1937         |\n|    time_elapsed                 | 9089         |\n|    total_timesteps              | 7748000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005363781 |\n|    clip_fraction                | 0.000875     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.877       |\n|    explained_variance           | 0.815        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 272          |\n|    n_updates                    | 3872         |\n|    policy_gradient_loss         | 0.000715     |\n|    value_loss                   | 600          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.83e+03     |\n|    water_produced               | 389          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 349          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1938         |\n|    time_elapsed                 | 9094         |\n|    total_timesteps              | 7752000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015586896 |\n|    clip_fraction                | 0.0085       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.739       |\n|    explained_variance           | 0.551        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 237          |\n|    n_updates                    | 3874         |\n|    policy_gradient_loss         | -0.00142     |\n|    value_loss                   | 476          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.72e+03     |\n|    water_produced               | 377          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 366          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1939         |\n|    time_elapsed                 | 9098         |\n|    total_timesteps              | 7756000      |\n| train/                          |              |\n|    approx_kl                    | 0.0053293956 |\n|    clip_fraction                | 0.0351       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.745       |\n|    explained_variance           | 0.574        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 268          |\n|    n_updates                    | 3876         |\n|    policy_gradient_loss         | 0.00388      |\n|    value_loss                   | 548          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.43e+03     |\n|    water_produced               | 333          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 347          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1940         |\n|    time_elapsed                 | 9103         |\n|    total_timesteps              | 7760000      |\n| train/                          |              |\n|    approx_kl                    | 0.0098836105 |\n|    clip_fraction                | 0.0557       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.845       |\n|    explained_variance           | 0.772        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 3878         |\n|    policy_gradient_loss         | 0.000167     |\n|    value_loss                   | 437          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 338          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 398         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1941        |\n|    time_elapsed                 | 9107        |\n|    total_timesteps              | 7764000     |\n| train/                          |             |\n|    approx_kl                    | 0.015249428 |\n|    clip_fraction                | 0.0765      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.902      |\n|    explained_variance           | 0.785       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 231         |\n|    n_updates                    | 3880        |\n|    policy_gradient_loss         | 0.0068      |\n|    value_loss                   | 464         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 1.98e+03    |\n|    water_produced               | 467         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 383         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1942        |\n|    time_elapsed                 | 9112        |\n|    total_timesteps              | 7768000     |\n| train/                          |             |\n|    approx_kl                    | 0.009058696 |\n|    clip_fraction                | 0.059       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.743      |\n|    explained_variance           | 0.59        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 164         |\n|    n_updates                    | 3882        |\n|    policy_gradient_loss         | 0.00513     |\n|    value_loss                   | 386         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.36e+03    |\n|    water_produced               | 324         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 379          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1943         |\n|    time_elapsed                 | 9116         |\n|    total_timesteps              | 7772000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011688629 |\n|    clip_fraction                | 0.00263      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.81        |\n|    explained_variance           | 0.794        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 3884         |\n|    policy_gradient_loss         | 0.00107      |\n|    value_loss                   | 474          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.89e+03     |\n|    water_produced               | 352          |\n--------------------------------------------------\nEval num_timesteps=7776000, episode_reward=1964.92 +/- 953.92\nEpisode length: 873.20 +/- 253.60\n---------------------------------------------------\n| eval/                           |               |\n|    mean_ep_length               | 873           |\n|    mean_reward                  | 1.96e+03      |\n| time/                           |               |\n|    total_timesteps              | 7776000       |\n| train/                          |               |\n|    approx_kl                    | 0.00059156434 |\n|    clip_fraction                | 0.00312       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.762        |\n|    explained_variance           | 0.534         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 372           |\n|    n_updates                    | 3886          |\n|    policy_gradient_loss         | 0.000378      |\n|    value_loss                   | 685           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 156           |\n|    action_queue_updates_total   | 162           |\n|    ice_dug                      | 1.72e+03      |\n|    water_produced               | 404           |\n---------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 394      |\n| time/              |          |\n|    fps             | 852      |\n|    iterations      | 1944     |\n|    time_elapsed    | 9126     |\n|    total_timesteps | 7776000  |\n---------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 395        |\n| time/                           |            |\n|    fps                          | 852        |\n|    iterations                   | 1945       |\n|    time_elapsed                 | 9130       |\n|    total_timesteps              | 7780000    |\n| train/                          |            |\n|    approx_kl                    | 0.00428027 |\n|    clip_fraction                | 0.0276     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.715     |\n|    explained_variance           | 0.636      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 182        |\n|    n_updates                    | 3888       |\n|    policy_gradient_loss         | 0.00478    |\n|    value_loss                   | 354        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 149        |\n|    action_queue_updates_total   | 152        |\n|    ice_dug                      | 1.51e+03   |\n|    water_produced               | 343        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 360          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1946         |\n|    time_elapsed                 | 9135         |\n|    total_timesteps              | 7784000      |\n| train/                          |              |\n|    approx_kl                    | 0.0056377454 |\n|    clip_fraction                | 0.0245       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.773       |\n|    explained_variance           | 0.583        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 3890         |\n|    policy_gradient_loss         | -0.00234     |\n|    value_loss                   | 369          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.32e+03     |\n|    water_produced               | 300          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 352         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1947        |\n|    time_elapsed                 | 9140        |\n|    total_timesteps              | 7788000     |\n| train/                          |             |\n|    approx_kl                    | 0.018297581 |\n|    clip_fraction                | 0.0949      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.891      |\n|    explained_variance           | 0.72        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 253         |\n|    n_updates                    | 3892        |\n|    policy_gradient_loss         | 0.0055      |\n|    value_loss                   | 537         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.43e+03    |\n|    water_produced               | 280         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 343         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1948        |\n|    time_elapsed                 | 9144        |\n|    total_timesteps              | 7792000     |\n| train/                          |             |\n|    approx_kl                    | 0.013641131 |\n|    clip_fraction                | 0.0748      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.881      |\n|    explained_variance           | 0.63        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 267         |\n|    n_updates                    | 3894        |\n|    policy_gradient_loss         | 0.00291     |\n|    value_loss                   | 619         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.44e+03    |\n|    water_produced               | 315         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 329          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1949         |\n|    time_elapsed                 | 9149         |\n|    total_timesteps              | 7796000      |\n| train/                          |              |\n|    approx_kl                    | 0.0044570076 |\n|    clip_fraction                | 0.0302       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.856       |\n|    explained_variance           | 0.83         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 257          |\n|    n_updates                    | 3896         |\n|    policy_gradient_loss         | -0.000933    |\n|    value_loss                   | 476          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.64e+03     |\n|    water_produced               | 334          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 325         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1950        |\n|    time_elapsed                 | 9153        |\n|    total_timesteps              | 7800000     |\n| train/                          |             |\n|    approx_kl                    | 0.008937414 |\n|    clip_fraction                | 0.0467      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.758      |\n|    explained_variance           | 0.47        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 363         |\n|    n_updates                    | 3898        |\n|    policy_gradient_loss         | 0.00205     |\n|    value_loss                   | 737         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.4e+03     |\n|    water_produced               | 324         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 333          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1951         |\n|    time_elapsed                 | 9157         |\n|    total_timesteps              | 7804000      |\n| train/                          |              |\n|    approx_kl                    | 0.0048430786 |\n|    clip_fraction                | 0.0421       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.793       |\n|    explained_variance           | 0.757        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 306          |\n|    n_updates                    | 3900         |\n|    policy_gradient_loss         | 0.00237      |\n|    value_loss                   | 599          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 340          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 362          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1952         |\n|    time_elapsed                 | 9162         |\n|    total_timesteps              | 7808000      |\n| train/                          |              |\n|    approx_kl                    | 0.0051242285 |\n|    clip_fraction                | 0.0263       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.805       |\n|    explained_variance           | 0.819        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 250          |\n|    n_updates                    | 3902         |\n|    policy_gradient_loss         | -0.000819    |\n|    value_loss                   | 525          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 159          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.84e+03     |\n|    water_produced               | 417          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 374        |\n| time/                           |            |\n|    fps                          | 852        |\n|    iterations                   | 1953       |\n|    time_elapsed                 | 9166       |\n|    total_timesteps              | 7812000    |\n| train/                          |            |\n|    approx_kl                    | 0.00537381 |\n|    clip_fraction                | 0.0399     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.691     |\n|    explained_variance           | 0.599      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 185        |\n|    n_updates                    | 3904       |\n|    policy_gradient_loss         | 0.00578    |\n|    value_loss                   | 390        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 153        |\n|    action_queue_updates_total   | 156        |\n|    ice_dug                      | 1.71e+03   |\n|    water_produced               | 373        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 344          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1954         |\n|    time_elapsed                 | 9171         |\n|    total_timesteps              | 7816000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038363182 |\n|    clip_fraction                | 0.0182       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.719       |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 3906         |\n|    policy_gradient_loss         | 0.000234     |\n|    value_loss                   | 501          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 919          |\n|    water_produced               | 191          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 363         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1955        |\n|    time_elapsed                 | 9175        |\n|    total_timesteps              | 7820000     |\n| train/                          |             |\n|    approx_kl                    | 0.019743374 |\n|    clip_fraction                | 0.11        |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.925      |\n|    explained_variance           | 0.809       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 276         |\n|    n_updates                    | 3908        |\n|    policy_gradient_loss         | 0.00482     |\n|    value_loss                   | 570         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.88e+03    |\n|    water_produced               | 416         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 385          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1956         |\n|    time_elapsed                 | 9180         |\n|    total_timesteps              | 7824000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012750446 |\n|    clip_fraction                | 0.00487      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.718       |\n|    explained_variance           | 0.494        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 252          |\n|    n_updates                    | 3910         |\n|    policy_gradient_loss         | -0.000783    |\n|    value_loss                   | 506          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.92e+03     |\n|    water_produced               | 446          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 385         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1957        |\n|    time_elapsed                 | 9184        |\n|    total_timesteps              | 7828000     |\n| train/                          |             |\n|    approx_kl                    | 0.016801473 |\n|    clip_fraction                | 0.0771      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.662      |\n|    explained_variance           | 0.625       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 223         |\n|    n_updates                    | 3912        |\n|    policy_gradient_loss         | 0.00614     |\n|    value_loss                   | 441         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 156         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.77e+03    |\n|    water_produced               | 417         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 361         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1958        |\n|    time_elapsed                 | 9189        |\n|    total_timesteps              | 7832000     |\n| train/                          |             |\n|    approx_kl                    | 0.005155462 |\n|    clip_fraction                | 0.0389      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.689      |\n|    explained_variance           | 0.668       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 177         |\n|    n_updates                    | 3914        |\n|    policy_gradient_loss         | 0.00329     |\n|    value_loss                   | 375         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 162         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.19e+03    |\n|    water_produced               | 260         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 398         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1959        |\n|    time_elapsed                 | 9193        |\n|    total_timesteps              | 7836000     |\n| train/                          |             |\n|    approx_kl                    | 0.018513847 |\n|    clip_fraction                | 0.101       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.856      |\n|    explained_variance           | 0.731       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 199         |\n|    n_updates                    | 3916        |\n|    policy_gradient_loss         | 0.00461     |\n|    value_loss                   | 475         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.59e+03    |\n|    water_produced               | 368         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 391         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1960        |\n|    time_elapsed                 | 9198        |\n|    total_timesteps              | 7840000     |\n| train/                          |             |\n|    approx_kl                    | 0.004608997 |\n|    clip_fraction                | 0.0315      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.829      |\n|    explained_variance           | 0.569       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 205         |\n|    n_updates                    | 3918        |\n|    policy_gradient_loss         | 0.000791    |\n|    value_loss                   | 456         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.61e+03    |\n|    water_produced               | 383         |\n-------------------------------------------------\n-----------------------------------------------\n| rollout/                        |           |\n|    ep_len_mean                  | 200       |\n|    ep_rew_mean                  | 353       |\n| time/                           |           |\n|    fps                          | 852       |\n|    iterations                   | 1961      |\n|    time_elapsed                 | 9202      |\n|    total_timesteps              | 7844000   |\n| train/                          |           |\n|    approx_kl                    | 0.0024462 |\n|    clip_fraction                | 0.00937   |\n|    clip_range                   | 0.2       |\n|    entropy_loss                 | -0.778    |\n|    explained_variance           | 0.634     |\n|    learning_rate                | 0.0003    |\n|    loss                         | 173       |\n|    n_updates                    | 3920      |\n|    policy_gradient_loss         | 0.00164   |\n|    value_loss                   | 374       |\n| train_metrics/                  |           |\n|    action_queue_updates_success | 164       |\n|    action_queue_updates_total   | 167       |\n|    ice_dug                      | 1.31e+03  |\n|    water_produced               | 264       |\n-----------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 356          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1962         |\n|    time_elapsed                 | 9207         |\n|    total_timesteps              | 7848000      |\n| train/                          |              |\n|    approx_kl                    | 0.0061669056 |\n|    clip_fraction                | 0.0324       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.79        |\n|    explained_variance           | 0.675        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 248          |\n|    n_updates                    | 3922         |\n|    policy_gradient_loss         | -0.00153     |\n|    value_loss                   | 531          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.84e+03     |\n|    water_produced               | 431          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 373          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1963         |\n|    time_elapsed                 | 9211         |\n|    total_timesteps              | 7852000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030539758 |\n|    clip_fraction                | 0.0168       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.723       |\n|    explained_variance           | 0.593        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 3924         |\n|    policy_gradient_loss         | 0.000853     |\n|    value_loss                   | 415          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 342          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 363          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1964         |\n|    time_elapsed                 | 9216         |\n|    total_timesteps              | 7856000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006748262 |\n|    clip_fraction                | 0.00175      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.796       |\n|    explained_variance           | 0.803        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 3926         |\n|    policy_gradient_loss         | 0.000228     |\n|    value_loss                   | 471          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.37e+03     |\n|    water_produced               | 316          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 342        |\n| time/                           |            |\n|    fps                          | 852        |\n|    iterations                   | 1965       |\n|    time_elapsed                 | 9220       |\n|    total_timesteps              | 7860000    |\n| train/                          |            |\n|    approx_kl                    | 0.01370422 |\n|    clip_fraction                | 0.0809     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.812     |\n|    explained_variance           | 0.769      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 267        |\n|    n_updates                    | 3928       |\n|    policy_gradient_loss         | 0.00415    |\n|    value_loss                   | 535        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 163        |\n|    action_queue_updates_total   | 168        |\n|    ice_dug                      | 1.33e+03   |\n|    water_produced               | 281        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 373          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1966         |\n|    time_elapsed                 | 9225         |\n|    total_timesteps              | 7864000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021599294 |\n|    clip_fraction                | 0.0145       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.864       |\n|    explained_variance           | 0.826        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 251          |\n|    n_updates                    | 3930         |\n|    policy_gradient_loss         | -0.00104     |\n|    value_loss                   | 514          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 416          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 349         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1967        |\n|    time_elapsed                 | 9230        |\n|    total_timesteps              | 7868000     |\n| train/                          |             |\n|    approx_kl                    | 0.002799375 |\n|    clip_fraction                | 0.0181      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.724      |\n|    explained_variance           | 0.47        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 257         |\n|    n_updates                    | 3932        |\n|    policy_gradient_loss         | 0.000953    |\n|    value_loss                   | 502         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.4e+03     |\n|    water_produced               | 314         |\n-------------------------------------------------\nEval num_timesteps=7872000, episode_reward=2522.68 +/- 185.96\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.52e+03    |\n| time/                           |             |\n|    total_timesteps              | 7872000     |\n| train/                          |             |\n|    approx_kl                    | 0.000999334 |\n|    clip_fraction                | 0.00337     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.841      |\n|    explained_variance           | 0.849       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 218         |\n|    n_updates                    | 3934        |\n|    policy_gradient_loss         | 0.00132     |\n|    value_loss                   | 455         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.84e+03    |\n|    water_produced               | 424         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 366      |\n| time/              |          |\n|    fps             | 851      |\n|    iterations      | 1968     |\n|    time_elapsed    | 9242     |\n|    total_timesteps | 7872000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 390          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 1969         |\n|    time_elapsed                 | 9246         |\n|    total_timesteps              | 7876000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006636847 |\n|    clip_fraction                | 0.00262      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.731       |\n|    explained_variance           | 0.603        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 3936         |\n|    policy_gradient_loss         | 0.000317     |\n|    value_loss                   | 403          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 434          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 385         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1970        |\n|    time_elapsed                 | 9251        |\n|    total_timesteps              | 7880000     |\n| train/                          |             |\n|    approx_kl                    | 0.010140918 |\n|    clip_fraction                | 0.058       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.712      |\n|    explained_variance           | 0.578       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 204         |\n|    n_updates                    | 3938        |\n|    policy_gradient_loss         | 0.00557     |\n|    value_loss                   | 422         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.25e+03    |\n|    water_produced               | 256         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 371         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1971        |\n|    time_elapsed                 | 9255        |\n|    total_timesteps              | 7884000     |\n| train/                          |             |\n|    approx_kl                    | 0.005556274 |\n|    clip_fraction                | 0.028       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.852      |\n|    explained_variance           | 0.767       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 267         |\n|    n_updates                    | 3940        |\n|    policy_gradient_loss         | -0.000138   |\n|    value_loss                   | 543         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.5e+03     |\n|    water_produced               | 351         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 378          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 1972         |\n|    time_elapsed                 | 9260         |\n|    total_timesteps              | 7888000      |\n| train/                          |              |\n|    approx_kl                    | 0.0047904616 |\n|    clip_fraction                | 0.033        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.842       |\n|    explained_variance           | 0.563        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 3942         |\n|    policy_gradient_loss         | 0.000897     |\n|    value_loss                   | 460          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 343          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 359         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1973        |\n|    time_elapsed                 | 9264        |\n|    total_timesteps              | 7892000     |\n| train/                          |             |\n|    approx_kl                    | 0.008066228 |\n|    clip_fraction                | 0.0362      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.764      |\n|    explained_variance           | 0.519       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 304         |\n|    n_updates                    | 3944        |\n|    policy_gradient_loss         | 0.00409     |\n|    value_loss                   | 633         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.4e+03     |\n|    water_produced               | 332         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 327          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 1974         |\n|    time_elapsed                 | 9269         |\n|    total_timesteps              | 7896000      |\n| train/                          |              |\n|    approx_kl                    | 0.0034408257 |\n|    clip_fraction                | 0.0204       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.837       |\n|    explained_variance           | 0.819        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 3946         |\n|    policy_gradient_loss         | 0.000364     |\n|    value_loss                   | 384          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 160          |\n|    ice_dug                      | 1.2e+03      |\n|    water_produced               | 284          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 361         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1975        |\n|    time_elapsed                 | 9273        |\n|    total_timesteps              | 7900000     |\n| train/                          |             |\n|    approx_kl                    | 0.018562028 |\n|    clip_fraction                | 0.0729      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.843      |\n|    explained_variance           | 0.811       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 137         |\n|    n_updates                    | 3948        |\n|    policy_gradient_loss         | -0.000649   |\n|    value_loss                   | 367         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.87e+03    |\n|    water_produced               | 420         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 375          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 1976         |\n|    time_elapsed                 | 9277         |\n|    total_timesteps              | 7904000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016886799 |\n|    clip_fraction                | 0.00862      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.755       |\n|    explained_variance           | 0.495        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 257          |\n|    n_updates                    | 3950         |\n|    policy_gradient_loss         | 0.0011       |\n|    value_loss                   | 555          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.8e+03      |\n|    water_produced               | 416          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 374          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 1977         |\n|    time_elapsed                 | 9282         |\n|    total_timesteps              | 7908000      |\n| train/                          |              |\n|    approx_kl                    | 0.0063379914 |\n|    clip_fraction                | 0.0411       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.764       |\n|    explained_variance           | 0.671        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 230          |\n|    n_updates                    | 3952         |\n|    policy_gradient_loss         | 0.00321      |\n|    value_loss                   | 514          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 338          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 370         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1978        |\n|    time_elapsed                 | 9286        |\n|    total_timesteps              | 7912000     |\n| train/                          |             |\n|    approx_kl                    | 0.009610927 |\n|    clip_fraction                | 0.0474      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.821      |\n|    explained_variance           | 0.813       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 180         |\n|    n_updates                    | 3954        |\n|    policy_gradient_loss         | -0.00016    |\n|    value_loss                   | 384         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.31e+03    |\n|    water_produced               | 312         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 384         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1979        |\n|    time_elapsed                 | 9291        |\n|    total_timesteps              | 7916000     |\n| train/                          |             |\n|    approx_kl                    | 0.012092674 |\n|    clip_fraction                | 0.0773      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.883      |\n|    explained_variance           | 0.8         |\n|    learning_rate                | 0.0003      |\n|    loss                         | 205         |\n|    n_updates                    | 3956        |\n|    policy_gradient_loss         | 0.00919     |\n|    value_loss                   | 501         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.46e+03    |\n|    water_produced               | 353         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 386          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 1980         |\n|    time_elapsed                 | 9295         |\n|    total_timesteps              | 7920000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024159688 |\n|    clip_fraction                | 0.00988      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.824       |\n|    explained_variance           | 0.86         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 241          |\n|    n_updates                    | 3958         |\n|    policy_gradient_loss         | 0.000296     |\n|    value_loss                   | 450          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.85e+03     |\n|    water_produced               | 431          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 373         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1981        |\n|    time_elapsed                 | 9300        |\n|    total_timesteps              | 7924000     |\n| train/                          |             |\n|    approx_kl                    | 0.009646703 |\n|    clip_fraction                | 0.0576      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.683      |\n|    explained_variance           | 0.599       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 192         |\n|    n_updates                    | 3960        |\n|    policy_gradient_loss         | 0.00416     |\n|    value_loss                   | 425         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.52e+03    |\n|    water_produced               | 354         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 367          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1982         |\n|    time_elapsed                 | 9304         |\n|    total_timesteps              | 7928000      |\n| train/                          |              |\n|    approx_kl                    | 0.0074303187 |\n|    clip_fraction                | 0.0379       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.704       |\n|    explained_variance           | 0.653        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 346          |\n|    n_updates                    | 3962         |\n|    policy_gradient_loss         | 0.00371      |\n|    value_loss                   | 722          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 147          |\n|    action_queue_updates_total   | 153          |\n|    ice_dug                      | 1.33e+03     |\n|    water_produced               | 310          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 372          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1983         |\n|    time_elapsed                 | 9309         |\n|    total_timesteps              | 7932000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035929903 |\n|    clip_fraction                | 0.0222       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.773       |\n|    explained_variance           | 0.666        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 268          |\n|    n_updates                    | 3964         |\n|    policy_gradient_loss         | 8.59e-05     |\n|    value_loss                   | 492          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.42e+03     |\n|    water_produced               | 335          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 371         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 1984        |\n|    time_elapsed                 | 9313        |\n|    total_timesteps              | 7936000     |\n| train/                          |             |\n|    approx_kl                    | 0.011326131 |\n|    clip_fraction                | 0.0608      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.843      |\n|    explained_variance           | 0.869       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 190         |\n|    n_updates                    | 3966        |\n|    policy_gradient_loss         | 0.00213     |\n|    value_loss                   | 405         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.5e+03     |\n|    water_produced               | 349         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 370          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1985         |\n|    time_elapsed                 | 9318         |\n|    total_timesteps              | 7940000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024185977 |\n|    clip_fraction                | 0.0107       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.875       |\n|    explained_variance           | 0.847        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 301          |\n|    n_updates                    | 3968         |\n|    policy_gradient_loss         | -0.00111     |\n|    value_loss                   | 567          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.87e+03     |\n|    water_produced               | 423          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 366          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1986         |\n|    time_elapsed                 | 9322         |\n|    total_timesteps              | 7944000      |\n| train/                          |              |\n|    approx_kl                    | 0.0063770623 |\n|    clip_fraction                | 0.0355       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.692       |\n|    explained_variance           | 0.449        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 234          |\n|    n_updates                    | 3970         |\n|    policy_gradient_loss         | 0.00377      |\n|    value_loss                   | 478          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 338          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 367          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1987         |\n|    time_elapsed                 | 9327         |\n|    total_timesteps              | 7948000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008291608 |\n|    clip_fraction                | 0.00463      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.779       |\n|    explained_variance           | 0.796        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 308          |\n|    n_updates                    | 3972         |\n|    policy_gradient_loss         | 0.000197     |\n|    value_loss                   | 597          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 316          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 379        |\n| time/                           |            |\n|    fps                          | 852        |\n|    iterations                   | 1988       |\n|    time_elapsed                 | 9331       |\n|    total_timesteps              | 7952000    |\n| train/                          |            |\n|    approx_kl                    | 0.02051478 |\n|    clip_fraction                | 0.11       |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.85      |\n|    explained_variance           | 0.83       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 275        |\n|    n_updates                    | 3974       |\n|    policy_gradient_loss         | 0.00507    |\n|    value_loss                   | 551        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 163        |\n|    action_queue_updates_total   | 166        |\n|    ice_dug                      | 1.89e+03   |\n|    water_produced               | 389        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 359          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1989         |\n|    time_elapsed                 | 9336         |\n|    total_timesteps              | 7956000      |\n| train/                          |              |\n|    approx_kl                    | 0.0044641523 |\n|    clip_fraction                | 0.0221       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.678       |\n|    explained_variance           | 0.434        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 236          |\n|    n_updates                    | 3976         |\n|    policy_gradient_loss         | 0.00164      |\n|    value_loss                   | 524          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.19e+03     |\n|    water_produced               | 253          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 354          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1990         |\n|    time_elapsed                 | 9340         |\n|    total_timesteps              | 7960000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027304091 |\n|    clip_fraction                | 0.0278       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.854       |\n|    explained_variance           | 0.796        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 312          |\n|    n_updates                    | 3978         |\n|    policy_gradient_loss         | -0.00141     |\n|    value_loss                   | 669          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 160          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.85e+03     |\n|    water_produced               | 397          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 348          |\n| time/                           |              |\n|    fps                          | 852          |\n|    iterations                   | 1991         |\n|    time_elapsed                 | 9344         |\n|    total_timesteps              | 7964000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007987049 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.678       |\n|    explained_variance           | 0.457        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 300          |\n|    n_updates                    | 3980         |\n|    policy_gradient_loss         | 7.74e-05     |\n|    value_loss                   | 623          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 157          |\n|    ice_dug                      | 1.38e+03     |\n|    water_produced               | 308          |\n--------------------------------------------------\nEval num_timesteps=7968000, episode_reward=2667.28 +/- 375.85\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.67e+03    |\n| time/                           |             |\n|    total_timesteps              | 7968000     |\n| train/                          |             |\n|    approx_kl                    | 0.000806533 |\n|    clip_fraction                | 0.00263     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.775      |\n|    explained_variance           | 0.821       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 232         |\n|    n_updates                    | 3982        |\n|    policy_gradient_loss         | -0.000252   |\n|    value_loss                   | 472         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 1.83e+03    |\n|    water_produced               | 412         |\n-------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 368      |\n| time/              |          |\n|    fps             | 851      |\n|    iterations      | 1992     |\n|    time_elapsed    | 9357     |\n|    total_timesteps | 7968000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 367          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 1993         |\n|    time_elapsed                 | 9362         |\n|    total_timesteps              | 7972000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006899486 |\n|    clip_fraction                | 0.00387      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.665       |\n|    explained_variance           | 0.467        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 293          |\n|    n_updates                    | 3984         |\n|    policy_gradient_loss         | -5.75e-05    |\n|    value_loss                   | 552          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 382          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 383         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1994        |\n|    time_elapsed                 | 9366        |\n|    total_timesteps              | 7976000     |\n| train/                          |             |\n|    approx_kl                    | 0.010766556 |\n|    clip_fraction                | 0.0608      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.695      |\n|    explained_variance           | 0.576       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 312         |\n|    n_updates                    | 3986        |\n|    policy_gradient_loss         | 0.00551     |\n|    value_loss                   | 661         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 139         |\n|    action_queue_updates_total   | 141         |\n|    ice_dug                      | 1.41e+03    |\n|    water_produced               | 330         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 363          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 1995         |\n|    time_elapsed                 | 9371         |\n|    total_timesteps              | 7980000      |\n| train/                          |              |\n|    approx_kl                    | 0.0045960206 |\n|    clip_fraction                | 0.0178       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.694       |\n|    explained_variance           | 0.581        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 179          |\n|    n_updates                    | 3988         |\n|    policy_gradient_loss         | -0.00205     |\n|    value_loss                   | 401          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.35e+03     |\n|    water_produced               | 306          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 388         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1996        |\n|    time_elapsed                 | 9375        |\n|    total_timesteps              | 7984000     |\n| train/                          |             |\n|    approx_kl                    | 0.010038058 |\n|    clip_fraction                | 0.0571      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.799      |\n|    explained_variance           | 0.928       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 162         |\n|    n_updates                    | 3990        |\n|    policy_gradient_loss         | -0.00162    |\n|    value_loss                   | 342         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.88e+03    |\n|    water_produced               | 428         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 381         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1997        |\n|    time_elapsed                 | 9380        |\n|    total_timesteps              | 7988000     |\n| train/                          |             |\n|    approx_kl                    | 0.003897271 |\n|    clip_fraction                | 0.0272      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.718      |\n|    explained_variance           | 0.611       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 174         |\n|    n_updates                    | 3992        |\n|    policy_gradient_loss         | 0.000731    |\n|    value_loss                   | 326         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 153         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.66e+03    |\n|    water_produced               | 377         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 356          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 1998         |\n|    time_elapsed                 | 9384         |\n|    total_timesteps              | 7992000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032323361 |\n|    clip_fraction                | 0.0186       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.743       |\n|    explained_variance           | 0.553        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 3994         |\n|    policy_gradient_loss         | -0.00027     |\n|    value_loss                   | 352          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.13e+03     |\n|    water_produced               | 263          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 373         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 1999        |\n|    time_elapsed                 | 9388        |\n|    total_timesteps              | 7996000     |\n| train/                          |             |\n|    approx_kl                    | 0.016650228 |\n|    clip_fraction                | 0.0866      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.88       |\n|    explained_variance           | 0.786       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 253         |\n|    n_updates                    | 3996        |\n|    policy_gradient_loss         | 0.00674     |\n|    value_loss                   | 545         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.87e+03    |\n|    water_produced               | 413         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 379           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 2000          |\n|    time_elapsed                 | 9393          |\n|    total_timesteps              | 8000000       |\n| train/                          |               |\n|    approx_kl                    | 0.00067820103 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.784        |\n|    explained_variance           | 0.487         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 216           |\n|    n_updates                    | 3998          |\n|    policy_gradient_loss         | -0.00118      |\n|    value_loss                   | 459           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 168           |\n|    action_queue_updates_total   | 170           |\n|    ice_dug                      | 1.41e+03      |\n|    water_produced               | 334           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 362           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 2001          |\n|    time_elapsed                 | 9397          |\n|    total_timesteps              | 8004000       |\n| train/                          |               |\n|    approx_kl                    | 0.00094402523 |\n|    clip_fraction                | 0.00262       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.828        |\n|    explained_variance           | 0.684         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 272           |\n|    n_updates                    | 4000          |\n|    policy_gradient_loss         | -0.00118      |\n|    value_loss                   | 522           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 167           |\n|    action_queue_updates_total   | 171           |\n|    ice_dug                      | 1.56e+03      |\n|    water_produced               | 346           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 360         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2002        |\n|    time_elapsed                 | 9401        |\n|    total_timesteps              | 8008000     |\n| train/                          |             |\n|    approx_kl                    | 0.005980217 |\n|    clip_fraction                | 0.0245      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.842      |\n|    explained_variance           | 0.78        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 231         |\n|    n_updates                    | 4002        |\n|    policy_gradient_loss         | 0.000257    |\n|    value_loss                   | 492         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.6e+03     |\n|    water_produced               | 367         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 384          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2003         |\n|    time_elapsed                 | 9406         |\n|    total_timesteps              | 8012000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036993376 |\n|    clip_fraction                | 0.0207       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.814       |\n|    explained_variance           | 0.83         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 4004         |\n|    policy_gradient_loss         | 0.000664     |\n|    value_loss                   | 466          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 161          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 376          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 381        |\n| time/                           |            |\n|    fps                          | 851        |\n|    iterations                   | 2004       |\n|    time_elapsed                 | 9410       |\n|    total_timesteps              | 8016000    |\n| train/                          |            |\n|    approx_kl                    | 0.00428968 |\n|    clip_fraction                | 0.0229     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.678     |\n|    explained_variance           | 0.55       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 281        |\n|    n_updates                    | 4006       |\n|    policy_gradient_loss         | 0.000188   |\n|    value_loss                   | 538        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 154        |\n|    action_queue_updates_total   | 158        |\n|    ice_dug                      | 1.81e+03   |\n|    water_produced               | 399        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 382         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2005        |\n|    time_elapsed                 | 9415        |\n|    total_timesteps              | 8020000     |\n| train/                          |             |\n|    approx_kl                    | 0.009266066 |\n|    clip_fraction                | 0.0424      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.627      |\n|    explained_variance           | 0.6         |\n|    learning_rate                | 0.0003      |\n|    loss                         | 205         |\n|    n_updates                    | 4008        |\n|    policy_gradient_loss         | 0.00251     |\n|    value_loss                   | 427         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 138         |\n|    action_queue_updates_total   | 145         |\n|    ice_dug                      | 1.48e+03    |\n|    water_produced               | 340         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 393          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2006         |\n|    time_elapsed                 | 9419         |\n|    total_timesteps              | 8024000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050862357 |\n|    clip_fraction                | 0.0268       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.707       |\n|    explained_variance           | 0.564        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 4010         |\n|    policy_gradient_loss         | -0.00233     |\n|    value_loss                   | 409          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.78e+03     |\n|    water_produced               | 400          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 399          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2007         |\n|    time_elapsed                 | 9424         |\n|    total_timesteps              | 8028000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015142991 |\n|    clip_fraction                | 0.00613      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.759       |\n|    explained_variance           | 0.541        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 4012         |\n|    policy_gradient_loss         | 0.000441     |\n|    value_loss                   | 416          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.68e+03     |\n|    water_produced               | 392          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 411         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2008        |\n|    time_elapsed                 | 9428        |\n|    total_timesteps              | 8032000     |\n| train/                          |             |\n|    approx_kl                    | 0.005244498 |\n|    clip_fraction                | 0.0256      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.765      |\n|    explained_variance           | 0.665       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 170         |\n|    n_updates                    | 4014        |\n|    policy_gradient_loss         | 8.51e-05    |\n|    value_loss                   | 376         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.84e+03    |\n|    water_produced               | 436         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 406          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2009         |\n|    time_elapsed                 | 9433         |\n|    total_timesteps              | 8036000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023531772 |\n|    clip_fraction                | 0.0174       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.765       |\n|    explained_variance           | 0.659        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 162          |\n|    n_updates                    | 4016         |\n|    policy_gradient_loss         | 0.00159      |\n|    value_loss                   | 315          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.73e+03     |\n|    water_produced               | 375          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 414          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2010         |\n|    time_elapsed                 | 9437         |\n|    total_timesteps              | 8040000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007724618 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.743       |\n|    explained_variance           | 0.503        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 4018         |\n|    policy_gradient_loss         | 0.000851     |\n|    value_loss                   | 409          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.69e+03     |\n|    water_produced               | 379          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 413          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2011         |\n|    time_elapsed                 | 9441         |\n|    total_timesteps              | 8044000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036249652 |\n|    clip_fraction                | 0.0233       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.782       |\n|    explained_variance           | 0.571        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 4020         |\n|    policy_gradient_loss         | -0.00285     |\n|    value_loss                   | 498          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.75e+03     |\n|    water_produced               | 396          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 406          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2012         |\n|    time_elapsed                 | 9446         |\n|    total_timesteps              | 8048000      |\n| train/                          |              |\n|    approx_kl                    | 0.0047882623 |\n|    clip_fraction                | 0.0225       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.743       |\n|    explained_variance           | 0.538        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 204          |\n|    n_updates                    | 4022         |\n|    policy_gradient_loss         | -0.000283    |\n|    value_loss                   | 389          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.58e+03     |\n|    water_produced               | 357          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 381          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2013         |\n|    time_elapsed                 | 9451         |\n|    total_timesteps              | 8052000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026077535 |\n|    clip_fraction                | 0.015        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.752       |\n|    explained_variance           | 0.661        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 162          |\n|    n_updates                    | 4024         |\n|    policy_gradient_loss         | -0.0015      |\n|    value_loss                   | 320          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 316          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 354         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2014        |\n|    time_elapsed                 | 9455        |\n|    total_timesteps              | 8056000     |\n| train/                          |             |\n|    approx_kl                    | 0.017065432 |\n|    clip_fraction                | 0.0743      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.843      |\n|    explained_variance           | 0.753       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 189         |\n|    n_updates                    | 4026        |\n|    policy_gradient_loss         | 0.00246     |\n|    value_loss                   | 421         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.32e+03    |\n|    water_produced               | 245         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 343         |\n| time/                           |             |\n|    fps                          | 852         |\n|    iterations                   | 2015        |\n|    time_elapsed                 | 9460        |\n|    total_timesteps              | 8060000     |\n| train/                          |             |\n|    approx_kl                    | 0.018991768 |\n|    clip_fraction                | 0.0941      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.859      |\n|    explained_variance           | 0.634       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 377         |\n|    n_updates                    | 4028        |\n|    policy_gradient_loss         | 0.00687     |\n|    value_loss                   | 695         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 158         |\n|    action_queue_updates_total   | 164         |\n|    ice_dug                      | 1.53e+03    |\n|    water_produced               | 326         |\n-------------------------------------------------\nEval num_timesteps=8064000, episode_reward=2366.88 +/- 395.12\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.37e+03    |\n| time/                           |             |\n|    total_timesteps              | 8064000     |\n| train/                          |             |\n|    approx_kl                    | 0.006271967 |\n|    clip_fraction                | 0.0409      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.786      |\n|    explained_variance           | 0.527       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 242         |\n|    n_updates                    | 4030        |\n|    policy_gradient_loss         | 0.00233     |\n|    value_loss                   | 525         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.11e+03    |\n|    water_produced               | 232         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 309      |\n| time/              |          |\n|    fps             | 851      |\n|    iterations      | 2016     |\n|    time_elapsed    | 9472     |\n|    total_timesteps | 8064000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 334          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2017         |\n|    time_elapsed                 | 9476         |\n|    total_timesteps              | 8068000      |\n| train/                          |              |\n|    approx_kl                    | 0.0065166517 |\n|    clip_fraction                | 0.0341       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.924       |\n|    explained_variance           | 0.853        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 4032         |\n|    policy_gradient_loss         | -0.000566    |\n|    value_loss                   | 526          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 2.08e+03     |\n|    water_produced               | 479          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 342          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2018         |\n|    time_elapsed                 | 9481         |\n|    total_timesteps              | 8072000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010827022 |\n|    clip_fraction                | 0.00262      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.731       |\n|    explained_variance           | 0.545        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 4034         |\n|    policy_gradient_loss         | -0.000838    |\n|    value_loss                   | 582          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.77e+03     |\n|    water_produced               | 350          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 372        |\n| time/                           |            |\n|    fps                          | 851        |\n|    iterations                   | 2019       |\n|    time_elapsed                 | 9485       |\n|    total_timesteps              | 8076000    |\n| train/                          |            |\n|    approx_kl                    | 0.02226323 |\n|    clip_fraction                | 0.115      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.722     |\n|    explained_variance           | 0.553      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 428        |\n|    n_updates                    | 4036       |\n|    policy_gradient_loss         | 0.00764    |\n|    value_loss                   | 851        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 166        |\n|    action_queue_updates_total   | 167        |\n|    ice_dug                      | 1.69e+03   |\n|    water_produced               | 393        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 398          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2020         |\n|    time_elapsed                 | 9490         |\n|    total_timesteps              | 8080000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016640289 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.775       |\n|    explained_variance           | 0.842        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 4038         |\n|    policy_gradient_loss         | 0.00108      |\n|    value_loss                   | 498          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.99e+03     |\n|    water_produced               | 448          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 443         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2021        |\n|    time_elapsed                 | 9495        |\n|    total_timesteps              | 8084000     |\n| train/                          |             |\n|    approx_kl                    | 0.003628717 |\n|    clip_fraction                | 0.0225      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.657      |\n|    explained_variance           | 0.572       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 236         |\n|    n_updates                    | 4040        |\n|    policy_gradient_loss         | 0.00266     |\n|    value_loss                   | 486         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.91e+03    |\n|    water_produced               | 451         |\n-------------------------------------------------\n-----------------------------------------------\n| rollout/                        |           |\n|    ep_len_mean                  | 200       |\n|    ep_rew_mean                  | 405       |\n| time/                           |           |\n|    fps                          | 851       |\n|    iterations                   | 2022      |\n|    time_elapsed                 | 9499      |\n|    total_timesteps              | 8088000   |\n| train/                          |           |\n|    approx_kl                    | 0.0093629 |\n|    clip_fraction                | 0.0591    |\n|    clip_range                   | 0.2       |\n|    entropy_loss                 | -0.672    |\n|    explained_variance           | 0.656     |\n|    learning_rate                | 0.0003    |\n|    loss                         | 237       |\n|    n_updates                    | 4042      |\n|    policy_gradient_loss         | 0.00518   |\n|    value_loss                   | 501       |\n| train_metrics/                  |           |\n|    action_queue_updates_success | 159       |\n|    action_queue_updates_total   | 161       |\n|    ice_dug                      | 1.34e+03  |\n|    water_produced               | 297       |\n-----------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 382         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2023        |\n|    time_elapsed                 | 9503        |\n|    total_timesteps              | 8092000     |\n| train/                          |             |\n|    approx_kl                    | 0.009541961 |\n|    clip_fraction                | 0.0476      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.845      |\n|    explained_variance           | 0.801       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 228         |\n|    n_updates                    | 4044        |\n|    policy_gradient_loss         | -0.000687   |\n|    value_loss                   | 513         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.03e+03    |\n|    water_produced               | 240         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 399        |\n| time/                           |            |\n|    fps                          | 851        |\n|    iterations                   | 2024       |\n|    time_elapsed                 | 9508       |\n|    total_timesteps              | 8096000    |\n| train/                          |            |\n|    approx_kl                    | 0.04107832 |\n|    clip_fraction                | 0.177      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.931     |\n|    explained_variance           | 0.842      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 185        |\n|    n_updates                    | 4046       |\n|    policy_gradient_loss         | 0.0115     |\n|    value_loss                   | 417        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 175        |\n|    action_queue_updates_total   | 177        |\n|    ice_dug                      | 2e+03      |\n|    water_produced               | 475        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 347          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2025         |\n|    time_elapsed                 | 9512         |\n|    total_timesteps              | 8100000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025384359 |\n|    clip_fraction                | 0.01         |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.728       |\n|    explained_variance           | 0.55         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 4048         |\n|    policy_gradient_loss         | -0.000869    |\n|    value_loss                   | 445          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 890          |\n|    water_produced               | 200          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 319         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2026        |\n|    time_elapsed                 | 9517        |\n|    total_timesteps              | 8104000     |\n| train/                          |             |\n|    approx_kl                    | 0.000974549 |\n|    clip_fraction                | 0.00125     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.02       |\n|    explained_variance           | 0.82        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 339         |\n|    n_updates                    | 4050        |\n|    policy_gradient_loss         | -0.000167   |\n|    value_loss                   | 692         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.45e+03    |\n|    water_produced               | 317         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 357         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2027        |\n|    time_elapsed                 | 9521        |\n|    total_timesteps              | 8108000     |\n| train/                          |             |\n|    approx_kl                    | 0.009160448 |\n|    clip_fraction                | 0.0741      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.861      |\n|    explained_variance           | 0.842       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 245         |\n|    n_updates                    | 4052        |\n|    policy_gradient_loss         | 0.00256     |\n|    value_loss                   | 486         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 2.13e+03    |\n|    water_produced               | 477         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 377         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2028        |\n|    time_elapsed                 | 9526        |\n|    total_timesteps              | 8112000     |\n| train/                          |             |\n|    approx_kl                    | 0.009240562 |\n|    clip_fraction                | 0.0555      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.649      |\n|    explained_variance           | 0.389       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 221         |\n|    n_updates                    | 4054        |\n|    policy_gradient_loss         | 0.00373     |\n|    value_loss                   | 508         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.46e+03    |\n|    water_produced               | 337         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 365          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2029         |\n|    time_elapsed                 | 9530         |\n|    total_timesteps              | 8116000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014366801 |\n|    clip_fraction                | 0.0126       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.79        |\n|    explained_variance           | 0.845        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 4056         |\n|    policy_gradient_loss         | 0.00116      |\n|    value_loss                   | 535          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.78e+03     |\n|    water_produced               | 416          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 408          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2030         |\n|    time_elapsed                 | 9535         |\n|    total_timesteps              | 8120000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004244387 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.67        |\n|    explained_variance           | 0.635        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 198          |\n|    n_updates                    | 4058         |\n|    policy_gradient_loss         | 0.000529     |\n|    value_loss                   | 403          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 406          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 428          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2031         |\n|    time_elapsed                 | 9539         |\n|    total_timesteps              | 8124000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042957417 |\n|    clip_fraction                | 0.0304       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.689       |\n|    explained_variance           | 0.62         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 235          |\n|    n_updates                    | 4060         |\n|    policy_gradient_loss         | 0.00263      |\n|    value_loss                   | 503          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 152          |\n|    action_queue_updates_total   | 154          |\n|    ice_dug                      | 1.77e+03     |\n|    water_produced               | 417          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 417         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2032        |\n|    time_elapsed                 | 9544        |\n|    total_timesteps              | 8128000     |\n| train/                          |             |\n|    approx_kl                    | 0.009486402 |\n|    clip_fraction                | 0.0577      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.726      |\n|    explained_variance           | 0.63        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 162         |\n|    n_updates                    | 4062        |\n|    policy_gradient_loss         | -0.00557    |\n|    value_loss                   | 319         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.87e+03    |\n|    water_produced               | 421         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 429          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2033         |\n|    time_elapsed                 | 9549         |\n|    total_timesteps              | 8132000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025658389 |\n|    clip_fraction                | 0.004        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.706       |\n|    explained_variance           | 0.601        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 172          |\n|    n_updates                    | 4064         |\n|    policy_gradient_loss         | 0.000783     |\n|    value_loss                   | 366          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 155          |\n|    action_queue_updates_total   | 159          |\n|    ice_dug                      | 1.74e+03     |\n|    water_produced               | 397          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 409         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2034        |\n|    time_elapsed                 | 9553        |\n|    total_timesteps              | 8136000     |\n| train/                          |             |\n|    approx_kl                    | 0.002153415 |\n|    clip_fraction                | 0.013       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.661      |\n|    explained_variance           | 0.628       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 188         |\n|    n_updates                    | 4066        |\n|    policy_gradient_loss         | 0.00232     |\n|    value_loss                   | 363         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 159         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.4e+03     |\n|    water_produced               | 317         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 414         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2035        |\n|    time_elapsed                 | 9557        |\n|    total_timesteps              | 8140000     |\n| train/                          |             |\n|    approx_kl                    | 0.014271702 |\n|    clip_fraction                | 0.103       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.834      |\n|    explained_variance           | 0.773       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 195         |\n|    n_updates                    | 4068        |\n|    policy_gradient_loss         | 0.00467     |\n|    value_loss                   | 452         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.82e+03    |\n|    water_produced               | 432         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 400          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2036         |\n|    time_elapsed                 | 9562         |\n|    total_timesteps              | 8144000      |\n| train/                          |              |\n|    approx_kl                    | 0.0005690606 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.773       |\n|    explained_variance           | 0.617        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 134          |\n|    n_updates                    | 4070         |\n|    policy_gradient_loss         | -0.000108    |\n|    value_loss                   | 278          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.46e+03     |\n|    water_produced               | 350          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 397          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2037         |\n|    time_elapsed                 | 9566         |\n|    total_timesteps              | 8148000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011457058 |\n|    clip_fraction                | 0.00388      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.854       |\n|    explained_variance           | 0.813        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 196          |\n|    n_updates                    | 4072         |\n|    policy_gradient_loss         | 8.24e-05     |\n|    value_loss                   | 412          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 409          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 378          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2038         |\n|    time_elapsed                 | 9570         |\n|    total_timesteps              | 8152000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007244175 |\n|    clip_fraction                | 0.00262      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.747       |\n|    explained_variance           | 0.569        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 160          |\n|    n_updates                    | 4074         |\n|    policy_gradient_loss         | -0.000262    |\n|    value_loss                   | 309          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.32e+03     |\n|    water_produced               | 304          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 379           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 2039          |\n|    time_elapsed                 | 9575          |\n|    total_timesteps              | 8156000       |\n| train/                          |               |\n|    approx_kl                    | 0.00065592723 |\n|    clip_fraction                | 0.00112       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.832        |\n|    explained_variance           | 0.814         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 206           |\n|    n_updates                    | 4076          |\n|    policy_gradient_loss         | 9.36e-05      |\n|    value_loss                   | 445           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 144           |\n|    action_queue_updates_total   | 152           |\n|    ice_dug                      | 1.5e+03       |\n|    water_produced               | 323           |\n---------------------------------------------------\nEval num_timesteps=8160000, episode_reward=2423.20 +/- 746.28\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.42e+03     |\n| time/                           |              |\n|    total_timesteps              | 8160000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030000962 |\n|    clip_fraction                | 0.0103       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.736       |\n|    explained_variance           | 0.497        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 279          |\n|    n_updates                    | 4078         |\n|    policy_gradient_loss         | 0.000319     |\n|    value_loss                   | 602          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.44e+03     |\n|    water_produced               | 333          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 359      |\n| time/              |          |\n|    fps             | 851      |\n|    iterations      | 2040     |\n|    time_elapsed    | 9588     |\n|    total_timesteps | 8160000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 341          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2041         |\n|    time_elapsed                 | 9592         |\n|    total_timesteps              | 8164000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038220026 |\n|    clip_fraction                | 0.0185       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.84        |\n|    explained_variance           | 0.866        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 180          |\n|    n_updates                    | 4080         |\n|    policy_gradient_loss         | 0.000867     |\n|    value_loss                   | 375          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.41e+03     |\n|    water_produced               | 263          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 337          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2042         |\n|    time_elapsed                 | 9597         |\n|    total_timesteps              | 8168000      |\n| train/                          |              |\n|    approx_kl                    | 0.0076325587 |\n|    clip_fraction                | 0.0501       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.867       |\n|    explained_variance           | 0.819        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 291          |\n|    n_updates                    | 4082         |\n|    policy_gradient_loss         | 0.00127      |\n|    value_loss                   | 598          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.64e+03     |\n|    water_produced               | 387          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 317          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2043         |\n|    time_elapsed                 | 9601         |\n|    total_timesteps              | 8172000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006881108 |\n|    clip_fraction                | 0.00075      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.755       |\n|    explained_variance           | 0.601        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 305          |\n|    n_updates                    | 4084         |\n|    policy_gradient_loss         | 0.00049      |\n|    value_loss                   | 615          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 877          |\n|    water_produced               | 209          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 314         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2044        |\n|    time_elapsed                 | 9605        |\n|    total_timesteps              | 8176000     |\n| train/                          |             |\n|    approx_kl                    | 0.022018462 |\n|    clip_fraction                | 0.127       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.02       |\n|    explained_variance           | 0.865       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 248         |\n|    n_updates                    | 4086        |\n|    policy_gradient_loss         | 0.00685     |\n|    value_loss                   | 546         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 142         |\n|    action_queue_updates_total   | 150         |\n|    ice_dug                      | 1.4e+03     |\n|    water_produced               | 311         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 292           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 2045          |\n|    time_elapsed                 | 9610          |\n|    total_timesteps              | 8180000       |\n| train/                          |               |\n|    approx_kl                    | 0.00057054363 |\n|    clip_fraction                | 0.002         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.71         |\n|    explained_variance           | 0.909         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 296           |\n|    n_updates                    | 4088          |\n|    policy_gradient_loss         | -0.000268     |\n|    value_loss                   | 631           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 168           |\n|    action_queue_updates_total   | 171           |\n|    ice_dug                      | 1e+03         |\n|    water_produced               | 228           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 313         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2046        |\n|    time_elapsed                 | 9614        |\n|    total_timesteps              | 8184000     |\n| train/                          |             |\n|    approx_kl                    | 0.004998551 |\n|    clip_fraction                | 0.0315      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.936      |\n|    explained_variance           | 0.904       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 218         |\n|    n_updates                    | 4090        |\n|    policy_gradient_loss         | 0.000882    |\n|    value_loss                   | 519         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.63e+03    |\n|    water_produced               | 363         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 322          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2047         |\n|    time_elapsed                 | 9619         |\n|    total_timesteps              | 8188000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013541003 |\n|    clip_fraction                | 0.00925      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.8         |\n|    explained_variance           | 0.658        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 261          |\n|    n_updates                    | 4092         |\n|    policy_gradient_loss         | -0.000548    |\n|    value_loss                   | 597          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.87e+03     |\n|    water_produced               | 432          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 349         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2048        |\n|    time_elapsed                 | 9623        |\n|    total_timesteps              | 8192000     |\n| train/                          |             |\n|    approx_kl                    | 0.013392347 |\n|    clip_fraction                | 0.0669      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.681      |\n|    explained_variance           | 0.525       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 188         |\n|    n_updates                    | 4094        |\n|    policy_gradient_loss         | 0.00447     |\n|    value_loss                   | 432         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 168         |\n|    ice_dug                      | 1.49e+03    |\n|    water_produced               | 339         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 370         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2049        |\n|    time_elapsed                 | 9628        |\n|    total_timesteps              | 8196000     |\n| train/                          |             |\n|    approx_kl                    | 0.001292355 |\n|    clip_fraction                | 0.0075      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.784      |\n|    explained_variance           | 0.82        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 257         |\n|    n_updates                    | 4096        |\n|    policy_gradient_loss         | 0.00203     |\n|    value_loss                   | 535         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.82e+03    |\n|    water_produced               | 409         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 384           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 2050          |\n|    time_elapsed                 | 9632          |\n|    total_timesteps              | 8200000       |\n| train/                          |               |\n|    approx_kl                    | 0.00051921094 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.685        |\n|    explained_variance           | 0.554         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 185           |\n|    n_updates                    | 4098          |\n|    policy_gradient_loss         | -0.000519     |\n|    value_loss                   | 383           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 167           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 1.36e+03      |\n|    water_produced               | 297           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 381           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 2051          |\n|    time_elapsed                 | 9637          |\n|    total_timesteps              | 8204000       |\n| train/                          |               |\n|    approx_kl                    | 0.00086659007 |\n|    clip_fraction                | 0.00075       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.846        |\n|    explained_variance           | 0.764         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 279           |\n|    n_updates                    | 4100          |\n|    policy_gradient_loss         | 0.000295      |\n|    value_loss                   | 633           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 166           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 1.58e+03      |\n|    water_produced               | 347           |\n---------------------------------------------------\n-----------------------------------------------\n| rollout/                        |           |\n|    ep_len_mean                  | 200       |\n|    ep_rew_mean                  | 364       |\n| time/                           |           |\n|    fps                          | 851       |\n|    iterations                   | 2052      |\n|    time_elapsed                 | 9641      |\n|    total_timesteps              | 8208000   |\n| train/                          |           |\n|    approx_kl                    | 0.0088313 |\n|    clip_fraction                | 0.0595    |\n|    clip_range                   | 0.2       |\n|    entropy_loss                 | -0.88     |\n|    explained_variance           | 0.857     |\n|    learning_rate                | 0.0003    |\n|    loss                         | 227       |\n|    n_updates                    | 4102      |\n|    policy_gradient_loss         | -0.000953 |\n|    value_loss                   | 451       |\n| train_metrics/                  |           |\n|    action_queue_updates_success | 176       |\n|    action_queue_updates_total   | 177       |\n|    ice_dug                      | 1.55e+03  |\n|    water_produced               | 350       |\n-----------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 386          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2053         |\n|    time_elapsed                 | 9646         |\n|    total_timesteps              | 8212000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017535149 |\n|    clip_fraction                | 0.00762      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.842       |\n|    explained_variance           | 0.877        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 199          |\n|    n_updates                    | 4104         |\n|    policy_gradient_loss         | -0.00062     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.92e+03     |\n|    water_produced               | 447          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 369         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2054        |\n|    time_elapsed                 | 9650        |\n|    total_timesteps              | 8216000     |\n| train/                          |             |\n|    approx_kl                    | 0.005359447 |\n|    clip_fraction                | 0.0326      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.728      |\n|    explained_variance           | 0.523       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 186         |\n|    n_updates                    | 4106        |\n|    policy_gradient_loss         | 0.00301     |\n|    value_loss                   | 386         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 162         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 1.43e+03    |\n|    water_produced               | 329         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 388          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2055         |\n|    time_elapsed                 | 9654         |\n|    total_timesteps              | 8220000      |\n| train/                          |              |\n|    approx_kl                    | 0.0003549492 |\n|    clip_fraction                | 0.000625     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.793       |\n|    explained_variance           | 0.845        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 178          |\n|    n_updates                    | 4108         |\n|    policy_gradient_loss         | 0.00174      |\n|    value_loss                   | 438          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.83e+03     |\n|    water_produced               | 382          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 364         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2056        |\n|    time_elapsed                 | 9659        |\n|    total_timesteps              | 8224000     |\n| train/                          |             |\n|    approx_kl                    | 0.000171995 |\n|    clip_fraction                | 0.000125    |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.746      |\n|    explained_variance           | 0.297       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 325         |\n|    n_updates                    | 4110        |\n|    policy_gradient_loss         | 0.000168    |\n|    value_loss                   | 676         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.21e+03    |\n|    water_produced               | 231         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 367          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2057         |\n|    time_elapsed                 | 9663         |\n|    total_timesteps              | 8228000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011642633 |\n|    clip_fraction                | 0.00575      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.866       |\n|    explained_variance           | 0.759        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 356          |\n|    n_updates                    | 4112         |\n|    policy_gradient_loss         | 0.000342     |\n|    value_loss                   | 735          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.58e+03     |\n|    water_produced               | 368          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 357          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2058         |\n|    time_elapsed                 | 9668         |\n|    total_timesteps              | 8232000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022140513 |\n|    clip_fraction                | 0.0148       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.752       |\n|    explained_variance           | 0.516        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 4114         |\n|    policy_gradient_loss         | -0.00398     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.77e+03     |\n|    water_produced               | 398          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 356          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2059         |\n|    time_elapsed                 | 9672         |\n|    total_timesteps              | 8236000      |\n| train/                          |              |\n|    approx_kl                    | 0.0075510545 |\n|    clip_fraction                | 0.0506       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.759       |\n|    explained_variance           | 0.62         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 241          |\n|    n_updates                    | 4116         |\n|    policy_gradient_loss         | 0.00188      |\n|    value_loss                   | 511          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.38e+03     |\n|    water_produced               | 321          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 361          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2060         |\n|    time_elapsed                 | 9677         |\n|    total_timesteps              | 8240000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025653038 |\n|    clip_fraction                | 0.0134       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.831       |\n|    explained_variance           | 0.827        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 208          |\n|    n_updates                    | 4118         |\n|    policy_gradient_loss         | -6.61e-05    |\n|    value_loss                   | 466          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.72e+03     |\n|    water_produced               | 411          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 385           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 2061          |\n|    time_elapsed                 | 9682          |\n|    total_timesteps              | 8244000       |\n| train/                          |               |\n|    approx_kl                    | 0.00041111588 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.772        |\n|    explained_variance           | 0.642         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 236           |\n|    n_updates                    | 4120          |\n|    policy_gradient_loss         | -0.00103      |\n|    value_loss                   | 505           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 168           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 1.66e+03      |\n|    water_produced               | 344           |\n---------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 386        |\n| time/                           |            |\n|    fps                          | 851        |\n|    iterations                   | 2062       |\n|    time_elapsed                 | 9686       |\n|    total_timesteps              | 8248000    |\n| train/                          |            |\n|    approx_kl                    | 0.00303431 |\n|    clip_fraction                | 0.0127     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.742     |\n|    explained_variance           | 0.678      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 261        |\n|    n_updates                    | 4122       |\n|    policy_gradient_loss         | 6.44e-06   |\n|    value_loss                   | 520        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 156        |\n|    action_queue_updates_total   | 160        |\n|    ice_dug                      | 1.7e+03    |\n|    water_produced               | 375        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 370          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2063         |\n|    time_elapsed                 | 9691         |\n|    total_timesteps              | 8252000      |\n| train/                          |              |\n|    approx_kl                    | 0.0047731823 |\n|    clip_fraction                | 0.0356       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.747       |\n|    explained_variance           | 0.543        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 259          |\n|    n_updates                    | 4124         |\n|    policy_gradient_loss         | -9.57e-05    |\n|    value_loss                   | 551          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.39e+03     |\n|    water_produced               | 319          |\n--------------------------------------------------\nEval num_timesteps=8256000, episode_reward=2582.48 +/- 263.79\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.58e+03     |\n| time/                           |              |\n|    total_timesteps              | 8256000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014859857 |\n|    clip_fraction                | 0.007        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.804       |\n|    explained_variance           | 0.749        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 302          |\n|    n_updates                    | 4126         |\n|    policy_gradient_loss         | -0.000546    |\n|    value_loss                   | 637          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.78e+03     |\n|    water_produced               | 423          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 391      |\n| time/              |          |\n|    fps             | 850      |\n|    iterations      | 2064     |\n|    time_elapsed    | 9703     |\n|    total_timesteps | 8256000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 397          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2065         |\n|    time_elapsed                 | 9708         |\n|    total_timesteps              | 8260000      |\n| train/                          |              |\n|    approx_kl                    | 0.0040135668 |\n|    clip_fraction                | 0.0221       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.724       |\n|    explained_variance           | 0.577        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 225          |\n|    n_updates                    | 4128         |\n|    policy_gradient_loss         | 0.00104      |\n|    value_loss                   | 484          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 440          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 404         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2066        |\n|    time_elapsed                 | 9712        |\n|    total_timesteps              | 8264000     |\n| train/                          |             |\n|    approx_kl                    | 0.008315885 |\n|    clip_fraction                | 0.0516      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.683      |\n|    explained_variance           | 0.618       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 162         |\n|    n_updates                    | 4130        |\n|    policy_gradient_loss         | 0.00665     |\n|    value_loss                   | 329         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.66e+03    |\n|    water_produced               | 376         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 391         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2067        |\n|    time_elapsed                 | 9717        |\n|    total_timesteps              | 8268000     |\n| train/                          |             |\n|    approx_kl                    | 0.011976483 |\n|    clip_fraction                | 0.0705      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.78       |\n|    explained_variance           | 0.656       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 167         |\n|    n_updates                    | 4132        |\n|    policy_gradient_loss         | -0.000835   |\n|    value_loss                   | 350         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 162         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.33e+03    |\n|    water_produced               | 316         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 406        |\n| time/                           |            |\n|    fps                          | 850        |\n|    iterations                   | 2068       |\n|    time_elapsed                 | 9721       |\n|    total_timesteps              | 8272000    |\n| train/                          |            |\n|    approx_kl                    | 0.01194909 |\n|    clip_fraction                | 0.0571     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.828     |\n|    explained_variance           | 0.786      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 234        |\n|    n_updates                    | 4134       |\n|    policy_gradient_loss         | 0.00359    |\n|    value_loss                   | 517        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 170        |\n|    action_queue_updates_total   | 173        |\n|    ice_dug                      | 1.91e+03   |\n|    water_produced               | 388        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 383          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2069         |\n|    time_elapsed                 | 9725         |\n|    total_timesteps              | 8276000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029511189 |\n|    clip_fraction                | 0.0205       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.718       |\n|    explained_variance           | 0.788        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 284          |\n|    n_updates                    | 4136         |\n|    policy_gradient_loss         | -0.000649    |\n|    value_loss                   | 584          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.49e+03     |\n|    water_produced               | 314          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 382          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2070         |\n|    time_elapsed                 | 9730         |\n|    total_timesteps              | 8280000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018486753 |\n|    clip_fraction                | 0.00937      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.771       |\n|    explained_variance           | 0.791        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 254          |\n|    n_updates                    | 4138         |\n|    policy_gradient_loss         | -0.00055     |\n|    value_loss                   | 538          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.86e+03     |\n|    water_produced               | 435          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 390         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2071        |\n|    time_elapsed                 | 9734        |\n|    total_timesteps              | 8284000     |\n| train/                          |             |\n|    approx_kl                    | 0.004497521 |\n|    clip_fraction                | 0.0291      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.709      |\n|    explained_variance           | 0.779       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 208         |\n|    n_updates                    | 4140        |\n|    policy_gradient_loss         | 0.000393    |\n|    value_loss                   | 493         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 154         |\n|    action_queue_updates_total   | 158         |\n|    ice_dug                      | 1.78e+03    |\n|    water_produced               | 412         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 393         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2072        |\n|    time_elapsed                 | 9739        |\n|    total_timesteps              | 8288000     |\n| train/                          |             |\n|    approx_kl                    | 0.010616461 |\n|    clip_fraction                | 0.0519      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.617      |\n|    explained_variance           | 0.504       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 230         |\n|    n_updates                    | 4142        |\n|    policy_gradient_loss         | 0.00472     |\n|    value_loss                   | 455         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 155         |\n|    action_queue_updates_total   | 159         |\n|    ice_dug                      | 1.42e+03    |\n|    water_produced               | 332         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 398          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2073         |\n|    time_elapsed                 | 9743         |\n|    total_timesteps              | 8292000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028506916 |\n|    clip_fraction                | 0.0153       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.787       |\n|    explained_variance           | 0.808        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 246          |\n|    n_updates                    | 4144         |\n|    policy_gradient_loss         | 0.000881     |\n|    value_loss                   | 501          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.79e+03     |\n|    water_produced               | 415          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 415           |\n| time/                           |               |\n|    fps                          | 851           |\n|    iterations                   | 2074          |\n|    time_elapsed                 | 9747          |\n|    total_timesteps              | 8296000       |\n| train/                          |               |\n|    approx_kl                    | 0.00048887066 |\n|    clip_fraction                | 0.000375      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.728        |\n|    explained_variance           | 0.645         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 221           |\n|    n_updates                    | 4146          |\n|    policy_gradient_loss         | -0.000666     |\n|    value_loss                   | 433           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 155           |\n|    action_queue_updates_total   | 158           |\n|    ice_dug                      | 1.75e+03      |\n|    water_produced               | 398           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 410         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2075        |\n|    time_elapsed                 | 9752        |\n|    total_timesteps              | 8300000     |\n| train/                          |             |\n|    approx_kl                    | 0.003010216 |\n|    clip_fraction                | 0.0179      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.725      |\n|    explained_variance           | 0.619       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 189         |\n|    n_updates                    | 4148        |\n|    policy_gradient_loss         | -0.00138    |\n|    value_loss                   | 402         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.8e+03     |\n|    water_produced               | 411         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 401          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2076         |\n|    time_elapsed                 | 9756         |\n|    total_timesteps              | 8304000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017876122 |\n|    clip_fraction                | 0.00737      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.772       |\n|    explained_variance           | 0.616        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 4150         |\n|    policy_gradient_loss         | 0.0019       |\n|    value_loss                   | 428          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.6e+03      |\n|    water_produced               | 364          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 395          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2077         |\n|    time_elapsed                 | 9761         |\n|    total_timesteps              | 8308000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007712871 |\n|    clip_fraction                | 0.001        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.772       |\n|    explained_variance           | 0.563        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 220          |\n|    n_updates                    | 4152         |\n|    policy_gradient_loss         | 8.09e-05     |\n|    value_loss                   | 448          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 165          |\n|    ice_dug                      | 1.33e+03     |\n|    water_produced               | 305          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 395         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2078        |\n|    time_elapsed                 | 9765        |\n|    total_timesteps              | 8312000     |\n| train/                          |             |\n|    approx_kl                    | 0.009217052 |\n|    clip_fraction                | 0.0607      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.817      |\n|    explained_variance           | 0.669       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 234         |\n|    n_updates                    | 4154        |\n|    policy_gradient_loss         | -0.00127    |\n|    value_loss                   | 492         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 173         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.84e+03    |\n|    water_produced               | 412         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 406          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2079         |\n|    time_elapsed                 | 9770         |\n|    total_timesteps              | 8316000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017693958 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.751       |\n|    explained_variance           | 0.479        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 197          |\n|    n_updates                    | 4156         |\n|    policy_gradient_loss         | -0.000405    |\n|    value_loss                   | 418          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.91e+03     |\n|    water_produced               | 452          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 409         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2080        |\n|    time_elapsed                 | 9774        |\n|    total_timesteps              | 8320000     |\n| train/                          |             |\n|    approx_kl                    | 0.007174744 |\n|    clip_fraction                | 0.0501      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.75       |\n|    explained_variance           | 0.643       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 180         |\n|    n_updates                    | 4158        |\n|    policy_gradient_loss         | 0.00368     |\n|    value_loss                   | 386         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.86e+03    |\n|    water_produced               | 428         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 415          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2081         |\n|    time_elapsed                 | 9779         |\n|    total_timesteps              | 8324000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030506253 |\n|    clip_fraction                | 0.0225       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.756       |\n|    explained_variance           | 0.584        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 185          |\n|    n_updates                    | 4160         |\n|    policy_gradient_loss         | 0.00252      |\n|    value_loss                   | 338          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.65e+03     |\n|    water_produced               | 390          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 434          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2082         |\n|    time_elapsed                 | 9783         |\n|    total_timesteps              | 8328000      |\n| train/                          |              |\n|    approx_kl                    | 0.0053747953 |\n|    clip_fraction                | 0.0306       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.816       |\n|    explained_variance           | 0.643        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 133          |\n|    n_updates                    | 4162         |\n|    policy_gradient_loss         | -0.000879    |\n|    value_loss                   | 287          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.81e+03     |\n|    water_produced               | 398          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 425          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2083         |\n|    time_elapsed                 | 9788         |\n|    total_timesteps              | 8332000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012591173 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.782       |\n|    explained_variance           | 0.579        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 235          |\n|    n_updates                    | 4164         |\n|    policy_gradient_loss         | -2.94e-05    |\n|    value_loss                   | 417          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.66e+03     |\n|    water_produced               | 367          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 407          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2084         |\n|    time_elapsed                 | 9792         |\n|    total_timesteps              | 8336000      |\n| train/                          |              |\n|    approx_kl                    | 0.0053355806 |\n|    clip_fraction                | 0.025        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.817       |\n|    explained_variance           | 0.828        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 274          |\n|    n_updates                    | 4166         |\n|    policy_gradient_loss         | 0.000252     |\n|    value_loss                   | 540          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.75e+03     |\n|    water_produced               | 362          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 402         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2085        |\n|    time_elapsed                 | 9797        |\n|    total_timesteps              | 8340000     |\n| train/                          |             |\n|    approx_kl                    | 0.002711601 |\n|    clip_fraction                | 0.0095      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.81       |\n|    explained_variance           | 0.571       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 228         |\n|    n_updates                    | 4168        |\n|    policy_gradient_loss         | -0.00188    |\n|    value_loss                   | 461         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 180         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.91e+03    |\n|    water_produced               | 403         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 417          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2086         |\n|    time_elapsed                 | 9801         |\n|    total_timesteps              | 8344000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033077698 |\n|    clip_fraction                | 0.0216       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.781       |\n|    explained_variance           | 0.463        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 205          |\n|    n_updates                    | 4170         |\n|    policy_gradient_loss         | 0.000846     |\n|    value_loss                   | 433          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 2.06e+03     |\n|    water_produced               | 463          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 414          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2087         |\n|    time_elapsed                 | 9806         |\n|    total_timesteps              | 8348000      |\n| train/                          |              |\n|    approx_kl                    | 0.0060081347 |\n|    clip_fraction                | 0.0356       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.732       |\n|    explained_variance           | 0.596        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 173          |\n|    n_updates                    | 4172         |\n|    policy_gradient_loss         | 0.00141      |\n|    value_loss                   | 361          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.72e+03     |\n|    water_produced               | 383          |\n--------------------------------------------------\nEval num_timesteps=8352000, episode_reward=2369.68 +/- 430.51\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.37e+03     |\n| time/                           |              |\n|    total_timesteps              | 8352000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015782971 |\n|    clip_fraction                | 0.008        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.739       |\n|    explained_variance           | 0.626        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 183          |\n|    n_updates                    | 4174         |\n|    policy_gradient_loss         | 0.000354     |\n|    value_loss                   | 397          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.05e+03     |\n|    water_produced               | 252          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 390      |\n| time/              |          |\n|    fps             | 850      |\n|    iterations      | 2088     |\n|    time_elapsed    | 9818     |\n|    total_timesteps | 8352000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 407         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2089        |\n|    time_elapsed                 | 9823        |\n|    total_timesteps              | 8356000     |\n| train/                          |             |\n|    approx_kl                    | 0.020575082 |\n|    clip_fraction                | 0.0905      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.897      |\n|    explained_variance           | 0.806       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 164         |\n|    n_updates                    | 4176        |\n|    policy_gradient_loss         | 0.00231     |\n|    value_loss                   | 437         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 1.96e+03    |\n|    water_produced               | 445         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 400           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2090          |\n|    time_elapsed                 | 9827          |\n|    total_timesteps              | 8360000       |\n| train/                          |               |\n|    approx_kl                    | 0.00076079194 |\n|    clip_fraction                | 0.00625       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.744        |\n|    explained_variance           | 0.593         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 197           |\n|    n_updates                    | 4178          |\n|    policy_gradient_loss         | -0.000794     |\n|    value_loss                   | 401           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 162           |\n|    action_queue_updates_total   | 168           |\n|    ice_dug                      | 1.61e+03      |\n|    water_produced               | 373           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 392         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2091        |\n|    time_elapsed                 | 9832        |\n|    total_timesteps              | 8364000     |\n| train/                          |             |\n|    approx_kl                    | 0.002718552 |\n|    clip_fraction                | 0.013       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.781      |\n|    explained_variance           | 0.641       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 225         |\n|    n_updates                    | 4180        |\n|    policy_gradient_loss         | -0.0016     |\n|    value_loss                   | 500         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.82e+03    |\n|    water_produced               | 426         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 399          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2092         |\n|    time_elapsed                 | 9836         |\n|    total_timesteps              | 8368000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026552759 |\n|    clip_fraction                | 0.0152       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.743       |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 207          |\n|    n_updates                    | 4182         |\n|    policy_gradient_loss         | 0.000456     |\n|    value_loss                   | 395          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.73e+03     |\n|    water_produced               | 416          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 428          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2093         |\n|    time_elapsed                 | 9841         |\n|    total_timesteps              | 8372000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010816688 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.767       |\n|    explained_variance           | 0.636        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 4184         |\n|    policy_gradient_loss         | 0.000591     |\n|    value_loss                   | 364          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.83e+03     |\n|    water_produced               | 392          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 408         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2094        |\n|    time_elapsed                 | 9845        |\n|    total_timesteps              | 8376000     |\n| train/                          |             |\n|    approx_kl                    | 0.008102829 |\n|    clip_fraction                | 0.0583      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.798      |\n|    explained_variance           | 0.604       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 189         |\n|    n_updates                    | 4186        |\n|    policy_gradient_loss         | -0.00246    |\n|    value_loss                   | 390         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.5e+03     |\n|    water_produced               | 348         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 402          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2095         |\n|    time_elapsed                 | 9850         |\n|    total_timesteps              | 8380000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017025906 |\n|    clip_fraction                | 0.00562      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.798       |\n|    explained_variance           | 0.752        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 247          |\n|    n_updates                    | 4188         |\n|    policy_gradient_loss         | 4.71e-05     |\n|    value_loss                   | 497          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.53e+03     |\n|    water_produced               | 343          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 418         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2096        |\n|    time_elapsed                 | 9854        |\n|    total_timesteps              | 8384000     |\n| train/                          |             |\n|    approx_kl                    | 0.013295896 |\n|    clip_fraction                | 0.0644      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.819      |\n|    explained_variance           | 0.81        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 191         |\n|    n_updates                    | 4190        |\n|    policy_gradient_loss         | 0.000957    |\n|    value_loss                   | 391         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 2.12e+03    |\n|    water_produced               | 503         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 408          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2097         |\n|    time_elapsed                 | 9858         |\n|    total_timesteps              | 8388000      |\n| train/                          |              |\n|    approx_kl                    | 0.0068767825 |\n|    clip_fraction                | 0.0471       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.68        |\n|    explained_variance           | 0.56         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 4192         |\n|    policy_gradient_loss         | 0.00441      |\n|    value_loss                   | 442          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.59e+03     |\n|    water_produced               | 369          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 398          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2098         |\n|    time_elapsed                 | 9863         |\n|    total_timesteps              | 8392000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016422889 |\n|    clip_fraction                | 0.00587      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.771       |\n|    explained_variance           | 0.854        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 228          |\n|    n_updates                    | 4194         |\n|    policy_gradient_loss         | 0.00016      |\n|    value_loss                   | 471          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.45e+03     |\n|    water_produced               | 345          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 401         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2099        |\n|    time_elapsed                 | 9867        |\n|    total_timesteps              | 8396000     |\n| train/                          |             |\n|    approx_kl                    | 0.010605672 |\n|    clip_fraction                | 0.0717      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.842      |\n|    explained_variance           | 0.838       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 225         |\n|    n_updates                    | 4196        |\n|    policy_gradient_loss         | 0.00466     |\n|    value_loss                   | 489         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.57e+03    |\n|    water_produced               | 362         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 411          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2100         |\n|    time_elapsed                 | 9872         |\n|    total_timesteps              | 8400000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015139016 |\n|    clip_fraction                | 0.00562      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.794       |\n|    explained_variance           | 0.842        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 265          |\n|    n_updates                    | 4198         |\n|    policy_gradient_loss         | -0.00179     |\n|    value_loss                   | 531          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.76e+03     |\n|    water_produced               | 392          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 380          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2101         |\n|    time_elapsed                 | 9876         |\n|    total_timesteps              | 8404000      |\n| train/                          |              |\n|    approx_kl                    | 0.0077414513 |\n|    clip_fraction                | 0.044        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.694       |\n|    explained_variance           | 0.58         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 298          |\n|    n_updates                    | 4200         |\n|    policy_gradient_loss         | 0.00248      |\n|    value_loss                   | 625          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.53e+03     |\n|    water_produced               | 352          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 396          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2102         |\n|    time_elapsed                 | 9880         |\n|    total_timesteps              | 8408000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023091508 |\n|    clip_fraction                | 0.0174       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.794       |\n|    explained_variance           | 0.871        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 217          |\n|    n_updates                    | 4202         |\n|    policy_gradient_loss         | -0.000223    |\n|    value_loss                   | 494          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.89e+03     |\n|    water_produced               | 447          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 407         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2103        |\n|    time_elapsed                 | 9885        |\n|    total_timesteps              | 8412000     |\n| train/                          |             |\n|    approx_kl                    | 0.001241642 |\n|    clip_fraction                | 0.00662     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.697      |\n|    explained_variance           | 0.5         |\n|    learning_rate                | 0.0003      |\n|    loss                         | 237         |\n|    n_updates                    | 4204        |\n|    policy_gradient_loss         | -0.00034    |\n|    value_loss                   | 563         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.76e+03    |\n|    water_produced               | 396         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 401        |\n| time/                           |            |\n|    fps                          | 850        |\n|    iterations                   | 2104       |\n|    time_elapsed                 | 9889       |\n|    total_timesteps              | 8416000    |\n| train/                          |            |\n|    approx_kl                    | 0.00498671 |\n|    clip_fraction                | 0.0329     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.765     |\n|    explained_variance           | 0.66       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 259        |\n|    n_updates                    | 4206       |\n|    policy_gradient_loss         | 0.00139    |\n|    value_loss                   | 552        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 166        |\n|    action_queue_updates_total   | 169        |\n|    ice_dug                      | 1.53e+03   |\n|    water_produced               | 335        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 396         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2105        |\n|    time_elapsed                 | 9894        |\n|    total_timesteps              | 8420000     |\n| train/                          |             |\n|    approx_kl                    | 0.009208963 |\n|    clip_fraction                | 0.0524      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.841      |\n|    explained_variance           | 0.871       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 186         |\n|    n_updates                    | 4208        |\n|    policy_gradient_loss         | 3.24e-05    |\n|    value_loss                   | 378         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.58e+03    |\n|    water_produced               | 366         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 420         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2106        |\n|    time_elapsed                 | 9898        |\n|    total_timesteps              | 8424000     |\n| train/                          |             |\n|    approx_kl                    | 0.002853797 |\n|    clip_fraction                | 0.0181      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.855      |\n|    explained_variance           | 0.88        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 234         |\n|    n_updates                    | 4210        |\n|    policy_gradient_loss         | -0.000416   |\n|    value_loss                   | 453         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 2.01e+03    |\n|    water_produced               | 469         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 415         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2107        |\n|    time_elapsed                 | 9903        |\n|    total_timesteps              | 8428000     |\n| train/                          |             |\n|    approx_kl                    | 0.008642881 |\n|    clip_fraction                | 0.0565      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.698      |\n|    explained_variance           | 0.505       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 202         |\n|    n_updates                    | 4212        |\n|    policy_gradient_loss         | 0.00552     |\n|    value_loss                   | 393         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 161         |\n|    ice_dug                      | 1.82e+03    |\n|    water_produced               | 424         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 411          |\n| time/                           |              |\n|    fps                          | 851          |\n|    iterations                   | 2108         |\n|    time_elapsed                 | 9907         |\n|    total_timesteps              | 8432000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021088952 |\n|    clip_fraction                | 0.00963      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.73        |\n|    explained_variance           | 0.601        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 131          |\n|    n_updates                    | 4214         |\n|    policy_gradient_loss         | -0.00139     |\n|    value_loss                   | 299          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 163          |\n|    ice_dug                      | 1.59e+03     |\n|    water_produced               | 374          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 416         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2109        |\n|    time_elapsed                 | 9912        |\n|    total_timesteps              | 8436000     |\n| train/                          |             |\n|    approx_kl                    | 0.013048375 |\n|    clip_fraction                | 0.0675      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.768      |\n|    explained_variance           | 0.58        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 206         |\n|    n_updates                    | 4216        |\n|    policy_gradient_loss         | 0.00161     |\n|    value_loss                   | 432         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 151         |\n|    action_queue_updates_total   | 162         |\n|    ice_dug                      | 1.52e+03    |\n|    water_produced               | 364         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 409         |\n| time/                           |             |\n|    fps                          | 851         |\n|    iterations                   | 2110        |\n|    time_elapsed                 | 9916        |\n|    total_timesteps              | 8440000     |\n| train/                          |             |\n|    approx_kl                    | 0.010423036 |\n|    clip_fraction                | 0.0655      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.782      |\n|    explained_variance           | 0.607       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 210         |\n|    n_updates                    | 4218        |\n|    policy_gradient_loss         | 0.00615     |\n|    value_loss                   | 451         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.46e+03    |\n|    water_produced               | 333         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 392        |\n| time/                           |            |\n|    fps                          | 851        |\n|    iterations                   | 2111       |\n|    time_elapsed                 | 9920       |\n|    total_timesteps              | 8444000    |\n| train/                          |            |\n|    approx_kl                    | 0.01458323 |\n|    clip_fraction                | 0.0703     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.801     |\n|    explained_variance           | 0.819      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 206        |\n|    n_updates                    | 4220       |\n|    policy_gradient_loss         | 0.00478    |\n|    value_loss                   | 454        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 175        |\n|    action_queue_updates_total   | 179        |\n|    ice_dug                      | 1.95e+03   |\n|    water_produced               | 383        |\n------------------------------------------------\nEval num_timesteps=8448000, episode_reward=2481.84 +/- 1091.22\nEpisode length: 918.20 +/- 163.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 918          |\n|    mean_reward                  | 2.48e+03     |\n| time/                           |              |\n|    total_timesteps              | 8448000      |\n| train/                          |              |\n|    approx_kl                    | 0.0044925087 |\n|    clip_fraction                | 0.0201       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.722       |\n|    explained_variance           | 0.207        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 290          |\n|    n_updates                    | 4222         |\n|    policy_gradient_loss         | 0.000287     |\n|    value_loss                   | 616          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 2.09e+03     |\n|    water_produced               | 469          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 402      |\n| time/              |          |\n|    fps             | 850      |\n|    iterations      | 2112     |\n|    time_elapsed    | 9933     |\n|    total_timesteps | 8448000  |\n---------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 374        |\n| time/                           |            |\n|    fps                          | 850        |\n|    iterations                   | 2113       |\n|    time_elapsed                 | 9937       |\n|    total_timesteps              | 8452000    |\n| train/                          |            |\n|    approx_kl                    | 0.01624485 |\n|    clip_fraction                | 0.0765     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.674     |\n|    explained_variance           | 0.394      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 230        |\n|    n_updates                    | 4224       |\n|    policy_gradient_loss         | 0.00554    |\n|    value_loss                   | 483        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 153        |\n|    action_queue_updates_total   | 155        |\n|    ice_dug                      | 1.04e+03   |\n|    water_produced               | 239        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 384          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2114         |\n|    time_elapsed                 | 9942         |\n|    total_timesteps              | 8456000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033599087 |\n|    clip_fraction                | 0.0281       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.817       |\n|    explained_variance           | 0.802        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 412          |\n|    n_updates                    | 4226         |\n|    policy_gradient_loss         | 0.001        |\n|    value_loss                   | 834          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 161          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.82e+03     |\n|    water_produced               | 415          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 391           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2115          |\n|    time_elapsed                 | 9946          |\n|    total_timesteps              | 8460000       |\n| train/                          |               |\n|    approx_kl                    | 0.00095463917 |\n|    clip_fraction                | 0.000875      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.705        |\n|    explained_variance           | 0.61          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 180           |\n|    n_updates                    | 4228          |\n|    policy_gradient_loss         | -0.00125      |\n|    value_loss                   | 399           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 170           |\n|    action_queue_updates_total   | 171           |\n|    ice_dug                      | 1.58e+03      |\n|    water_produced               | 367           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 394         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2116        |\n|    time_elapsed                 | 9950        |\n|    total_timesteps              | 8464000     |\n| train/                          |             |\n|    approx_kl                    | 0.004607455 |\n|    clip_fraction                | 0.023       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.831      |\n|    explained_variance           | 0.876       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 177         |\n|    n_updates                    | 4230        |\n|    policy_gradient_loss         | -0.000179   |\n|    value_loss                   | 367         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.77e+03    |\n|    water_produced               | 397         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 378          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2117         |\n|    time_elapsed                 | 9955         |\n|    total_timesteps              | 8468000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018770971 |\n|    clip_fraction                | 0.0125       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.777       |\n|    explained_variance           | 0.576        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 4232         |\n|    policy_gradient_loss         | -0.00124     |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.91e+03     |\n|    water_produced               | 394          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 412          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2118         |\n|    time_elapsed                 | 9960         |\n|    total_timesteps              | 8472000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050174696 |\n|    clip_fraction                | 0.0276       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.751       |\n|    explained_variance           | 0.31         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 230          |\n|    n_updates                    | 4234         |\n|    policy_gradient_loss         | 0.00167      |\n|    value_loss                   | 507          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 1.75e+03     |\n|    water_produced               | 402          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 400          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2119         |\n|    time_elapsed                 | 9964         |\n|    total_timesteps              | 8476000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029003897 |\n|    clip_fraction                | 0.0149       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.784       |\n|    explained_variance           | 0.738        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 166          |\n|    n_updates                    | 4236         |\n|    policy_gradient_loss         | 0.00315      |\n|    value_loss                   | 332          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.53e+03     |\n|    water_produced               | 356          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 390          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2120         |\n|    time_elapsed                 | 9968         |\n|    total_timesteps              | 8480000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050434396 |\n|    clip_fraction                | 0.024        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.779       |\n|    explained_variance           | 0.642        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 4238         |\n|    policy_gradient_loss         | -0.00316     |\n|    value_loss                   | 428          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.47e+03     |\n|    water_produced               | 317          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 361         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2121        |\n|    time_elapsed                 | 9973        |\n|    total_timesteps              | 8484000     |\n| train/                          |             |\n|    approx_kl                    | 0.015603763 |\n|    clip_fraction                | 0.0766      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.832      |\n|    explained_variance           | 0.731       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 201         |\n|    n_updates                    | 4240        |\n|    policy_gradient_loss         | 0.00338     |\n|    value_loss                   | 447         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.14e+03    |\n|    water_produced               | 256         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 364         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2122        |\n|    time_elapsed                 | 9977        |\n|    total_timesteps              | 8488000     |\n| train/                          |             |\n|    approx_kl                    | 0.025822535 |\n|    clip_fraction                | 0.118       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.946      |\n|    explained_variance           | 0.903       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 141         |\n|    n_updates                    | 4242        |\n|    policy_gradient_loss         | 0.00782     |\n|    value_loss                   | 333         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 177         |\n|    ice_dug                      | 1.79e+03    |\n|    water_produced               | 410         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 385         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2123        |\n|    time_elapsed                 | 9981        |\n|    total_timesteps              | 8492000     |\n| train/                          |             |\n|    approx_kl                    | 0.004624338 |\n|    clip_fraction                | 0.024       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.808      |\n|    explained_variance           | 0.598       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 280         |\n|    n_updates                    | 4244        |\n|    policy_gradient_loss         | 0.00018     |\n|    value_loss                   | 586         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 2.1e+03     |\n|    water_produced               | 503         |\n-------------------------------------------------\n-----------------------------------------------\n| rollout/                        |           |\n|    ep_len_mean                  | 200       |\n|    ep_rew_mean                  | 404       |\n| time/                           |           |\n|    fps                          | 850       |\n|    iterations                   | 2124      |\n|    time_elapsed                 | 9986      |\n|    total_timesteps              | 8496000   |\n| train/                          |           |\n|    approx_kl                    | 0.0156557 |\n|    clip_fraction                | 0.0931    |\n|    clip_range                   | 0.2       |\n|    entropy_loss                 | -0.699    |\n|    explained_variance           | 0.536     |\n|    learning_rate                | 0.0003    |\n|    loss                         | 144       |\n|    n_updates                    | 4246      |\n|    policy_gradient_loss         | 0.00679   |\n|    value_loss                   | 364       |\n| train_metrics/                  |           |\n|    action_queue_updates_success | 171       |\n|    action_queue_updates_total   | 174       |\n|    ice_dug                      | 2.02e+03  |\n|    water_produced               | 448       |\n-----------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 401         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2125        |\n|    time_elapsed                 | 9991        |\n|    total_timesteps              | 8500000     |\n| train/                          |             |\n|    approx_kl                    | 0.008825344 |\n|    clip_fraction                | 0.07        |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.7        |\n|    explained_variance           | 0.544       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 174         |\n|    n_updates                    | 4248        |\n|    policy_gradient_loss         | 0.00583     |\n|    value_loss                   | 356         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.28e+03    |\n|    water_produced               | 303         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 404         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2126        |\n|    time_elapsed                 | 9995        |\n|    total_timesteps              | 8504000     |\n| train/                          |             |\n|    approx_kl                    | 0.009906362 |\n|    clip_fraction                | 0.0531      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.835      |\n|    explained_variance           | 0.774       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 193         |\n|    n_updates                    | 4250        |\n|    policy_gradient_loss         | 0.000552    |\n|    value_loss                   | 468         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.31e+03    |\n|    water_produced               | 271         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 412         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2127        |\n|    time_elapsed                 | 10000       |\n|    total_timesteps              | 8508000     |\n| train/                          |             |\n|    approx_kl                    | 0.033247046 |\n|    clip_fraction                | 0.135       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.884      |\n|    explained_variance           | 0.737       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 282         |\n|    n_updates                    | 4252        |\n|    policy_gradient_loss         | 0.0121      |\n|    value_loss                   | 579         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.92e+03    |\n|    water_produced               | 450         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 401          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2128         |\n|    time_elapsed                 | 10004        |\n|    total_timesteps              | 8512000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017536103 |\n|    clip_fraction                | 0.009        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.766       |\n|    explained_variance           | 0.508        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 188          |\n|    n_updates                    | 4254         |\n|    policy_gradient_loss         | 0.00115      |\n|    value_loss                   | 396          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.89e+03     |\n|    water_produced               | 448          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 395         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2129        |\n|    time_elapsed                 | 10009       |\n|    total_timesteps              | 8516000     |\n| train/                          |             |\n|    approx_kl                    | 0.010206027 |\n|    clip_fraction                | 0.0521      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.733      |\n|    explained_variance           | 0.602       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 153         |\n|    n_updates                    | 4256        |\n|    policy_gradient_loss         | 0.00476     |\n|    value_loss                   | 330         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.82e+03    |\n|    water_produced               | 420         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 406          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2130         |\n|    time_elapsed                 | 10013        |\n|    total_timesteps              | 8520000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026093915 |\n|    clip_fraction                | 0.00862      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.785       |\n|    explained_variance           | 0.619        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 170          |\n|    n_updates                    | 4258         |\n|    policy_gradient_loss         | -0.000528    |\n|    value_loss                   | 328          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.52e+03     |\n|    water_produced               | 359          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 420        |\n| time/                           |            |\n|    fps                          | 850        |\n|    iterations                   | 2131       |\n|    time_elapsed                 | 10018      |\n|    total_timesteps              | 8524000    |\n| train/                          |            |\n|    approx_kl                    | 0.01549492 |\n|    clip_fraction                | 0.0682     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.881     |\n|    explained_variance           | 0.824      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 147        |\n|    n_updates                    | 4260       |\n|    policy_gradient_loss         | 0.00303    |\n|    value_loss                   | 337        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 170        |\n|    action_queue_updates_total   | 174        |\n|    ice_dug                      | 1.58e+03   |\n|    water_produced               | 336        |\n------------------------------------------------\n-----------------------------------------------\n| rollout/                        |           |\n|    ep_len_mean                  | 200       |\n|    ep_rew_mean                  | 400       |\n| time/                           |           |\n|    fps                          | 850       |\n|    iterations                   | 2132      |\n|    time_elapsed                 | 10022     |\n|    total_timesteps              | 8528000   |\n| train/                          |           |\n|    approx_kl                    | 0.0221469 |\n|    clip_fraction                | 0.103     |\n|    clip_range                   | 0.2       |\n|    entropy_loss                 | -0.864    |\n|    explained_variance           | 0.625     |\n|    learning_rate                | 0.0003    |\n|    loss                         | 231       |\n|    n_updates                    | 4262      |\n|    policy_gradient_loss         | 0.0103    |\n|    value_loss                   | 531       |\n| train_metrics/                  |           |\n|    action_queue_updates_success | 177       |\n|    action_queue_updates_total   | 179       |\n|    ice_dug                      | 1.48e+03  |\n|    water_produced               | 356       |\n-----------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 350          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2133         |\n|    time_elapsed                 | 10026        |\n|    total_timesteps              | 8532000      |\n| train/                          |              |\n|    approx_kl                    | 0.0092130015 |\n|    clip_fraction                | 0.0529       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.88        |\n|    explained_variance           | 0.846        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 230          |\n|    n_updates                    | 4264         |\n|    policy_gradient_loss         | 0.00248      |\n|    value_loss                   | 454          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 1e+03        |\n|    water_produced               | 203          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 352         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2134        |\n|    time_elapsed                 | 10031       |\n|    total_timesteps              | 8536000     |\n| train/                          |             |\n|    approx_kl                    | 0.003615386 |\n|    clip_fraction                | 0.0254      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.986      |\n|    explained_variance           | 0.779       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 412         |\n|    n_updates                    | 4266        |\n|    policy_gradient_loss         | -0.000223   |\n|    value_loss                   | 888         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 1.9e+03     |\n|    water_produced               | 430         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 367          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2135         |\n|    time_elapsed                 | 10035        |\n|    total_timesteps              | 8540000      |\n| train/                          |              |\n|    approx_kl                    | 0.0047112866 |\n|    clip_fraction                | 0.0226       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.755       |\n|    explained_variance           | 0.463        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 249          |\n|    n_updates                    | 4268         |\n|    policy_gradient_loss         | 0.00124      |\n|    value_loss                   | 549          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.95e+03     |\n|    water_produced               | 432          |\n--------------------------------------------------\nEval num_timesteps=8544000, episode_reward=2741.76 +/- 282.14\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.74e+03    |\n| time/                           |             |\n|    total_timesteps              | 8544000     |\n| train/                          |             |\n|    approx_kl                    | 0.014862399 |\n|    clip_fraction                | 0.0778      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.731      |\n|    explained_variance           | 0.34        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 262         |\n|    n_updates                    | 4270        |\n|    policy_gradient_loss         | 0.00532     |\n|    value_loss                   | 622         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.83e+03    |\n|    water_produced               | 402         |\n-------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 381      |\n| time/              |          |\n|    fps             | 850      |\n|    iterations      | 2136     |\n|    time_elapsed    | 10048    |\n|    total_timesteps | 8544000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 397         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2137        |\n|    time_elapsed                 | 10053       |\n|    total_timesteps              | 8548000     |\n| train/                          |             |\n|    approx_kl                    | 0.011530579 |\n|    clip_fraction                | 0.0587      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.731      |\n|    explained_variance           | 0.526       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 250         |\n|    n_updates                    | 4272        |\n|    policy_gradient_loss         | 0.00593     |\n|    value_loss                   | 507         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 160         |\n|    action_queue_updates_total   | 163         |\n|    ice_dug                      | 1.83e+03    |\n|    water_produced               | 431         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 444          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2138         |\n|    time_elapsed                 | 10057        |\n|    total_timesteps              | 8552000      |\n| train/                          |              |\n|    approx_kl                    | 0.0054835314 |\n|    clip_fraction                | 0.0309       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.735       |\n|    explained_variance           | 0.681        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 139          |\n|    n_updates                    | 4274         |\n|    policy_gradient_loss         | -0.00149     |\n|    value_loss                   | 306          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 433          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 424         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2139        |\n|    time_elapsed                 | 10062       |\n|    total_timesteps              | 8556000     |\n| train/                          |             |\n|    approx_kl                    | 0.002501835 |\n|    clip_fraction                | 0.0161      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.747      |\n|    explained_variance           | 0.587       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 185         |\n|    n_updates                    | 4276        |\n|    policy_gradient_loss         | 0.00219     |\n|    value_loss                   | 390         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.44e+03    |\n|    water_produced               | 331         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 410           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2140          |\n|    time_elapsed                 | 10066         |\n|    total_timesteps              | 8560000       |\n| train/                          |               |\n|    approx_kl                    | 0.00080142776 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.81         |\n|    explained_variance           | 0.824         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 179           |\n|    n_updates                    | 4278          |\n|    policy_gradient_loss         | -0.00087      |\n|    value_loss                   | 438           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 170           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 1.68e+03      |\n|    water_produced               | 365           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 397         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2141        |\n|    time_elapsed                 | 10070       |\n|    total_timesteps              | 8564000     |\n| train/                          |             |\n|    approx_kl                    | 0.014872784 |\n|    clip_fraction                | 0.079       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.845      |\n|    explained_variance           | 0.807       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 229         |\n|    n_updates                    | 4280        |\n|    policy_gradient_loss         | 0.00188     |\n|    value_loss                   | 459         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 177         |\n|    ice_dug                      | 1.47e+03    |\n|    water_produced               | 341         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 374          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2142         |\n|    time_elapsed                 | 10075        |\n|    total_timesteps              | 8568000      |\n| train/                          |              |\n|    approx_kl                    | 0.0048157685 |\n|    clip_fraction                | 0.0306       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.875       |\n|    explained_variance           | 0.773        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 4282         |\n|    policy_gradient_loss         | -0.00118     |\n|    value_loss                   | 482          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.44e+03     |\n|    water_produced               | 322          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 371         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2143        |\n|    time_elapsed                 | 10079       |\n|    total_timesteps              | 8572000     |\n| train/                          |             |\n|    approx_kl                    | 0.010081726 |\n|    clip_fraction                | 0.0524      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.863      |\n|    explained_variance           | 0.832       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 172         |\n|    n_updates                    | 4284        |\n|    policy_gradient_loss         | 0.0048      |\n|    value_loss                   | 372         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 180         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.77e+03    |\n|    water_produced               | 416         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 386          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2144         |\n|    time_elapsed                 | 10084        |\n|    total_timesteps              | 8576000      |\n| train/                          |              |\n|    approx_kl                    | 0.0069931387 |\n|    clip_fraction                | 0.0447       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.832       |\n|    explained_variance           | 0.898        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 164          |\n|    n_updates                    | 4286         |\n|    policy_gradient_loss         | 0.000628     |\n|    value_loss                   | 382          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.77e+03     |\n|    water_produced               | 405          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 367         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2145        |\n|    time_elapsed                 | 10088       |\n|    total_timesteps              | 8580000     |\n| train/                          |             |\n|    approx_kl                    | 0.009236114 |\n|    clip_fraction                | 0.0581      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.731      |\n|    explained_variance           | 0.522       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 270         |\n|    n_updates                    | 4288        |\n|    policy_gradient_loss         | 0.00385     |\n|    value_loss                   | 547         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.16e+03    |\n|    water_produced               | 272         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 372          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2146         |\n|    time_elapsed                 | 10093        |\n|    total_timesteps              | 8584000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006037053 |\n|    clip_fraction                | 0.00112      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.882       |\n|    explained_variance           | 0.837        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 411          |\n|    n_updates                    | 4290         |\n|    policy_gradient_loss         | 0.000231     |\n|    value_loss                   | 772          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.78e+03     |\n|    water_produced               | 363          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 381          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2147         |\n|    time_elapsed                 | 10097        |\n|    total_timesteps              | 8588000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004727982 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.756       |\n|    explained_variance           | 0.497        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 428          |\n|    n_updates                    | 4292         |\n|    policy_gradient_loss         | 0.00039      |\n|    value_loss                   | 941          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.6e+03      |\n|    water_produced               | 368          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 384           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2148          |\n|    time_elapsed                 | 10102         |\n|    total_timesteps              | 8592000       |\n| train/                          |               |\n|    approx_kl                    | 0.00068454165 |\n|    clip_fraction                | 0.00212       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.826        |\n|    explained_variance           | 0.892         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 184           |\n|    n_updates                    | 4294          |\n|    policy_gradient_loss         | -0.000134     |\n|    value_loss                   | 396           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 170           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 1.84e+03      |\n|    water_produced               | 430           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 375           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2149          |\n|    time_elapsed                 | 10106         |\n|    total_timesteps              | 8596000       |\n| train/                          |               |\n|    approx_kl                    | 0.00071558816 |\n|    clip_fraction                | 0.00188       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.746        |\n|    explained_variance           | 0.555         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 320           |\n|    n_updates                    | 4296          |\n|    policy_gradient_loss         | 0.00113       |\n|    value_loss                   | 606           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 169           |\n|    action_queue_updates_total   | 171           |\n|    ice_dug                      | 1.54e+03      |\n|    water_produced               | 364           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 414          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2150         |\n|    time_elapsed                 | 10111        |\n|    total_timesteps              | 8600000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008193256 |\n|    clip_fraction                | 0.00375      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.811       |\n|    explained_variance           | 0.885        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 177          |\n|    n_updates                    | 4298         |\n|    policy_gradient_loss         | 9.87e-05     |\n|    value_loss                   | 392          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.98e+03     |\n|    water_produced               | 456          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 410           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2151          |\n|    time_elapsed                 | 10115         |\n|    total_timesteps              | 8604000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035793148 |\n|    clip_fraction                | 0.000125      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.714        |\n|    explained_variance           | 0.692         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 202           |\n|    n_updates                    | 4300          |\n|    policy_gradient_loss         | -0.000446     |\n|    value_loss                   | 380           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 156           |\n|    action_queue_updates_total   | 159           |\n|    ice_dug                      | 1.54e+03      |\n|    water_produced               | 349           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 417          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2152         |\n|    time_elapsed                 | 10119        |\n|    total_timesteps              | 8608000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021583794 |\n|    clip_fraction                | 0.0135       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.746       |\n|    explained_variance           | 0.459        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 387          |\n|    n_updates                    | 4302         |\n|    policy_gradient_loss         | 0.00106      |\n|    value_loss                   | 785          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 164          |\n|    ice_dug                      | 1.7e+03      |\n|    water_produced               | 401          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 422        |\n| time/                           |            |\n|    fps                          | 850        |\n|    iterations                   | 2153       |\n|    time_elapsed                 | 10124      |\n|    total_timesteps              | 8612000    |\n| train/                          |            |\n|    approx_kl                    | 0.00276974 |\n|    clip_fraction                | 0.0167     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.713     |\n|    explained_variance           | 0.657      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 219        |\n|    n_updates                    | 4304       |\n|    policy_gradient_loss         | -0.000622  |\n|    value_loss                   | 409        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 168        |\n|    action_queue_updates_total   | 172        |\n|    ice_dug                      | 1.96e+03   |\n|    water_produced               | 454        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 412         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2154        |\n|    time_elapsed                 | 10128       |\n|    total_timesteps              | 8616000     |\n| train/                          |             |\n|    approx_kl                    | 0.003393298 |\n|    clip_fraction                | 0.0201      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.739      |\n|    explained_variance           | 0.627       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 145         |\n|    n_updates                    | 4306        |\n|    policy_gradient_loss         | 0.00196     |\n|    value_loss                   | 306         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 167         |\n|    ice_dug                      | 1.37e+03    |\n|    water_produced               | 313         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 390         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2155        |\n|    time_elapsed                 | 10133       |\n|    total_timesteps              | 8620000     |\n| train/                          |             |\n|    approx_kl                    | 0.004567408 |\n|    clip_fraction                | 0.0226      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.836      |\n|    explained_variance           | 0.803       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 230         |\n|    n_updates                    | 4308        |\n|    policy_gradient_loss         | 0.000813    |\n|    value_loss                   | 476         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.56e+03    |\n|    water_produced               | 351         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 394         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2156        |\n|    time_elapsed                 | 10137       |\n|    total_timesteps              | 8624000     |\n| train/                          |             |\n|    approx_kl                    | 0.013947767 |\n|    clip_fraction                | 0.0763      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.871      |\n|    explained_variance           | 0.827       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 181         |\n|    n_updates                    | 4310        |\n|    policy_gradient_loss         | 0.00528     |\n|    value_loss                   | 372         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 1.61e+03    |\n|    water_produced               | 368         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 384         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2157        |\n|    time_elapsed                 | 10142       |\n|    total_timesteps              | 8628000     |\n| train/                          |             |\n|    approx_kl                    | 0.006186254 |\n|    clip_fraction                | 0.0353      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.858      |\n|    explained_variance           | 0.817       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 195         |\n|    n_updates                    | 4312        |\n|    policy_gradient_loss         | 0.00099     |\n|    value_loss                   | 424         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 1.55e+03    |\n|    water_produced               | 353         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 382          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2158         |\n|    time_elapsed                 | 10147        |\n|    total_timesteps              | 8632000      |\n| train/                          |              |\n|    approx_kl                    | 0.0044074445 |\n|    clip_fraction                | 0.0158       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.837       |\n|    explained_variance           | 0.847        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 4314         |\n|    policy_gradient_loss         | 1.57e-05     |\n|    value_loss                   | 514          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.94e+03     |\n|    water_produced               | 447          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 404         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2159        |\n|    time_elapsed                 | 10151       |\n|    total_timesteps              | 8636000     |\n| train/                          |             |\n|    approx_kl                    | 0.010825453 |\n|    clip_fraction                | 0.0674      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.707      |\n|    explained_variance           | 0.502       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 252         |\n|    n_updates                    | 4316        |\n|    policy_gradient_loss         | 0.0035      |\n|    value_loss                   | 561         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 165         |\n|    ice_dug                      | 1.88e+03    |\n|    water_produced               | 415         |\n-------------------------------------------------\nEval num_timesteps=8640000, episode_reward=2804.88 +/- 242.81\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.8e+03      |\n| time/                           |              |\n|    total_timesteps              | 8640000      |\n| train/                          |              |\n|    approx_kl                    | 0.0051530516 |\n|    clip_fraction                | 0.0327       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.671       |\n|    explained_variance           | 0.593        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 238          |\n|    n_updates                    | 4318         |\n|    policy_gradient_loss         | 0.00425      |\n|    value_loss                   | 444          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.84e+03     |\n|    water_produced               | 421          |\n--------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 418      |\n| time/              |          |\n|    fps             | 850      |\n|    iterations      | 2160     |\n|    time_elapsed    | 10164    |\n|    total_timesteps | 8640000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 435         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2161        |\n|    time_elapsed                 | 10168       |\n|    total_timesteps              | 8644000     |\n| train/                          |             |\n|    approx_kl                    | 0.004315392 |\n|    clip_fraction                | 0.026       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.711      |\n|    explained_variance           | 0.717       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 201         |\n|    n_updates                    | 4320        |\n|    policy_gradient_loss         | -0.000921   |\n|    value_loss                   | 406         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.88e+03    |\n|    water_produced               | 450         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 418          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2162         |\n|    time_elapsed                 | 10172        |\n|    total_timesteps              | 8648000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025400124 |\n|    clip_fraction                | 0.0109       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.687       |\n|    explained_variance           | 0.616        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 149          |\n|    n_updates                    | 4322         |\n|    policy_gradient_loss         | 0.000679     |\n|    value_loss                   | 302          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 149          |\n|    action_queue_updates_total   | 158          |\n|    ice_dug                      | 1.12e+03     |\n|    water_produced               | 268          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 407          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2163         |\n|    time_elapsed                 | 10177        |\n|    total_timesteps              | 8652000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035552992 |\n|    clip_fraction                | 0.0284       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.905       |\n|    explained_variance           | 0.971        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 4324         |\n|    policy_gradient_loss         | 3.81e-05     |\n|    value_loss                   | 516          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 163          |\n|    action_queue_updates_total   | 166          |\n|    ice_dug                      | 1.78e+03     |\n|    water_produced               | 398          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 412          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2164         |\n|    time_elapsed                 | 10181        |\n|    total_timesteps              | 8656000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010439471 |\n|    clip_fraction                | 0.00487      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.757       |\n|    explained_variance           | 0.612        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 189          |\n|    n_updates                    | 4326         |\n|    policy_gradient_loss         | -0.00235     |\n|    value_loss                   | 376          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.89e+03     |\n|    water_produced               | 436          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 389         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2165        |\n|    time_elapsed                 | 10186       |\n|    total_timesteps              | 8660000     |\n| train/                          |             |\n|    approx_kl                    | 0.007839397 |\n|    clip_fraction                | 0.0491      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.731      |\n|    explained_variance           | 0.623       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 142         |\n|    n_updates                    | 4328        |\n|    policy_gradient_loss         | 0.00212     |\n|    value_loss                   | 273         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.38e+03    |\n|    water_produced               | 315         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 388          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2166         |\n|    time_elapsed                 | 10190        |\n|    total_timesteps              | 8664000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037426595 |\n|    clip_fraction                | 0.0217       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.816       |\n|    explained_variance           | 0.821        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 188          |\n|    n_updates                    | 4330         |\n|    policy_gradient_loss         | -0.000177    |\n|    value_loss                   | 452          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.92e+03     |\n|    water_produced               | 441          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 406          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2167         |\n|    time_elapsed                 | 10194        |\n|    total_timesteps              | 8668000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008397731 |\n|    clip_fraction                | 0.00238      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.739       |\n|    explained_variance           | 0.647        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 157          |\n|    n_updates                    | 4332         |\n|    policy_gradient_loss         | -0.00144     |\n|    value_loss                   | 302          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 1.51e+03     |\n|    water_produced               | 358          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 415          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2168         |\n|    time_elapsed                 | 10199        |\n|    total_timesteps              | 8672000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037137992 |\n|    clip_fraction                | 0.0203       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.858       |\n|    explained_variance           | 0.839        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 225          |\n|    n_updates                    | 4334         |\n|    policy_gradient_loss         | 0.00068      |\n|    value_loss                   | 441          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 440          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 411           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2169          |\n|    time_elapsed                 | 10203         |\n|    total_timesteps              | 8676000       |\n| train/                          |               |\n|    approx_kl                    | 0.00035193982 |\n|    clip_fraction                | 0.000875      |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.776        |\n|    explained_variance           | 0.587         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 224           |\n|    n_updates                    | 4336          |\n|    policy_gradient_loss         | -0.000583     |\n|    value_loss                   | 358           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 174           |\n|    action_queue_updates_total   | 174           |\n|    ice_dug                      | 1.9e+03       |\n|    water_produced               | 414           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 429          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2170         |\n|    time_elapsed                 | 10208        |\n|    total_timesteps              | 8680000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042107515 |\n|    clip_fraction                | 0.0297       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.74        |\n|    explained_variance           | 0.513        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 4338         |\n|    policy_gradient_loss         | 0.00168      |\n|    value_loss                   | 416          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 167          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 402          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 413          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2171         |\n|    time_elapsed                 | 10212        |\n|    total_timesteps              | 8684000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029562172 |\n|    clip_fraction                | 0.0169       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.755       |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 193          |\n|    n_updates                    | 4340         |\n|    policy_gradient_loss         | -0.00309     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.65e+03     |\n|    water_produced               | 368          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 429         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2172        |\n|    time_elapsed                 | 10217       |\n|    total_timesteps              | 8688000     |\n| train/                          |             |\n|    approx_kl                    | 0.012553734 |\n|    clip_fraction                | 0.0586      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.82       |\n|    explained_variance           | 0.779       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 189         |\n|    n_updates                    | 4342        |\n|    policy_gradient_loss         | 0.00307     |\n|    value_loss                   | 429         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.98e+03    |\n|    water_produced               | 429         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 391          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2173         |\n|    time_elapsed                 | 10221        |\n|    total_timesteps              | 8692000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002945454 |\n|    clip_fraction                | 0.000125     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.756       |\n|    explained_variance           | 0.513        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 204          |\n|    n_updates                    | 4344         |\n|    policy_gradient_loss         | -0.00134     |\n|    value_loss                   | 409          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.36e+03     |\n|    water_produced               | 256          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 379          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2174         |\n|    time_elapsed                 | 10226        |\n|    total_timesteps              | 8696000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011792342 |\n|    clip_fraction                | 0.00437      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.887       |\n|    explained_variance           | 0.771        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 338          |\n|    n_updates                    | 4346         |\n|    policy_gradient_loss         | -0.000301    |\n|    value_loss                   | 690          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.62e+03     |\n|    water_produced               | 357          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 397         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2175        |\n|    time_elapsed                 | 10230       |\n|    total_timesteps              | 8700000     |\n| train/                          |             |\n|    approx_kl                    | 0.011132106 |\n|    clip_fraction                | 0.0643      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.872      |\n|    explained_variance           | 0.862       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 186         |\n|    n_updates                    | 4348        |\n|    policy_gradient_loss         | 0.00428     |\n|    value_loss                   | 405         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 182         |\n|    ice_dug                      | 2.14e+03    |\n|    water_produced               | 486         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 407         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2176        |\n|    time_elapsed                 | 10235       |\n|    total_timesteps              | 8704000     |\n| train/                          |             |\n|    approx_kl                    | 0.007198114 |\n|    clip_fraction                | 0.0547      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.751      |\n|    explained_variance           | 0.572       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 208         |\n|    n_updates                    | 4350        |\n|    policy_gradient_loss         | 0.003       |\n|    value_loss                   | 407         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.77e+03    |\n|    water_produced               | 416         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 413          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2177         |\n|    time_elapsed                 | 10239        |\n|    total_timesteps              | 8708000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037615646 |\n|    clip_fraction                | 0.0256       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.735       |\n|    explained_variance           | 0.541        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 4352         |\n|    policy_gradient_loss         | 0.00187      |\n|    value_loss                   | 440          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.94e+03     |\n|    water_produced               | 460          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 447          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2178         |\n|    time_elapsed                 | 10243        |\n|    total_timesteps              | 8712000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012457243 |\n|    clip_fraction                | 0.00225      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.719       |\n|    explained_variance           | 0.64         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 136          |\n|    n_updates                    | 4354         |\n|    policy_gradient_loss         | 0.00148      |\n|    value_loss                   | 291          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 167          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.82e+03     |\n|    water_produced               | 422          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 424           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2179          |\n|    time_elapsed                 | 10248         |\n|    total_timesteps              | 8716000       |\n| train/                          |               |\n|    approx_kl                    | 0.00092315767 |\n|    clip_fraction                | 0.0035        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.711        |\n|    explained_variance           | 0.59          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 152           |\n|    n_updates                    | 4356          |\n|    policy_gradient_loss         | -0.000335     |\n|    value_loss                   | 334           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 166           |\n|    action_queue_updates_total   | 171           |\n|    ice_dug                      | 1.07e+03      |\n|    water_produced               | 250           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 379         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2180        |\n|    time_elapsed                 | 10252       |\n|    total_timesteps              | 8720000     |\n| train/                          |             |\n|    approx_kl                    | 0.011942551 |\n|    clip_fraction                | 0.0685      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.878      |\n|    explained_variance           | 0.843       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 194         |\n|    n_updates                    | 4358        |\n|    policy_gradient_loss         | 0.00308     |\n|    value_loss                   | 462         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.15e+03    |\n|    water_produced               | 270         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 367         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2181        |\n|    time_elapsed                 | 10257       |\n|    total_timesteps              | 8724000     |\n| train/                          |             |\n|    approx_kl                    | 0.020019155 |\n|    clip_fraction                | 0.11        |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.886      |\n|    explained_variance           | 0.822       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 267         |\n|    n_updates                    | 4360        |\n|    policy_gradient_loss         | 0.0055      |\n|    value_loss                   | 569         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.58e+03    |\n|    water_produced               | 360         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 352         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2182        |\n|    time_elapsed                 | 10261       |\n|    total_timesteps              | 8728000     |\n| train/                          |             |\n|    approx_kl                    | 0.005898337 |\n|    clip_fraction                | 0.032       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.839      |\n|    explained_variance           | 0.834       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 210         |\n|    n_updates                    | 4362        |\n|    policy_gradient_loss         | -0.000407   |\n|    value_loss                   | 429         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.63e+03    |\n|    water_produced               | 384         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 336          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2183         |\n|    time_elapsed                 | 10266        |\n|    total_timesteps              | 8732000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015323764 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.844       |\n|    explained_variance           | 0.904        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 4364         |\n|    policy_gradient_loss         | -0.000641    |\n|    value_loss                   | 409          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.53e+03     |\n|    water_produced               | 349          |\n--------------------------------------------------\nEval num_timesteps=8736000, episode_reward=2976.48 +/- 225.03\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.98e+03     |\n| time/                           |              |\n|    total_timesteps              | 8736000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021640193 |\n|    clip_fraction                | 0.00925      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.843       |\n|    explained_variance           | 0.902        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 182          |\n|    n_updates                    | 4366         |\n|    policy_gradient_loss         | -0.000247    |\n|    value_loss                   | 416          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.68e+03     |\n|    water_produced               | 383          |\n--------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 364      |\n| time/              |          |\n|    fps             | 849      |\n|    iterations      | 2184     |\n|    time_elapsed    | 10279    |\n|    total_timesteps | 8736000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 412          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2185         |\n|    time_elapsed                 | 10283        |\n|    total_timesteps              | 8740000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029977583 |\n|    clip_fraction                | 0.017        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.813       |\n|    explained_variance           | 0.905        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 239          |\n|    n_updates                    | 4368         |\n|    policy_gradient_loss         | 0.000156     |\n|    value_loss                   | 505          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 2.09e+03     |\n|    water_produced               | 499          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 423         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2186        |\n|    time_elapsed                 | 10287       |\n|    total_timesteps              | 8744000     |\n| train/                          |             |\n|    approx_kl                    | 0.013542414 |\n|    clip_fraction                | 0.0772      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.674      |\n|    explained_variance           | 0.552       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 133         |\n|    n_updates                    | 4370        |\n|    policy_gradient_loss         | 0.01        |\n|    value_loss                   | 298         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 163         |\n|    action_queue_updates_total   | 166         |\n|    ice_dug                      | 1.8e+03     |\n|    water_produced               | 411         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 440        |\n| time/                           |            |\n|    fps                          | 849        |\n|    iterations                   | 2187       |\n|    time_elapsed                 | 10292      |\n|    total_timesteps              | 8748000    |\n| train/                          |            |\n|    approx_kl                    | 0.00607983 |\n|    clip_fraction                | 0.0424     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.757     |\n|    explained_variance           | 0.592      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 171        |\n|    n_updates                    | 4372       |\n|    policy_gradient_loss         | -0.00163   |\n|    value_loss                   | 348        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 177        |\n|    action_queue_updates_total   | 179        |\n|    ice_dug                      | 2.05e+03   |\n|    water_produced               | 469        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 450          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2188         |\n|    time_elapsed                 | 10296        |\n|    total_timesteps              | 8752000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018842642 |\n|    clip_fraction                | 0.0144       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.771       |\n|    explained_variance           | 0.51         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 160          |\n|    n_updates                    | 4374         |\n|    policy_gradient_loss         | -0.000668    |\n|    value_loss                   | 337          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 1.79e+03     |\n|    water_produced               | 395          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 467          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2189         |\n|    time_elapsed                 | 10301        |\n|    total_timesteps              | 8756000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010175469 |\n|    clip_fraction                | 0.0055       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.789       |\n|    explained_variance           | 0.526        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 237          |\n|    n_updates                    | 4376         |\n|    policy_gradient_loss         | -2.45e-06    |\n|    value_loss                   | 503          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 2.07e+03     |\n|    water_produced               | 463          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 462          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2190         |\n|    time_elapsed                 | 10305        |\n|    total_timesteps              | 8760000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007065552 |\n|    clip_fraction                | 0.00287      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.75        |\n|    explained_variance           | 0.533        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 162          |\n|    n_updates                    | 4378         |\n|    policy_gradient_loss         | -0.000229    |\n|    value_loss                   | 350          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 177          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 2.02e+03     |\n|    water_produced               | 474          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 439         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2191        |\n|    time_elapsed                 | 10310       |\n|    total_timesteps              | 8764000     |\n| train/                          |             |\n|    approx_kl                    | 0.010164012 |\n|    clip_fraction                | 0.0637      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.718      |\n|    explained_variance           | 0.562       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 165         |\n|    n_updates                    | 4380        |\n|    policy_gradient_loss         | 0.00684     |\n|    value_loss                   | 338         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.31e+03    |\n|    water_produced               | 303         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 431          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2192         |\n|    time_elapsed                 | 10314        |\n|    total_timesteps              | 8768000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011527243 |\n|    clip_fraction                | 0.00462      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.772       |\n|    explained_variance           | 0.775        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 256          |\n|    n_updates                    | 4382         |\n|    policy_gradient_loss         | -0.000231    |\n|    value_loss                   | 550          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.87e+03     |\n|    water_produced               | 431          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 441          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2193         |\n|    time_elapsed                 | 10319        |\n|    total_timesteps              | 8772000      |\n| train/                          |              |\n|    approx_kl                    | 0.0051373094 |\n|    clip_fraction                | 0.0269       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.756       |\n|    explained_variance           | 0.586        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 203          |\n|    n_updates                    | 4384         |\n|    policy_gradient_loss         | -0.00262     |\n|    value_loss                   | 364          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.9e+03      |\n|    water_produced               | 442          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 435           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2194          |\n|    time_elapsed                 | 10323         |\n|    total_timesteps              | 8776000       |\n| train/                          |               |\n|    approx_kl                    | 0.00084577006 |\n|    clip_fraction                | 0.00337       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.769        |\n|    explained_variance           | 0.586         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 138           |\n|    n_updates                    | 4386          |\n|    policy_gradient_loss         | -0.00121      |\n|    value_loss                   | 286           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 166           |\n|    action_queue_updates_total   | 173           |\n|    ice_dug                      | 1.87e+03      |\n|    water_produced               | 437           |\n---------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 426        |\n| time/                           |            |\n|    fps                          | 850        |\n|    iterations                   | 2195       |\n|    time_elapsed                 | 10328      |\n|    total_timesteps              | 8780000    |\n| train/                          |            |\n|    approx_kl                    | 0.00376143 |\n|    clip_fraction                | 0.0225     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.755     |\n|    explained_variance           | 0.611      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 160        |\n|    n_updates                    | 4388       |\n|    policy_gradient_loss         | -0.000542  |\n|    value_loss                   | 354        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 168        |\n|    action_queue_updates_total   | 175        |\n|    ice_dug                      | 1.82e+03   |\n|    water_produced               | 428        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 434         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2196        |\n|    time_elapsed                 | 10332       |\n|    total_timesteps              | 8784000     |\n| train/                          |             |\n|    approx_kl                    | 0.003949637 |\n|    clip_fraction                | 0.0236      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.736      |\n|    explained_variance           | 0.611       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 152         |\n|    n_updates                    | 4390        |\n|    policy_gradient_loss         | 0.000103    |\n|    value_loss                   | 343         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.51e+03    |\n|    water_produced               | 343         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 434         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2197        |\n|    time_elapsed                 | 10337       |\n|    total_timesteps              | 8788000     |\n| train/                          |             |\n|    approx_kl                    | 0.002740169 |\n|    clip_fraction                | 0.0131      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.794      |\n|    explained_variance           | 0.78        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 163         |\n|    n_updates                    | 4392        |\n|    policy_gradient_loss         | -0.00109    |\n|    value_loss                   | 418         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.9e+03     |\n|    water_produced               | 431         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 418          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2198         |\n|    time_elapsed                 | 10341        |\n|    total_timesteps              | 8792000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016261537 |\n|    clip_fraction                | 0.00775      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.741       |\n|    explained_variance           | 0.582        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 218          |\n|    n_updates                    | 4394         |\n|    policy_gradient_loss         | -0.00191     |\n|    value_loss                   | 392          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.55e+03     |\n|    water_produced               | 367          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 425         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2199        |\n|    time_elapsed                 | 10345       |\n|    total_timesteps              | 8796000     |\n| train/                          |             |\n|    approx_kl                    | 0.008168863 |\n|    clip_fraction                | 0.0372      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.813      |\n|    explained_variance           | 0.777       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 228         |\n|    n_updates                    | 4396        |\n|    policy_gradient_loss         | 0.00413     |\n|    value_loss                   | 444         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 2.02e+03    |\n|    water_produced               | 470         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 408          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2200         |\n|    time_elapsed                 | 10350        |\n|    total_timesteps              | 8800000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004899821 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.726       |\n|    explained_variance           | 0.576        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 171          |\n|    n_updates                    | 4398         |\n|    policy_gradient_loss         | -0.00043     |\n|    value_loss                   | 370          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 1.54e+03     |\n|    water_produced               | 345          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 431          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2201         |\n|    time_elapsed                 | 10354        |\n|    total_timesteps              | 8804000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007983474 |\n|    clip_fraction                | 0.00238      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.807       |\n|    explained_variance           | 0.829        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 4400         |\n|    policy_gradient_loss         | 0.00024      |\n|    value_loss                   | 443          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 177          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 2.06e+03     |\n|    water_produced               | 451          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 420           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2202          |\n|    time_elapsed                 | 10359         |\n|    total_timesteps              | 8808000       |\n| train/                          |               |\n|    approx_kl                    | 0.00031360137 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.721        |\n|    explained_variance           | 0.519         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 252           |\n|    n_updates                    | 4402          |\n|    policy_gradient_loss         | -5.35e-05     |\n|    value_loss                   | 501           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 171           |\n|    action_queue_updates_total   | 173           |\n|    ice_dug                      | 1.58e+03      |\n|    water_produced               | 381           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 445           |\n| time/                           |               |\n|    fps                          | 850           |\n|    iterations                   | 2203          |\n|    time_elapsed                 | 10363         |\n|    total_timesteps              | 8812000       |\n| train/                          |               |\n|    approx_kl                    | 0.00085215794 |\n|    clip_fraction                | 0.00337       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.787        |\n|    explained_variance           | 0.821         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 194           |\n|    n_updates                    | 4404          |\n|    policy_gradient_loss         | 0.00101       |\n|    value_loss                   | 422           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 175           |\n|    action_queue_updates_total   | 176           |\n|    ice_dug                      | 2.02e+03      |\n|    water_produced               | 484           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 446          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2204         |\n|    time_elapsed                 | 10368        |\n|    total_timesteps              | 8816000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013017606 |\n|    clip_fraction                | 0.00812      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.7         |\n|    explained_variance           | 0.556        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 171          |\n|    n_updates                    | 4406         |\n|    policy_gradient_loss         | -0.000579    |\n|    value_loss                   | 368          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.98e+03     |\n|    water_produced               | 478          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 461         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2205        |\n|    time_elapsed                 | 10373       |\n|    total_timesteps              | 8820000     |\n| train/                          |             |\n|    approx_kl                    | 0.005983813 |\n|    clip_fraction                | 0.0379      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.695      |\n|    explained_variance           | 0.633       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 125         |\n|    n_updates                    | 4408        |\n|    policy_gradient_loss         | 0.00387     |\n|    value_loss                   | 270         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.92e+03    |\n|    water_produced               | 414         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 400          |\n| time/                           |              |\n|    fps                          | 850          |\n|    iterations                   | 2206         |\n|    time_elapsed                 | 10377        |\n|    total_timesteps              | 8824000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024948514 |\n|    clip_fraction                | 0.0241       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.741       |\n|    explained_variance           | 0.466        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 4410         |\n|    policy_gradient_loss         | 0.00185      |\n|    value_loss                   | 469          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 712          |\n|    water_produced               | 161          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 404         |\n| time/                           |             |\n|    fps                          | 850         |\n|    iterations                   | 2207        |\n|    time_elapsed                 | 10382       |\n|    total_timesteps              | 8828000     |\n| train/                          |             |\n|    approx_kl                    | 0.011430837 |\n|    clip_fraction                | 0.06        |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.918      |\n|    explained_variance           | 0.811       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 258         |\n|    n_updates                    | 4412        |\n|    policy_gradient_loss         | -0.000819   |\n|    value_loss                   | 674         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 170         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.78e+03    |\n|    water_produced               | 399         |\n-------------------------------------------------\nEval num_timesteps=8832000, episode_reward=2160.68 +/- 622.80\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.16e+03     |\n| time/                           |              |\n|    total_timesteps              | 8832000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050947047 |\n|    clip_fraction                | 0.0421       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.781       |\n|    explained_variance           | 0.771        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 4414         |\n|    policy_gradient_loss         | 0.000768     |\n|    value_loss                   | 446          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 164          |\n|    action_queue_updates_total   | 168          |\n|    ice_dug                      | 1.82e+03     |\n|    water_produced               | 422          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 391      |\n| time/              |          |\n|    fps             | 849      |\n|    iterations      | 2208     |\n|    time_elapsed    | 10395    |\n|    total_timesteps | 8832000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 395          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2209         |\n|    time_elapsed                 | 10400        |\n|    total_timesteps              | 8836000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037127924 |\n|    clip_fraction                | 0.0199       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.715       |\n|    explained_variance           | 0.551        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 199          |\n|    n_updates                    | 4416         |\n|    policy_gradient_loss         | 0.00182      |\n|    value_loss                   | 391          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 2.08e+03     |\n|    water_produced               | 496          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 391         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2210        |\n|    time_elapsed                 | 10405       |\n|    total_timesteps              | 8840000     |\n| train/                          |             |\n|    approx_kl                    | 0.004617389 |\n|    clip_fraction                | 0.0264      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.711      |\n|    explained_variance           | 0.662       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 135         |\n|    n_updates                    | 4418        |\n|    policy_gradient_loss         | 0.00433     |\n|    value_loss                   | 274         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.84e+03    |\n|    water_produced               | 396         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 434          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2211         |\n|    time_elapsed                 | 10409        |\n|    total_timesteps              | 8844000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019218773 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.753       |\n|    explained_variance           | 0.559        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 221          |\n|    n_updates                    | 4420         |\n|    policy_gradient_loss         | -0.000272    |\n|    value_loss                   | 435          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.56e+03     |\n|    water_produced               | 367          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 425         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2212        |\n|    time_elapsed                 | 10414       |\n|    total_timesteps              | 8848000     |\n| train/                          |             |\n|    approx_kl                    | 0.016213834 |\n|    clip_fraction                | 0.0876      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.823      |\n|    explained_variance           | 0.651       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 181         |\n|    n_updates                    | 4422        |\n|    policy_gradient_loss         | 0.00442     |\n|    value_loss                   | 386         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.54e+03    |\n|    water_produced               | 357         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 431        |\n| time/                           |            |\n|    fps                          | 849        |\n|    iterations                   | 2213       |\n|    time_elapsed                 | 10418      |\n|    total_timesteps              | 8852000    |\n| train/                          |            |\n|    approx_kl                    | 0.01828618 |\n|    clip_fraction                | 0.0949     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.847     |\n|    explained_variance           | 0.763      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 206        |\n|    n_updates                    | 4424       |\n|    policy_gradient_loss         | 0.00364    |\n|    value_loss                   | 391        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 174        |\n|    action_queue_updates_total   | 178        |\n|    ice_dug                      | 1.93e+03   |\n|    water_produced               | 450        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 426          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2214         |\n|    time_elapsed                 | 10423        |\n|    total_timesteps              | 8856000      |\n| train/                          |              |\n|    approx_kl                    | 0.0063423947 |\n|    clip_fraction                | 0.0424       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.739       |\n|    explained_variance           | 0.501        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 4426         |\n|    policy_gradient_loss         | 0.00142      |\n|    value_loss                   | 351          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 2.01e+03     |\n|    water_produced               | 474          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 397         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2215        |\n|    time_elapsed                 | 10427       |\n|    total_timesteps              | 8860000     |\n| train/                          |             |\n|    approx_kl                    | 0.010112471 |\n|    clip_fraction                | 0.0714      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.712      |\n|    explained_variance           | 0.619       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 169         |\n|    n_updates                    | 4428        |\n|    policy_gradient_loss         | 0.00624     |\n|    value_loss                   | 366         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.14e+03    |\n|    water_produced               | 256         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 410          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2216         |\n|    time_elapsed                 | 10432        |\n|    total_timesteps              | 8864000      |\n| train/                          |              |\n|    approx_kl                    | 0.0076975212 |\n|    clip_fraction                | 0.0465       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.902       |\n|    explained_variance           | 0.868        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 4430         |\n|    policy_gradient_loss         | 0.000227     |\n|    value_loss                   | 478          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.85e+03     |\n|    water_produced               | 429          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 430          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2217         |\n|    time_elapsed                 | 10437        |\n|    total_timesteps              | 8868000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016235991 |\n|    clip_fraction                | 0.00675      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.766       |\n|    explained_variance           | 0.559        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 156          |\n|    n_updates                    | 4432         |\n|    policy_gradient_loss         | -0.00215     |\n|    value_loss                   | 347          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.95e+03     |\n|    water_produced               | 452          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 415         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2218        |\n|    time_elapsed                 | 10441       |\n|    total_timesteps              | 8872000     |\n| train/                          |             |\n|    approx_kl                    | 0.003207181 |\n|    clip_fraction                | 0.0179      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.744      |\n|    explained_variance           | 0.444       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 196         |\n|    n_updates                    | 4434        |\n|    policy_gradient_loss         | 0.00269     |\n|    value_loss                   | 381         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.78e+03    |\n|    water_produced               | 378         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 413          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2219         |\n|    time_elapsed                 | 10446        |\n|    total_timesteps              | 8876000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036357283 |\n|    clip_fraction                | 0.0189       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.739       |\n|    explained_variance           | 0.372        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 275          |\n|    n_updates                    | 4436         |\n|    policy_gradient_loss         | 0.000302     |\n|    value_loss                   | 563          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.95e+03     |\n|    water_produced               | 462          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 400          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2220         |\n|    time_elapsed                 | 10450        |\n|    total_timesteps              | 8880000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012010974 |\n|    clip_fraction                | 0.00537      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.717       |\n|    explained_variance           | 0.614        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 167          |\n|    n_updates                    | 4438         |\n|    policy_gradient_loss         | -0.00148     |\n|    value_loss                   | 318          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 861          |\n|    water_produced               | 193          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 399         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2221        |\n|    time_elapsed                 | 10455       |\n|    total_timesteps              | 8884000     |\n| train/                          |             |\n|    approx_kl                    | 0.009493016 |\n|    clip_fraction                | 0.0511      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.953      |\n|    explained_variance           | 0.83        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 270         |\n|    n_updates                    | 4440        |\n|    policy_gradient_loss         | 0.0041      |\n|    value_loss                   | 663         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 1.87e+03    |\n|    water_produced               | 428         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 389          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2222         |\n|    time_elapsed                 | 10459        |\n|    total_timesteps              | 8888000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013606315 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.768       |\n|    explained_variance           | 0.49         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 4442         |\n|    policy_gradient_loss         | -0.000328    |\n|    value_loss                   | 440          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 1.91e+03     |\n|    water_produced               | 401          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 374         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2223        |\n|    time_elapsed                 | 10464       |\n|    total_timesteps              | 8892000     |\n| train/                          |             |\n|    approx_kl                    | 0.008248873 |\n|    clip_fraction                | 0.0459      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.738      |\n|    explained_variance           | 0.448       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 232         |\n|    n_updates                    | 4444        |\n|    policy_gradient_loss         | 0.00189     |\n|    value_loss                   | 432         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.33e+03    |\n|    water_produced               | 308         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 372          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2224         |\n|    time_elapsed                 | 10468        |\n|    total_timesteps              | 8896000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042110714 |\n|    clip_fraction                | 0.0285       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.83        |\n|    explained_variance           | 0.794        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 195          |\n|    n_updates                    | 4446         |\n|    policy_gradient_loss         | 0.000867     |\n|    value_loss                   | 469          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 166          |\n|    action_queue_updates_total   | 170          |\n|    ice_dug                      | 1.89e+03     |\n|    water_produced               | 454          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 424           |\n| time/                           |               |\n|    fps                          | 849           |\n|    iterations                   | 2225          |\n|    time_elapsed                 | 10473         |\n|    total_timesteps              | 8900000       |\n| train/                          |               |\n|    approx_kl                    | 0.00093202124 |\n|    clip_fraction                | 0.00187       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.733        |\n|    explained_variance           | 0.635         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 134           |\n|    n_updates                    | 4448          |\n|    policy_gradient_loss         | -0.00146      |\n|    value_loss                   | 304           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 171           |\n|    action_queue_updates_total   | 172           |\n|    ice_dug                      | 1.87e+03      |\n|    water_produced               | 440           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 419         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2226        |\n|    time_elapsed                 | 10477       |\n|    total_timesteps              | 8904000     |\n| train/                          |             |\n|    approx_kl                    | 0.004853439 |\n|    clip_fraction                | 0.0383      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.749      |\n|    explained_variance           | 0.601       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 140         |\n|    n_updates                    | 4450        |\n|    policy_gradient_loss         | 0.000612    |\n|    value_loss                   | 286         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.86e+03    |\n|    water_produced               | 405         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 425         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2227        |\n|    time_elapsed                 | 10482       |\n|    total_timesteps              | 8908000     |\n| train/                          |             |\n|    approx_kl                    | 0.004212131 |\n|    clip_fraction                | 0.0255      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.774      |\n|    explained_variance           | 0.564       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 192         |\n|    n_updates                    | 4452        |\n|    policy_gradient_loss         | -0.00263    |\n|    value_loss                   | 376         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.91e+03    |\n|    water_produced               | 430         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 461         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2228        |\n|    time_elapsed                 | 10486       |\n|    total_timesteps              | 8912000     |\n| train/                          |             |\n|    approx_kl                    | 0.006697533 |\n|    clip_fraction                | 0.0435      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.752      |\n|    explained_variance           | 0.584       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 221         |\n|    n_updates                    | 4454        |\n|    policy_gradient_loss         | 0.00298     |\n|    value_loss                   | 439         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 2.03e+03    |\n|    water_produced               | 479         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 464          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2229         |\n|    time_elapsed                 | 10491        |\n|    total_timesteps              | 8916000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038822845 |\n|    clip_fraction                | 0.0249       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.689       |\n|    explained_variance           | 0.499        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 232          |\n|    n_updates                    | 4456         |\n|    policy_gradient_loss         | 0.00214      |\n|    value_loss                   | 401          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 2e+03        |\n|    water_produced               | 467          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 440         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2230        |\n|    time_elapsed                 | 10496       |\n|    total_timesteps              | 8920000     |\n| train/                          |             |\n|    approx_kl                    | 0.007933498 |\n|    clip_fraction                | 0.0546      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.65       |\n|    explained_variance           | 0.545       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 166         |\n|    n_updates                    | 4458        |\n|    policy_gradient_loss         | 0.00302     |\n|    value_loss                   | 355         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 170         |\n|    ice_dug                      | 1.38e+03    |\n|    water_produced               | 325         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 444         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2231        |\n|    time_elapsed                 | 10500       |\n|    total_timesteps              | 8924000     |\n| train/                          |             |\n|    approx_kl                    | 0.004665231 |\n|    clip_fraction                | 0.0248      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.777      |\n|    explained_variance           | 0.722       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 248         |\n|    n_updates                    | 4460        |\n|    policy_gradient_loss         | 0.000941    |\n|    value_loss                   | 533         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 174         |\n|    ice_dug                      | 1.86e+03    |\n|    water_produced               | 428         |\n-------------------------------------------------\nEval num_timesteps=8928000, episode_reward=2313.84 +/- 665.24\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.31e+03     |\n| time/                           |              |\n|    total_timesteps              | 8928000      |\n| train/                          |              |\n|    approx_kl                    | 0.0033125144 |\n|    clip_fraction                | 0.0132       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.754       |\n|    explained_variance           | 0.595        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 4462         |\n|    policy_gradient_loss         | -0.00187     |\n|    value_loss                   | 353          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 2.04e+03     |\n|    water_produced               | 469          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 452      |\n| time/              |          |\n|    fps             | 849      |\n|    iterations      | 2232     |\n|    time_elapsed    | 10512    |\n|    total_timesteps | 8928000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 449         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2233        |\n|    time_elapsed                 | 10517       |\n|    total_timesteps              | 8932000     |\n| train/                          |             |\n|    approx_kl                    | 0.004564115 |\n|    clip_fraction                | 0.034       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.777      |\n|    explained_variance           | 0.611       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 121         |\n|    n_updates                    | 4464        |\n|    policy_gradient_loss         | 0.0034      |\n|    value_loss                   | 244         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 1.94e+03    |\n|    water_produced               | 463         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 417          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2234         |\n|    time_elapsed                 | 10521        |\n|    total_timesteps              | 8936000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015784312 |\n|    clip_fraction                | 0.00363      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.774       |\n|    explained_variance           | 0.626        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 116          |\n|    n_updates                    | 4466         |\n|    policy_gradient_loss         | 0.00053      |\n|    value_loss                   | 233          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 1.43e+03     |\n|    water_produced               | 314          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 436         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2235        |\n|    time_elapsed                 | 10526       |\n|    total_timesteps              | 8940000     |\n| train/                          |             |\n|    approx_kl                    | 0.009645185 |\n|    clip_fraction                | 0.043       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.85       |\n|    explained_variance           | 0.689       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 225         |\n|    n_updates                    | 4468        |\n|    policy_gradient_loss         | 0.00423     |\n|    value_loss                   | 550         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.81e+03    |\n|    water_produced               | 415         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 447         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2236        |\n|    time_elapsed                 | 10531       |\n|    total_timesteps              | 8944000     |\n| train/                          |             |\n|    approx_kl                    | 0.004613583 |\n|    clip_fraction                | 0.0315      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.819      |\n|    explained_variance           | 0.567       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 188         |\n|    n_updates                    | 4470        |\n|    policy_gradient_loss         | -0.00129    |\n|    value_loss                   | 351         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 182         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 2.05e+03    |\n|    water_produced               | 481         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 443         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2237        |\n|    time_elapsed                 | 10535       |\n|    total_timesteps              | 8948000     |\n| train/                          |             |\n|    approx_kl                    | 0.008585619 |\n|    clip_fraction                | 0.0613      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.76       |\n|    explained_variance           | 0.547       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 135         |\n|    n_updates                    | 4472        |\n|    policy_gradient_loss         | 0.00217     |\n|    value_loss                   | 289         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 1.98e+03    |\n|    water_produced               | 449         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 435         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2238        |\n|    time_elapsed                 | 10540       |\n|    total_timesteps              | 8952000     |\n| train/                          |             |\n|    approx_kl                    | 0.005005373 |\n|    clip_fraction                | 0.037       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.716      |\n|    explained_variance           | 0.614       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 145         |\n|    n_updates                    | 4474        |\n|    policy_gradient_loss         | 0.00309     |\n|    value_loss                   | 285         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 167         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.81e+03    |\n|    water_produced               | 425         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 472          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2239         |\n|    time_elapsed                 | 10544        |\n|    total_timesteps              | 8956000      |\n| train/                          |              |\n|    approx_kl                    | 0.0041159326 |\n|    clip_fraction                | 0.031        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.75        |\n|    explained_variance           | 0.57         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 146          |\n|    n_updates                    | 4476         |\n|    policy_gradient_loss         | 4.98e-06     |\n|    value_loss                   | 336          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 2.03e+03     |\n|    water_produced               | 494          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 464          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2240         |\n|    time_elapsed                 | 10548        |\n|    total_timesteps              | 8960000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011849392 |\n|    clip_fraction                | 0.00325      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.748       |\n|    explained_variance           | 0.636        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 119          |\n|    n_updates                    | 4478         |\n|    policy_gradient_loss         | 0.000529     |\n|    value_loss                   | 262          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.59e+03     |\n|    water_produced               | 376          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 429          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2241         |\n|    time_elapsed                 | 10553        |\n|    total_timesteps              | 8964000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017790342 |\n|    clip_fraction                | 0.00675      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.76        |\n|    explained_variance           | 0.634        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 4480         |\n|    policy_gradient_loss         | -0.000598    |\n|    value_loss                   | 419          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.56e+03     |\n|    water_produced               | 309          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 432         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2242        |\n|    time_elapsed                 | 10558       |\n|    total_timesteps              | 8968000     |\n| train/                          |             |\n|    approx_kl                    | 0.009307973 |\n|    clip_fraction                | 0.0425      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.801      |\n|    explained_variance           | 0.58        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 276         |\n|    n_updates                    | 4482        |\n|    policy_gradient_loss         | 0.0016      |\n|    value_loss                   | 587         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.94e+03    |\n|    water_produced               | 467         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 434         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2243        |\n|    time_elapsed                 | 10562       |\n|    total_timesteps              | 8972000     |\n| train/                          |             |\n|    approx_kl                    | 0.002598818 |\n|    clip_fraction                | 0.0185      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.757      |\n|    explained_variance           | 0.603       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 160         |\n|    n_updates                    | 4484        |\n|    policy_gradient_loss         | -0.00158    |\n|    value_loss                   | 309         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 164         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 1.84e+03    |\n|    water_produced               | 433         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 412          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2244         |\n|    time_elapsed                 | 10567        |\n|    total_timesteps              | 8976000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022997358 |\n|    clip_fraction                | 0.0125       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.764       |\n|    explained_variance           | 0.571        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 4486         |\n|    policy_gradient_loss         | -0.000163    |\n|    value_loss                   | 391          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 1.61e+03     |\n|    water_produced               | 387          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 409         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2245        |\n|    time_elapsed                 | 10571       |\n|    total_timesteps              | 8980000     |\n| train/                          |             |\n|    approx_kl                    | 0.014557044 |\n|    clip_fraction                | 0.0829      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.806      |\n|    explained_variance           | 0.697       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 204         |\n|    n_updates                    | 4488        |\n|    policy_gradient_loss         | 0.00395     |\n|    value_loss                   | 476         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 1.63e+03    |\n|    water_produced               | 365         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 441         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2246        |\n|    time_elapsed                 | 10576       |\n|    total_timesteps              | 8984000     |\n| train/                          |             |\n|    approx_kl                    | 0.015411967 |\n|    clip_fraction                | 0.0826      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.854      |\n|    explained_variance           | 0.818       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 220         |\n|    n_updates                    | 4490        |\n|    policy_gradient_loss         | 0.00808     |\n|    value_loss                   | 447         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 187         |\n|    action_queue_updates_total   | 187         |\n|    ice_dug                      | 2.13e+03    |\n|    water_produced               | 463         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 431         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2247        |\n|    time_elapsed                 | 10580       |\n|    total_timesteps              | 8988000     |\n| train/                          |             |\n|    approx_kl                    | 0.004259362 |\n|    clip_fraction                | 0.024       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.745      |\n|    explained_variance           | 0.281       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 215         |\n|    n_updates                    | 4492        |\n|    policy_gradient_loss         | -0.000996   |\n|    value_loss                   | 448         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 183         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 1.75e+03    |\n|    water_produced               | 420         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 449         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2248        |\n|    time_elapsed                 | 10584       |\n|    total_timesteps              | 8992000     |\n| train/                          |             |\n|    approx_kl                    | 0.001993012 |\n|    clip_fraction                | 0.00937     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.783      |\n|    explained_variance           | 0.802       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 196         |\n|    n_updates                    | 4494        |\n|    policy_gradient_loss         | 0.00206     |\n|    value_loss                   | 438         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 183         |\n|    ice_dug                      | 2.19e+03    |\n|    water_produced               | 516         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 449          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2249         |\n|    time_elapsed                 | 10589        |\n|    total_timesteps              | 8996000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011754934 |\n|    clip_fraction                | 0.003        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.714       |\n|    explained_variance           | 0.425        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 208          |\n|    n_updates                    | 4496         |\n|    policy_gradient_loss         | 0.000195     |\n|    value_loss                   | 489          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 178          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.69e+03     |\n|    water_produced               | 387          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 448          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2250         |\n|    time_elapsed                 | 10594        |\n|    total_timesteps              | 9000000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004396849 |\n|    clip_fraction                | 0.00025      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.751       |\n|    explained_variance           | 0.819        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 183          |\n|    n_updates                    | 4498         |\n|    policy_gradient_loss         | 0.000856     |\n|    value_loss                   | 419          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.55e+03     |\n|    water_produced               | 362          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 455         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2251        |\n|    time_elapsed                 | 10598       |\n|    total_timesteps              | 9004000     |\n| train/                          |             |\n|    approx_kl                    | 0.015407222 |\n|    clip_fraction                | 0.073       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.818      |\n|    explained_variance           | 0.802       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 226         |\n|    n_updates                    | 4500        |\n|    policy_gradient_loss         | 0.00424     |\n|    value_loss                   | 490         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 182         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 2.12e+03    |\n|    water_produced               | 499         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 475          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2252         |\n|    time_elapsed                 | 10603        |\n|    total_timesteps              | 9008000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015994937 |\n|    clip_fraction                | 0.00763      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.705       |\n|    explained_variance           | 0.378        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 229          |\n|    n_updates                    | 4502         |\n|    policy_gradient_loss         | 0.000325     |\n|    value_loss                   | 496          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 177          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 2.15e+03     |\n|    water_produced               | 514          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 463         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2253        |\n|    time_elapsed                 | 10607       |\n|    total_timesteps              | 9012000     |\n| train/                          |             |\n|    approx_kl                    | 0.010962804 |\n|    clip_fraction                | 0.0786      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.676      |\n|    explained_variance           | 0.654       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 123         |\n|    n_updates                    | 4504        |\n|    policy_gradient_loss         | 0.00894     |\n|    value_loss                   | 254         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 166         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.95e+03    |\n|    water_produced               | 457         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 463          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2254         |\n|    time_elapsed                 | 10612        |\n|    total_timesteps              | 9016000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031204966 |\n|    clip_fraction                | 0.0226       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.722       |\n|    explained_variance           | 0.602        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 142          |\n|    n_updates                    | 4506         |\n|    policy_gradient_loss         | 0.00169      |\n|    value_loss                   | 286          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 1.64e+03     |\n|    water_produced               | 388          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 481          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2255         |\n|    time_elapsed                 | 10616        |\n|    total_timesteps              | 9020000      |\n| train/                          |              |\n|    approx_kl                    | 0.0075485436 |\n|    clip_fraction                | 0.0471       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.82        |\n|    explained_variance           | 0.85         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 173          |\n|    n_updates                    | 4508         |\n|    policy_gradient_loss         | 2.68e-05     |\n|    value_loss                   | 377          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.89e+03     |\n|    water_produced               | 447          |\n--------------------------------------------------\nEval num_timesteps=9024000, episode_reward=2210.84 +/- 1020.76\nEpisode length: 901.20 +/- 197.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 901          |\n|    mean_reward                  | 2.21e+03     |\n| time/                           |              |\n|    total_timesteps              | 9024000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014657674 |\n|    clip_fraction                | 0.00725      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.751       |\n|    explained_variance           | 0.509        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 160          |\n|    n_updates                    | 4510         |\n|    policy_gradient_loss         | -0.00151     |\n|    value_loss                   | 331          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 1.75e+03     |\n|    water_produced               | 408          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 462      |\n| time/              |          |\n|    fps             | 848      |\n|    iterations      | 2256     |\n|    time_elapsed    | 10630    |\n|    total_timesteps | 9024000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 427         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2257        |\n|    time_elapsed                 | 10634       |\n|    total_timesteps              | 9028000     |\n| train/                          |             |\n|    approx_kl                    | 0.008516772 |\n|    clip_fraction                | 0.0501      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.816      |\n|    explained_variance           | 0.519       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 319         |\n|    n_updates                    | 4512        |\n|    policy_gradient_loss         | -0.000857   |\n|    value_loss                   | 587         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.53e+03    |\n|    water_produced               | 346         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 412         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2258        |\n|    time_elapsed                 | 10639       |\n|    total_timesteps              | 9032000     |\n| train/                          |             |\n|    approx_kl                    | 0.005807864 |\n|    clip_fraction                | 0.0227      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.843      |\n|    explained_variance           | 0.806       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 208         |\n|    n_updates                    | 4514        |\n|    policy_gradient_loss         | 0.000162    |\n|    value_loss                   | 457         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 180         |\n|    action_queue_updates_total   | 182         |\n|    ice_dug                      | 1.66e+03    |\n|    water_produced               | 387         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 432        |\n| time/                           |            |\n|    fps                          | 848        |\n|    iterations                   | 2259       |\n|    time_elapsed                 | 10643      |\n|    total_timesteps              | 9036000    |\n| train/                          |            |\n|    approx_kl                    | 0.01768725 |\n|    clip_fraction                | 0.0871     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.868     |\n|    explained_variance           | 0.845      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 177        |\n|    n_updates                    | 4516       |\n|    policy_gradient_loss         | 0.00405    |\n|    value_loss                   | 363        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 183        |\n|    action_queue_updates_total   | 184        |\n|    ice_dug                      | 2.11e+03   |\n|    water_produced               | 484        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 432         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2260        |\n|    time_elapsed                 | 10648       |\n|    total_timesteps              | 9040000     |\n| train/                          |             |\n|    approx_kl                    | 0.004756939 |\n|    clip_fraction                | 0.0304      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.754      |\n|    explained_variance           | 0.583       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 127         |\n|    n_updates                    | 4518        |\n|    policy_gradient_loss         | 0.00122     |\n|    value_loss                   | 277         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.91e+03    |\n|    water_produced               | 445         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 438         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2261        |\n|    time_elapsed                 | 10652       |\n|    total_timesteps              | 9044000     |\n| train/                          |             |\n|    approx_kl                    | 0.005667842 |\n|    clip_fraction                | 0.0333      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.731      |\n|    explained_variance           | 0.513       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 172         |\n|    n_updates                    | 4520        |\n|    policy_gradient_loss         | 0.00272     |\n|    value_loss                   | 380         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 168         |\n|    action_queue_updates_total   | 171         |\n|    ice_dug                      | 1.86e+03    |\n|    water_produced               | 438         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 456          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2262         |\n|    time_elapsed                 | 10657        |\n|    total_timesteps              | 9048000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029995881 |\n|    clip_fraction                | 0.0164       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.766       |\n|    explained_variance           | 0.608        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 164          |\n|    n_updates                    | 4522         |\n|    policy_gradient_loss         | -0.000694    |\n|    value_loss                   | 348          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.85e+03     |\n|    water_produced               | 434          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 467         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2263        |\n|    time_elapsed                 | 10661       |\n|    total_timesteps              | 9052000     |\n| train/                          |             |\n|    approx_kl                    | 0.008333765 |\n|    clip_fraction                | 0.0551      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.788      |\n|    explained_variance           | 0.733       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 174         |\n|    n_updates                    | 4524        |\n|    policy_gradient_loss         | 0.00326     |\n|    value_loss                   | 335         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.88e+03    |\n|    water_produced               | 439         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 471          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2264         |\n|    time_elapsed                 | 10665        |\n|    total_timesteps              | 9056000      |\n| train/                          |              |\n|    approx_kl                    | 0.0043971897 |\n|    clip_fraction                | 0.0241       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.731       |\n|    explained_variance           | 0.531        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 191          |\n|    n_updates                    | 4526         |\n|    policy_gradient_loss         | -0.000527    |\n|    value_loss                   | 383          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 177          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 2.13e+03     |\n|    water_produced               | 504          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 461          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2265         |\n|    time_elapsed                 | 10670        |\n|    total_timesteps              | 9060000      |\n| train/                          |              |\n|    approx_kl                    | 0.0063373423 |\n|    clip_fraction                | 0.0384       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.662       |\n|    explained_variance           | 0.606        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 143          |\n|    n_updates                    | 4528         |\n|    policy_gradient_loss         | 0.00595      |\n|    value_loss                   | 274          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.64e+03     |\n|    water_produced               | 396          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 454           |\n| time/                           |               |\n|    fps                          | 849           |\n|    iterations                   | 2266          |\n|    time_elapsed                 | 10674         |\n|    total_timesteps              | 9064000       |\n| train/                          |               |\n|    approx_kl                    | 0.00076420075 |\n|    clip_fraction                | 0.00075       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.718        |\n|    explained_variance           | 0.79          |\n|    learning_rate                | 0.0003        |\n|    loss                         | 221           |\n|    n_updates                    | 4530          |\n|    policy_gradient_loss         | 0.00124       |\n|    value_loss                   | 480           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 162           |\n|    action_queue_updates_total   | 167           |\n|    ice_dug                      | 1.7e+03       |\n|    water_produced               | 407           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 465          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2267         |\n|    time_elapsed                 | 10679        |\n|    total_timesteps              | 9068000      |\n| train/                          |              |\n|    approx_kl                    | 0.0048862845 |\n|    clip_fraction                | 0.0241       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.711       |\n|    explained_variance           | 0.592        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 190          |\n|    n_updates                    | 4532         |\n|    policy_gradient_loss         | -0.00212     |\n|    value_loss                   | 414          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 2.05e+03     |\n|    water_produced               | 487          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 463          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2268         |\n|    time_elapsed                 | 10683        |\n|    total_timesteps              | 9072000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021715309 |\n|    clip_fraction                | 0.00825      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.71        |\n|    explained_variance           | 0.654        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 137          |\n|    n_updates                    | 4534         |\n|    policy_gradient_loss         | -0.00142     |\n|    value_loss                   | 263          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 162          |\n|    action_queue_updates_total   | 171          |\n|    ice_dug                      | 1.8e+03      |\n|    water_produced               | 426          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 419         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2269        |\n|    time_elapsed                 | 10688       |\n|    total_timesteps              | 9076000     |\n| train/                          |             |\n|    approx_kl                    | 0.001217762 |\n|    clip_fraction                | 0.0005      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.757      |\n|    explained_variance           | 0.624       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 177         |\n|    n_updates                    | 4536        |\n|    policy_gradient_loss         | 0.000165    |\n|    value_loss                   | 350         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 1.22e+03    |\n|    water_produced               | 295         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 442         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2270        |\n|    time_elapsed                 | 10692       |\n|    total_timesteps              | 9080000     |\n| train/                          |             |\n|    approx_kl                    | 0.014954187 |\n|    clip_fraction                | 0.0983      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.879      |\n|    explained_variance           | 0.84        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 163         |\n|    n_updates                    | 4538        |\n|    policy_gradient_loss         | 0.00121     |\n|    value_loss                   | 447         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 182         |\n|    action_queue_updates_total   | 185         |\n|    ice_dug                      | 2.14e+03    |\n|    water_produced               | 506         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 433          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2271         |\n|    time_elapsed                 | 10697        |\n|    total_timesteps              | 9084000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002578348 |\n|    clip_fraction                | 0.000875     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.759       |\n|    explained_variance           | 0.513        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 154          |\n|    n_updates                    | 4540         |\n|    policy_gradient_loss         | -0.001       |\n|    value_loss                   | 315          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.55e+03     |\n|    water_produced               | 362          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 428           |\n| time/                           |               |\n|    fps                          | 849           |\n|    iterations                   | 2272          |\n|    time_elapsed                 | 10701         |\n|    total_timesteps              | 9088000       |\n| train/                          |               |\n|    approx_kl                    | 0.00066861033 |\n|    clip_fraction                | 0.00162       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.813        |\n|    explained_variance           | 0.839         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 203           |\n|    n_updates                    | 4542          |\n|    policy_gradient_loss         | 0.000414      |\n|    value_loss                   | 466           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 179           |\n|    action_queue_updates_total   | 183           |\n|    ice_dug                      | 2.09e+03      |\n|    water_produced               | 464           |\n---------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 434           |\n| time/                           |               |\n|    fps                          | 849           |\n|    iterations                   | 2273          |\n|    time_elapsed                 | 10705         |\n|    total_timesteps              | 9092000       |\n| train/                          |               |\n|    approx_kl                    | 0.00033865706 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.753        |\n|    explained_variance           | 0.384         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 213           |\n|    n_updates                    | 4544          |\n|    policy_gradient_loss         | 0.000137      |\n|    value_loss                   | 452           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 177           |\n|    action_queue_updates_total   | 181           |\n|    ice_dug                      | 1.93e+03      |\n|    water_produced               | 452           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 451         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2274        |\n|    time_elapsed                 | 10710       |\n|    total_timesteps              | 9096000     |\n| train/                          |             |\n|    approx_kl                    | 0.008612961 |\n|    clip_fraction                | 0.0521      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.731      |\n|    explained_variance           | 0.481       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 201         |\n|    n_updates                    | 4546        |\n|    policy_gradient_loss         | 0.00344     |\n|    value_loss                   | 385         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 173         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.67e+03    |\n|    water_produced               | 377         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 439          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2275         |\n|    time_elapsed                 | 10715        |\n|    total_timesteps              | 9100000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042890958 |\n|    clip_fraction                | 0.0308       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.743       |\n|    explained_variance           | 0.724        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 215          |\n|    n_updates                    | 4548         |\n|    policy_gradient_loss         | -0.000316    |\n|    value_loss                   | 502          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 165          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 1.96e+03     |\n|    water_produced               | 445          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 469          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2276         |\n|    time_elapsed                 | 10719        |\n|    total_timesteps              | 9104000      |\n| train/                          |              |\n|    approx_kl                    | 0.0019322352 |\n|    clip_fraction                | 0.013        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.713       |\n|    explained_variance           | 0.545        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 4550         |\n|    policy_gradient_loss         | -0.000755    |\n|    value_loss                   | 404          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 177          |\n|    action_queue_updates_total   | 178          |\n|    ice_dug                      | 2.19e+03     |\n|    water_produced               | 507          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 443          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2277         |\n|    time_elapsed                 | 10724        |\n|    total_timesteps              | 9108000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037735575 |\n|    clip_fraction                | 0.0186       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.687       |\n|    explained_variance           | 0.502        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 170          |\n|    n_updates                    | 4552         |\n|    policy_gradient_loss         | 0.00275      |\n|    value_loss                   | 334          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 154          |\n|    action_queue_updates_total   | 162          |\n|    ice_dug                      | 1.47e+03     |\n|    water_produced               | 340          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 422          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2278         |\n|    time_elapsed                 | 10728        |\n|    total_timesteps              | 9112000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012164984 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.755       |\n|    explained_variance           | 0.583        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 284          |\n|    n_updates                    | 4554         |\n|    policy_gradient_loss         | 1.48e-06     |\n|    value_loss                   | 612          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 171          |\n|    action_queue_updates_total   | 176          |\n|    ice_dug                      | 1.61e+03     |\n|    water_produced               | 350          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 438         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2279        |\n|    time_elapsed                 | 10732       |\n|    total_timesteps              | 9116000     |\n| train/                          |             |\n|    approx_kl                    | 0.012898478 |\n|    clip_fraction                | 0.0446      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.775      |\n|    explained_variance           | 0.577       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 166         |\n|    n_updates                    | 4556        |\n|    policy_gradient_loss         | -0.00187    |\n|    value_loss                   | 431         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 1.96e+03    |\n|    water_produced               | 454         |\n-------------------------------------------------\nEval num_timesteps=9120000, episode_reward=2831.64 +/- 232.11\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.83e+03     |\n| time/                           |              |\n|    total_timesteps              | 9120000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018258102 |\n|    clip_fraction                | 0.0106       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.72        |\n|    explained_variance           | 0.61         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 161          |\n|    n_updates                    | 4558         |\n|    policy_gradient_loss         | 0.000162     |\n|    value_loss                   | 330          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 178          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.69e+03     |\n|    water_produced               | 401          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 429      |\n| time/              |          |\n|    fps             | 848      |\n|    iterations      | 2280     |\n|    time_elapsed    | 10745    |\n|    total_timesteps | 9120000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 428          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2281         |\n|    time_elapsed                 | 10750        |\n|    total_timesteps              | 9124000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011598516 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.786       |\n|    explained_variance           | 0.772        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 184          |\n|    n_updates                    | 4560         |\n|    policy_gradient_loss         | -3.12e-05    |\n|    value_loss                   | 416          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 2.1e+03      |\n|    water_produced               | 506          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 436           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 2282          |\n|    time_elapsed                 | 10754         |\n|    total_timesteps              | 9128000       |\n| train/                          |               |\n|    approx_kl                    | 0.00064730976 |\n|    clip_fraction                | 0.0015        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.751        |\n|    explained_variance           | 0.563         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 143           |\n|    n_updates                    | 4562          |\n|    policy_gradient_loss         | -0.000495     |\n|    value_loss                   | 332           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 179           |\n|    action_queue_updates_total   | 180           |\n|    ice_dug                      | 1.6e+03       |\n|    water_produced               | 381           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 456          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2283         |\n|    time_elapsed                 | 10759        |\n|    total_timesteps              | 9132000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010598463 |\n|    clip_fraction                | 0.004        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.807       |\n|    explained_variance           | 0.808        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 199          |\n|    n_updates                    | 4564         |\n|    policy_gradient_loss         | 0.000364     |\n|    value_loss                   | 447          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.95e+03     |\n|    water_produced               | 446          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 457          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2284         |\n|    time_elapsed                 | 10763        |\n|    total_timesteps              | 9136000      |\n| train/                          |              |\n|    approx_kl                    | 0.0029714943 |\n|    clip_fraction                | 0.0161       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.748       |\n|    explained_variance           | 0.745        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 262          |\n|    n_updates                    | 4566         |\n|    policy_gradient_loss         | -0.00167     |\n|    value_loss                   | 609          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 1.92e+03     |\n|    water_produced               | 460          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 469          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2285         |\n|    time_elapsed                 | 10768        |\n|    total_timesteps              | 9140000      |\n| train/                          |              |\n|    approx_kl                    | 0.0004103078 |\n|    clip_fraction                | 0.000375     |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.757       |\n|    explained_variance           | 0.572        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 180          |\n|    n_updates                    | 4568         |\n|    policy_gradient_loss         | 0.00161      |\n|    value_loss                   | 392          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 1.98e+03     |\n|    water_produced               | 456          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 465          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2286         |\n|    time_elapsed                 | 10772        |\n|    total_timesteps              | 9144000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026286938 |\n|    clip_fraction                | 0.0156       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.742       |\n|    explained_variance           | 0.506        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 192          |\n|    n_updates                    | 4570         |\n|    policy_gradient_loss         | 0.00248      |\n|    value_loss                   | 367          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 178          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 2.03e+03     |\n|    water_produced               | 487          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 460          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2287         |\n|    time_elapsed                 | 10777        |\n|    total_timesteps              | 9148000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022144592 |\n|    clip_fraction                | 0.01         |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.755       |\n|    explained_variance           | 0.634        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 122          |\n|    n_updates                    | 4572         |\n|    policy_gradient_loss         | 0.00222      |\n|    value_loss                   | 242          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.50e+03     |\n|    water_produced               | 359          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 468         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2288        |\n|    time_elapsed                 | 10781       |\n|    total_timesteps              | 9152000     |\n| train/                          |             |\n|    approx_kl                    | 0.008856027 |\n|    clip_fraction                | 0.047       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.849      |\n|    explained_variance           | 0.742       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 172         |\n|    n_updates                    | 4574        |\n|    policy_gradient_loss         | 0.0027      |\n|    value_loss                   | 414         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 182         |\n|    ice_dug                      | 1.98e+03    |\n|    water_produced               | 483         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 432          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2289         |\n|    time_elapsed                 | 10785        |\n|    total_timesteps              | 9156000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009990705 |\n|    clip_fraction                | 0.0005       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.838       |\n|    explained_variance           | 0.616        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 113          |\n|    n_updates                    | 4576         |\n|    policy_gradient_loss         | -0.00152     |\n|    value_loss                   | 235          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.36e+03     |\n|    water_produced               | 286          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 433         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2290        |\n|    time_elapsed                 | 10790       |\n|    total_timesteps              | 9160000     |\n| train/                          |             |\n|    approx_kl                    | 0.003496889 |\n|    clip_fraction                | 0.0257      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -1.05       |\n|    explained_variance           | 0.976       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 378         |\n|    n_updates                    | 4578        |\n|    policy_gradient_loss         | 0.00138     |\n|    value_loss                   | 791         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 183         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 2.04e+03    |\n|    water_produced               | 458         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 419         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2291        |\n|    time_elapsed                 | 10794       |\n|    total_timesteps              | 9164000     |\n| train/                          |             |\n|    approx_kl                    | 0.010921186 |\n|    clip_fraction                | 0.0737      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.776      |\n|    explained_variance           | 0.49        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 116         |\n|    n_updates                    | 4580        |\n|    policy_gradient_loss         | -0.00057    |\n|    value_loss                   | 251         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 173         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 1.79e+03    |\n|    water_produced               | 420         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 428        |\n| time/                           |            |\n|    fps                          | 848        |\n|    iterations                   | 2292       |\n|    time_elapsed                 | 10799      |\n|    total_timesteps              | 9168000    |\n| train/                          |            |\n|    approx_kl                    | 0.00247345 |\n|    clip_fraction                | 0.0111     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.813     |\n|    explained_variance           | 0.53       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 183        |\n|    n_updates                    | 4582       |\n|    policy_gradient_loss         | -0.000375  |\n|    value_loss                   | 386        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 176        |\n|    action_queue_updates_total   | 181        |\n|    ice_dug                      | 1.76e+03   |\n|    water_produced               | 400        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 426         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2293        |\n|    time_elapsed                 | 10803       |\n|    total_timesteps              | 9172000     |\n| train/                          |             |\n|    approx_kl                    | 0.011218883 |\n|    clip_fraction                | 0.0875      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.861      |\n|    explained_variance           | 0.564       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 190         |\n|    n_updates                    | 4584        |\n|    policy_gradient_loss         | 0.00324     |\n|    value_loss                   | 395         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 183         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 2.09e+03    |\n|    water_produced               | 476         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 452         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2294        |\n|    time_elapsed                 | 10808       |\n|    total_timesteps              | 9176000     |\n| train/                          |             |\n|    approx_kl                    | 0.003704197 |\n|    clip_fraction                | 0.0231      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.777      |\n|    explained_variance           | 0.501       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 162         |\n|    n_updates                    | 4586        |\n|    policy_gradient_loss         | -0.00117    |\n|    value_loss                   | 301         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 1.77e+03    |\n|    water_produced               | 410         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 452          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2295         |\n|    time_elapsed                 | 10813        |\n|    total_timesteps              | 9180000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010622924 |\n|    clip_fraction                | 0.00513      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.81        |\n|    explained_variance           | 0.731        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 179          |\n|    n_updates                    | 4588         |\n|    policy_gradient_loss         | -0.00116     |\n|    value_loss                   | 426          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 183          |\n|    ice_dug                      | 1.94e+03     |\n|    water_produced               | 460          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 414           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 2296          |\n|    time_elapsed                 | 10817         |\n|    total_timesteps              | 9184000       |\n| train/                          |               |\n|    approx_kl                    | 0.00059745286 |\n|    clip_fraction                | 0.00325       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.764        |\n|    explained_variance           | 0.555         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 195           |\n|    n_updates                    | 4590          |\n|    policy_gradient_loss         | -0.00097      |\n|    value_loss                   | 391           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 186           |\n|    action_queue_updates_total   | 186           |\n|    ice_dug                      | 986           |\n|    water_produced               | 238           |\n---------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 431        |\n| time/                           |            |\n|    fps                          | 848        |\n|    iterations                   | 2297       |\n|    time_elapsed                 | 10822      |\n|    total_timesteps              | 9188000    |\n| train/                          |            |\n|    approx_kl                    | 0.00394004 |\n|    clip_fraction                | 0.0244     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.935     |\n|    explained_variance           | 0.788      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 262        |\n|    n_updates                    | 4592       |\n|    policy_gradient_loss         | 0.00489    |\n|    value_loss                   | 605        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 183        |\n|    action_queue_updates_total   | 186        |\n|    ice_dug                      | 2.01e+03   |\n|    water_produced               | 481        |\n------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 435           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 2298          |\n|    time_elapsed                 | 10826         |\n|    total_timesteps              | 9192000       |\n| train/                          |               |\n|    approx_kl                    | 0.00027140585 |\n|    clip_fraction                | 0.00025       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.742        |\n|    explained_variance           | 0.438         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 169           |\n|    n_updates                    | 4594          |\n|    policy_gradient_loss         | -0.000413     |\n|    value_loss                   | 364           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 179           |\n|    action_queue_updates_total   | 182           |\n|    ice_dug                      | 2.11e+03      |\n|    water_produced               | 496           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 446         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2299        |\n|    time_elapsed                 | 10831       |\n|    total_timesteps              | 9196000     |\n| train/                          |             |\n|    approx_kl                    | 0.008208895 |\n|    clip_fraction                | 0.0545      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.723      |\n|    explained_variance           | 0.46        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 146         |\n|    n_updates                    | 4596        |\n|    policy_gradient_loss         | 0.00621     |\n|    value_loss                   | 321         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.94e+03    |\n|    water_produced               | 465         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 430          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2300         |\n|    time_elapsed                 | 10835        |\n|    total_timesteps              | 9200000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010685816 |\n|    clip_fraction                | 0.00188      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.744       |\n|    explained_variance           | 0.662        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 127          |\n|    n_updates                    | 4598         |\n|    policy_gradient_loss         | 0.00231      |\n|    value_loss                   | 264          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 178          |\n|    ice_dug                      | 1.63e+03     |\n|    water_produced               | 385          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 475         |\n| time/                           |             |\n|    fps                          | 849         |\n|    iterations                   | 2301        |\n|    time_elapsed                 | 10840       |\n|    total_timesteps              | 9204000     |\n| train/                          |             |\n|    approx_kl                    | 0.006601901 |\n|    clip_fraction                | 0.037       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.777      |\n|    explained_variance           | 0.681       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 172         |\n|    n_updates                    | 4600        |\n|    policy_gradient_loss         | -0.000384   |\n|    value_loss                   | 427         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 2.04e+03    |\n|    water_produced               | 450         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 424          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2302         |\n|    time_elapsed                 | 10845        |\n|    total_timesteps              | 9208000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014349454 |\n|    clip_fraction                | 0.0025       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.754       |\n|    explained_variance           | 0.494        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 159          |\n|    n_updates                    | 4602         |\n|    policy_gradient_loss         | -0.00147     |\n|    value_loss                   | 342          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 185          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 997          |\n|    water_produced               | 235          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 405          |\n| time/                           |              |\n|    fps                          | 849          |\n|    iterations                   | 2303         |\n|    time_elapsed                 | 10849        |\n|    total_timesteps              | 9212000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023419969 |\n|    clip_fraction                | 0.0109       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.872       |\n|    explained_variance           | 0.832        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 245          |\n|    n_updates                    | 4604         |\n|    policy_gradient_loss         | 0.00142      |\n|    value_loss                   | 608          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.73e+03     |\n|    water_produced               | 408          |\n--------------------------------------------------\nEval num_timesteps=9216000, episode_reward=2918.84 +/- 127.12\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.92e+03    |\n| time/                           |             |\n|    total_timesteps              | 9216000     |\n| train/                          |             |\n|    approx_kl                    | 0.008576147 |\n|    clip_fraction                | 0.0336      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.771      |\n|    explained_variance           | 0.806       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 161         |\n|    n_updates                    | 4606        |\n|    policy_gradient_loss         | 0.00128     |\n|    value_loss                   | 350         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 182         |\n|    action_queue_updates_total   | 182         |\n|    ice_dug                      | 2.23e+03    |\n|    water_produced               | 534         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 420      |\n| time/              |          |\n|    fps             | 848      |\n|    iterations      | 2304     |\n|    time_elapsed    | 10862    |\n|    total_timesteps | 9216000  |\n---------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 435           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 2305          |\n|    time_elapsed                 | 10867         |\n|    total_timesteps              | 9220000       |\n| train/                          |               |\n|    approx_kl                    | 0.00074573676 |\n|    clip_fraction                | 0.001         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.683        |\n|    explained_variance           | 0.556         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 152           |\n|    n_updates                    | 4608          |\n|    policy_gradient_loss         | -0.000141     |\n|    value_loss                   | 316           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 169           |\n|    action_queue_updates_total   | 174           |\n|    ice_dug                      | 2e+03         |\n|    water_produced               | 456           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 399         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2306        |\n|    time_elapsed                 | 10871       |\n|    total_timesteps              | 9224000     |\n| train/                          |             |\n|    approx_kl                    | 0.002142942 |\n|    clip_fraction                | 0.00775     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.7        |\n|    explained_variance           | 0.515       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 196         |\n|    n_updates                    | 4610        |\n|    policy_gradient_loss         | 0.00233     |\n|    value_loss                   | 388         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 180         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.23e+03    |\n|    water_produced               | 281         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 453         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2307        |\n|    time_elapsed                 | 10876       |\n|    total_timesteps              | 9228000     |\n| train/                          |             |\n|    approx_kl                    | 0.014079688 |\n|    clip_fraction                | 0.066       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.872      |\n|    explained_variance           | 0.86        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 199         |\n|    n_updates                    | 4612        |\n|    policy_gradient_loss         | -0.00122    |\n|    value_loss                   | 505         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 2.12e+03    |\n|    water_produced               | 495         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 453          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2308         |\n|    time_elapsed                 | 10881        |\n|    total_timesteps              | 9232000      |\n| train/                          |              |\n|    approx_kl                    | 0.0002249728 |\n|    clip_fraction                | 0            |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.721       |\n|    explained_variance           | 0.463        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 154          |\n|    n_updates                    | 4614         |\n|    policy_gradient_loss         | -0.000324    |\n|    value_loss                   | 316          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 183          |\n|    ice_dug                      | 1.73e+03     |\n|    water_produced               | 404          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 404          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2309         |\n|    time_elapsed                 | 10885        |\n|    total_timesteps              | 9236000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006359081 |\n|    clip_fraction                | 0.00262      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.816       |\n|    explained_variance           | 0.872        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 155          |\n|    n_updates                    | 4616         |\n|    policy_gradient_loss         | 0.00115      |\n|    value_loss                   | 366          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 185          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.36e+03     |\n|    water_produced               | 298          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 417         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2310        |\n|    time_elapsed                 | 10889       |\n|    total_timesteps              | 9240000     |\n| train/                          |             |\n|    approx_kl                    | 0.016502852 |\n|    clip_fraction                | 0.0963      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.895      |\n|    explained_variance           | 0.87        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 231         |\n|    n_updates                    | 4618        |\n|    policy_gradient_loss         | 0.00404     |\n|    value_loss                   | 459         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 180         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 2.22e+03    |\n|    water_produced               | 518         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 465          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2311         |\n|    time_elapsed                 | 10894        |\n|    total_timesteps              | 9244000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022442443 |\n|    clip_fraction                | 0.0128       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.726       |\n|    explained_variance           | 0.483        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 161          |\n|    n_updates                    | 4620         |\n|    policy_gradient_loss         | 0.00166      |\n|    value_loss                   | 324          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 183          |\n|    ice_dug                      | 2.2e+03      |\n|    water_produced               | 512          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 457        |\n| time/                           |            |\n|    fps                          | 848        |\n|    iterations                   | 2312       |\n|    time_elapsed                 | 10898      |\n|    total_timesteps              | 9248000    |\n| train/                          |            |\n|    approx_kl                    | 0.00811842 |\n|    clip_fraction                | 0.0473     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.704     |\n|    explained_variance           | 0.485      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 127        |\n|    n_updates                    | 4622       |\n|    policy_gradient_loss         | 0.00542    |\n|    value_loss                   | 267        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 171        |\n|    action_queue_updates_total   | 174        |\n|    ice_dug                      | 1.97e+03   |\n|    water_produced               | 460        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 470          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2313         |\n|    time_elapsed                 | 10903        |\n|    total_timesteps              | 9252000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012770619 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.744       |\n|    explained_variance           | 0.557        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 149          |\n|    n_updates                    | 4624         |\n|    policy_gradient_loss         | 0.00257      |\n|    value_loss                   | 310          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 2.05e+03     |\n|    water_produced               | 466          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 503         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2314        |\n|    time_elapsed                 | 10908       |\n|    total_timesteps              | 9256000     |\n| train/                          |             |\n|    approx_kl                    | 0.010045847 |\n|    clip_fraction                | 0.0541      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.765      |\n|    explained_variance           | 0.535       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 145         |\n|    n_updates                    | 4626        |\n|    policy_gradient_loss         | -0.00294    |\n|    value_loss                   | 294         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 1.94e+03    |\n|    water_produced               | 457         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 483         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2315        |\n|    time_elapsed                 | 10912       |\n|    total_timesteps              | 9260000     |\n| train/                          |             |\n|    approx_kl                    | 0.003954715 |\n|    clip_fraction                | 0.0236      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.792      |\n|    explained_variance           | 0.586       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 158         |\n|    n_updates                    | 4628        |\n|    policy_gradient_loss         | -9.53e-05   |\n|    value_loss                   | 317         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.79e+03    |\n|    water_produced               | 420         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 461          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2316         |\n|    time_elapsed                 | 10917        |\n|    total_timesteps              | 9264000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023005365 |\n|    clip_fraction                | 0.0128       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.768       |\n|    explained_variance           | 0.551        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 193          |\n|    n_updates                    | 4630         |\n|    policy_gradient_loss         | -0.00163     |\n|    value_loss                   | 399          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 1.86e+03     |\n|    water_produced               | 407          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 454         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2317        |\n|    time_elapsed                 | 10922       |\n|    total_timesteps              | 9268000     |\n| train/                          |             |\n|    approx_kl                    | 0.004637479 |\n|    clip_fraction                | 0.0239      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.763      |\n|    explained_variance           | 0.649       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 284         |\n|    n_updates                    | 4632        |\n|    policy_gradient_loss         | -0.000679   |\n|    value_loss                   | 522         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 182         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 1.77e+03    |\n|    water_produced               | 425         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 444          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2318         |\n|    time_elapsed                 | 10926        |\n|    total_timesteps              | 9272000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042394777 |\n|    clip_fraction                | 0.0187       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.791       |\n|    explained_variance           | 0.854        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 127          |\n|    n_updates                    | 4634         |\n|    policy_gradient_loss         | 0.000582     |\n|    value_loss                   | 315          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 178          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 1.74e+03     |\n|    water_produced               | 419          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 452        |\n| time/                           |            |\n|    fps                          | 848        |\n|    iterations                   | 2319       |\n|    time_elapsed                 | 10931      |\n|    total_timesteps              | 9276000    |\n| train/                          |            |\n|    approx_kl                    | 0.01155627 |\n|    clip_fraction                | 0.0575     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.793     |\n|    explained_variance           | 0.882      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 132        |\n|    n_updates                    | 4636       |\n|    policy_gradient_loss         | 0.000548   |\n|    value_loss                   | 301        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 175        |\n|    action_queue_updates_total   | 179        |\n|    ice_dug                      | 2.1e+03    |\n|    water_produced               | 496        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 471         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2320        |\n|    time_elapsed                 | 10936       |\n|    total_timesteps              | 9280000     |\n| train/                          |             |\n|    approx_kl                    | 0.003634321 |\n|    clip_fraction                | 0.0231      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.694      |\n|    explained_variance           | 0.504       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 171         |\n|    n_updates                    | 4638        |\n|    policy_gradient_loss         | 0.00312     |\n|    value_loss                   | 350         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 177         |\n|    ice_dug                      | 2.14e+03    |\n|    water_produced               | 513         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 488         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2321        |\n|    time_elapsed                 | 10940       |\n|    total_timesteps              | 9284000     |\n| train/                          |             |\n|    approx_kl                    | 0.007512834 |\n|    clip_fraction                | 0.0469      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.683      |\n|    explained_variance           | 0.551       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 161         |\n|    n_updates                    | 4640        |\n|    policy_gradient_loss         | 0.00648     |\n|    value_loss                   | 340         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 173         |\n|    ice_dug                      | 2.12e+03    |\n|    water_produced               | 488         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 495        |\n| time/                           |            |\n|    fps                          | 848        |\n|    iterations                   | 2322       |\n|    time_elapsed                 | 10945      |\n|    total_timesteps              | 9288000    |\n| train/                          |            |\n|    approx_kl                    | 0.00496649 |\n|    clip_fraction                | 0.034      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.698     |\n|    explained_variance           | 0.529      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 135        |\n|    n_updates                    | 4642       |\n|    policy_gradient_loss         | 0.00172    |\n|    value_loss                   | 263        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 173        |\n|    action_queue_updates_total   | 178        |\n|    ice_dug                      | 1.96e+03   |\n|    water_produced               | 457        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 500          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2323         |\n|    time_elapsed                 | 10949        |\n|    total_timesteps              | 9292000      |\n| train/                          |              |\n|    approx_kl                    | 0.0053839297 |\n|    clip_fraction                | 0.0349       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.777       |\n|    explained_variance           | 0.603        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 118          |\n|    n_updates                    | 4644         |\n|    policy_gradient_loss         | -0.00128     |\n|    value_loss                   | 245          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 1.89e+03     |\n|    water_produced               | 441          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 480         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2324        |\n|    time_elapsed                 | 10954       |\n|    total_timesteps              | 9296000     |\n| train/                          |             |\n|    approx_kl                    | 0.006465492 |\n|    clip_fraction                | 0.0377      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.791      |\n|    explained_variance           | 0.576       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 139         |\n|    n_updates                    | 4646        |\n|    policy_gradient_loss         | -0.00351    |\n|    value_loss                   | 291         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 1.88e+03    |\n|    water_produced               | 400         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 459          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2325         |\n|    time_elapsed                 | 10958        |\n|    total_timesteps              | 9300000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024996554 |\n|    clip_fraction                | 0.0112       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.76        |\n|    explained_variance           | 0.527        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 176          |\n|    n_updates                    | 4648         |\n|    policy_gradient_loss         | 0.000372     |\n|    value_loss                   | 390          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 183          |\n|    ice_dug                      | 1.76e+03     |\n|    water_produced               | 412          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 423         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2326        |\n|    time_elapsed                 | 10963       |\n|    total_timesteps              | 9304000     |\n| train/                          |             |\n|    approx_kl                    | 0.008336334 |\n|    clip_fraction                | 0.0356      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.785      |\n|    explained_variance           | 0.801       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 124         |\n|    n_updates                    | 4650        |\n|    policy_gradient_loss         | 0.0013      |\n|    value_loss                   | 322         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 185         |\n|    action_queue_updates_total   | 187         |\n|    ice_dug                      | 1.32e+03    |\n|    water_produced               | 314         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 432        |\n| time/                           |            |\n|    fps                          | 848        |\n|    iterations                   | 2327       |\n|    time_elapsed                 | 10968      |\n|    total_timesteps              | 9308000    |\n| train/                          |            |\n|    approx_kl                    | 0.03694043 |\n|    clip_fraction                | 0.136      |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.895     |\n|    explained_variance           | 0.88       |\n|    learning_rate                | 0.0003     |\n|    loss                         | 159        |\n|    n_updates                    | 4652       |\n|    policy_gradient_loss         | 0.00967    |\n|    value_loss                   | 375        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 180        |\n|    action_queue_updates_total   | 184        |\n|    ice_dug                      | 2.2e+03    |\n|    water_produced               | 503        |\n------------------------------------------------\nEval num_timesteps=9312000, episode_reward=2532.56 +/- 1267.46\nEpisode length: 860.20 +/- 279.60\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 860          |\n|    mean_reward                  | 2.53e+03     |\n| time/                           |              |\n|    total_timesteps              | 9312000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020627377 |\n|    clip_fraction                | 0.0113       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.719       |\n|    explained_variance           | 0.514        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 154          |\n|    n_updates                    | 4654         |\n|    policy_gradient_loss         | -0.000363    |\n|    value_loss                   | 323          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 2.2e+03      |\n|    water_produced               | 515          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 448      |\n| time/              |          |\n|    fps             | 848      |\n|    iterations      | 2328     |\n|    time_elapsed    | 10978    |\n|    total_timesteps | 9312000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 444         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2329        |\n|    time_elapsed                 | 10982       |\n|    total_timesteps              | 9316000     |\n| train/                          |             |\n|    approx_kl                    | 0.010326197 |\n|    clip_fraction                | 0.0604      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.667      |\n|    explained_variance           | 0.488       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 175         |\n|    n_updates                    | 4656        |\n|    policy_gradient_loss         | 0.00686     |\n|    value_loss                   | 363         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 1.63e+03    |\n|    water_produced               | 384         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 445          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2330         |\n|    time_elapsed                 | 10987        |\n|    total_timesteps              | 9320000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011785689 |\n|    clip_fraction                | 0.009        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.742       |\n|    explained_variance           | 0.81         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 262          |\n|    n_updates                    | 4658         |\n|    policy_gradient_loss         | 0.000863     |\n|    value_loss                   | 526          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.79e+03     |\n|    water_produced               | 416          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 486         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2331        |\n|    time_elapsed                 | 10991       |\n|    total_timesteps              | 9324000     |\n| train/                          |             |\n|    approx_kl                    | 0.010344926 |\n|    clip_fraction                | 0.0544      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.772      |\n|    explained_variance           | 0.811       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 231         |\n|    n_updates                    | 4660        |\n|    policy_gradient_loss         | 0.00214     |\n|    value_loss                   | 452         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 2.16e+03    |\n|    water_produced               | 512         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 471          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2332         |\n|    time_elapsed                 | 10996        |\n|    total_timesteps              | 9328000      |\n| train/                          |              |\n|    approx_kl                    | 0.0024609999 |\n|    clip_fraction                | 0.0131       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.664       |\n|    explained_variance           | 0.571        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 161          |\n|    n_updates                    | 4662         |\n|    policy_gradient_loss         | 0.00132      |\n|    value_loss                   | 297          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 1.87e+03     |\n|    water_produced               | 431          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 465          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2333         |\n|    time_elapsed                 | 11000        |\n|    total_timesteps              | 9332000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027131469 |\n|    clip_fraction                | 0.019        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.722       |\n|    explained_variance           | 0.724        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 245          |\n|    n_updates                    | 4664         |\n|    policy_gradient_loss         | 0.00115      |\n|    value_loss                   | 453          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 169          |\n|    ice_dug                      | 2.02e+03     |\n|    water_produced               | 486          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 467           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 2334          |\n|    time_elapsed                 | 11005         |\n|    total_timesteps              | 9336000       |\n| train/                          |               |\n|    approx_kl                    | 0.00067179825 |\n|    clip_fraction                | 0.0005        |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.652        |\n|    explained_variance           | 0.569         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 157           |\n|    n_updates                    | 4666          |\n|    policy_gradient_loss         | 3.39e-05      |\n|    value_loss                   | 288           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 176           |\n|    action_queue_updates_total   | 177           |\n|    ice_dug                      | 1.67e+03      |\n|    water_produced               | 397           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 480          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2335         |\n|    time_elapsed                 | 11010        |\n|    total_timesteps              | 9340000      |\n| train/                          |              |\n|    approx_kl                    | 0.0022577436 |\n|    clip_fraction                | 0.0133       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.753       |\n|    explained_variance           | 0.865        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 158          |\n|    n_updates                    | 4668         |\n|    policy_gradient_loss         | -0.000675    |\n|    value_loss                   | 379          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 1.98e+03     |\n|    water_produced               | 479          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 472           |\n| time/                           |               |\n|    fps                          | 848           |\n|    iterations                   | 2336          |\n|    time_elapsed                 | 11014         |\n|    total_timesteps              | 9344000       |\n| train/                          |               |\n|    approx_kl                    | 0.00089740724 |\n|    clip_fraction                | 0.004         |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.723        |\n|    explained_variance           | 0.582         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 147           |\n|    n_updates                    | 4670          |\n|    policy_gradient_loss         | -0.00217      |\n|    value_loss                   | 300           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 178           |\n|    action_queue_updates_total   | 181           |\n|    ice_dug                      | 1.97e+03      |\n|    water_produced               | 474           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 416          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2337         |\n|    time_elapsed                 | 11019        |\n|    total_timesteps              | 9348000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012563644 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.741       |\n|    explained_variance           | 0.841        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 157          |\n|    n_updates                    | 4672         |\n|    policy_gradient_loss         | -0.00117     |\n|    value_loss                   | 347          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 723          |\n|    water_produced               | 161          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 388        |\n| time/                           |            |\n|    fps                          | 848        |\n|    iterations                   | 2338       |\n|    time_elapsed                 | 11024      |\n|    total_timesteps              | 9352000    |\n| train/                          |            |\n|    approx_kl                    | 0.01467626 |\n|    clip_fraction                | 0.0615     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.963     |\n|    explained_variance           | 0.902      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 124        |\n|    n_updates                    | 4674       |\n|    policy_gradient_loss         | 0.0022     |\n|    value_loss                   | 443        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 181        |\n|    action_queue_updates_total   | 184        |\n|    ice_dug                      | 1.6e+03    |\n|    water_produced               | 352        |\n------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 398        |\n| time/                           |            |\n|    fps                          | 848        |\n|    iterations                   | 2339       |\n|    time_elapsed                 | 11028      |\n|    total_timesteps              | 9356000    |\n| train/                          |            |\n|    approx_kl                    | 0.00815667 |\n|    clip_fraction                | 0.0706     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.846     |\n|    explained_variance           | 0.863      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 328        |\n|    n_updates                    | 4676       |\n|    policy_gradient_loss         | 0.00157    |\n|    value_loss                   | 652        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 175        |\n|    action_queue_updates_total   | 179        |\n|    ice_dug                      | 1.97e+03   |\n|    water_produced               | 440        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 365          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2340         |\n|    time_elapsed                 | 11033        |\n|    total_timesteps              | 9360000      |\n| train/                          |              |\n|    approx_kl                    | 0.0025957678 |\n|    clip_fraction                | 0.0121       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.73        |\n|    explained_variance           | 0.513        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 4678         |\n|    policy_gradient_loss         | 0.00124      |\n|    value_loss                   | 465          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 185          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.36e+03     |\n|    water_produced               | 323          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 372          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2341         |\n|    time_elapsed                 | 11038        |\n|    total_timesteps              | 9364000      |\n| train/                          |              |\n|    approx_kl                    | 0.0063687502 |\n|    clip_fraction                | 0.0495       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.857       |\n|    explained_variance           | 0.915        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 217          |\n|    n_updates                    | 4680         |\n|    policy_gradient_loss         | -0.000661    |\n|    value_loss                   | 469          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 183          |\n|    ice_dug                      | 2.23e+03     |\n|    water_produced               | 503          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 440          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2342         |\n|    time_elapsed                 | 11042        |\n|    total_timesteps              | 9368000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012950774 |\n|    clip_fraction                | 0.0075       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.703       |\n|    explained_variance           | 0.364        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 196          |\n|    n_updates                    | 4682         |\n|    policy_gradient_loss         | 0.00078      |\n|    value_loss                   | 450          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 2.1e+03      |\n|    water_produced               | 488          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 461          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2343         |\n|    time_elapsed                 | 11047        |\n|    total_timesteps              | 9372000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050349403 |\n|    clip_fraction                | 0.0406       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.713       |\n|    explained_variance           | 0.594        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 170          |\n|    n_updates                    | 4684         |\n|    policy_gradient_loss         | 0.00436      |\n|    value_loss                   | 359          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 178          |\n|    ice_dug                      | 1.97e+03     |\n|    water_produced               | 455          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 475          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2344         |\n|    time_elapsed                 | 11051        |\n|    total_timesteps              | 9376000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021766934 |\n|    clip_fraction                | 0.0101       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.709       |\n|    explained_variance           | 0.516        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 4686         |\n|    policy_gradient_loss         | -0.000329    |\n|    value_loss                   | 349          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 177          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 2.21e+03     |\n|    water_produced               | 509          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 513          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2345         |\n|    time_elapsed                 | 11056        |\n|    total_timesteps              | 9380000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036064584 |\n|    clip_fraction                | 0.0153       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.664       |\n|    explained_variance           | 0.52         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 4688         |\n|    policy_gradient_loss         | 0.00246      |\n|    value_loss                   | 386          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 2.12e+03     |\n|    water_produced               | 505          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 504          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2346         |\n|    time_elapsed                 | 11061        |\n|    total_timesteps              | 9384000      |\n| train/                          |              |\n|    approx_kl                    | 0.0039001186 |\n|    clip_fraction                | 0.021        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.647       |\n|    explained_variance           | 0.573        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 126          |\n|    n_updates                    | 4690         |\n|    policy_gradient_loss         | 0.00359      |\n|    value_loss                   | 259          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 168          |\n|    action_queue_updates_total   | 173          |\n|    ice_dug                      | 1.97e+03     |\n|    water_produced               | 459          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 496         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2347        |\n|    time_elapsed                 | 11066       |\n|    total_timesteps              | 9388000     |\n| train/                          |             |\n|    approx_kl                    | 0.010609596 |\n|    clip_fraction                | 0.0661      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.72       |\n|    explained_variance           | 0.565       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 173         |\n|    n_updates                    | 4692        |\n|    policy_gradient_loss         | -0.000551   |\n|    value_loss                   | 374         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 177         |\n|    ice_dug                      | 2.07e+03    |\n|    water_produced               | 450         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 502          |\n| time/                           |              |\n|    fps                          | 848          |\n|    iterations                   | 2348         |\n|    time_elapsed                 | 11071        |\n|    total_timesteps              | 9392000      |\n| train/                          |              |\n|    approx_kl                    | 0.0047283596 |\n|    clip_fraction                | 0.0326       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.736       |\n|    explained_variance           | 0.449        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 177          |\n|    n_updates                    | 4694         |\n|    policy_gradient_loss         | -0.000841    |\n|    value_loss                   | 365          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 2.07e+03     |\n|    water_produced               | 485          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 477         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2349        |\n|    time_elapsed                 | 11076       |\n|    total_timesteps              | 9396000     |\n| train/                          |             |\n|    approx_kl                    | 0.002083626 |\n|    clip_fraction                | 0.0164      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.727      |\n|    explained_variance           | 0.61        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 143         |\n|    n_updates                    | 4696        |\n|    policy_gradient_loss         | -0.00057    |\n|    value_loss                   | 285         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 177         |\n|    ice_dug                      | 1.64e+03    |\n|    water_produced               | 390         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 453         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2350        |\n|    time_elapsed                 | 11080       |\n|    total_timesteps              | 9400000     |\n| train/                          |             |\n|    approx_kl                    | 0.011196817 |\n|    clip_fraction                | 0.0537      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.75       |\n|    explained_variance           | 0.773       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 165         |\n|    n_updates                    | 4698        |\n|    policy_gradient_loss         | 0.00327     |\n|    value_loss                   | 387         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 182         |\n|    ice_dug                      | 1.7e+03     |\n|    water_produced               | 389         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 412         |\n| time/                           |             |\n|    fps                          | 848         |\n|    iterations                   | 2351        |\n|    time_elapsed                 | 11085       |\n|    total_timesteps              | 9404000     |\n| train/                          |             |\n|    approx_kl                    | 0.027732307 |\n|    clip_fraction                | 0.0888      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.8        |\n|    explained_variance           | 0.818       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 185         |\n|    n_updates                    | 4700        |\n|    policy_gradient_loss         | 0.0141      |\n|    value_loss                   | 389         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 180         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 1.13e+03    |\n|    water_produced               | 259         |\n-------------------------------------------------\nEval num_timesteps=9408000, episode_reward=2483.60 +/- 215.65\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.48e+03    |\n| time/                           |             |\n|    total_timesteps              | 9408000     |\n| train/                          |             |\n|    approx_kl                    | 0.019396499 |\n|    clip_fraction                | 0.0779      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.901      |\n|    explained_variance           | 0.849       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 224         |\n|    n_updates                    | 4702        |\n|    policy_gradient_loss         | 0.00223     |\n|    value_loss                   | 528         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 185         |\n|    action_queue_updates_total   | 188         |\n|    ice_dug                      | 2.2e+03     |\n|    water_produced               | 517         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 425      |\n| time/              |          |\n|    fps             | 847      |\n|    iterations      | 2352     |\n|    time_elapsed    | 11099    |\n|    total_timesteps | 9408000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 404          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2353         |\n|    time_elapsed                 | 11104        |\n|    total_timesteps              | 9412000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012090851 |\n|    clip_fraction                | 0.00437      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.72        |\n|    explained_variance           | 0.488        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 4704         |\n|    policy_gradient_loss         | -0.00109     |\n|    value_loss                   | 322          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 186          |\n|    ice_dug                      | 1.74e+03     |\n|    water_produced               | 382          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 434          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2354         |\n|    time_elapsed                 | 11108        |\n|    total_timesteps              | 9416000      |\n| train/                          |              |\n|    approx_kl                    | 0.0042796265 |\n|    clip_fraction                | 0.0264       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.782       |\n|    explained_variance           | 0.856        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 243          |\n|    n_updates                    | 4706         |\n|    policy_gradient_loss         | 0.000656     |\n|    value_loss                   | 489          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 2.23e+03     |\n|    water_produced               | 533          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 466          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2355         |\n|    time_elapsed                 | 11113        |\n|    total_timesteps              | 9420000      |\n| train/                          |              |\n|    approx_kl                    | 0.0058628637 |\n|    clip_fraction                | 0.032        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.651       |\n|    explained_variance           | 0.45         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 155          |\n|    n_updates                    | 4708         |\n|    policy_gradient_loss         | 0.00311      |\n|    value_loss                   | 340          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 2.3e+03      |\n|    water_produced               | 545          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 508        |\n| time/                           |            |\n|    fps                          | 847        |\n|    iterations                   | 2356       |\n|    time_elapsed                 | 11118      |\n|    total_timesteps              | 9424000    |\n| train/                          |            |\n|    approx_kl                    | 0.01051643 |\n|    clip_fraction                | 0.0675     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.641     |\n|    explained_variance           | 0.548      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 148        |\n|    n_updates                    | 4710       |\n|    policy_gradient_loss         | 0.0104     |\n|    value_loss                   | 310        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 167        |\n|    action_queue_updates_total   | 169        |\n|    ice_dug                      | 1.91e+03   |\n|    water_produced               | 458        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 498          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2357         |\n|    time_elapsed                 | 11122        |\n|    total_timesteps              | 9428000      |\n| train/                          |              |\n|    approx_kl                    | 0.0049885074 |\n|    clip_fraction                | 0.0302       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.695       |\n|    explained_variance           | 0.558        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 209          |\n|    n_updates                    | 4712         |\n|    policy_gradient_loss         | 0.000827     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 178          |\n|    ice_dug                      | 2.04e+03     |\n|    water_produced               | 472          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 487         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2358        |\n|    time_elapsed                 | 11127       |\n|    total_timesteps              | 9432000     |\n| train/                          |             |\n|    approx_kl                    | 0.009934834 |\n|    clip_fraction                | 0.0625      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.751      |\n|    explained_variance           | 0.608       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 131         |\n|    n_updates                    | 4714        |\n|    policy_gradient_loss         | -0.00183    |\n|    value_loss                   | 272         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 183         |\n|    ice_dug                      | 1.46e+03    |\n|    water_produced               | 326         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 472          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2359         |\n|    time_elapsed                 | 11132        |\n|    total_timesteps              | 9436000      |\n| train/                          |              |\n|    approx_kl                    | 0.0117950095 |\n|    clip_fraction                | 0.0541       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.798       |\n|    explained_variance           | 0.753        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 266          |\n|    n_updates                    | 4716         |\n|    policy_gradient_loss         | 0.000209     |\n|    value_loss                   | 632          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 2.06e+03     |\n|    water_produced               | 462          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 453           |\n| time/                           |               |\n|    fps                          | 847           |\n|    iterations                   | 2360          |\n|    time_elapsed                 | 11136         |\n|    total_timesteps              | 9440000       |\n| train/                          |               |\n|    approx_kl                    | 0.00029095385 |\n|    clip_fraction                | 0.00075       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.697        |\n|    explained_variance           | 0.448         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 198           |\n|    n_updates                    | 4718          |\n|    policy_gradient_loss         | -0.000309     |\n|    value_loss                   | 432           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 177           |\n|    action_queue_updates_total   | 182           |\n|    ice_dug                      | 2.03e+03      |\n|    water_produced               | 452           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 465          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2361         |\n|    time_elapsed                 | 11141        |\n|    total_timesteps              | 9444000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010333622 |\n|    clip_fraction                | 0.00512      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.703       |\n|    explained_variance           | 0.541        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 4720         |\n|    policy_gradient_loss         | 0.000921     |\n|    value_loss                   | 422          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 178          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 2.15e+03     |\n|    water_produced               | 514          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 458          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2362         |\n|    time_elapsed                 | 11146        |\n|    total_timesteps              | 9448000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012579989 |\n|    clip_fraction                | 0.0055       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.689       |\n|    explained_variance           | 0.565        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 127          |\n|    n_updates                    | 4722         |\n|    policy_gradient_loss         | 0.000931     |\n|    value_loss                   | 268          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.86e+03     |\n|    water_produced               | 442          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 454          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2363         |\n|    time_elapsed                 | 11150        |\n|    total_timesteps              | 9452000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011682168 |\n|    clip_fraction                | 0.0045       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.734       |\n|    explained_variance           | 0.632        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 216          |\n|    n_updates                    | 4724         |\n|    policy_gradient_loss         | 0.000248     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 1.41e+03     |\n|    water_produced               | 305          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 401         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2364        |\n|    time_elapsed                 | 11155       |\n|    total_timesteps              | 9456000     |\n| train/                          |             |\n|    approx_kl                    | 0.011872305 |\n|    clip_fraction                | 0.0729      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.845      |\n|    explained_variance           | 0.781       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 247         |\n|    n_updates                    | 4726        |\n|    policy_gradient_loss         | 0.00175     |\n|    value_loss                   | 604         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 876         |\n|    water_produced               | 210         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 415         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2365        |\n|    time_elapsed                 | 11160       |\n|    total_timesteps              | 9460000     |\n| train/                          |             |\n|    approx_kl                    | 0.033495918 |\n|    clip_fraction                | 0.137       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.89       |\n|    explained_variance           | 0.81        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 202         |\n|    n_updates                    | 4728        |\n|    policy_gradient_loss         | 0.00978     |\n|    value_loss                   | 620         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 187         |\n|    action_queue_updates_total   | 188         |\n|    ice_dug                      | 2.21e+03    |\n|    water_produced               | 517         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 416          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2366         |\n|    time_elapsed                 | 11165        |\n|    total_timesteps              | 9464000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011165475 |\n|    clip_fraction                | 0.00388      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.718       |\n|    explained_variance           | 0.441        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 151          |\n|    n_updates                    | 4730         |\n|    policy_gradient_loss         | -0.000363    |\n|    value_loss                   | 325          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 186          |\n|    action_queue_updates_total   | 189          |\n|    ice_dug                      | 2.23e+03     |\n|    water_produced               | 519          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 431         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2367        |\n|    time_elapsed                 | 11169       |\n|    total_timesteps              | 9468000     |\n| train/                          |             |\n|    approx_kl                    | 0.014505406 |\n|    clip_fraction                | 0.0747      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.684      |\n|    explained_variance           | 0.44        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 160         |\n|    n_updates                    | 4732        |\n|    policy_gradient_loss         | 0.00862     |\n|    value_loss                   | 337         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 2.12e+03    |\n|    water_produced               | 518         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 450         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2368        |\n|    time_elapsed                 | 11174       |\n|    total_timesteps              | 9472000     |\n| train/                          |             |\n|    approx_kl                    | 0.011040315 |\n|    clip_fraction                | 0.064       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.685      |\n|    explained_variance           | 0.484       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 154         |\n|    n_updates                    | 4734        |\n|    policy_gradient_loss         | 0.00944     |\n|    value_loss                   | 389         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 175         |\n|    action_queue_updates_total   | 176         |\n|    ice_dug                      | 1.68e+03    |\n|    water_produced               | 394         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 503          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2369         |\n|    time_elapsed                 | 11179        |\n|    total_timesteps              | 9476000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008101237 |\n|    clip_fraction                | 0.00237      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.757       |\n|    explained_variance           | 0.805        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 234          |\n|    n_updates                    | 4736         |\n|    policy_gradient_loss         | 0.000499     |\n|    value_loss                   | 470          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 178          |\n|    ice_dug                      | 1.99e+03     |\n|    water_produced               | 466          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 491         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2370        |\n|    time_elapsed                 | 11183       |\n|    total_timesteps              | 9480000     |\n| train/                          |             |\n|    approx_kl                    | 0.004652885 |\n|    clip_fraction                | 0.0306      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.75       |\n|    explained_variance           | 0.562       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 178         |\n|    n_updates                    | 4738        |\n|    policy_gradient_loss         | -0.000404   |\n|    value_loss                   | 343         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 1.96e+03    |\n|    water_produced               | 460         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 480          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2371         |\n|    time_elapsed                 | 11188        |\n|    total_timesteps              | 9484000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010046693 |\n|    clip_fraction                | 0.00175      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.765       |\n|    explained_variance           | 0.594        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 163          |\n|    n_updates                    | 4740         |\n|    policy_gradient_loss         | -0.000804    |\n|    value_loss                   | 307          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 2.01e+03     |\n|    water_produced               | 464          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 452         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2372        |\n|    time_elapsed                 | 11193       |\n|    total_timesteps              | 9488000     |\n| train/                          |             |\n|    approx_kl                    | 0.004011142 |\n|    clip_fraction                | 0.0199      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.804      |\n|    explained_variance           | 0.603       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 127         |\n|    n_updates                    | 4742        |\n|    policy_gradient_loss         | -0.00225    |\n|    value_loss                   | 259         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 183         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 1.59e+03    |\n|    water_produced               | 382         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 445          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2373         |\n|    time_elapsed                 | 11197        |\n|    total_timesteps              | 9492000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023933959 |\n|    clip_fraction                | 0.0135       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.823       |\n|    explained_variance           | 0.747        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 4744         |\n|    policy_gradient_loss         | -0.000724    |\n|    value_loss                   | 378          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 185          |\n|    action_queue_updates_total   | 186          |\n|    ice_dug                      | 1.56e+03     |\n|    water_produced               | 361          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 440         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2374        |\n|    time_elapsed                 | 11202       |\n|    total_timesteps              | 9496000     |\n| train/                          |             |\n|    approx_kl                    | 0.015158415 |\n|    clip_fraction                | 0.0623      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.85       |\n|    explained_variance           | 0.718       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 167         |\n|    n_updates                    | 4746        |\n|    policy_gradient_loss         | 0.0027      |\n|    value_loss                   | 419         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 186         |\n|    ice_dug                      | 1.88e+03    |\n|    water_produced               | 444         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 432          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2375         |\n|    time_elapsed                 | 11206        |\n|    total_timesteps              | 9500000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018767361 |\n|    clip_fraction                | 0.00638      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.811       |\n|    explained_variance           | 0.544        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 170          |\n|    n_updates                    | 4748         |\n|    policy_gradient_loss         | -0.00115     |\n|    value_loss                   | 356          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 422          |\n--------------------------------------------------\nEval num_timesteps=9504000, episode_reward=2627.72 +/- 588.57\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.63e+03     |\n| time/                           |              |\n|    total_timesteps              | 9504000      |\n| train/                          |              |\n|    approx_kl                    | 0.0052313404 |\n|    clip_fraction                | 0.0215       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.772       |\n|    explained_variance           | 0.651        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 251          |\n|    n_updates                    | 4750         |\n|    policy_gradient_loss         | -0.00112     |\n|    value_loss                   | 512          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 1.61e+03     |\n|    water_produced               | 322          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 403      |\n| time/              |          |\n|    fps             | 847      |\n|    iterations      | 2376     |\n|    time_elapsed    | 11220    |\n|    total_timesteps | 9504000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 415         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2377        |\n|    time_elapsed                 | 11225       |\n|    total_timesteps              | 9508000     |\n| train/                          |             |\n|    approx_kl                    | 0.011267556 |\n|    clip_fraction                | 0.0603      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.841      |\n|    explained_variance           | 0.761       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 337         |\n|    n_updates                    | 4752        |\n|    policy_gradient_loss         | 0.00386     |\n|    value_loss                   | 696         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 183         |\n|    action_queue_updates_total   | 185         |\n|    ice_dug                      | 1.83e+03    |\n|    water_produced               | 437         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 446        |\n| time/                           |            |\n|    fps                          | 847        |\n|    iterations                   | 2378       |\n|    time_elapsed                 | 11229      |\n|    total_timesteps              | 9512000    |\n| train/                          |            |\n|    approx_kl                    | 0.01377283 |\n|    clip_fraction                | 0.0799     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.752     |\n|    explained_variance           | 0.794      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 234        |\n|    n_updates                    | 4754       |\n|    policy_gradient_loss         | 0.00904    |\n|    value_loss                   | 476        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 174        |\n|    action_queue_updates_total   | 174        |\n|    ice_dug                      | 2.16e+03   |\n|    water_produced               | 513        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 455         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2379        |\n|    time_elapsed                 | 11234       |\n|    total_timesteps              | 9516000     |\n| train/                          |             |\n|    approx_kl                    | 0.007626064 |\n|    clip_fraction                | 0.0486      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.651      |\n|    explained_variance           | 0.541       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 116         |\n|    n_updates                    | 4756        |\n|    policy_gradient_loss         | 0.00509     |\n|    value_loss                   | 277         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 169         |\n|    action_queue_updates_total   | 169         |\n|    ice_dug                      | 2.02e+03    |\n|    water_produced               | 486         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 477         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2380        |\n|    time_elapsed                 | 11238       |\n|    total_timesteps              | 9520000     |\n| train/                          |             |\n|    approx_kl                    | 0.008628403 |\n|    clip_fraction                | 0.0586      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.675      |\n|    explained_variance           | 0.541       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 140         |\n|    n_updates                    | 4758        |\n|    policy_gradient_loss         | -0.00162    |\n|    value_loss                   | 313         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 2.21e+03    |\n|    water_produced               | 532         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 464          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2381         |\n|    time_elapsed                 | 11243        |\n|    total_timesteps              | 9524000      |\n| train/                          |              |\n|    approx_kl                    | 0.0039610504 |\n|    clip_fraction                | 0.0301       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.692       |\n|    explained_variance           | 0.604        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 127          |\n|    n_updates                    | 4760         |\n|    policy_gradient_loss         | 0.0024       |\n|    value_loss                   | 260          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 156          |\n|    action_queue_updates_total   | 172          |\n|    ice_dug                      | 1.11e+03     |\n|    water_produced               | 259          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 476          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2382         |\n|    time_elapsed                 | 11247        |\n|    total_timesteps              | 9528000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012599954 |\n|    clip_fraction                | 0.00187      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.915       |\n|    explained_variance           | 0.957        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 305          |\n|    n_updates                    | 4762         |\n|    policy_gradient_loss         | -0.000638    |\n|    value_loss                   | 607          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 176          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 2.14e+03     |\n|    water_produced               | 493          |\n--------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 452           |\n| time/                           |               |\n|    fps                          | 847           |\n|    iterations                   | 2383          |\n|    time_elapsed                 | 11252         |\n|    total_timesteps              | 9532000       |\n| train/                          |               |\n|    approx_kl                    | 0.00075831113 |\n|    clip_fraction                | 0.00175       |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.713        |\n|    explained_variance           | 0.558         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 127           |\n|    n_updates                    | 4764          |\n|    policy_gradient_loss         | 0.000426      |\n|    value_loss                   | 257           |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 176           |\n|    action_queue_updates_total   | 181           |\n|    ice_dug                      | 1.81e+03      |\n|    water_produced               | 399           |\n---------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 451          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2384         |\n|    time_elapsed                 | 11257        |\n|    total_timesteps              | 9536000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016576694 |\n|    clip_fraction                | 0.00538      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.786       |\n|    explained_variance           | 0.547        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 234          |\n|    n_updates                    | 4766         |\n|    policy_gradient_loss         | -0.00135     |\n|    value_loss                   | 464          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 2.07e+03     |\n|    water_produced               | 480          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 445         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2385        |\n|    time_elapsed                 | 11261       |\n|    total_timesteps              | 9540000     |\n| train/                          |             |\n|    approx_kl                    | 0.005006415 |\n|    clip_fraction                | 0.0325      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.796      |\n|    explained_variance           | 0.584       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 135         |\n|    n_updates                    | 4768        |\n|    policy_gradient_loss         | -0.00322    |\n|    value_loss                   | 296         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 185         |\n|    action_queue_updates_total   | 188         |\n|    ice_dug                      | 2.13e+03    |\n|    water_produced               | 500         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 464         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2386        |\n|    time_elapsed                 | 11266       |\n|    total_timesteps              | 9544000     |\n| train/                          |             |\n|    approx_kl                    | 0.004128362 |\n|    clip_fraction                | 0.0286      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.787      |\n|    explained_variance           | 0.49        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 121         |\n|    n_updates                    | 4770        |\n|    policy_gradient_loss         | 0.00193     |\n|    value_loss                   | 249         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 1.5e+03     |\n|    water_produced               | 353         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 461          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2387         |\n|    time_elapsed                 | 11271        |\n|    total_timesteps              | 9548000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037109659 |\n|    clip_fraction                | 0.0231       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.825       |\n|    explained_variance           | 0.781        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 212          |\n|    n_updates                    | 4772         |\n|    policy_gradient_loss         | 0.000712     |\n|    value_loss                   | 484          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 2.1e+03      |\n|    water_produced               | 477          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 455          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2388         |\n|    time_elapsed                 | 11275        |\n|    total_timesteps              | 9552000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010517909 |\n|    clip_fraction                | 0.00163      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.772       |\n|    explained_variance           | 0.535        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 143          |\n|    n_updates                    | 4774         |\n|    policy_gradient_loss         | -0.00069     |\n|    value_loss                   | 287          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 1.6e+03      |\n|    water_produced               | 371          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 437          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2389         |\n|    time_elapsed                 | 11280        |\n|    total_timesteps              | 9556000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012059052 |\n|    clip_fraction                | 0.0055       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.836       |\n|    explained_variance           | 0.78         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 4776         |\n|    policy_gradient_loss         | 0.000432     |\n|    value_loss                   | 452          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 185          |\n|    action_queue_updates_total   | 186          |\n|    ice_dug                      | 1.68e+03     |\n|    water_produced               | 396          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 439          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2390         |\n|    time_elapsed                 | 11285        |\n|    total_timesteps              | 9560000      |\n| train/                          |              |\n|    approx_kl                    | 0.0145686595 |\n|    clip_fraction                | 0.0581       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.87        |\n|    explained_variance           | 0.786        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 142          |\n|    n_updates                    | 4778         |\n|    policy_gradient_loss         | 0.0016       |\n|    value_loss                   | 322          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 189          |\n|    action_queue_updates_total   | 189          |\n|    ice_dug                      | 2.14e+03     |\n|    water_produced               | 510          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 471          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2391         |\n|    time_elapsed                 | 11289        |\n|    total_timesteps              | 9564000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013376598 |\n|    clip_fraction                | 0.00262      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.775       |\n|    explained_variance           | 0.644        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 91.6         |\n|    n_updates                    | 4780         |\n|    policy_gradient_loss         | -0.00133     |\n|    value_loss                   | 181          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 185          |\n|    action_queue_updates_total   | 187          |\n|    ice_dug                      | 2.15e+03     |\n|    water_produced               | 503          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 460         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2392        |\n|    time_elapsed                 | 11294       |\n|    total_timesteps              | 9568000     |\n| train/                          |             |\n|    approx_kl                    | 0.005525791 |\n|    clip_fraction                | 0.045       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.745      |\n|    explained_variance           | 0.567       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 124         |\n|    n_updates                    | 4782        |\n|    policy_gradient_loss         | 0.00408     |\n|    value_loss                   | 226         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 185         |\n|    action_queue_updates_total   | 186         |\n|    ice_dug                      | 1.77e+03    |\n|    water_produced               | 424         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 483          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2393         |\n|    time_elapsed                 | 11299        |\n|    total_timesteps              | 9572000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027570822 |\n|    clip_fraction                | 0.0162       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.823       |\n|    explained_variance           | 0.826        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 160          |\n|    n_updates                    | 4784         |\n|    policy_gradient_loss         | 0.000366     |\n|    value_loss                   | 368          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 2.03e+03     |\n|    water_produced               | 482          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 485          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2394         |\n|    time_elapsed                 | 11304        |\n|    total_timesteps              | 9576000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023526854 |\n|    clip_fraction                | 0.0155       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.809       |\n|    explained_variance           | 0.582        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 194          |\n|    n_updates                    | 4786         |\n|    policy_gradient_loss         | -0.000984    |\n|    value_loss                   | 384          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.8e+03      |\n|    water_produced               | 406          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 447          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2395         |\n|    time_elapsed                 | 11308        |\n|    total_timesteps              | 9580000      |\n| train/                          |              |\n|    approx_kl                    | 0.0062380545 |\n|    clip_fraction                | 0.0379       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.811       |\n|    explained_variance           | 0.453        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 247          |\n|    n_updates                    | 4788         |\n|    policy_gradient_loss         | 0.00218      |\n|    value_loss                   | 516          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.48e+03     |\n|    water_produced               | 327          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 442         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2396        |\n|    time_elapsed                 | 11313       |\n|    total_timesteps              | 9584000     |\n| train/                          |             |\n|    approx_kl                    | 0.017745992 |\n|    clip_fraction                | 0.117       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.895      |\n|    explained_variance           | 0.785       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 357         |\n|    n_updates                    | 4790        |\n|    policy_gradient_loss         | 0.00496     |\n|    value_loss                   | 692         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 186         |\n|    action_queue_updates_total   | 189         |\n|    ice_dug                      | 2.08e+03    |\n|    water_produced               | 478         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 465         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2397        |\n|    time_elapsed                 | 11318       |\n|    total_timesteps              | 9588000     |\n| train/                          |             |\n|    approx_kl                    | 0.010017256 |\n|    clip_fraction                | 0.0641      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.764      |\n|    explained_variance           | 0.461       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 158         |\n|    n_updates                    | 4792        |\n|    policy_gradient_loss         | -0.00238    |\n|    value_loss                   | 326         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 185         |\n|    action_queue_updates_total   | 186         |\n|    ice_dug                      | 2.29e+03    |\n|    water_produced               | 533         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 468         |\n| time/                           |             |\n|    fps                          | 847         |\n|    iterations                   | 2398        |\n|    time_elapsed                 | 11322       |\n|    total_timesteps              | 9592000     |\n| train/                          |             |\n|    approx_kl                    | 0.010085699 |\n|    clip_fraction                | 0.0541      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.723      |\n|    explained_variance           | 0.494       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 157         |\n|    n_updates                    | 4794        |\n|    policy_gradient_loss         | 0.00461     |\n|    value_loss                   | 303         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 182         |\n|    ice_dug                      | 2.12e+03    |\n|    water_produced               | 495         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 461          |\n| time/                           |              |\n|    fps                          | 847          |\n|    iterations                   | 2399         |\n|    time_elapsed                 | 11327        |\n|    total_timesteps              | 9596000      |\n| train/                          |              |\n|    approx_kl                    | 0.0020869272 |\n|    clip_fraction                | 0.011        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.719       |\n|    explained_variance           | 0.635        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 138          |\n|    n_updates                    | 4796         |\n|    policy_gradient_loss         | 0.00142      |\n|    value_loss                   | 274          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.6e+03      |\n|    water_produced               | 373          |\n--------------------------------------------------\nEval num_timesteps=9600000, episode_reward=2978.68 +/- 188.10\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 2.98e+03    |\n| time/                           |             |\n|    total_timesteps              | 9600000     |\n| train/                          |             |\n|    approx_kl                    | 0.017827902 |\n|    clip_fraction                | 0.0954      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.8        |\n|    explained_variance           | 0.808       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 211         |\n|    n_updates                    | 4798        |\n|    policy_gradient_loss         | 0.00475     |\n|    value_loss                   | 472         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 184         |\n|    action_queue_updates_total   | 186         |\n|    ice_dug                      | 1.82e+03    |\n|    water_produced               | 425         |\n-------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 481      |\n| time/              |          |\n|    fps             | 846      |\n|    iterations      | 2400     |\n|    time_elapsed    | 11340    |\n|    total_timesteps | 9600000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 484         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2401        |\n|    time_elapsed                 | 11344       |\n|    total_timesteps              | 9604000     |\n| train/                          |             |\n|    approx_kl                    | 0.010478855 |\n|    clip_fraction                | 0.0681      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.811      |\n|    explained_variance           | 0.834       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 185         |\n|    n_updates                    | 4800        |\n|    policy_gradient_loss         | -0.000517   |\n|    value_loss                   | 373         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 183         |\n|    ice_dug                      | 2.1e+03     |\n|    water_produced               | 492         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 464         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2402        |\n|    time_elapsed                 | 11349       |\n|    total_timesteps              | 9608000     |\n| train/                          |             |\n|    approx_kl                    | 0.006390956 |\n|    clip_fraction                | 0.0385      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.724      |\n|    explained_variance           | 0.53        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 154         |\n|    n_updates                    | 4802        |\n|    policy_gradient_loss         | 0.00432     |\n|    value_loss                   | 315         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 1.86e+03    |\n|    water_produced               | 442         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 467          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2403         |\n|    time_elapsed                 | 11354        |\n|    total_timesteps              | 9612000      |\n| train/                          |              |\n|    approx_kl                    | 0.0026904668 |\n|    clip_fraction                | 0.0205       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.785       |\n|    explained_variance           | 0.854        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 197          |\n|    n_updates                    | 4804         |\n|    policy_gradient_loss         | 0.00293      |\n|    value_loss                   | 432          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 183          |\n|    ice_dug                      | 2.17e+03     |\n|    water_produced               | 507          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 496          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2404         |\n|    time_elapsed                 | 11358        |\n|    total_timesteps              | 9616000      |\n| train/                          |              |\n|    approx_kl                    | 0.0009059904 |\n|    clip_fraction                | 0.003        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.722       |\n|    explained_variance           | 0.549        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 106          |\n|    n_updates                    | 4806         |\n|    policy_gradient_loss         | 0.000953     |\n|    value_loss                   | 232          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 2.15e+03     |\n|    water_produced               | 514          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 487          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2405         |\n|    time_elapsed                 | 11363        |\n|    total_timesteps              | 9620000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028195546 |\n|    clip_fraction                | 0.0139       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.755       |\n|    explained_variance           | 0.626        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 107          |\n|    n_updates                    | 4808         |\n|    policy_gradient_loss         | -0.000888    |\n|    value_loss                   | 230          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.62e+03     |\n|    water_produced               | 382          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 457         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2406        |\n|    time_elapsed                 | 11367       |\n|    total_timesteps              | 9624000     |\n| train/                          |             |\n|    approx_kl                    | 0.015192917 |\n|    clip_fraction                | 0.0954      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.82       |\n|    explained_variance           | 0.817       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 182         |\n|    n_updates                    | 4810        |\n|    policy_gradient_loss         | 0.00225     |\n|    value_loss                   | 419         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 183         |\n|    ice_dug                      | 1.59e+03    |\n|    water_produced               | 344         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 438        |\n| time/                           |            |\n|    fps                          | 846        |\n|    iterations                   | 2407       |\n|    time_elapsed                 | 11372      |\n|    total_timesteps              | 9628000    |\n| train/                          |            |\n|    approx_kl                    | 0.01815093 |\n|    clip_fraction                | 0.0847     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.84      |\n|    explained_variance           | 0.846      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 202        |\n|    n_updates                    | 4812       |\n|    policy_gradient_loss         | 0.00519    |\n|    value_loss                   | 444        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 179        |\n|    action_queue_updates_total   | 183        |\n|    ice_dug                      | 1.53e+03   |\n|    water_produced               | 352        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 437          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2408         |\n|    time_elapsed                 | 11376        |\n|    total_timesteps              | 9632000      |\n| train/                          |              |\n|    approx_kl                    | 0.0070714825 |\n|    clip_fraction                | 0.0497       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.842       |\n|    explained_variance           | 0.87         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 214          |\n|    n_updates                    | 4814         |\n|    policy_gradient_loss         | -0.000495    |\n|    value_loss                   | 480          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 183          |\n|    action_queue_updates_total   | 189          |\n|    ice_dug                      | 2.21e+03     |\n|    water_produced               | 499          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 433          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2409         |\n|    time_elapsed                 | 11381        |\n|    total_timesteps              | 9636000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037243858 |\n|    clip_fraction                | 0.0211       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.75        |\n|    explained_variance           | 0.429        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 193          |\n|    n_updates                    | 4816         |\n|    policy_gradient_loss         | -0.00125     |\n|    value_loss                   | 449          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 186          |\n|    ice_dug                      | 2.17e+03     |\n|    water_produced               | 496          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 450         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2410        |\n|    time_elapsed                 | 11386       |\n|    total_timesteps              | 9640000     |\n| train/                          |             |\n|    approx_kl                    | 0.011154035 |\n|    clip_fraction                | 0.0531      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.717      |\n|    explained_variance           | 0.445       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 163         |\n|    n_updates                    | 4818        |\n|    policy_gradient_loss         | 0.00408     |\n|    value_loss                   | 389         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 2.08e+03    |\n|    water_produced               | 463         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 483         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2411        |\n|    time_elapsed                 | 11390       |\n|    total_timesteps              | 9644000     |\n| train/                          |             |\n|    approx_kl                    | 0.005140834 |\n|    clip_fraction                | 0.0333      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.721      |\n|    explained_variance           | 0.483       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 183         |\n|    n_updates                    | 4820        |\n|    policy_gradient_loss         | 0.00209     |\n|    value_loss                   | 363         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 2.1e+03     |\n|    water_produced               | 502         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 501          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2412         |\n|    time_elapsed                 | 11395        |\n|    total_timesteps              | 9648000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011798551 |\n|    clip_fraction                | 0.00513      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.726       |\n|    explained_variance           | 0.492        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 154          |\n|    n_updates                    | 4822         |\n|    policy_gradient_loss         | 0.00179      |\n|    value_loss                   | 305          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 169          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 1.87e+03     |\n|    water_produced               | 440          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 484          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2413         |\n|    time_elapsed                 | 11399        |\n|    total_timesteps              | 9652000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027094271 |\n|    clip_fraction                | 0.0148       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.791       |\n|    explained_variance           | 0.618        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 223          |\n|    n_updates                    | 4824         |\n|    policy_gradient_loss         | -0.000156    |\n|    value_loss                   | 453          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 186          |\n|    action_queue_updates_total   | 186          |\n|    ice_dug                      | 1.75e+03     |\n|    water_produced               | 418          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 491         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2414        |\n|    time_elapsed                 | 11404       |\n|    total_timesteps              | 9656000     |\n| train/                          |             |\n|    approx_kl                    | 0.022977028 |\n|    clip_fraction                | 0.098       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.824      |\n|    explained_variance           | 0.789       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 202         |\n|    n_updates                    | 4826        |\n|    policy_gradient_loss         | 0.00836     |\n|    value_loss                   | 381         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 187         |\n|    action_queue_updates_total   | 189         |\n|    ice_dug                      | 2.24e+03    |\n|    water_produced               | 531         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 484          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2415         |\n|    time_elapsed                 | 11409        |\n|    total_timesteps              | 9660000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016470244 |\n|    clip_fraction                | 0.00612      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.732       |\n|    explained_variance           | 0.589        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 115          |\n|    n_updates                    | 4828         |\n|    policy_gradient_loss         | -0.00101     |\n|    value_loss                   | 268          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 183          |\n|    action_queue_updates_total   | 186          |\n|    ice_dug                      | 1.82e+03     |\n|    water_produced               | 432          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 440          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2416         |\n|    time_elapsed                 | 11413        |\n|    total_timesteps              | 9664000      |\n| train/                          |              |\n|    approx_kl                    | 0.0012843075 |\n|    clip_fraction                | 0.00288      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.782       |\n|    explained_variance           | 0.816        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 171          |\n|    n_updates                    | 4830         |\n|    policy_gradient_loss         | 0.000568     |\n|    value_loss                   | 420          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 158          |\n|    action_queue_updates_total   | 174          |\n|    ice_dug                      | 1.28e+03     |\n|    water_produced               | 287          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 464        |\n| time/                           |            |\n|    fps                          | 846        |\n|    iterations                   | 2417       |\n|    time_elapsed                 | 11418      |\n|    total_timesteps              | 9668000    |\n| train/                          |            |\n|    approx_kl                    | 0.00936853 |\n|    clip_fraction                | 0.0565     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.871     |\n|    explained_variance           | 0.795      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 295        |\n|    n_updates                    | 4832       |\n|    policy_gradient_loss         | 0.00545    |\n|    value_loss                   | 665        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 186        |\n|    action_queue_updates_total   | 189        |\n|    ice_dug                      | 2.34e+03   |\n|    water_produced               | 557        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 491          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2418         |\n|    time_elapsed                 | 11422        |\n|    total_timesteps              | 9672000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032620535 |\n|    clip_fraction                | 0.0209       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.702       |\n|    explained_variance           | 0.408        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 196          |\n|    n_updates                    | 4834         |\n|    policy_gradient_loss         | 0.000807     |\n|    value_loss                   | 393          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 2.28e+03     |\n|    water_produced               | 545          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 462         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2419        |\n|    time_elapsed                 | 11427       |\n|    total_timesteps              | 9676000     |\n| train/                          |             |\n|    approx_kl                    | 0.009002058 |\n|    clip_fraction                | 0.0694      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.66       |\n|    explained_variance           | 0.586       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 122         |\n|    n_updates                    | 4836        |\n|    policy_gradient_loss         | 0.00591     |\n|    value_loss                   | 248         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 174         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 1.71e+03    |\n|    water_produced               | 392         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 479          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2420         |\n|    time_elapsed                 | 11431        |\n|    total_timesteps              | 9680000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014434035 |\n|    clip_fraction                | 0.00837      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.747       |\n|    explained_variance           | 0.823        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 301          |\n|    n_updates                    | 4838         |\n|    policy_gradient_loss         | 0.000916     |\n|    value_loss                   | 601          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 2.18e+03     |\n|    water_produced               | 517          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 497          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2421         |\n|    time_elapsed                 | 11436        |\n|    total_timesteps              | 9684000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018429654 |\n|    clip_fraction                | 0.00925      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.696       |\n|    explained_variance           | 0.602        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 107          |\n|    n_updates                    | 4840         |\n|    policy_gradient_loss         | 0.000357     |\n|    value_loss                   | 219          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 1.56e+03     |\n|    water_produced               | 370          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 458         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2422        |\n|    time_elapsed                 | 11441       |\n|    total_timesteps              | 9688000     |\n| train/                          |             |\n|    approx_kl                    | 0.004236453 |\n|    clip_fraction                | 0.0212      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.738      |\n|    explained_variance           | 0.818       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 228         |\n|    n_updates                    | 4842        |\n|    policy_gradient_loss         | 0.00139     |\n|    value_loss                   | 485         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 179         |\n|    ice_dug                      | 1.63e+03    |\n|    water_produced               | 370         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 447         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2423        |\n|    time_elapsed                 | 11445       |\n|    total_timesteps              | 9692000     |\n| train/                          |             |\n|    approx_kl                    | 0.012860459 |\n|    clip_fraction                | 0.047       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.746      |\n|    explained_variance           | 0.838       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 175         |\n|    n_updates                    | 4844        |\n|    policy_gradient_loss         | 0.00111     |\n|    value_loss                   | 430         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 165         |\n|    action_queue_updates_total   | 178         |\n|    ice_dug                      | 2.12e+03    |\n|    water_produced               | 495         |\n-------------------------------------------------\nEval num_timesteps=9696000, episode_reward=2977.68 +/- 216.21\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 2.98e+03     |\n| time/                           |              |\n|    total_timesteps              | 9696000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030915726 |\n|    clip_fraction                | 0.0212       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.653       |\n|    explained_variance           | 0.489        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 164          |\n|    n_updates                    | 4846         |\n|    policy_gradient_loss         | -0.000938    |\n|    value_loss                   | 336          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 178          |\n|    ice_dug                      | 1.58e+03     |\n|    water_produced               | 364          |\n--------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 441      |\n| time/              |          |\n|    fps             | 846      |\n|    iterations      | 2424     |\n|    time_elapsed    | 11458    |\n|    total_timesteps | 9696000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 437         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2425        |\n|    time_elapsed                 | 11463       |\n|    total_timesteps              | 9700000     |\n| train/                          |             |\n|    approx_kl                    | 0.004927095 |\n|    clip_fraction                | 0.0404      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.744      |\n|    explained_variance           | 0.886       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 219         |\n|    n_updates                    | 4848        |\n|    policy_gradient_loss         | 0.00124     |\n|    value_loss                   | 482         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 171         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 2.14e+03    |\n|    water_produced               | 496         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 451          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2426         |\n|    time_elapsed                 | 11467        |\n|    total_timesteps              | 9704000      |\n| train/                          |              |\n|    approx_kl                    | 0.0006491734 |\n|    clip_fraction                | 0.002        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.675       |\n|    explained_variance           | 0.447        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 201          |\n|    n_updates                    | 4850         |\n|    policy_gradient_loss         | -0.000733    |\n|    value_loss                   | 431          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 1.91e+03     |\n|    water_produced               | 435          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 432          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2427         |\n|    time_elapsed                 | 11472        |\n|    total_timesteps              | 9708000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021513992 |\n|    clip_fraction                | 0.0101       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.725       |\n|    explained_variance           | 0.85         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 233          |\n|    n_updates                    | 4852         |\n|    policy_gradient_loss         | -0.000248    |\n|    value_loss                   | 455          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.18e+03     |\n|    water_produced               | 280          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 406         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2428        |\n|    time_elapsed                 | 11477       |\n|    total_timesteps              | 9712000     |\n| train/                          |             |\n|    approx_kl                    | 0.017581766 |\n|    clip_fraction                | 0.118       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.863      |\n|    explained_variance           | 0.888       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 279         |\n|    n_updates                    | 4854        |\n|    policy_gradient_loss         | 0.00227     |\n|    value_loss                   | 603         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 1.84e+03    |\n|    water_produced               | 372         |\n-------------------------------------------------\n---------------------------------------------------\n| rollout/                        |               |\n|    ep_len_mean                  | 200           |\n|    ep_rew_mean                  | 427           |\n| time/                           |               |\n|    fps                          | 846           |\n|    iterations                   | 2429          |\n|    time_elapsed                 | 11481         |\n|    total_timesteps              | 9716000       |\n| train/                          |               |\n|    approx_kl                    | 0.00028889978 |\n|    clip_fraction                | 0             |\n|    clip_range                   | 0.2           |\n|    entropy_loss                 | -0.723        |\n|    explained_variance           | 0.542         |\n|    learning_rate                | 0.0003        |\n|    loss                         | 727           |\n|    n_updates                    | 4856          |\n|    policy_gradient_loss         | -0.000175     |\n|    value_loss                   | 1.64e+03      |\n| train_metrics/                  |               |\n|    action_queue_updates_success | 184           |\n|    action_queue_updates_total   | 185           |\n|    ice_dug                      | 2.12e+03      |\n|    water_produced               | 461           |\n---------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 418         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2430        |\n|    time_elapsed                 | 11486       |\n|    total_timesteps              | 9720000     |\n| train/                          |             |\n|    approx_kl                    | 0.012463536 |\n|    clip_fraction                | 0.0692      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.689      |\n|    explained_variance           | 0.642       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 327         |\n|    n_updates                    | 4858        |\n|    policy_gradient_loss         | 0.0075      |\n|    value_loss                   | 667         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 172         |\n|    action_queue_updates_total   | 175         |\n|    ice_dug                      | 1.99e+03    |\n|    water_produced               | 450         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 438          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2431         |\n|    time_elapsed                 | 11491        |\n|    total_timesteps              | 9724000      |\n| train/                          |              |\n|    approx_kl                    | 0.0007932523 |\n|    clip_fraction                | 0.002        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.699       |\n|    explained_variance           | 0.507        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 222          |\n|    n_updates                    | 4860         |\n|    policy_gradient_loss         | 4.45e-05     |\n|    value_loss                   | 518          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 2.23e+03     |\n|    water_produced               | 533          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 480          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2432         |\n|    time_elapsed                 | 11495        |\n|    total_timesteps              | 9728000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031177578 |\n|    clip_fraction                | 0.0227       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.707       |\n|    explained_variance           | 0.59         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 170          |\n|    n_updates                    | 4862         |\n|    policy_gradient_loss         | -0.000476    |\n|    value_loss                   | 345          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 2.12e+03     |\n|    water_produced               | 484          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 481          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2433         |\n|    time_elapsed                 | 11500        |\n|    total_timesteps              | 9732000      |\n| train/                          |              |\n|    approx_kl                    | 0.0032485432 |\n|    clip_fraction                | 0.0219       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.694       |\n|    explained_variance           | 0.51         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 4864         |\n|    policy_gradient_loss         | 0.0022       |\n|    value_loss                   | 308          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 1.6e+03      |\n|    water_produced               | 377          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 468        |\n| time/                           |            |\n|    fps                          | 846        |\n|    iterations                   | 2434       |\n|    time_elapsed                 | 11505      |\n|    total_timesteps              | 9736000    |\n| train/                          |            |\n|    approx_kl                    | 0.00186541 |\n|    clip_fraction                | 0.00887    |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.796     |\n|    explained_variance           | 0.774      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 233        |\n|    n_updates                    | 4866       |\n|    policy_gradient_loss         | -0.000282  |\n|    value_loss                   | 489        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 182        |\n|    action_queue_updates_total   | 185        |\n|    ice_dug                      | 1.73e+03   |\n|    water_produced               | 402        |\n------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 451         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2435        |\n|    time_elapsed                 | 11509       |\n|    total_timesteps              | 9740000     |\n| train/                          |             |\n|    approx_kl                    | 0.007154856 |\n|    clip_fraction                | 0.0276      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.796      |\n|    explained_variance           | 0.83        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 127         |\n|    n_updates                    | 4868        |\n|    policy_gradient_loss         | -0.00177    |\n|    value_loss                   | 312         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 181         |\n|    ice_dug                      | 1.55e+03    |\n|    water_produced               | 366         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 430         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2436        |\n|    time_elapsed                 | 11514       |\n|    total_timesteps              | 9744000     |\n| train/                          |             |\n|    approx_kl                    | 0.026422447 |\n|    clip_fraction                | 0.0945      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.841      |\n|    explained_variance           | 0.844       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 191         |\n|    n_updates                    | 4870        |\n|    policy_gradient_loss         | 0.00679     |\n|    value_loss                   | 398         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 184         |\n|    action_queue_updates_total   | 187         |\n|    ice_dug                      | 1.81e+03    |\n|    water_produced               | 434         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 418          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2437         |\n|    time_elapsed                 | 11518        |\n|    total_timesteps              | 9748000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023568808 |\n|    clip_fraction                | 0.0202       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.805       |\n|    explained_variance           | 0.804        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 200          |\n|    n_updates                    | 4872         |\n|    policy_gradient_loss         | -0.000578    |\n|    value_loss                   | 433          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 184          |\n|    action_queue_updates_total   | 187          |\n|    ice_dug                      | 1.83e+03     |\n|    water_produced               | 424          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 430         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2438        |\n|    time_elapsed                 | 11523       |\n|    total_timesteps              | 9752000     |\n| train/                          |             |\n|    approx_kl                    | 0.015850669 |\n|    clip_fraction                | 0.0818      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.741      |\n|    explained_variance           | 0.837       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 234         |\n|    n_updates                    | 4874        |\n|    policy_gradient_loss         | 0.00977     |\n|    value_loss                   | 524         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 182         |\n|    action_queue_updates_total   | 185         |\n|    ice_dug                      | 1.83e+03    |\n|    water_produced               | 437         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 448          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2439         |\n|    time_elapsed                 | 11527        |\n|    total_timesteps              | 9756000      |\n| train/                          |              |\n|    approx_kl                    | 0.0015218777 |\n|    clip_fraction                | 0.00625      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.78        |\n|    explained_variance           | 0.872        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 4876         |\n|    policy_gradient_loss         | 0.000297     |\n|    value_loss                   | 452          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 173          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 2.05e+03     |\n|    water_produced               | 488          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 486          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2440         |\n|    time_elapsed                 | 11532        |\n|    total_timesteps              | 9760000      |\n| train/                          |              |\n|    approx_kl                    | 0.0017068187 |\n|    clip_fraction                | 0.0085       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.725       |\n|    explained_variance           | 0.617        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 156          |\n|    n_updates                    | 4878         |\n|    policy_gradient_loss         | 0.00103      |\n|    value_loss                   | 330          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 185          |\n|    action_queue_updates_total   | 186          |\n|    ice_dug                      | 2.27e+03     |\n|    water_produced               | 547          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 503         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2441        |\n|    time_elapsed                 | 11537       |\n|    total_timesteps              | 9764000     |\n| train/                          |             |\n|    approx_kl                    | 0.004326597 |\n|    clip_fraction                | 0.0304      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.726      |\n|    explained_variance           | 0.589       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 102         |\n|    n_updates                    | 4880        |\n|    policy_gradient_loss         | -0.000772   |\n|    value_loss                   | 232         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 182         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 2.15e+03    |\n|    water_produced               | 517         |\n-------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 518        |\n| time/                           |            |\n|    fps                          | 846        |\n|    iterations                   | 2442       |\n|    time_elapsed                 | 11542      |\n|    total_timesteps              | 9768000    |\n| train/                          |            |\n|    approx_kl                    | 0.00584829 |\n|    clip_fraction                | 0.0396     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.724     |\n|    explained_variance           | 0.486      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 119        |\n|    n_updates                    | 4882       |\n|    policy_gradient_loss         | 0.00284    |\n|    value_loss                   | 278        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 178        |\n|    action_queue_updates_total   | 181        |\n|    ice_dug                      | 2.09e+03   |\n|    water_produced               | 496        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 522          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2443         |\n|    time_elapsed                 | 11546        |\n|    total_timesteps              | 9772000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016685236 |\n|    clip_fraction                | 0.00687      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.737       |\n|    explained_variance           | 0.537        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 140          |\n|    n_updates                    | 4884         |\n|    policy_gradient_loss         | 0.00187      |\n|    value_loss                   | 294          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.98e+03     |\n|    water_produced               | 458          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 524          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2444         |\n|    time_elapsed                 | 11551        |\n|    total_timesteps              | 9776000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035102759 |\n|    clip_fraction                | 0.0189       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.782       |\n|    explained_variance           | 0.541        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 137          |\n|    n_updates                    | 4886         |\n|    policy_gradient_loss         | -0.00122     |\n|    value_loss                   | 302          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 2.14e+03     |\n|    water_produced               | 495          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 503          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2445         |\n|    time_elapsed                 | 11555        |\n|    total_timesteps              | 9780000      |\n| train/                          |              |\n|    approx_kl                    | 0.0013134221 |\n|    clip_fraction                | 0.00413      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.756       |\n|    explained_variance           | 0.493        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 107          |\n|    n_updates                    | 4888         |\n|    policy_gradient_loss         | 0.000419     |\n|    value_loss                   | 220          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 175          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 1.9e+03      |\n|    water_produced               | 446          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 493         |\n| time/                           |             |\n|    fps                          | 846         |\n|    iterations                   | 2446        |\n|    time_elapsed                 | 11559       |\n|    total_timesteps              | 9784000     |\n| train/                          |             |\n|    approx_kl                    | 0.001484865 |\n|    clip_fraction                | 0.004       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.769      |\n|    explained_variance           | 0.519       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 160         |\n|    n_updates                    | 4890        |\n|    policy_gradient_loss         | -0.000382   |\n|    value_loss                   | 370         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 183         |\n|    action_queue_updates_total   | 187         |\n|    ice_dug                      | 2.07e+03    |\n|    water_produced               | 469         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 486          |\n| time/                           |              |\n|    fps                          | 846          |\n|    iterations                   | 2447         |\n|    time_elapsed                 | 11564        |\n|    total_timesteps              | 9788000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023289039 |\n|    clip_fraction                | 0.0136       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.754       |\n|    explained_variance           | 0.552        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 171          |\n|    n_updates                    | 4892         |\n|    policy_gradient_loss         | -0.00101     |\n|    value_loss                   | 337          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.95e+03     |\n|    water_produced               | 462          |\n--------------------------------------------------\nEval num_timesteps=9792000, episode_reward=3015.12 +/- 171.45\nEpisode length: 1000.00 +/- 0.00\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 1e+03       |\n|    mean_reward                  | 3.02e+03    |\n| time/                           |             |\n|    total_timesteps              | 9792000     |\n| train/                          |             |\n|    approx_kl                    | 0.002318712 |\n|    clip_fraction                | 0.0136      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.758      |\n|    explained_variance           | 0.585       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 184         |\n|    n_updates                    | 4894        |\n|    policy_gradient_loss         | -0.000227   |\n|    value_loss                   | 368         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 186         |\n|    ice_dug                      | 1.71e+03    |\n|    water_produced               | 392         |\n-------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 473      |\n| time/              |          |\n|    fps             | 845      |\n|    iterations      | 2448     |\n|    time_elapsed    | 11577    |\n|    total_timesteps | 9792000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 448         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2449        |\n|    time_elapsed                 | 11582       |\n|    total_timesteps              | 9796000     |\n| train/                          |             |\n|    approx_kl                    | 0.008764498 |\n|    clip_fraction                | 0.0526      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.762      |\n|    explained_variance           | 0.681       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 173         |\n|    n_updates                    | 4896        |\n|    policy_gradient_loss         | 0.00203     |\n|    value_loss                   | 439         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 180         |\n|    action_queue_updates_total   | 187         |\n|    ice_dug                      | 1.83e+03    |\n|    water_produced               | 375         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 439         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2450        |\n|    time_elapsed                 | 11586       |\n|    total_timesteps              | 9800000     |\n| train/                          |             |\n|    approx_kl                    | 0.008266241 |\n|    clip_fraction                | 0.053       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.791      |\n|    explained_variance           | 0.481       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 289         |\n|    n_updates                    | 4898        |\n|    policy_gradient_loss         | 0.000857    |\n|    value_loss                   | 572         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 185         |\n|    action_queue_updates_total   | 187         |\n|    ice_dug                      | 1.74e+03    |\n|    water_produced               | 405         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 454         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2451        |\n|    time_elapsed                 | 11591       |\n|    total_timesteps              | 9804000     |\n| train/                          |             |\n|    approx_kl                    | 0.013237382 |\n|    clip_fraction                | 0.073       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.796      |\n|    explained_variance           | 0.732       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 192         |\n|    n_updates                    | 4900        |\n|    policy_gradient_loss         | 0.00573     |\n|    value_loss                   | 426         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 191         |\n|    action_queue_updates_total   | 192         |\n|    ice_dug                      | 2.35e+03    |\n|    water_produced               | 538         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 473          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2452         |\n|    time_elapsed                 | 11596        |\n|    total_timesteps              | 9808000      |\n| train/                          |              |\n|    approx_kl                    | 0.0036357143 |\n|    clip_fraction                | 0.0188       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.693       |\n|    explained_variance           | 0.384        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 139          |\n|    n_updates                    | 4902         |\n|    policy_gradient_loss         | -0.00319     |\n|    value_loss                   | 297          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 188          |\n|    action_queue_updates_total   | 191          |\n|    ice_dug                      | 2.33e+03     |\n|    water_produced               | 557          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 503         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2453        |\n|    time_elapsed                 | 11600       |\n|    total_timesteps              | 9812000     |\n| train/                          |             |\n|    approx_kl                    | 0.017738938 |\n|    clip_fraction                | 0.0882      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.636      |\n|    explained_variance           | 0.474       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 114         |\n|    n_updates                    | 4904        |\n|    policy_gradient_loss         | 0.00993     |\n|    value_loss                   | 248         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 183         |\n|    ice_dug                      | 2.24e+03    |\n|    water_produced               | 533         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 531         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2454        |\n|    time_elapsed                 | 11605       |\n|    total_timesteps              | 9816000     |\n| train/                          |             |\n|    approx_kl                    | 0.008367067 |\n|    clip_fraction                | 0.0709      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.67       |\n|    explained_variance           | 0.668       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 146         |\n|    n_updates                    | 4906        |\n|    policy_gradient_loss         | 0.00768     |\n|    value_loss                   | 334         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 2.13e+03    |\n|    water_produced               | 512         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 559          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2455         |\n|    time_elapsed                 | 11609        |\n|    total_timesteps              | 9820000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037679109 |\n|    clip_fraction                | 0.0292       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.675       |\n|    explained_variance           | 0.582        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 142          |\n|    n_updates                    | 4908         |\n|    policy_gradient_loss         | 0.00216      |\n|    value_loss                   | 305          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 183          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 2.28e+03     |\n|    water_produced               | 540          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 515          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2456         |\n|    time_elapsed                 | 11614        |\n|    total_timesteps              | 9824000      |\n| train/                          |              |\n|    approx_kl                    | 0.0031816426 |\n|    clip_fraction                | 0.0201       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.693       |\n|    explained_variance           | 0.637        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 104          |\n|    n_updates                    | 4910         |\n|    policy_gradient_loss         | 0.00285      |\n|    value_loss                   | 219          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 178          |\n|    action_queue_updates_total   | 183          |\n|    ice_dug                      | 1.4e+03      |\n|    water_produced               | 330          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 494         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2457        |\n|    time_elapsed                 | 11618       |\n|    total_timesteps              | 9828000     |\n| train/                          |             |\n|    approx_kl                    | 0.003042151 |\n|    clip_fraction                | 0.0183      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.79       |\n|    explained_variance           | 0.633       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 304         |\n|    n_updates                    | 4912        |\n|    policy_gradient_loss         | 0.00156     |\n|    value_loss                   | 641         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 1.92e+03    |\n|    water_produced               | 456         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 458         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2458        |\n|    time_elapsed                 | 11623       |\n|    total_timesteps              | 9832000     |\n| train/                          |             |\n|    approx_kl                    | 0.005021657 |\n|    clip_fraction                | 0.0349      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.785      |\n|    explained_variance           | 0.609       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 152         |\n|    n_updates                    | 4914        |\n|    policy_gradient_loss         | -0.000407   |\n|    value_loss                   | 275         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 183         |\n|    ice_dug                      | 1.54e+03    |\n|    water_produced               | 362         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 443         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2459        |\n|    time_elapsed                 | 11627       |\n|    total_timesteps              | 9836000     |\n| train/                          |             |\n|    approx_kl                    | 0.012508273 |\n|    clip_fraction                | 0.0673      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.824      |\n|    explained_variance           | 0.67        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 174         |\n|    n_updates                    | 4916        |\n|    policy_gradient_loss         | -0.000365   |\n|    value_loss                   | 461         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 183         |\n|    action_queue_updates_total   | 188         |\n|    ice_dug                      | 1.93e+03    |\n|    water_produced               | 437         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 425          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2460         |\n|    time_elapsed                 | 11632        |\n|    total_timesteps              | 9840000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037656673 |\n|    clip_fraction                | 0.0228       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.752       |\n|    explained_variance           | 0.458        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 236          |\n|    n_updates                    | 4918         |\n|    policy_gradient_loss         | -0.0023      |\n|    value_loss                   | 469          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.9e+03      |\n|    water_produced               | 451          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 429         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2461        |\n|    time_elapsed                 | 11637       |\n|    total_timesteps              | 9844000     |\n| train/                          |             |\n|    approx_kl                    | 0.004763481 |\n|    clip_fraction                | 0.0296      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.77       |\n|    explained_variance           | 0.769       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 183         |\n|    n_updates                    | 4920        |\n|    policy_gradient_loss         | 0.00589     |\n|    value_loss                   | 398         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 188         |\n|    action_queue_updates_total   | 190         |\n|    ice_dug                      | 1.49e+03    |\n|    water_produced               | 348         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 425          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2462         |\n|    time_elapsed                 | 11641        |\n|    total_timesteps              | 9848000      |\n| train/                          |              |\n|    approx_kl                    | 0.0050090617 |\n|    clip_fraction                | 0.0281       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.823       |\n|    explained_variance           | 0.825        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 261          |\n|    n_updates                    | 4922         |\n|    policy_gradient_loss         | 0.000964     |\n|    value_loss                   | 576          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.89e+03     |\n|    water_produced               | 438          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 469          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2463         |\n|    time_elapsed                 | 11646        |\n|    total_timesteps              | 9852000      |\n| train/                          |              |\n|    approx_kl                    | 0.0057955375 |\n|    clip_fraction                | 0.0335       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.728       |\n|    explained_variance           | 0.821        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 269          |\n|    n_updates                    | 4924         |\n|    policy_gradient_loss         | 0.00272      |\n|    value_loss                   | 522          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 186          |\n|    action_queue_updates_total   | 188          |\n|    ice_dug                      | 2.39e+03     |\n|    water_produced               | 574          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 462         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2464        |\n|    time_elapsed                 | 11651       |\n|    total_timesteps              | 9856000     |\n| train/                          |             |\n|    approx_kl                    | 0.009026811 |\n|    clip_fraction                | 0.0561      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.658      |\n|    explained_variance           | 0.547       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 112         |\n|    n_updates                    | 4926        |\n|    policy_gradient_loss         | 0.00729     |\n|    value_loss                   | 258         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 1.68e+03    |\n|    water_produced               | 404         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 472          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2465         |\n|    time_elapsed                 | 11655        |\n|    total_timesteps              | 9860000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016266145 |\n|    clip_fraction                | 0.0055       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.73        |\n|    explained_variance           | 0.866        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 236          |\n|    n_updates                    | 4928         |\n|    policy_gradient_loss         | 0.00219      |\n|    value_loss                   | 495          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 174          |\n|    action_queue_updates_total   | 178          |\n|    ice_dug                      | 2.15e+03     |\n|    water_produced               | 501          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 501          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2466         |\n|    time_elapsed                 | 11660        |\n|    total_timesteps              | 9864000      |\n| train/                          |              |\n|    approx_kl                    | 0.0038536482 |\n|    clip_fraction                | 0.0195       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.701       |\n|    explained_variance           | 0.586        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 168          |\n|    n_updates                    | 4930         |\n|    policy_gradient_loss         | -0.00152     |\n|    value_loss                   | 355          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 172          |\n|    action_queue_updates_total   | 175          |\n|    ice_dug                      | 2.05e+03     |\n|    water_produced               | 488          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 523         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2467        |\n|    time_elapsed                 | 11665       |\n|    total_timesteps              | 9868000     |\n| train/                          |             |\n|    approx_kl                    | 0.005929725 |\n|    clip_fraction                | 0.0375      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.691      |\n|    explained_variance           | 0.395       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 204         |\n|    n_updates                    | 4932        |\n|    policy_gradient_loss         | 0.000912    |\n|    value_loss                   | 474         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 184         |\n|    action_queue_updates_total   | 185         |\n|    ice_dug                      | 2.26e+03    |\n|    water_produced               | 543         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 509          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2468         |\n|    time_elapsed                 | 11669        |\n|    total_timesteps              | 9872000      |\n| train/                          |              |\n|    approx_kl                    | 0.0021373264 |\n|    clip_fraction                | 0.008        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.686       |\n|    explained_variance           | 0.546        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 109          |\n|    n_updates                    | 4934         |\n|    policy_gradient_loss         | 0.00256      |\n|    value_loss                   | 233          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 2.18e+03     |\n|    water_produced               | 504          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 501          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2469         |\n|    time_elapsed                 | 11674        |\n|    total_timesteps              | 9876000      |\n| train/                          |              |\n|    approx_kl                    | 0.0028925114 |\n|    clip_fraction                | 0.019        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.683       |\n|    explained_variance           | 0.554        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 137          |\n|    n_updates                    | 4936         |\n|    policy_gradient_loss         | 0.00399      |\n|    value_loss                   | 274          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 1.62e+03     |\n|    water_produced               | 370          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 483         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2470        |\n|    time_elapsed                 | 11678       |\n|    total_timesteps              | 9880000     |\n| train/                          |             |\n|    approx_kl                    | 0.003828212 |\n|    clip_fraction                | 0.0259      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.768      |\n|    explained_variance           | 0.809       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 217         |\n|    n_updates                    | 4938        |\n|    policy_gradient_loss         | 2.35e-05    |\n|    value_loss                   | 522         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 182         |\n|    action_queue_updates_total   | 186         |\n|    ice_dug                      | 1.73e+03    |\n|    water_produced               | 410         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 480         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2471        |\n|    time_elapsed                 | 11683       |\n|    total_timesteps              | 9884000     |\n| train/                          |             |\n|    approx_kl                    | 0.007290258 |\n|    clip_fraction                | 0.0377      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.784      |\n|    explained_variance           | 0.812       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 132         |\n|    n_updates                    | 4940        |\n|    policy_gradient_loss         | -0.00176    |\n|    value_loss                   | 363         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 178         |\n|    action_queue_updates_total   | 184         |\n|    ice_dug                      | 2.07e+03    |\n|    water_produced               | 474         |\n-------------------------------------------------\nEval num_timesteps=9888000, episode_reward=3197.04 +/- 68.21\nEpisode length: 1000.00 +/- 0.00\n--------------------------------------------------\n| eval/                           |              |\n|    mean_ep_length               | 1e+03        |\n|    mean_reward                  | 3.2e+03      |\n| time/                           |              |\n|    total_timesteps              | 9888000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023834954 |\n|    clip_fraction                | 0.00988      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.719       |\n|    explained_variance           | 0.514        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 217          |\n|    n_updates                    | 4942         |\n|    policy_gradient_loss         | -0.00249     |\n|    value_loss                   | 425          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.56e+03     |\n|    water_produced               | 312          |\n--------------------------------------------------\nNew best mean reward!\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 432      |\n| time/              |          |\n|    fps             | 845      |\n|    iterations      | 2472     |\n|    time_elapsed    | 11696    |\n|    total_timesteps | 9888000  |\n---------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 412         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2473        |\n|    time_elapsed                 | 11701       |\n|    total_timesteps              | 9892000     |\n| train/                          |             |\n|    approx_kl                    | 0.002290069 |\n|    clip_fraction                | 0.0114      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.815      |\n|    explained_variance           | 0.738       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 417         |\n|    n_updates                    | 4944        |\n|    policy_gradient_loss         | 0.00076     |\n|    value_loss                   | 808         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 161         |\n|    action_queue_updates_total   | 172         |\n|    ice_dug                      | 1.70e+03    |\n|    water_produced               | 409         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 452          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2474         |\n|    time_elapsed                 | 11706        |\n|    total_timesteps              | 9896000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014016537 |\n|    clip_fraction                | 0.00212      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.798       |\n|    explained_variance           | 0.465        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 325          |\n|    n_updates                    | 4946         |\n|    policy_gradient_loss         | -0.000583    |\n|    value_loss                   | 660          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 184          |\n|    action_queue_updates_total   | 188          |\n|    ice_dug                      | 2.35e+03     |\n|    water_produced               | 559          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 480         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2475        |\n|    time_elapsed                 | 11710       |\n|    total_timesteps              | 9900000     |\n| train/                          |             |\n|    approx_kl                    | 0.002519654 |\n|    clip_fraction                | 0.0149      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.697      |\n|    explained_variance           | 0.454       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 146         |\n|    n_updates                    | 4948        |\n|    policy_gradient_loss         | 0.00234     |\n|    value_loss                   | 323         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 184         |\n|    action_queue_updates_total   | 187         |\n|    ice_dug                      | 2.29e+03    |\n|    water_produced               | 547         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 469          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2476         |\n|    time_elapsed                 | 11715        |\n|    total_timesteps              | 9904000      |\n| train/                          |              |\n|    approx_kl                    | 0.0071517965 |\n|    clip_fraction                | 0.062        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.698       |\n|    explained_variance           | 0.534        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 124          |\n|    n_updates                    | 4950         |\n|    policy_gradient_loss         | 0.0045       |\n|    value_loss                   | 279          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 183          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.76e+03     |\n|    water_produced               | 423          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 500          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2477         |\n|    time_elapsed                 | 11719        |\n|    total_timesteps              | 9908000      |\n| train/                          |              |\n|    approx_kl                    | 0.0060427887 |\n|    clip_fraction                | 0.0291       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.78        |\n|    explained_variance           | 0.715        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 220          |\n|    n_updates                    | 4952         |\n|    policy_gradient_loss         | 0.000528     |\n|    value_loss                   | 444          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 182          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.95e+03     |\n|    water_produced               | 464          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 496          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2478         |\n|    time_elapsed                 | 11724        |\n|    total_timesteps              | 9912000      |\n| train/                          |              |\n|    approx_kl                    | 0.0010130932 |\n|    clip_fraction                | 0.00738      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.788       |\n|    explained_variance           | 0.544        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 211          |\n|    n_updates                    | 4954         |\n|    policy_gradient_loss         | -0.00144     |\n|    value_loss                   | 464          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 185          |\n|    action_queue_updates_total   | 188          |\n|    ice_dug                      | 1.62e+03     |\n|    water_produced               | 385          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 481          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2479         |\n|    time_elapsed                 | 11729        |\n|    total_timesteps              | 9916000      |\n| train/                          |              |\n|    approx_kl                    | 0.0030077803 |\n|    clip_fraction                | 0.0153       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.816       |\n|    explained_variance           | 0.674        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 283          |\n|    n_updates                    | 4956         |\n|    policy_gradient_loss         | 0.00132      |\n|    value_loss                   | 577          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 186          |\n|    action_queue_updates_total   | 189          |\n|    ice_dug                      | 2.04e+03     |\n|    water_produced               | 488          |\n--------------------------------------------------\n------------------------------------------------\n| rollout/                        |            |\n|    ep_len_mean                  | 200        |\n|    ep_rew_mean                  | 472        |\n| time/                           |            |\n|    fps                          | 845        |\n|    iterations                   | 2480       |\n|    time_elapsed                 | 11733      |\n|    total_timesteps              | 9920000    |\n| train/                          |            |\n|    approx_kl                    | 0.00915241 |\n|    clip_fraction                | 0.0406     |\n|    clip_range                   | 0.2        |\n|    entropy_loss                 | -0.778     |\n|    explained_variance           | 0.561      |\n|    learning_rate                | 0.0003     |\n|    loss                         | 130        |\n|    n_updates                    | 4958       |\n|    policy_gradient_loss         | -0.00266   |\n|    value_loss                   | 263        |\n| train_metrics/                  |            |\n|    action_queue_updates_success | 184        |\n|    action_queue_updates_total   | 186        |\n|    ice_dug                      | 2.14e+03   |\n|    water_produced               | 503        |\n------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 470          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2481         |\n|    time_elapsed                 | 11738        |\n|    total_timesteps              | 9924000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035016835 |\n|    clip_fraction                | 0.0185       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.727       |\n|    explained_variance           | 0.563        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 157          |\n|    n_updates                    | 4960         |\n|    policy_gradient_loss         | 0.000114     |\n|    value_loss                   | 320          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 1.72e+03     |\n|    water_produced               | 413          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 461          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2482         |\n|    time_elapsed                 | 11742        |\n|    total_timesteps              | 9928000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011350395 |\n|    clip_fraction                | 0.00275      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.728       |\n|    explained_variance           | 0.76         |\n|    learning_rate                | 0.0003       |\n|    loss                         | 196          |\n|    n_updates                    | 4962         |\n|    policy_gradient_loss         | -0.000216    |\n|    value_loss                   | 436          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 178          |\n|    action_queue_updates_total   | 183          |\n|    ice_dug                      | 1.78e+03     |\n|    water_produced               | 422          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 487         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2483        |\n|    time_elapsed                 | 11746       |\n|    total_timesteps              | 9932000     |\n| train/                          |             |\n|    approx_kl                    | 0.008398686 |\n|    clip_fraction                | 0.0256      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.749      |\n|    explained_variance           | 0.754       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 142         |\n|    n_updates                    | 4964        |\n|    policy_gradient_loss         | 0.00295     |\n|    value_loss                   | 395         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 177         |\n|    action_queue_updates_total   | 180         |\n|    ice_dug                      | 2.21e+03    |\n|    water_produced               | 507         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 493          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2484         |\n|    time_elapsed                 | 11751        |\n|    total_timesteps              | 9936000      |\n| train/                          |              |\n|    approx_kl                    | 0.0018969681 |\n|    clip_fraction                | 0.0121       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.667       |\n|    explained_variance           | 0.466        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 138          |\n|    n_updates                    | 4966         |\n|    policy_gradient_loss         | -0.000893    |\n|    value_loss                   | 287          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 170          |\n|    action_queue_updates_total   | 177          |\n|    ice_dug                      | 2.17e+03     |\n|    water_produced               | 521          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 494         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2485        |\n|    time_elapsed                 | 11755       |\n|    total_timesteps              | 9940000     |\n| train/                          |             |\n|    approx_kl                    | 0.009596362 |\n|    clip_fraction                | 0.058       |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.685      |\n|    explained_variance           | 0.497       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 129         |\n|    n_updates                    | 4968        |\n|    policy_gradient_loss         | 0.00388     |\n|    value_loss                   | 302         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 179         |\n|    action_queue_updates_total   | 183         |\n|    ice_dug                      | 2.12e+03    |\n|    water_produced               | 506         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 498          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2486         |\n|    time_elapsed                 | 11760        |\n|    total_timesteps              | 9944000      |\n| train/                          |              |\n|    approx_kl                    | 0.0027502503 |\n|    clip_fraction                | 0.0127       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.73        |\n|    explained_variance           | 0.647        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 101          |\n|    n_updates                    | 4970         |\n|    policy_gradient_loss         | 0.00201      |\n|    value_loss                   | 218          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 180          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 1.88e+03     |\n|    water_produced               | 432          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 506         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2487        |\n|    time_elapsed                 | 11765       |\n|    total_timesteps              | 9948000     |\n| train/                          |             |\n|    approx_kl                    | 0.014853746 |\n|    clip_fraction                | 0.0834      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.802      |\n|    explained_variance           | 0.59        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 121         |\n|    n_updates                    | 4972        |\n|    policy_gradient_loss         | -0.00605    |\n|    value_loss                   | 303         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 176         |\n|    action_queue_updates_total   | 182         |\n|    ice_dug                      | 1.97e+03    |\n|    water_produced               | 459         |\n-------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 507         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2488        |\n|    time_elapsed                 | 11769       |\n|    total_timesteps              | 9952000     |\n| train/                          |             |\n|    approx_kl                    | 0.008676271 |\n|    clip_fraction                | 0.0564      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.778      |\n|    explained_variance           | 0.63        |\n|    learning_rate                | 0.0003      |\n|    loss                         | 137         |\n|    n_updates                    | 4974        |\n|    policy_gradient_loss         | 0.00441     |\n|    value_loss                   | 308         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 185         |\n|    ice_dug                      | 2.16e+03    |\n|    water_produced               | 513         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 480          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2489         |\n|    time_elapsed                 | 11774        |\n|    total_timesteps              | 9956000      |\n| train/                          |              |\n|    approx_kl                    | 0.0016001301 |\n|    clip_fraction                | 0.005        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.724       |\n|    explained_variance           | 0.539        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 127          |\n|    n_updates                    | 4976         |\n|    policy_gradient_loss         | -0.00079     |\n|    value_loss                   | 247          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 183          |\n|    action_queue_updates_total   | 186          |\n|    ice_dug                      | 1.71e+03     |\n|    water_produced               | 391          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 469          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2490         |\n|    time_elapsed                 | 11778        |\n|    total_timesteps              | 9960000      |\n| train/                          |              |\n|    approx_kl                    | 0.0023267046 |\n|    clip_fraction                | 0.0105       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.778       |\n|    explained_variance           | 0.783        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 231          |\n|    n_updates                    | 4978         |\n|    policy_gradient_loss         | -3.61e-05    |\n|    value_loss                   | 542          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 1.92e+03     |\n|    water_produced               | 453          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 493         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2491        |\n|    time_elapsed                 | 11783       |\n|    total_timesteps              | 9964000     |\n| train/                          |             |\n|    approx_kl                    | 0.012433732 |\n|    clip_fraction                | 0.0476      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.752      |\n|    explained_variance           | 0.772       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 186         |\n|    n_updates                    | 4980        |\n|    policy_gradient_loss         | 0.000852    |\n|    value_loss                   | 406         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 185         |\n|    action_queue_updates_total   | 187         |\n|    ice_dug                      | 2.28e+03    |\n|    water_produced               | 550         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 471          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2492         |\n|    time_elapsed                 | 11787        |\n|    total_timesteps              | 9968000      |\n| train/                          |              |\n|    approx_kl                    | 0.0043629273 |\n|    clip_fraction                | 0.0288       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.692       |\n|    explained_variance           | 0.618        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 104          |\n|    n_updates                    | 4982         |\n|    policy_gradient_loss         | 0.0038       |\n|    value_loss                   | 203          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 184          |\n|    ice_dug                      | 1.63e+03     |\n|    water_produced               | 351          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 471          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2493         |\n|    time_elapsed                 | 11792        |\n|    total_timesteps              | 9972000      |\n| train/                          |              |\n|    approx_kl                    | 0.0037867278 |\n|    clip_fraction                | 0.0253       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.785       |\n|    explained_variance           | 0.723        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 382          |\n|    n_updates                    | 4984         |\n|    policy_gradient_loss         | 0.00307      |\n|    value_loss                   | 777          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 181          |\n|    ice_dug                      | 2.12e+03     |\n|    water_produced               | 516          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 475          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2494         |\n|    time_elapsed                 | 11797        |\n|    total_timesteps              | 9976000      |\n| train/                          |              |\n|    approx_kl                    | 0.0014532156 |\n|    clip_fraction                | 0.006        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.696       |\n|    explained_variance           | 0.558        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 128          |\n|    n_updates                    | 4986         |\n|    policy_gradient_loss         | 0.000727     |\n|    value_loss                   | 260          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 180          |\n|    ice_dug                      | 1.72e+03     |\n|    water_produced               | 410          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 490          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2495         |\n|    time_elapsed                 | 11801        |\n|    total_timesteps              | 9980000      |\n| train/                          |              |\n|    approx_kl                    | 0.0011101568 |\n|    clip_fraction                | 0.00413      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.752       |\n|    explained_variance           | 0.858        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 202          |\n|    n_updates                    | 4988         |\n|    policy_gradient_loss         | -0.000888    |\n|    value_loss                   | 437          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 181          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 2.17e+03     |\n|    water_produced               | 526          |\n--------------------------------------------------\nEval num_timesteps=9984000, episode_reward=2474.72 +/- 1244.12\nEpisode length: 860.20 +/- 279.60\n-------------------------------------------------\n| eval/                           |             |\n|    mean_ep_length               | 860         |\n|    mean_reward                  | 2.47e+03    |\n| time/                           |             |\n|    total_timesteps              | 9984000     |\n| train/                          |             |\n|    approx_kl                    | 0.001343507 |\n|    clip_fraction                | 0.00537     |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.705      |\n|    explained_variance           | 0.617       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 100         |\n|    n_updates                    | 4990        |\n|    policy_gradient_loss         | -0.00172    |\n|    value_loss                   | 227         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 181         |\n|    action_queue_updates_total   | 183         |\n|    ice_dug                      | 1.75e+03    |\n|    water_produced               | 417         |\n-------------------------------------------------\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 200      |\n|    ep_rew_mean     | 463      |\n| time/              |          |\n|    fps             | 845      |\n|    iterations      | 2496     |\n|    time_elapsed    | 11815    |\n|    total_timesteps | 9984000  |\n---------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 497          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2497         |\n|    time_elapsed                 | 11819        |\n|    total_timesteps              | 9988000      |\n| train/                          |              |\n|    approx_kl                    | 0.0035659745 |\n|    clip_fraction                | 0.0179       |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.775       |\n|    explained_variance           | 0.863        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 185          |\n|    n_updates                    | 4992         |\n|    policy_gradient_loss         | 0.000781     |\n|    value_loss                   | 407          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 183          |\n|    action_queue_updates_total   | 185          |\n|    ice_dug                      | 2.17e+03     |\n|    water_produced               | 518          |\n--------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 499          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2498         |\n|    time_elapsed                 | 11824        |\n|    total_timesteps              | 9992000      |\n| train/                          |              |\n|    approx_kl                    | 0.0008365599 |\n|    clip_fraction                | 0.003        |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.71        |\n|    explained_variance           | 0.576        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 92           |\n|    n_updates                    | 4994         |\n|    policy_gradient_loss         | 0.000245     |\n|    value_loss                   | 191          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 178          |\n|    action_queue_updates_total   | 179          |\n|    ice_dug                      | 2.23e+03     |\n|    water_produced               | 527          |\n--------------------------------------------------\n-------------------------------------------------\n| rollout/                        |             |\n|    ep_len_mean                  | 200         |\n|    ep_rew_mean                  | 499         |\n| time/                           |             |\n|    fps                          | 845         |\n|    iterations                   | 2499        |\n|    time_elapsed                 | 11829       |\n|    total_timesteps              | 9996000     |\n| train/                          |             |\n|    approx_kl                    | 0.005147227 |\n|    clip_fraction                | 0.0391      |\n|    clip_range                   | 0.2         |\n|    entropy_loss                 | -0.684      |\n|    explained_variance           | 0.446       |\n|    learning_rate                | 0.0003      |\n|    loss                         | 138         |\n|    n_updates                    | 4996        |\n|    policy_gradient_loss         | 0.00436     |\n|    value_loss                   | 266         |\n| train_metrics/                  |             |\n|    action_queue_updates_success | 183         |\n|    action_queue_updates_total   | 185         |\n|    ice_dug                      | 1.74e+03    |\n|    water_produced               | 405         |\n-------------------------------------------------\n--------------------------------------------------\n| rollout/                        |              |\n|    ep_len_mean                  | 200          |\n|    ep_rew_mean                  | 492          |\n| time/                           |              |\n|    fps                          | 845          |\n|    iterations                   | 2500         |\n|    time_elapsed                 | 11833        |\n|    total_timesteps              | 10000000     |\n| train/                          |              |\n|    approx_kl                    | 0.0015240045 |\n|    clip_fraction                | 0.00525      |\n|    clip_range                   | 0.2          |\n|    entropy_loss                 | -0.746       |\n|    explained_variance           | 0.781        |\n|    learning_rate                | 0.0003       |\n|    loss                         | 184          |\n|    n_updates                    | 4998         |\n|    policy_gradient_loss         | 0.000118     |\n|    value_loss                   | 407          |\n| train_metrics/                  |              |\n|    action_queue_updates_success | 179          |\n|    action_queue_updates_total   | 182          |\n|    ice_dug                      | 2.04e+03     |\n|    water_produced               | 492          |\n--------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Packaging and Submission\n\nWe now have a trained policy. In order to make it submittable to the competition we recommend you write code on separate files and only use kaggle notebooks for training as it can get very messy to program an RL agent just using a Kaggle notebook interface. The starter kit that was downloaded earlier has all of the code above written already and organized into separate files and folders. The observation wrapper and controller written here are saved to the `wrappers` folder. The SB3Wrapper is not in the kit, but is a part of the official luxai_s2 package and you can import it with\n\n```\nfrom luxai_s2.wrappers import SB3Wrapper\n```\n\nThe main files to take note of are `nn.py` and `agent.py`. Since kaggle servers don't have Stable Baselines 3 installed, `nn.py` is where we program some utility functions as well as the neural network model to load the SB3 trained weights into a PyTorch neural network model. `agent.py` will then use those utilities to load the model zip file at `MODEL_WEIGHTS_RELATIVE_PATH` which can be changed at the top of `agent.py`\n\n`agent.py` also uses the actions_mask function to invalidate some actions so that the policy only generates valid actions, which is a easy way to improve performance.","metadata":{}},{"cell_type":"code","source":"# if running on kaggle, run below to copy the rl starter kit files to the working directory\n!cp -r ../input/luxai-s2-rl-sb3-kit/* .\n!mv best_model.dontunzipme best_model.zip # kaggle auto unzips files but we don't want it to here so we do this","metadata":{"execution":{"iopub.status.busy":"2023-02-01T07:40:23.554448Z","iopub.execute_input":"2023-02-01T07:40:23.555045Z","iopub.status.idle":"2023-02-01T07:40:25.919537Z","shell.execute_reply.started":"2023-02-01T07:40:23.555001Z","shell.execute_reply":"2023-02-01T07:40:25.917314Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# if you trained an actual agent, copy its model weights here\n!mv logs/exp_1/models/best_model.zip best_model.zip","metadata":{"execution":{"iopub.status.busy":"2023-02-01T07:40:25.921667Z","iopub.execute_input":"2023-02-01T07:40:25.922141Z","iopub.status.idle":"2023-02-01T07:40:27.045959Z","shell.execute_reply.started":"2023-02-01T07:40:25.9221Z","shell.execute_reply":"2023-02-01T07:40:27.044353Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"\nTo submit your trained agent create a .tar.gz file. You can download the submission.tar.gz file from the right and submit it to the competition directly.","metadata":{}},{"cell_type":"code","source":"!tar -cvzf submission.tar.gz *","metadata":{"execution":{"iopub.status.busy":"2023-02-01T07:40:27.048011Z","iopub.execute_input":"2023-02-01T07:40:27.048719Z","iopub.status.idle":"2023-02-01T07:40:28.328749Z","shell.execute_reply.started":"2023-02-01T07:40:27.048677Z","shell.execute_reply":"2023-02-01T07:40:28.326997Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"README.md\n__notebook_source__.ipynb\nagent.py\nbest_model.zip\nlogs/\nlogs/exp_1/\nlogs/exp_1/PPO_1/\nlogs/exp_1/PPO_1/events.out.tfevents.1675225394.4c8e5063e14a.27.0\nlogs/exp_1/models/\nlogs/exp_1/models/latest_model.zip\nlogs/exp_1/eval_logs/\nlogs/exp_1/eval_logs/evaluations.npz\nlux/\nlux/team.py\nlux/factory.py\nlux/unit.py\nlux/utils.py\nlux/cargo.py\nlux/config.py\nlux/kit.py\nmain.py\nnn.py\ntrain.py\nwrappers/\nwrappers/__init__.py\nwrappers/controllers.py\nwrappers/obs_wrappers.py\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Tips for Improving your Agent\n\nThis tutorial agent will train a policy that can efficiently control a single heavy robot that learns to pickup power, constantly dig ice, and transfer ice back to the factory and survive the full 1000 turns in the game. A simple improvement would be to add lichen planting to the action space / controller or program it directly as a rule in the agent.py file, allowing you to score points by the end of the game as well as generate more power.\n\nAnother easy idea is to modify the `agent.py` code so that you spawn multiple factories and multiple heavy robots, and simply run the trained policy on each heavy robot.\n\n\nIf you want to look into more scalable solutions, it's critical to first figure out how to model multiple units at once. This kit shows you how to control a single heavy robot effectively but not multiple. Another thing to consider is what observations and features would be the most useful. Finally, you can always try and develop a more complex action controller in addition to developing better reward functions.\n\nIf you feel you are experienced enough, you can take a look at [last season's winning solution by team Toad Brigade](https://www.kaggle.com/competitions/lux-ai-2021/discussion/294993) or [our paper: Emergent collective intelligence from massive-agent cooperation and competition](https://arxiv.org/abs/2301.01609) which show how to use convolutional neural nets and various other techniques (e.g. invalid action masking) to control a massive number of units at once.","metadata":{}}]}